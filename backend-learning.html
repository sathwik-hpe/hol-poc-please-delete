<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Backend Engineering Hub - Go, Kubernetes, AWS & System Design</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            line-height: 1.6;
            color: #333;
            background: #f5f7fa;
        }

        .container {
            display: flex;
            min-height: 100vh;
        }

        /* Sidebar Navigation */
        .sidebar {
            width: 320px;
            background: linear-gradient(135deg, #0f2027 0%, #203a43 50%, #2c5364 100%);
            color: white;
            padding: 30px 20px;
            position: fixed;
            height: 100vh;
            overflow-y: auto;
            box-shadow: 2px 0 10px rgba(0,0,0,0.2);
        }

        .sidebar h1 {
            font-size: 24px;
            margin-bottom: 10px;
            font-weight: 700;
        }

        .sidebar p {
            font-size: 14px;
            opacity: 0.9;
            margin-bottom: 30px;
        }

        .nav-group {
            margin-bottom: 25px;
        }

        .nav-group-title {
            font-size: 12px;
            text-transform: uppercase;
            letter-spacing: 1px;
            opacity: 0.7;
            margin-bottom: 10px;
            font-weight: 600;
        }

        .nav-item {
            display: block;
            padding: 10px 15px;
            margin: 5px 0;
            color: white;
            text-decoration: none;
            border-radius: 6px;
            transition: all 0.3s ease;
            font-size: 13px;
            background: rgba(255,255,255,0.05);
        }

        .nav-item:hover {
            background: rgba(255,255,255,0.15);
            transform: translateX(5px);
        }

        .nav-item.active {
            background: rgba(255,255,255,0.25);
            font-weight: 600;
        }

        /* Main Content */
        .main-content {
            margin-left: 320px;
            flex: 1;
            padding: 40px 60px;
            max-width: 1200px;
        }

        .module-content {
            display: none;
            background: white;
            padding: 50px;
            border-radius: 15px;
            box-shadow: 0 2px 20px rgba(0,0,0,0.08);
            animation: fadeIn 0.5s ease;
        }

        .module-content.active {
            display: block;
        }

        @keyframes fadeIn {
            from {
                opacity: 0;
                transform: translateY(20px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        /* Typography */
        h1 {
            font-size: 42px;
            color: #1a202c;
            margin-bottom: 20px;
            font-weight: 800;
            line-height: 1.2;
        }

        h2 {
            font-size: 32px;
            color: #2d3748;
            margin: 40px 0 20px 0;
            font-weight: 700;
            border-bottom: 3px solid #2c5364;
            padding-bottom: 10px;
        }

        h3 {
            font-size: 24px;
            color: #2c5364;
            margin: 30px 0 15px 0;
            font-weight: 600;
        }

        p {
            margin: 15px 0;
            color: #4a5568;
            font-size: 16px;
            line-height: 1.8;
        }

        /* Lists */
        ul {
            margin: 20px 0;
            padding-left: 0;
            list-style: none;
        }

        li {
            margin: 12px 0;
            padding-left: 30px;
            position: relative;
            color: #4a5568;
            line-height: 1.8;
        }

        li:before {
            content: "‚ñ∏";
            position: absolute;
            left: 0;
            color: #2c5364;
            font-size: 14px;
            font-weight: bold;
        }

        /* Code Blocks */
        pre {
            background: #1a202c;
            color: #e2e8f0;
            padding: 25px;
            border-radius: 10px;
            overflow-x: auto;
            margin: 25px 0;
            border-left: 4px solid #2c5364;
        }

        code {
            font-family: 'Monaco', 'Menlo', 'Consolas', monospace;
            font-size: 14px;
            line-height: 1.6;
        }

        p code, li code {
            background: #f7fafc;
            color: #2c5364;
            padding: 3px 8px;
            border-radius: 4px;
            font-size: 14px;
            font-weight: 600;
        }

        strong {
            color: #1a202c;
            font-weight: 600;
        }

        /* Tables */
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 25px 0;
        }

        th, td {
            padding: 12px;
            text-align: left;
            border-bottom: 1px solid #e2e8f0;
        }

        th {
            background: #f7fafc;
            font-weight: 600;
            color: #2d3748;
        }

        /* Responsive */
        @media (max-width: 768px) {
            .sidebar {
                width: 100%;
                position: relative;
                height: auto;
            }

            .main-content {
                margin-left: 0;
                padding: 20px;
            }

            .container {
                flex-direction: column;
            }

            .module-content {
                padding: 30px 20px;
            }
        }

        /* Progress Indicator */
        .progress-bar {
            position: fixed;
            top: 0;
            left: 320px;
            right: 0;
            height: 4px;
            background: linear-gradient(90deg, #2c5364 0%, #203a43 100%);
            transform-origin: left;
            z-index: 1000;
        }

        /* Scroll to Top */
        .scroll-top {
            position: fixed;
            bottom: 30px;
            right: 30px;
            width: 50px;
            height: 50px;
            background: #2c5364;
            color: white;
            border: none;
            border-radius: 50%;
            font-size: 24px;
            cursor: pointer;
            box-shadow: 0 4px 12px rgba(44, 83, 100, 0.4);
            transition: all 0.3s ease;
            opacity: 0;
            pointer-events: none;
        }

        .scroll-top.visible {
            opacity: 1;
            pointer-events: all;
        }

        .scroll-top:hover {
            transform: scale(1.1);
            background: #203a43;
        }

        /* Search Box */
        .search-box {
            margin-bottom: 20px;
            position: relative;
        }

        .search-box input {
            width: 100%;
            padding: 12px 15px;
            border: 1px solid rgba(255,255,255,0.2);
            background: rgba(255,255,255,0.1);
            color: white;
            border-radius: 8px;
            font-size: 14px;
        }

        .search-box input::placeholder {
            color: rgba(255,255,255,0.6);
        }

        .search-box input:focus {
            outline: none;
            background: rgba(255,255,255,0.15);
            border-color: rgba(255,255,255,0.3);
        }
    </style>
</head>
<body>
    <div class="progress-bar" id="progressBar"></div>
    
    <div class="container">
        <aside class="sidebar">
            <h1>üíª Backend Engineering Hub</h1>
            <p>Master Go, Kubernetes, AWS & System Design</p>
            
            <div class="search-box">
                <input type="text" id="searchInput" placeholder="Search modules..." onkeyup="searchModules()">
            </div>
            
            <nav id="navigation">
                
        <div class="nav-group">
            <div class="nav-group-title">Getting Started</div>
            <a href="#module-0" class="nav-item" onclick="showModule('module-0')">00 LEARNING PATH</a>
        </div>
    

        <div class="nav-group">
            <div class="nav-group-title">Part 1: Go Programming</div>
            <a href="#module-1" class="nav-item" onclick="showModule('module-1')">01 Go Fundamentals</a>
<a href="#module-2" class="nav-item" onclick="showModule('module-2')">02 Go Concurrency</a>
<a href="#module-3" class="nav-item" onclick="showModule('module-3')">03 Go REST APIs</a>
<a href="#module-4" class="nav-item" onclick="showModule('module-4')">04 Go Database Integration</a>
<a href="#module-5" class="nav-item" onclick="showModule('module-5')">05 Go Testing Best Practices</a>
        </div>
    

        <div class="nav-group">
            <div class="nav-group-title">Part 2: Kubernetes</div>
            <a href="#module-6" class="nav-item" onclick="showModule('module-6')">06 Kubernetes Architecture</a>
<a href="#module-7" class="nav-item" onclick="showModule('module-7')">07 Kubernetes Workloads CRDs</a>
<a href="#module-8" class="nav-item" onclick="showModule('module-8')">08 Kubernetes Networking</a>
<a href="#module-9" class="nav-item" onclick="showModule('module-9')">09 Kubernetes Storage</a>
<a href="#module-10" class="nav-item" onclick="showModule('module-10')">10 Kubernetes Configuration</a>
<a href="#module-11" class="nav-item" onclick="showModule('module-11')">11 Kubernetes Tools</a>
        </div>
    

        <div class="nav-group">
            <div class="nav-group-title">Part 3: Infrastructure & Databases</div>
            <a href="#module-12" class="nav-item" onclick="showModule('module-12')">12 Infrastructure Server Setup</a>
<a href="#module-13" class="nav-item" onclick="showModule('module-13')">13 Terraform IaC</a>
<a href="#module-14" class="nav-item" onclick="showModule('module-14')">14 Ansible Configuration Management</a>
<a href="#module-15" class="nav-item" onclick="showModule('module-15')">15 Database Deep Dive</a>
        </div>
    

        <div class="nav-group">
            <div class="nav-group-title">Part 4: Microservices</div>
            <a href="#module-16" class="nav-item" onclick="showModule('module-16')">16 System Design Patterns</a>
<a href="#module-17" class="nav-item" onclick="showModule('module-17')">17 Microservices Architecture</a>
<a href="#module-18" class="nav-item" onclick="showModule('module-18')">18 Authentication Authorization</a>
<a href="#module-19" class="nav-item" onclick="showModule('module-19')">19 Kafka Event Driven</a>
<a href="#module-20" class="nav-item" onclick="showModule('module-20')">20 Frontend Backend Integration</a>
        </div>
    

        <div class="nav-group">
            <div class="nav-group-title">Part 5: AWS</div>
            <a href="#module-21" class="nav-item" onclick="showModule('module-21')">21 AWS IAM VPC</a>
<a href="#module-22" class="nav-item" onclick="showModule('module-22')">22 AWS Compute</a>
<a href="#module-23" class="nav-item" onclick="showModule('module-23')">23 AWS Storage</a>
<a href="#module-24" class="nav-item" onclick="showModule('module-24')">24 AWS Databases</a>
<a href="#module-25" class="nav-item" onclick="showModule('module-25')">25 AWS DevOps CICD</a>
        </div>
    

        <div class="nav-group">
            <div class="nav-group-title">Part 6: Observability</div>
            <a href="#module-26" class="nav-item" onclick="showModule('module-26')">26 Prometheus Monitoring</a>
<a href="#module-27" class="nav-item" onclick="showModule('module-27')">27 Grafana Dashboards</a>
<a href="#module-28" class="nav-item" onclick="showModule('module-28')">28 EFK Stack</a>
        </div>
    

        <div class="nav-group">
            <div class="nav-group-title">Part 7: Production & Interview</div>
            <a href="#module-29" class="nav-item" onclick="showModule('module-29')">29 Distributed Tracing</a>
<a href="#module-30" class="nav-item" onclick="showModule('module-30')">30 Production Best Practices</a>
<a href="#module-31" class="nav-item" onclick="showModule('module-31')">31 System Design Interview</a>
<a href="#module-32" class="nav-item" onclick="showModule('module-32')">32 Backend Interview Prep</a>
        </div>
    
            </nav>
        </aside>

        <main class="main-content">
            
    <div class="module-content" id="module-0">
        <h1>üöÄ Full Stack Backend Development - Complete Learning Path</h1>
<h2>Master Production-Grade Backend Engineering</h2>
<strong>Goal:</strong> Transform from beginner to production-ready backend engineer  
<strong>Timeline:</strong> 80-100 hours of focused study  
<strong>Outcome:</strong> Build, deploy, and scale real-world backend systems
<p>---</p>
<h2>üìã Overview</h2>
<p>This comprehensive learning path covers everything you need to become a professional backend engineer, from Go programming fundamentals to production AWS deployments. You'll master:</p>
<ul><li><strong>Go Programming</strong> - Build high-performance backend services</li>
<li><strong>Kubernetes</strong> - Orchestrate containerized applications at scale</li>
<li><strong>Infrastructure as Code</strong> - Automate infrastructure with Terraform & Ansible</li>
<li><strong>Microservices</strong> - Design distributed systems that scale</li>
<li><strong>AWS Cloud</strong> - Deploy and manage production workloads</li>
<li><strong>Observability</strong> - Monitor, log, and trace distributed systems</li>
<li><strong>Production Best Practices</strong> - Security, reliability, and performance</li>
<p>---</p>
<h2>üéØ Learning Phases</h2>
<h3><strong>Phase 1: Go Programming Fundamentals</strong> (15-20 hours)</h3>
Build a strong foundation in Go, the language of cloud-native infrastructure.
<strong>Modules:</strong>
1. <strong>Go Fundamentals</strong> - Syntax, types, control flow, functions
2. <strong>Go Concurrency</strong> - Goroutines, channels, and concurrent patterns
3. <strong>REST APIs with Go</strong> - Build production-ready HTTP services
4. <strong>Database Integration</strong> - Connect to PostgreSQL, MongoDB, Redis
5. <strong>Testing & Best Practices</strong> - Write maintainable, testable code
<strong>Checkpoint:</strong> Build a CRUD REST API with PostgreSQL, authentication, and tests.
<p>---</p>
<h3><strong>Phase 2: Kubernetes Deep Dive</strong> (20-25 hours)</h3>
Master container orchestration and understand how production systems run.
<strong>Modules:</strong>
6. <strong>Kubernetes Architecture</strong> - Control plane, nodes, etcd, scheduler
7. <strong>Core Workloads & CRDs</strong> - Pods, Deployments, StatefulSets, Jobs, DaemonSets
8. <strong>Networking</strong> - Services, Ingress, NetworkPolicies, DNS
9. <strong>Storage</strong> - Persistent Volumes, Storage Classes, CSI drivers
10. <strong>Configuration Management</strong> - ConfigMaps, Secrets, environment variables
11. <strong>Kubernetes Tools</strong> - kubectl, Helm, kustomize, k9s
<strong>Checkpoint:</strong> Deploy a multi-tier application on Kubernetes with persistent storage, secrets, and ingress.
<p>---</p>
<h3><strong>Phase 3: Infrastructure & System Design</strong> (15-20 hours)</h3>
Learn to provision and manage infrastructure from bare metal to cloud.
<strong>Modules:</strong>
12. <strong>Server Setup & Networking</strong> - Bare metal, VMs, DNS, networking, static IPs
13. <strong>Terraform (IaC)</strong> - Provision infrastructure as code across clouds
14. <strong>Ansible</strong> - Automate configuration management at scale
15. <strong>Database Deep Dive</strong> - PostgreSQL, Elasticsearch, MinIO production patterns
16. <strong>System Design Patterns</strong> - Scalability, reliability, CAP theorem
<strong>Checkpoint:</strong> Use Terraform to provision VMs, Ansible to configure them, and deploy a database cluster.
<p>---</p>
<h3><strong>Phase 4: Microservices Architecture</strong> (12-15 hours)</h3>
Design and build distributed systems that scale horizontally.
<strong>Modules:</strong>
17. <strong>Microservices Architecture</strong> - Patterns, service mesh, API gateways
18. <strong>Authentication & Authorization</strong> - JWT, OAuth2, sessions, RBAC
19. <strong>Kafka & Message Queues</strong> - Event-driven architecture, pub/sub patterns
20. <strong>Frontend Integration</strong> - REST, GraphQL, WebSockets, state management
<strong>Checkpoint:</strong> Build a microservices system with auth, event streaming, and frontend integration.
<p>---</p>
<h3><strong>Phase 5: AWS Cloud Platform</strong> (15-20 hours)</h3>
Deploy and manage production workloads on AWS.
<strong>Modules:</strong>
21. <strong>AWS Core Services</strong> - IAM, VPC, security groups, networking
22. <strong>Compute Services</strong> - EC2, Lambda, ECS, EKS, Fargate
23. <strong>Storage Services</strong> - S3, EBS, EFS, CloudFront, lifecycle policies
24. <strong>Database Services</strong> - RDS, DynamoDB, Aurora, ElastiCache
25. <strong>DevOps & CI/CD</strong> - CodePipeline, CloudWatch, X-Ray, deployment strategies
<strong>Checkpoint:</strong> Deploy a full application stack on AWS with CI/CD pipeline, monitoring, and auto-scaling.
<p>---</p>
<h3><strong>Phase 6: Observability & Monitoring</strong> (8-12 hours)</h3>
Implement production-grade monitoring, logging, and tracing.
<strong>Modules:</strong>
26. <strong>Prometheus & Grafana</strong> - Metrics collection, PromQL, alerting, dashboards
27. <strong>EFK Logging Stack</strong> - Elasticsearch, Fluentd/Fluent Bit, Kibana
28. <strong>Distributed Tracing</strong> - Jaeger, Zipkin, OpenTelemetry
<strong>Checkpoint:</strong> Set up complete observability stack for a microservices application.
<p>---</p>
<h3><strong>Phase 7: Production & Interview Prep</strong> (5-8 hours)</h3>
Master production operations and ace technical interviews.
<strong>Modules:</strong>
29. <strong>Production Best Practices</strong> - Security, disaster recovery, performance tuning
30. <strong>System Design Interviews</strong> - Common questions, problem-solving patterns
<strong>Checkpoint:</strong> Design and present a complete system architecture for a real-world problem.
<p>---</p>
<h2>üõ†Ô∏è What You'll Build</h2>
<p>By completing this path, you'll build:</p>
<p>1. <strong>RESTful API Service</strong> - Go + PostgreSQL + Redis + JWT auth
2. <strong>Kubernetes Cluster</strong> - Multi-tier app with ingress, secrets, persistent storage
3. <strong>Infrastructure as Code</strong> - Terraform + Ansible automation
4. <strong>Microservices System</strong> - 3+ services with Kafka event streaming
5. <strong>AWS Production Stack</strong> - Full deployment with CI/CD and monitoring
6. <strong>Observability Platform</strong> - Prometheus, Grafana, EFK stack
7. <strong>System Design Portfolio</strong> - 5+ architecture diagrams and designs</p>
<p>---</p>
<h2>üìä Prerequisites</h2>
<strong>Required:</strong>
<li>Basic programming knowledge (any language)</li>
<li>Command line comfort (bash/zsh)</li>
<li>Understanding of HTTP and REST APIs</li>
<li>Git fundamentals</li>
<strong>Helpful (but not required):</strong>
<li>Docker basics</li>
<li>Linux/Unix systems</li>
<li>Networking fundamentals</li>
<li>Database basics</li>
<p>---</p>
<h2>üìà Progress Tracking</h2>
<h3>Self-Assessment Checkpoints</h3>
<p>After each module, ask yourself:
<li>‚úÖ Can I explain this concept to someone else?</li>
<li>‚úÖ Have I written working code examples?</li>
<li>‚úÖ Do I understand the production use cases?</li>
<li>‚úÖ Can I troubleshoot common issues?</li></p>
<h3>Hands-On Validation</h3>
<li><strong>Phase 1-2:</strong> Build services locally</li>
<li><strong>Phase 3-4:</strong> Deploy to development clusters</li>
<li><strong>Phase 5-7:</strong> Deploy to production-like environments</li>
<p>---</p>
<h2>üéì Learning Tips</h2>
<h3>1. <strong>Code Along</strong></h3>
Don't just read - type every example and experiment with modifications.
<h3>2. <strong>Build Real Projects</strong></h3>
Each phase includes a checkpoint project. Complete them before moving on.
<h3>3. <strong>Read Official Documentation</strong></h3>
Use these modules as guides, but dive into official docs for depth.
<h3>4. <strong>Join Communities</strong></h3>
<li>Go community on Slack/Discord</li>
<li>Kubernetes Slack (#kubernetes-users)</li>
<li>AWS community forums</li>
<li>DevOps subreddits</li>
<h3>5. <strong>Practice Interview Questions</strong></h3>
Each module includes interview questions. Practice explaining concepts out loud.
<p>---</p>
<h2>üèÜ Career Outcomes</h2>
<p>After completing this path, you'll be qualified for:</p>
<li><strong>Backend Engineer</strong> - Build APIs and microservices</li>
<li><strong>DevOps Engineer</strong> - Automate infrastructure and deployments</li>
<li><strong>Site Reliability Engineer</strong> - Ensure system reliability and performance</li>
<li><strong>Cloud Engineer</strong> - Design and manage cloud infrastructure</li>
<li><strong>Platform Engineer</strong> - Build internal developer platforms</li>
<strong>Typical Salary Range:</strong> $100k - $180k+ (depending on location and experience)
<p>---</p>
<h2>üìö Module Structure</h2>
<p>Each module follows this pattern:</p>
<p>1. <strong>Concept Overview</strong> - What and why
2. <strong>Core Principles</strong> - Deep technical understanding
3. <strong>Code Examples</strong> - Working, production-ready code
4. <strong>Common Mistakes</strong> - What to avoid
5. <strong>Best Practices</strong> - Industry standards
6. <strong>Interview Questions</strong> - What employers ask
7. <strong>Hands-On Exercise</strong> - Apply what you learned
8. <strong>Resources</strong> - Official docs and further reading</p>
<p>---</p>
<h2>üö¶ Getting Started</h2>
<h3>Quick Start Path (Essential Only)</h3>
<p>If you have limited time, focus on these core modules:</p>
<p>1. <strong>Go Fundamentals</strong> (Module 01)
2. <strong>REST APIs with Go</strong> (Module 03)
3. <strong>Kubernetes Core Workloads</strong> (Module 07)
4. <strong>Kubernetes Networking</strong> (Module 08)
5. <strong>Terraform IaC</strong> (Module 13)
6. <strong>AWS Core Services</strong> (Module 21)
7. <strong>Prometheus & Grafana</strong> (Module 26)</p>
<strong>Time:</strong> 25-30 hours for essentials
<h3>Deep Dive Path (Complete Mastery)</h3>
<p>Complete all 30 modules in order for comprehensive understanding.</p>
<strong>Time:</strong> 80-100 hours for full mastery
<p>---</p>
<h2>üîÑ Updates and Maintenance</h2>
<p>This learning path is designed to stay current with:
<li>Go 1.21+</li>
<li>Kubernetes 1.28+</li>
<li>Terraform 1.6+</li>
<li>Ansible 2.15+</li>
<li>AWS latest services</li></p>
<strong>Note:</strong> Cloud technologies evolve rapidly. Always check official documentation for the latest features and best practices.
<p>---</p>
<h2>üí° Success Strategies</h2>
<h3>Week 1-2: Go Fundamentals</h3>
<li>Dedicate 10-15 hours per week</li>
<li>Build small CLI tools daily</li>
<li>Complete checkpoint project</li>
<h3>Week 3-4: Kubernetes</h3>
<li>Set up local cluster (minikube/kind)</li>
<li>Deploy examples from modules</li>
<li>Break things and fix them</li>
<h3>Week 5-6: Infrastructure & System Design</h3>
<li>Use free tier cloud accounts</li>
<li>Practice Terraform/Ansible locally</li>
<li>Design systems on paper</li>
<h3>Week 7-8: Microservices & AWS</h3>
<li>Build end-to-end project</li>
<li>Deploy to AWS free tier</li>
<li>Set up monitoring</li>
<h3>Week 9-10: Observability & Production</h3>
<li>Add monitoring to previous projects</li>
<li>Review security practices</li>
<li>Practice system design interviews</li>
<p>---</p>
<h2>üéØ Final Project</h2>
<p>Build a complete production system:</p>
<strong>"Cloud-Native Task Management Platform"</strong>
<li><strong>Backend:</strong> Go microservices (user service, task service, notification service)</li>
<li><strong>Storage:</strong> PostgreSQL + Redis + S3</li>
<li><strong>Infrastructure:</strong> Terraform + Ansible</li>
<li><strong>Orchestration:</strong> Kubernetes on AWS EKS</li>
<li><strong>Messaging:</strong> Kafka for events</li>
<li><strong>Observability:</strong> Prometheus + Grafana + EFK</li>
<li><strong>CI/CD:</strong> GitHub Actions ‚Üí AWS CodePipeline</li>
<li><strong>Frontend:</strong> React/Vue connecting via REST API</li>
<strong>Deliverables:</strong>
<li>Source code on GitHub</li>
<li>Infrastructure as code</li>
<li>Architecture diagrams</li>
<li>README with setup instructions</li>
<li>Monitoring dashboards</li>
<li>System design document</li>
<p>---</p>
<h2>üìû Need Help?</h2>
<li><strong>Stuck on concepts?</strong> Re-read the module and try examples</li>
<li><strong>Code not working?</strong> Check error messages and logs</li>
<li><strong>Need clarification?</strong> Review official documentation</li>
<li><strong>Want feedback?</strong> Share your projects in dev communities</li>
<p>---</p>
<h2>üöÄ Ready to Start?</h2>
<p>Begin with <strong>Module 01: Go Fundamentals</strong> and build your way up!</p>
<p>Remember: <strong>Every expert was once a beginner.</strong> Take it one module at a time, practice consistently, and you'll be building production systems before you know it.</p>
<strong>Let's build something amazing! üíªüî•</strong>
<p>---</p>
<h2>üìñ Quick Reference</h2>
<li><strong>Total Modules:</strong> 30</li>
<li><strong>Estimated Time:</strong> 80-100 hours</li>
<li><strong>Difficulty Curve:</strong> Beginner ‚Üí Intermediate ‚Üí Advanced</li>
<li><strong>Prerequisites:</strong> Basic programming knowledge</li>
<li><strong>Outcome:</strong> Production-ready backend engineer</li></ul>
<p>---</p>
<p>*Last Updated: December 2024*  
*Version: 1.0.0*</p>
    </div>
    

    <div class="module-content" id="module-1">
        <h1>Module 01: Go Fundamentals üîµ</h1>
<h2>Master the Basics of Go Programming</h2>
<strong>Duration:</strong> 3-4 hours  
<strong>Prerequisites:</strong> Basic programming knowledge in any language  
<strong>Outcome:</strong> Write idiomatic Go code with confidence
<p>---</p>
<h2>üìö Table of Contents</h2>
<p>1. [Why Go?](#why-go)
2. [Setup & Hello World](#setup--hello-world)
3. [Basic Syntax & Types](#basic-syntax--types)
4. [Variables & Constants](#variables--constants)
5. [Control Flow](#control-flow)
6. [Functions](#functions)
7. [Structs & Methods](#structs--methods)
8. [Interfaces](#interfaces)
9. [Packages & Modules](#packages--modules)
10. [Error Handling](#error-handling)
11. [Common Mistakes](#common-mistakes)
12. [Best Practices](#best-practices)
13. [Interview Questions](#interview-questions)
14. [Hands-On Exercise](#hands-on-exercise)</p>
<p>---</p>
<h2>Why Go?</h2>
<h3>The Language of Cloud Infrastructure</h3>
<p>Go (Golang) powers the world's most critical infrastructure:
<ul><li><strong>Docker</strong> - Container runtime</li>
<li><strong>Kubernetes</strong> - Container orchestration</li>
<li><strong>Terraform</strong> - Infrastructure as code</li>
<li><strong>Prometheus</strong> - Monitoring system</li>
<li><strong>Consul</strong> - Service mesh</li>
<li><strong>etcd</strong> - Distributed key-value store</li></p>
<h3>Key Advantages</h3>
<p>1. <strong>Fast Compilation</strong> - Compile large codebases in seconds
2. <strong>Static Typing</strong> - Catch errors at compile time
3. <strong>Built-in Concurrency</strong> - Goroutines make parallel programming easy
4. <strong>Simple Syntax</strong> - Just 25 keywords, easy to learn
5. <strong>Strong Standard Library</strong> - Everything from HTTP servers to cryptography
6. <strong>Cross-Platform</strong> - Compile for any OS/architecture
7. <strong>Backward Compatible</strong> - Go 1.x guarantees compatibility</p>
<h3>When to Use Go</h3>
<p>‚úÖ <strong>Perfect For:</strong>
<li>Microservices and APIs</li>
<li>CLI tools</li>
<li>DevOps automation</li>
<li>Network servers</li>
<li>Distributed systems</li>
<li>Cloud-native applications</li></p>
<p>‚ùå <strong>Not Ideal For:</strong>
<li>GUI applications</li>
<li>Mobile apps (though possible)</li>
<li>Machine learning (use Python)</li>
<li>Game development</li></p>
<p>---</p>
<h2>Setup & Hello World</h2>
<h3>Installation</h3>
<pre><code class="language-bash"># macOS
brew install go
<h1>Linux</h1>
wget https://go.dev/dl/go1.21.5.linux-amd64.tar.gz
sudo tar -C /usr/local -xzf go1.21.5.linux-amd64.tar.gz
export PATH=$PATH:/usr/local/go/bin
<h1>Verify installation</h1>
go version  # Should show: go version go1.21.5</code></pre>
<h3>Your First Go Program</h3>
<pre><code class="language-go">// main.go
package main
<p>import &quot;fmt&quot;</p>
<p>func main() {
    fmt.Println(&quot;Hello, Go!&quot;)
}</code></pre></p>
<pre><code class="language-bash"># Run directly
go run main.go
<h1>Build executable</h1>
go build main.go
./main
<h1>Build and install to $GOPATH/bin</h1>
go install</code></pre>
<h3>Understanding the Basics</h3>
<pre><code class="language-go">package main              // Every Go file belongs to a package
                          // &#039;main&#039; package = executable program
<p>import &quot;fmt&quot;              // Import standard library packages</p>
<p>func main() {             // main() is the entry point
    fmt.Println(&quot;Hello&quot;)  // Exported functions start with capital letter
}</code></pre></p>
<p>---</p>
<h2>Basic Syntax & Types</h2>
<h3>Primitive Types</h3>
<pre><code class="language-go">package main
<p>import &quot;fmt&quot;</p>
<p>func main() {
    // Boolean
    var isActive bool = true
    
    // Integers
    var age int = 30                    // Platform dependent (32 or 64 bit)
    var count int64 = 1000000000000     // Explicitly 64-bit
    var smallNum int8 = 127             // -128 to 127
    var unsignedAge uint = 30           // 0 to 2^32-1 or 2^64-1
    
    // Floating point
    var price float64 = 99.99           // Preferred for decimals
    var discount float32 = 0.15         // Less precision
    
    // String
    var name string = &quot;Alice&quot;
    var message = <code>Multi-line
    string using backticks</code>             // Raw string literal
    
    // Byte and Rune
    var b byte = &#039;A&#039;                    // byte = uint8, ASCII character
    var r rune = &#039;üòÄ&#039;                   // rune = int32, Unicode code point
    
    fmt.Printf(&quot;Boolean: %v\n&quot;, isActive)
    fmt.Printf(&quot;Integer: %d, Float: %.2f\n&quot;, age, price)
    fmt.Printf(&quot;String: %s\n&quot;, name)
    fmt.Printf(&quot;Rune: %c (code: %d)\n&quot;, r, r)
}</code></pre></p>
<h3>Type Inference</h3>
<pre><code class="language-go">// Go can infer types using :=
name := &quot;Bob&quot;           // Inferred as string
age := 25               // Inferred as int
price := 19.99          // Inferred as float64
isValid := true         // Inferred as bool
<p>// This is the most common way to declare variables</code></pre></p>
<h3>Zero Values</h3>
<p>Go initializes variables to their zero value if not explicitly set:</p>
<pre><code class="language-go">var i int        // 0
var f float64    // 0.0
var b bool       // false
var s string     // &quot;&quot; (empty string)
var p *int       // nil (pointer)</code></pre>
<p>---</p>
<h2>Variables & Constants</h2>
<h3>Variable Declaration Styles</h3>
<pre><code class="language-go">// Style 1: var keyword with type
var name string = &quot;Alice&quot;
<p>// Style 2: var keyword with type inference
var age = 30</p>
<p>// Style 3: Short declaration (most common, only inside functions)
city := &quot;New York&quot;</p>
<p>// Multiple declarations
var (
    username = &quot;admin&quot;
    password = &quot;secret&quot;
    port     = 8080
)</p>
<p>// Multiple assignment
x, y := 10, 20</code></pre></p>
<h3>Constants</h3>
<pre><code class="language-go">// Single constant
const Pi = 3.14159
<p>// Multiple constants
const (
    StatusOK       = 200
    StatusNotFound = 404
    StatusError    = 500
)</p>
<p>// Typed constants
const MaxConnections int = 100</p>
<p>// Untyped constants (more flexible)
const Port = 8080  // Can be used as int, int64, float64, etc.</p>
<p>// iota: auto-incrementing constant generator
const (
    Sunday = iota    // 0
    Monday           // 1
    Tuesday          // 2
    Wednesday        // 3
    Thursday         // 4
    Friday           // 5
    Saturday         // 6
)</p>
<p>// iota with expressions
const (
    _  = iota             // Skip 0
    KB = 1 &lt;&lt; (10 * iota) // 1 &lt;&lt; 10 = 1024
    MB                    // 1 &lt;&lt; 20 = 1048576
    GB                    // 1 &lt;&lt; 30 = 1073741824
    TB                    // 1 &lt;&lt; 40 = 1099511627776
)</code></pre></p>
<p>---</p>
<h2>Control Flow</h2>
<h3>If-Else</h3>
<pre><code class="language-go">// Basic if
if age &gt;= 18 {
    fmt.Println(&quot;Adult&quot;)
}
<p>// If-else
if score &gt;= 90 {
    fmt.Println(&quot;A&quot;)
} else if score &gt;= 80 {
    fmt.Println(&quot;B&quot;)
} else {
    fmt.Println(&quot;C&quot;)
}</p>
<p>// If with initialization statement (very common pattern)
if err := doSomething(); err != nil {
    fmt.Println(&quot;Error:&quot;, err)
    return
}
// &#039;err&#039; is only in scope within this if block</code></pre></p>
<h3>For Loops</h3>
<p>Go only has <code>for</code> loops, but they're versatile:</p>
<pre><code class="language-go">// Traditional for loop
for i := 0; i &lt; 10; i++ {
    fmt.Println(i)
}
<p>// While-style loop
count := 0
for count &lt; 10 {
    fmt.Println(count)
    count++
}</p>
<p>// Infinite loop
for {
    fmt.Println(&quot;Forever...&quot;)
    break  // Use break to exit
}</p>
<p>// For-range over slices
nums := []int{1, 2, 3, 4, 5}
for index, value := range nums {
    fmt.Printf(&quot;Index: %d, Value: %d\n&quot;, index, value)
}</p>
<p>// Ignore index with underscore
for _, value := range nums {
    fmt.Println(value)
}</p>
<p>// For-range over maps
ages := map[string]int{&quot;Alice&quot;: 30, &quot;Bob&quot;: 25}
for name, age := range ages {
    fmt.Printf(&quot;%s is %d years old\n&quot;, name, age)
}</p>
<p>// For-range over strings (iterates over runes)
for i, char := range &quot;Hello üòÄ&quot; {
    fmt.Printf(&quot;Index %d: %c\n&quot;, i, char)
}</code></pre></p>
<h3>Switch</h3>
<pre><code class="language-go">// Basic switch
day := &quot;Monday&quot;
switch day {
case &quot;Monday&quot;:
    fmt.Println(&quot;Start of work week&quot;)
case &quot;Friday&quot;:
    fmt.Println(&quot;TGIF!&quot;)
case &quot;Saturday&quot;, &quot;Sunday&quot;:
    fmt.Println(&quot;Weekend!&quot;)
default:
    fmt.Println(&quot;Midweek day&quot;)
}
<p>// Switch with initialization
switch hour := time.Now().Hour(); {
case hour &lt; 12:
    fmt.Println(&quot;Good morning&quot;)
case hour &lt; 18:
    fmt.Println(&quot;Good afternoon&quot;)
default:
    fmt.Println(&quot;Good evening&quot;)
}</p>
<p>// Switch without condition (like if-else chain)
score := 85
switch {
case score &gt;= 90:
    fmt.Println(&quot;A&quot;)
case score &gt;= 80:
    fmt.Println(&quot;B&quot;)
default:
    fmt.Println(&quot;C&quot;)
}</p>
<p>// Type switch (check interface type)
var i interface{} = &quot;hello&quot;
switch v := i.(type) {
case int:
    fmt.Printf(&quot;Integer: %d\n&quot;, v)
case string:
    fmt.Printf(&quot;String: %s\n&quot;, v)
default:
    fmt.Printf(&quot;Unknown type: %T\n&quot;, v)
}</code></pre></p>
<h3>Defer</h3>
<p>Execute a statement when the surrounding function returns:</p>
<pre><code class="language-go">func readFile(filename string) {
    file, err := os.Open(filename)
    if err != nil {
        return
    }
    defer file.Close()  // Ensures file is closed when function returns
    
    // Read from file...
    // Even if there&#039;s an error or early return, file.Close() will be called
}
<p>// Multiple defers execute in LIFO order (Last In, First Out)
func example() {
    defer fmt.Println(&quot;First&quot;)
    defer fmt.Println(&quot;Second&quot;)
    defer fmt.Println(&quot;Third&quot;)
    fmt.Println(&quot;Function body&quot;)
}
// Output:
// Function body
// Third
// Second
// First</code></pre></p>
<p>---</p>
<h2>Functions</h2>
<h3>Basic Functions</h3>
<pre><code class="language-go">// Function with parameters and return type
func add(a int, b int) int {
    return a + b
}
<p>// Shorthand when parameters share type
func multiply(a, b int) int {
    return a * b
}</p>
<p>// Multiple return values (idiomatic Go pattern)
func divide(a, b float64) (float64, error) {
    if b == 0 {
        return 0, fmt.Errorf(&quot;division by zero&quot;)
    }
    return a / b, nil
}</p>
<p>// Usage
result, err := divide(10, 2)
if err != nil {
    fmt.Println(&quot;Error:&quot;, err)
    return
}
fmt.Println(&quot;Result:&quot;, result)</code></pre></p>
<h3>Named Return Values</h3>
<pre><code class="language-go">func calculate(a, b int) (sum int, product int) {
    sum = a + b
    product = a * b
    return  // Naked return (returns named values)
}
<p>// Equivalent to:
func calculateExplicit(a, b int) (int, int) {
    sum := a + b
    product := a * b
    return sum, product
}</code></pre></p>
<h3>Variadic Functions</h3>
<pre><code class="language-go">// Accept variable number of arguments
func sum(nums ...int) int {
    total := 0
    for _, num := range nums {
        total += num
    }
    return total
}
<p>// Usage
fmt.Println(sum(1, 2, 3))           // 6
fmt.Println(sum(1, 2, 3, 4, 5))     // 15</p>
<p>// Pass slice with ... operator
numbers := []int{1, 2, 3, 4}
fmt.Println(sum(numbers...))        // 10</code></pre></p>
<h3>Higher-Order Functions</h3>
<pre><code class="language-go">// Functions as values
func applyOperation(a, b int, operation func(int, int) int) int {
    return operation(a, b)
}
<p>// Usage
add := func(x, y int) int { return x + y }
multiply := func(x, y int) int { return x * y }</p>
<p>fmt.Println(applyOperation(5, 3, add))       // 8
fmt.Println(applyOperation(5, 3, multiply))  // 15</p>
<p>// Closures (functions that capture variables)
func counter() func() int {
    count := 0
    return func() int {
        count++
        return count
    }
}</p>
<p>c := counter()
fmt.Println(c())  // 1
fmt.Println(c())  // 2
fmt.Println(c())  // 3</code></pre></p>
<p>---</p>
<h2>Structs & Methods</h2>
<h3>Defining Structs</h3>
<pre><code class="language-go">// Basic struct
type Person struct {
    Name string
    Age  int
}
<p>// Creating instances
p1 := Person{Name: &quot;Alice&quot;, Age: 30}
p2 := Person{&quot;Bob&quot;, 25}  // Positional (not recommended)</p>
<p>// Accessing fields
fmt.Println(p1.Name)
p1.Age = 31</p>
<p>// Pointer to struct
p3 := &amp;Person{Name: &quot;Charlie&quot;, Age: 35}
fmt.Println(p3.Name)  // Go auto-dereferences, no need for p3-&gt;Name</p>
<p>// Anonymous structs (useful for one-off data structures)
user := struct {
    Username string
    IsAdmin  bool
}{
    Username: &quot;admin&quot;,
    IsAdmin:  true,
}</code></pre></p>
<h3>Struct Embedding (Composition)</h3>
<pre><code class="language-go">// Go doesn&#039;t have inheritance, but composition through embedding
type Address struct {
    Street string
    City   string
}
<p>type Employee struct {
    Person           // Embedded struct (anonymous field)
    Address          // Embedded struct
    EmployeeID int
}</p>
<p>// Usage
emp := Employee{
    Person:     Person{Name: &quot;Alice&quot;, Age: 30},
    Address:    Address{Street: &quot;123 Main St&quot;, City: &quot;NYC&quot;},
    EmployeeID: 12345,
}</p>
<p>// Can access embedded fields directly
fmt.Println(emp.Name)    // From Person
fmt.Println(emp.City)    // From Address
fmt.Println(emp.EmployeeID)</code></pre></p>
<h3>Methods</h3>
<p>Methods are functions with a receiver:</p>
<pre><code class="language-go">type Rectangle struct {
    Width  float64
    Height float64
}
<p>// Value receiver (works on a copy)
func (r Rectangle) Area() float64 {
    return r.Width * r.Height
}</p>
<p>// Pointer receiver (works on original, can modify)
func (r *Rectangle) Scale(factor float64) {
    r.Width *= factor
    r.Height *= factor
}</p>
<p>// Usage
rect := Rectangle{Width: 10, Height: 5}
fmt.Println(&quot;Area:&quot;, rect.Area())  // 50</p>
<p>rect.Scale(2)
fmt.Println(&quot;New dimensions:&quot;, rect.Width, rect.Height)  // 20, 10</code></pre></p>
<strong>When to use pointer receivers:</strong>
<li>Need to modify the receiver</li>
<li>Struct is large (avoid copying)</li>
<li>Consistency (if one method uses pointer, all should)</li>
<p>---</p>
<h2>Interfaces</h2>
<p>Interfaces define behavior. Types implement interfaces implicitly:</p>
<pre><code class="language-go">// Define interface
type Shape interface {
    Area() float64
    Perimeter() float64
}
<p>// Rectangle implements Shape (implicitly)
type Rectangle struct {
    Width, Height float64
}</p>
<p>func (r Rectangle) Area() float64 {
    return r.Width * r.Height
}</p>
<p>func (r Rectangle) Perimeter() float64 {
    return 2 * (r.Width + r.Height)
}</p>
<p>// Circle implements Shape
type Circle struct {
    Radius float64
}</p>
<p>func (c Circle) Area() float64 {
    return 3.14159 * c.Radius * c.Radius
}</p>
<p>func (c Circle) Perimeter() float64 {
    return 2 * 3.14159 * c.Radius
}</p>
<p>// Function that accepts any Shape
func printShapeInfo(s Shape) {
    fmt.Printf(&quot;Area: %.2f, Perimeter: %.2f\n&quot;, s.Area(), s.Perimeter())
}</p>
<p>// Usage
rect := Rectangle{Width: 10, Height: 5}
circle := Circle{Radius: 7}</p>
<p>printShapeInfo(rect)    // Works!
printShapeInfo(circle)  // Works!</code></pre></p>
<h3>Empty Interface</h3>
<pre><code class="language-go">// interface{} can hold any type (like &#039;any&#039; in other languages)
func printAnything(v interface{}) {
    fmt.Println(v)
}
<p>printAnything(42)
printAnything(&quot;hello&quot;)
printAnything(true)
printAnything([]int{1, 2, 3})</p>
<p>// Type assertion to get underlying value
var i interface{} = &quot;hello&quot;
s, ok := i.(string)  // Type assertion with safety check
if ok {
    fmt.Println(&quot;String value:&quot;, s)
}</p>
<p>// Type switch
switch v := i.(type) {
case int:
    fmt.Printf(&quot;Integer: %d\n&quot;, v)
case string:
    fmt.Printf(&quot;String: %s\n&quot;, v)
default:
    fmt.Printf(&quot;Unknown type: %T\n&quot;, v)
}</code></pre></p>
<h3>Common Standard Interfaces</h3>
<pre><code class="language-go">// Stringer (like toString())
type Stringer interface {
    String() string
}
<p>type Person struct {
    Name string
    Age  int
}</p>
<p>func (p Person) String() string {
    return fmt.Sprintf(&quot;%s (%d years old)&quot;, p.Name, p.Age)
}</p>
<p>p := Person{&quot;Alice&quot;, 30}
fmt.Println(p)  // Automatically calls String() method</p>
<p>// Reader and Writer (for I/O)
type Reader interface {
    Read(p []byte) (n int, err error)
}</p>
<p>type Writer interface {
    Write(p []byte) (n int, err error)
}</code></pre></p>
<p>---</p>
<h2>Packages & Modules</h2>
<h3>Package Basics</h3>
<pre><code class="language-go">// Every Go file starts with package declaration
package main  // Executable package
<p>package utils  // Library package</p>
<p>// Exported names start with capital letter
func ExportedFunction() {}   // Can be used by other packages
func unexportedFunction() {} // Only visible within package</code></pre></p>
<h3>Creating a Module</h3>
<pre><code class="language-bash"># Initialize a new module
mkdir myapp
cd myapp
go mod init github.com/username/myapp
<h1>This creates go.mod file:</h1>
<h1>module github.com/username/myapp</h1>
<h1></h1>
<h1>go 1.21</code></pre></h1>
<h3>Project Structure</h3>
<pre><code class="language-text">myapp/
‚îú‚îÄ‚îÄ go.mod
‚îú‚îÄ‚îÄ go.sum
‚îú‚îÄ‚îÄ main.go
‚îú‚îÄ‚îÄ handlers/
‚îÇ   ‚îú‚îÄ‚îÄ user.go
‚îÇ   ‚îî‚îÄ‚îÄ product.go
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ user.go
‚îÇ   ‚îî‚îÄ‚îÄ product.go
‚îî‚îÄ‚îÄ utils/
    ‚îî‚îÄ‚îÄ helpers.go</code></pre>
<h3>Importing Packages</h3>
<pre><code class="language-go">package main
<p>import (
    &quot;fmt&quot;                                    // Standard library
    &quot;net/http&quot;                               // Standard library
    
    &quot;github.com/username/myapp/handlers&quot;     // Local package
    &quot;github.com/username/myapp/models&quot;       // Local package
    
    &quot;github.com/gorilla/mux&quot;                 // External package
)</p>
<p>func main() {
    router := mux.NewRouter()
    router.HandleFunc(&quot;/users&quot;, handlers.GetUsers)
    http.ListenAndServe(&quot;:8080&quot;, router)
}</code></pre></p>
<h3>Installing Dependencies</h3>
<pre><code class="language-bash"># Add dependency
go get github.com/gorilla/mux
<h1>Install all dependencies from go.mod</h1>
go mod download
<h1>Remove unused dependencies</h1>
go mod tidy
<h1>Update dependency</h1>
go get -u github.com/gorilla/mux
<h1>Update all dependencies</h1>
go get -u ./...</code></pre>
<p>---</p>
<h2>Error Handling</h2>
<p>Go's philosophy: Explicit error handling, no exceptions</p>
<h3>Basic Error Handling</h3>
<pre><code class="language-go">import (
    &quot;errors&quot;
    &quot;fmt&quot;
)
<p>// Function returns error as second value
func divide(a, b float64) (float64, error) {
    if b == 0 {
        return 0, errors.New(&quot;division by zero&quot;)
    }
    return a / b, nil
}</p>
<p>// Usage: always check errors
result, err := divide(10, 0)
if err != nil {
    fmt.Println(&quot;Error:&quot;, err)
    return
}
fmt.Println(&quot;Result:&quot;, result)</code></pre></p>
<h3>Creating Custom Errors</h3>
<pre><code class="language-go">// Method 1: errors.New()
err := errors.New(&quot;something went wrong&quot;)
<p>// Method 2: fmt.Errorf() with formatting
err := fmt.Errorf(&quot;user %s not found&quot;, username)</p>
<p>// Method 3: Custom error type
type ValidationError struct {
    Field   string
    Message string
}</p>
<p>func (e *ValidationError) Error() string {
    return fmt.Sprintf(&quot;validation error on field &#039;%s&#039;: %s&quot;, e.Field, e.Message)
}</p>
<p>// Usage
func validateAge(age int) error {
    if age &lt; 0 {
        return &amp;ValidationError{
            Field:   &quot;age&quot;,
            Message: &quot;must be non-negative&quot;,
        }
    }
    return nil
}</code></pre></p>
<h3>Error Wrapping (Go 1.13+)</h3>
<pre><code class="language-go">import (
    &quot;errors&quot;
    &quot;fmt&quot;
)
<p>// Wrap error to add context
func readConfig(filename string) error {
    _, err := os.Open(filename)
    if err != nil {
        return fmt.Errorf(&quot;failed to read config: %w&quot;, err)
    }
    return nil
}</p>
<p>// Check for specific error
err := readConfig(&quot;config.yaml&quot;)
if errors.Is(err, os.ErrNotExist) {
    fmt.Println(&quot;Config file doesn&#039;t exist&quot;)
}</p>
<p>// Unwrap error chain
var pathErr *os.PathError
if errors.As(err, &amp;pathErr) {
    fmt.Println(&quot;Path error:&quot;, pathErr.Path)
}</code></pre></p>
<h3>Panic and Recover</h3>
<pre><code class="language-go">// panic: something went terribly wrong (like throwing exception)
func riskyOperation() {
    panic(&quot;something went wrong!&quot;)
}
<p>// recover: catch panics (like try-catch)
func safeOperation() {
    defer func() {
        if r := recover(); r != nil {
            fmt.Println(&quot;Recovered from panic:&quot;, r)
        }
    }()
    
    riskyOperation()
    fmt.Println(&quot;This won&#039;t be printed&quot;)
}</p>
<p>// Only use panic for truly unrecoverable errors
// Most errors should be handled explicitly</code></pre></p>
<p>---</p>
<h2>Common Mistakes</h2>
<h3>1. Unused Variables</h3>
<pre><code class="language-go">// ‚ùå Error: &quot;declared and not used&quot;
func bad() {
    x := 10
    // x is never used
}
<p>// ‚úÖ Use underscore to ignore values
func good() {
    _, err := doSomething()
    if err != nil {
        return
    }
}</code></pre></p>
<h3>2. Shadowing Variables</h3>
<pre><code class="language-go">// ‚ùå Shadowing error variable
func bad() error {
    err := setup()
    if err != nil {
        return err
    }
    
    err := process()  // This creates NEW variable, doesn&#039;t reassign!
    return err
}
<p>// ‚úÖ Reuse existing variable
func good() error {
    err := setup()
    if err != nil {
        return err
    }
    
    err = process()  // Correctly reassigns
    return err
}</code></pre></p>
<h3>3. Slice Gotchas</h3>
<pre><code class="language-go">// ‚ùå Slices share underlying array
func bad() {
    a := []int{1, 2, 3}
    b := a
    b[0] = 999
    fmt.Println(a)  // [999, 2, 3] - a is also changed!
}
<p>// ‚úÖ Copy slice if you need independence
func good() {
    a := []int{1, 2, 3}
    b := make([]int, len(a))
    copy(b, a)
    b[0] = 999
    fmt.Println(a)  // [1, 2, 3] - a is unchanged
}</code></pre></p>
<h3>4. Goroutine Loop Variable Capture</h3>
<pre><code class="language-go">// ‚ùå All goroutines use same variable
for i := 0; i &lt; 5; i++ {
    go func() {
        fmt.Println(i)  // Might print 5 five times!
    }()
}
<p>// ‚úÖ Pass variable as parameter
for i := 0; i &lt; 5; i++ {
    go func(n int) {
        fmt.Println(n)  // Correctly prints 0, 1, 2, 3, 4
    }(i)
}</code></pre></p>
<p>---</p>
<h2>Best Practices</h2>
<h3>1. Error Handling</h3>
<pre><code class="language-go">// ‚úÖ Always check errors immediately
result, err := doSomething()
if err != nil {
    return fmt.Errorf(&quot;failed to do something: %w&quot;, err)
}
<p>// ‚úÖ Early returns for error cases
func processUser(id int) error {
    user, err := getUser(id)
    if err != nil {
        return err
    }
    
    if user.IsBlocked {
        return errors.New(&quot;user is blocked&quot;)
    }
    
    // Main logic here
    return nil
}</code></pre></p>
<h3>2. Naming Conventions</h3>
<pre><code class="language-go">// ‚úÖ Short, descriptive names
user := getUser(123)
err := validate(user)
<p>// ‚úÖ Use camelCase
func getUserByID(id int) (*User, error)</p>
<p>// ‚úÖ Acronyms in capitals
func ParseHTTPRequest(url string) error
var userID int
var apiURL string</p>
<p>// ‚úÖ Package names: lowercase, no underscores
package httputil
package userservice</code></pre></p>
<h3>3. Code Organization</h3>
<pre><code class="language-go">// ‚úÖ Imports: standard, external, local
import (
    &quot;fmt&quot;
    &quot;net/http&quot;
    
    &quot;github.com/gorilla/mux&quot;
    
    &quot;myapp/handlers&quot;
    &quot;myapp/models&quot;
)
<p>// ‚úÖ Exported types and functions first
type User struct { ... }
func NewUser() *User { ... }
func unexported() { ... }</code></pre></p>
<h3>4. Interface Design</h3>
<pre><code class="language-go">// ‚úÖ Small, focused interfaces
type Reader interface {
    Read(p []byte) (n int, err error)
}
<p>// ‚úÖ Accept interfaces, return structs
func ProcessData(r io.Reader) (*Result, error) {
    // ...
}</p>
<p>// ‚ùå Don&#039;t accept interfaces everywhere
// Only use when you need polymorphism</code></pre></p>
<p>---</p>
<h2>Interview Questions</h2>
<h3>Basic Level</h3>
<strong>Q1: What is the difference between <code>var</code> and <code>:=</code>?</strong>
<pre><code class="language-go">// var: can be used at package level and inside functions
var globalVar = 10
<p>// := can only be used inside functions (short declaration)
func example() {
    localVar := 20
}</code></pre></p>
<strong>Q2: Explain zero values in Go.</strong>
<p>Go initializes all variables to their zero value:
<li>Numbers: <code>0</code></li>
<li>Booleans: <code>false</code></li>
<li>Strings: <code>""</code> (empty)</li>
<li>Pointers, slices, maps, channels, functions, interfaces: <code>nil</code></li></p>
<strong>Q3: What's the difference between an array and a slice?</strong>
<pre><code class="language-go">// Array: fixed size, value type
var arr [5]int = [5]int{1, 2, 3, 4, 5}
<p>// Slice: dynamic size, reference type
var slice []int = []int{1, 2, 3, 4, 5}</code></pre></p>
<h3>Intermediate Level</h3>
<strong>Q4: When should you use pointer receivers vs value receivers?</strong>
<p>Use pointer receivers when:
<li>You need to modify the receiver</li>
<li>The struct is large (avoid copying)</li>
<li>For consistency across methods</li></p>
<strong>Q5: Explain interface implementation in Go.</strong>
<p>Interfaces are implemented implicitly. If a type has all the methods of an interface, it implements that interface automatically.</p>
<pre><code class="language-go">type Writer interface {
    Write([]byte) (int, error)
}
<p>type MyWriter struct {}</p>
<p>// MyWriter implements Writer implicitly
func (m MyWriter) Write(p []byte) (int, error) {
    // implementation
    return len(p), nil
}</code></pre></p>
<strong>Q6: What is the purpose of defer?</strong>
<code>defer</code> postpones function execution until surrounding function returns. Used for cleanup:
<pre><code class="language-go">defer file.Close()
defer mutex.Unlock()
defer transaction.Rollback()</code></pre>
<p>---</p>
<h2>Hands-On Exercise</h2>
<h3>Task: Build a CLI Todo Application</h3>
<p>Create a command-line todo app with these features:</p>
<strong>Requirements:</strong>
1. Add todo items
2. List all todos
3. Mark todo as complete
4. Delete todo
5. Save to/load from file (JSON)
<strong>Starter Code:</strong>
<pre><code class="language-go">package main
<p>import (
    &quot;encoding/json&quot;
    &quot;fmt&quot;
    &quot;io/ioutil&quot;
    &quot;os&quot;
)</p>
<p>type Todo struct {
    ID        int    <code>json:&quot;id&quot;</code>
    Title     string <code>json:&quot;title&quot;</code>
    Completed bool   <code>json:&quot;completed&quot;</code>
}</p>
<p>type TodoList struct {
    Todos []Todo <code>json:&quot;todos&quot;</code>
}</p>
<p>// TODO: Implement these methods
func (tl *TodoList) Add(title string) {
    // Add new todo
}</p>
<p>func (tl *TodoList) List() {
    // Print all todos
}</p>
<p>func (tl *TodoList) Complete(id int) error {
    // Mark todo as complete
    return nil
}</p>
<p>func (tl *TodoList) Delete(id int) error {
    // Delete todo
    return nil
}</p>
<p>func (tl *TodoList) Save(filename string) error {
    // Save to JSON file
    return nil
}</p>
<p>func Load(filename string) (*TodoList, error) {
    // Load from JSON file
    return nil, nil
}</p>
<p>func main() {
    // TODO: Implement CLI interface
    // Use os.Args for command-line arguments
    // Commands: add, list, complete, delete
}</code></pre></p>
<strong>Expected Usage:</strong>
<pre><code class="language-bash">go run todo.go add &quot;Buy groceries&quot;
go run todo.go add &quot;Write Go code&quot;
go run todo.go list
<h1>Output:</h1>
<h1>[1] Buy groceries</h1>
<h1>[2] Write Go code</h1>
<p>go run todo.go complete 1
go run todo.go list
<h1>Output:</h1>
<h1>[1] ‚úì Buy groceries</h1>
<h1>[2] Write Go code</h1></p>
<p>go run todo.go delete 1</code></pre></p>
<strong>Solution available in next module's appendix</strong>
<p>---</p>
<h2>üìö Additional Resources</h2>
<li>[Official Go Tour](https://go.dev/tour/)</li>
<li>[Effective Go](https://go.dev/doc/effective_go)</li>
<li>[Go by Example](https://gobyexample.com/)</li>
<li>[Go Standard Library](https://pkg.go.dev/std)</li>
<p>---</p>
<h2>‚úÖ Module Checklist</h2>
<p>Before moving to the next module, ensure you can:</p>
<li>[ ] Write and run basic Go programs</li>
<li>[ ] Use all primitive types correctly</li>
<li>[ ] Implement control flow (if, for, switch)</li>
<li>[ ] Write functions with multiple return values</li>
<li>[ ] Create and use structs with methods</li>
<li>[ ] Understand and implement interfaces</li>
<li>[ ] Handle errors properly</li>
<li>[ ] Organize code into packages</li>
<li>[ ] Complete the hands-on exercise</li></ul>
<p>---</p>
<strong>Next Module:</strong> [02_Go_Concurrency.md](./02_Go_Concurrency.md) - Learn goroutines and channels! üöÄ

    </div>
    

    <div class="module-content" id="module-2">
        <h1>Module 02: Go Concurrency üîÄ</h1>
<h2>Master Goroutines, Channels, and Concurrent Programming</h2>
<strong>Duration:</strong> 4-5 hours  
<strong>Prerequisites:</strong> Module 01 - Go Fundamentals  
<strong>Outcome:</strong> Build efficient concurrent programs using Go's built-in concurrency primitives
<p>---</p>
<h2>üìö Table of Contents</h2>
<p>1. [Why Concurrency Matters](#why-concurrency-matters)
2. [Goroutines](#goroutines)
3. [Channels](#channels)
4. [Select Statement](#select-statement)
5. [Buffered Channels](#buffered-channels)
6. [Channel Patterns](#channel-patterns)
7. [Sync Package](#sync-package)
8. [Context Package](#context-package)
9. [Common Concurrency Patterns](#common-concurrency-patterns)
10. [Race Conditions & How to Avoid Them](#race-conditions--how-to-avoid-them)
11. [Best Practices](#best-practices)
12. [Interview Questions](#interview-questions)
13. [Hands-On Exercise](#hands-on-exercise)</p>
<p>---</p>
<h2>Why Concurrency Matters</h2>
<h3>Concurrency vs Parallelism</h3>
<strong>Concurrency</strong> = Dealing with multiple things at once (structure)  
<strong>Parallelism</strong> = Doing multiple things at once (execution)
<pre><code class="language-text">Concurrency: I can juggle multiple tasks (check email, write code, answer calls)
Parallelism: Multiple people working on different tasks simultaneously</code></pre>
<h3>Go's Approach to Concurrency</h3>
<p>Go makes concurrency a first-class citizen with:
<ul><li><strong>Goroutines</strong> - Lightweight threads (2KB stack vs 1MB OS threads)</li>
<li><strong>Channels</strong> - Type-safe communication between goroutines</li>
<li><strong>Select</strong> - Multiplex channel operations</li>
<li><strong>Simple syntax</strong> - <code>go</code> keyword to launch concurrent execution</li></p>
<h3>Real-World Use Cases</h3>
<p>‚úÖ <strong>Web Servers</strong> - Handle thousands of concurrent HTTP requests  
‚úÖ <strong>Data Processing</strong> - Process large datasets in parallel  
‚úÖ <strong>API Aggregation</strong> - Call multiple APIs concurrently  
‚úÖ <strong>Background Jobs</strong> - Run tasks asynchronously  
‚úÖ <strong>Real-time Systems</strong> - Handle multiple event streams</p>
<p>---</p>
<h2>Goroutines</h2>
<h3>Basic Goroutine</h3>
<p>A goroutine is a lightweight thread managed by Go runtime:</p>
<pre><code class="language-go">package main
<p>import (
    &quot;fmt&quot;
    &quot;time&quot;
)</p>
<p>func sayHello() {
    fmt.Println(&quot;Hello from goroutine!&quot;)
}</p>
<p>func main() {
    // Launch goroutine with &#039;go&#039; keyword
    go sayHello()
    
    // Without sleep, main would exit before goroutine runs
    time.Sleep(100 * time.Millisecond)
    fmt.Println(&quot;Main function&quot;)
}</p>
<p>// Output:
// Hello from goroutine!
// Main function</code></pre></p>
<h3>Multiple Goroutines</h3>
<pre><code class="language-go">func printNumbers() {
    for i := 1; i &lt;= 5; i++ {
        fmt.Printf(&quot;Number: %d\n&quot;, i)
        time.Sleep(100 * time.Millisecond)
    }
}
<p>func printLetters() {
    for i := &#039;a&#039;; i &lt;= &#039;e&#039;; i++ {
        fmt.Printf(&quot;Letter: %c\n&quot;, i)
        time.Sleep(150 * time.Millisecond)
    }
}</p>
<p>func main() {
    go printNumbers()
    go printLetters()
    
    time.Sleep(1 * time.Second)
}</p>
<p>// Output (interleaved, order may vary):
// Number: 1
// Letter: a
// Number: 2
// Letter: b
// Number: 3
// ...</code></pre></p>
<h3>Anonymous Goroutines</h3>
<pre><code class="language-go">func main() {
    // Launch anonymous function as goroutine
    go func() {
        fmt.Println(&quot;Anonymous goroutine&quot;)
    }()
    
    // With parameters
    name := &quot;Alice&quot;
    go func(n string) {
        fmt.Printf(&quot;Hello, %s!\n&quot;, n)
    }(name)  // Pass parameter here!
    
    time.Sleep(100 * time.Millisecond)
}</code></pre>
<h3>How Many Goroutines Can You Run?</h3>
<pre><code class="language-go">package main
<p>import (
    &quot;fmt&quot;
    &quot;runtime&quot;
    &quot;sync&quot;
)</p>
<p>func main() {
    var wg sync.WaitGroup
    count := 100000
    
    for i := 0; i &lt; count; i++ {
        wg.Add(1)
        go func(id int) {
            defer wg.Done()
            // Each goroutine just exists
        }(i)
    }
    
    fmt.Printf(&quot;Launched %d goroutines\n&quot;, count)
    fmt.Printf(&quot;Number of CPUs: %d\n&quot;, runtime.NumCPU())
    fmt.Printf(&quot;Number of goroutines: %d\n&quot;, runtime.NumGoroutine())
    
    wg.Wait()
}</p>
<p>// Output:
// Launched 100000 goroutines
// Number of CPUs: 8
// Number of goroutines: 100001  (including main)</code></pre></p>
<strong>Note:</strong> You can easily run 100,000+ goroutines! Each goroutine only uses ~2KB of stack initially.
<p>---</p>
<h2>Channels</h2>
<p>Channels are typed conduits for communication between goroutines.</p>
<h3>Creating and Using Channels</h3>
<pre><code class="language-go">package main
<p>import &quot;fmt&quot;</p>
<p>func main() {
    // Create channel
    ch := make(chan int)
    
    // Send value in goroutine (must be in goroutine to avoid deadlock)
    go func() {
        ch &lt;- 42  // Send value to channel
    }()
    
    // Receive value
    value := &lt;-ch  // Receive value from channel
    fmt.Println(&quot;Received:&quot;, value)
}</code></pre></p>
<h3>Channel Operations</h3>
<pre><code class="language-go">// Create channel
ch := make(chan string)
<p>// Send (blocks until receiver is ready)
ch &lt;- &quot;hello&quot;</p>
<p>// Receive (blocks until sender sends)
msg := &lt;-ch</p>
<p>// Receive and ignore value
&lt;-ch</p>
<p>// Check if channel is closed
msg, ok := &lt;-ch
if !ok {
    fmt.Println(&quot;Channel closed&quot;)
}</p>
<p>// Close channel (only sender should close)
close(ch)</code></pre></p>
<h3>Deadlock Example</h3>
<pre><code class="language-go">func main() {
    ch := make(chan int)
    
    // ‚ùå This will deadlock!
    ch &lt;- 42  // Waiting for receiver
    value := &lt;-ch  // Never reached
    
    fmt.Println(value)
}
<p>// Output: fatal error: all goroutines are asleep - deadlock!</code></pre></p>
<h3>Proper Channel Usage</h3>
<pre><code class="language-go">func main() {
    ch := make(chan int)
    
    // ‚úÖ Send in separate goroutine
    go func() {
        ch &lt;- 42
    }()
    
    value := &lt;-ch
    fmt.Println(value)  // 42
}</code></pre>
<p>---</p>
<h2>Select Statement</h2>
<code>select</code> lets you wait on multiple channel operations:
<h3>Basic Select</h3>
<pre><code class="language-go">package main
<p>import (
    &quot;fmt&quot;
    &quot;time&quot;
)</p>
<p>func main() {
    ch1 := make(chan string)
    ch2 := make(chan string)
    
    go func() {
        time.Sleep(1 * time.Second)
        ch1 &lt;- &quot;from ch1&quot;
    }()
    
    go func() {
        time.Sleep(2 * time.Second)
        ch2 &lt;- &quot;from ch2&quot;
    }()
    
    // Select waits for first channel that&#039;s ready
    select {
    case msg1 := &lt;-ch1:
        fmt.Println(&quot;Received:&quot;, msg1)
    case msg2 := &lt;-ch2:
        fmt.Println(&quot;Received:&quot;, msg2)
    }
}</p>
<p>// Output: Received: from ch1 (ch1 is ready first)</code></pre></p>
<h3>Select with Timeout</h3>
<pre><code class="language-go">func main() {
    ch := make(chan string)
    
    go func() {
        time.Sleep(2 * time.Second)
        ch &lt;- &quot;result&quot;
    }()
    
    select {
    case result := &lt;-ch:
        fmt.Println(&quot;Got:&quot;, result)
    case &lt;-time.After(1 * time.Second):
        fmt.Println(&quot;Timeout!&quot;)
    }
}
<p>// Output: Timeout! (times out after 1 second)</code></pre></p>
<h3>Select with Default (Non-blocking)</h3>
<pre><code class="language-go">func main() {
    ch := make(chan int)
    
    select {
    case val := &lt;-ch:
        fmt.Println(&quot;Received:&quot;, val)
    default:
        fmt.Println(&quot;No value ready, doing something else&quot;)
    }
}
<p>// Output: No value ready, doing something else</code></pre></p>
<h3>Select in Loop</h3>
<pre><code class="language-go">func main() {
    ch1 := make(chan string)
    ch2 := make(chan string)
    
    go func() {
        for i := 0; i &lt; 3; i++ {
            time.Sleep(500 * time.Millisecond)
            ch1 &lt;- fmt.Sprintf(&quot;ch1: %d&quot;, i)
        }
    }()
    
    go func() {
        for i := 0; i &lt; 3; i++ {
            time.Sleep(700 * time.Millisecond)
            ch2 &lt;- fmt.Sprintf(&quot;ch2: %d&quot;, i)
        }
    }()
    
    for i := 0; i &lt; 6; i++ {
        select {
        case msg1 := &lt;-ch1:
            fmt.Println(msg1)
        case msg2 := &lt;-ch2:
            fmt.Println(msg2)
        }
    }
}</code></pre>
<p>---</p>
<h2>Buffered Channels</h2>
<p>Buffered channels have capacity and don't block until full:</p>
<h3>Creating Buffered Channels</h3>
<pre><code class="language-go">// Unbuffered channel (capacity 0)
ch := make(chan int)
<p>// Buffered channel (capacity 3)
ch := make(chan int, 3)</p>
<p>// Send without blocking (until buffer full)
ch &lt;- 1
ch &lt;- 2
ch &lt;- 3
// ch &lt;- 4  // This would block (buffer full)</p>
<p>// Receive
fmt.Println(&lt;-ch)  // 1
fmt.Println(&lt;-ch)  // 2
fmt.Println(&lt;-ch)  // 3</code></pre></p>
<h3>Buffered vs Unbuffered</h3>
<pre><code class="language-go">package main
<p>import (
    &quot;fmt&quot;
    &quot;time&quot;
)</p>
<p>func unbufferedExample() {
    ch := make(chan int)
    
    go func() {
        fmt.Println(&quot;Sending...&quot;)
        ch &lt;- 1  // Blocks until received
        fmt.Println(&quot;Sent!&quot;)
    }()
    
    time.Sleep(1 * time.Second)  // Sender waits here
    fmt.Println(&quot;Receiving...&quot;)
    fmt.Println(&lt;-ch)
}</p>
<p>func bufferedExample() {
    ch := make(chan int, 1)
    
    go func() {
        fmt.Println(&quot;Sending...&quot;)
        ch &lt;- 1  // Doesn&#039;t block (buffer available)
        fmt.Println(&quot;Sent!&quot;)
    }()
    
    time.Sleep(1 * time.Second)  // Sender doesn&#039;t wait
    fmt.Println(&quot;Receiving...&quot;)
    fmt.Println(&lt;-ch)
}</p>
<p>func main() {
    fmt.Println(&quot;=== Unbuffered ===&quot;)
    unbufferedExample()
    
    fmt.Println(&quot;\n=== Buffered ===&quot;)
    bufferedExample()
}</code></pre></p>
<h3>When to Use Buffered Channels</h3>
<p>‚úÖ <strong>Use buffered channels when:</strong>
<li>You know the number of items to send</li>
<li>You want to avoid blocking senders temporarily</li>
<li>You're implementing a queue/worker pool</li></p>
<p>‚ùå <strong>Don't use buffered channels:</strong>
<li>As a default (start with unbuffered)</li>
<li>To hide concurrency bugs</li>
<li>When you need synchronization</li></p>
<p>---</p>
<h2>Channel Patterns</h2>
<h3>1. Pipeline Pattern</h3>
<p>Chain goroutines together:</p>
<pre><code class="language-go">package main
<p>import &quot;fmt&quot;</p>
<p>// Stage 1: Generate numbers
func generate(nums ...int) &lt;-chan int {
    out := make(chan int)
    go func() {
        for _, n := range nums {
            out &lt;- n
        }
        close(out)
    }()
    return out
}</p>
<p>// Stage 2: Square numbers
func square(in &lt;-chan int) &lt;-chan int {
    out := make(chan int)
    go func() {
        for n := range in {
            out &lt;- n * n
        }
        close(out)
    }()
    return out
}</p>
<p>func main() {
    // Create pipeline
    numbers := generate(1, 2, 3, 4, 5)
    squares := square(numbers)
    
    // Consume pipeline
    for result := range squares {
        fmt.Println(result)
    }
}</p>
<p>// Output: 1, 4, 9, 16, 25</code></pre></p>
<h3>2. Fan-Out, Fan-In Pattern</h3>
<p>Distribute work across multiple workers:</p>
<pre><code class="language-go">package main
<p>import (
    &quot;fmt&quot;
    &quot;sync&quot;
    &quot;time&quot;
)</p>
<p>// Worker function
func worker(id int, jobs &lt;-chan int, results chan&lt;- int) {
    for j := range jobs {
        fmt.Printf(&quot;Worker %d processing job %d\n&quot;, id, j)
        time.Sleep(time.Second)  // Simulate work
        results &lt;- j * 2
    }
}</p>
<p>func main() {
    jobs := make(chan int, 10)
    results := make(chan int, 10)
    
    // Fan-out: Start 3 workers
    for w := 1; w &lt;= 3; w++ {
        go worker(w, jobs, results)
    }
    
    // Send 9 jobs
    for j := 1; j &lt;= 9; j++ {
        jobs &lt;- j
    }
    close(jobs)
    
    // Fan-in: Collect results
    for a := 1; a &lt;= 9; a++ {
        fmt.Println(&quot;Result:&quot;, &lt;-results)
    }
}</code></pre></p>
<h3>3. Worker Pool Pattern</h3>
<pre><code class="language-go">package main
<p>import (
    &quot;fmt&quot;
    &quot;sync&quot;
)</p>
<p>type Job struct {
    ID     int
    Data   string
}</p>
<p>type Result struct {
    JobID  int
    Output string
}</p>
<p>func worker(id int, jobs &lt;-chan Job, results chan&lt;- Result, wg *sync.WaitGroup) {
    defer wg.Done()
    
    for job := range jobs {
        fmt.Printf(&quot;Worker %d started job %d\n&quot;, id, job.ID)
        
        // Process job
        output := fmt.Sprintf(&quot;Processed: %s&quot;, job.Data)
        
        results &lt;- Result{
            JobID:  job.ID,
            Output: output,
        }
    }
}</p>
<p>func main() {
    const numWorkers = 3
    const numJobs = 10
    
    jobs := make(chan Job, numJobs)
    results := make(chan Result, numJobs)
    
    // Start workers
    var wg sync.WaitGroup
    for w := 1; w &lt;= numWorkers; w++ {
        wg.Add(1)
        go worker(w, jobs, results, &amp;wg)
    }
    
    // Send jobs
    for j := 1; j &lt;= numJobs; j++ {
        jobs &lt;- Job{
            ID:   j,
            Data: fmt.Sprintf(&quot;task-%d&quot;, j),
        }
    }
    close(jobs)
    
    // Wait for workers and close results
    go func() {
        wg.Wait()
        close(results)
    }()
    
    // Collect results
    for result := range results {
        fmt.Printf(&quot;Job %d: %s\n&quot;, result.JobID, result.Output)
    }
}</code></pre></p>
<h3>4. Done Channel Pattern</h3>
<p>Signal completion:</p>
<pre><code class="language-go">func doWork(done &lt;-chan bool) {
    for {
        select {
        case &lt;-done:
            fmt.Println(&quot;Work cancelled&quot;)
            return
        default:
            fmt.Println(&quot;Working...&quot;)
            time.Sleep(500 * time.Millisecond)
        }
    }
}
<p>func main() {
    done := make(chan bool)
    
    go doWork(done)
    
    time.Sleep(2 * time.Second)
    close(done)  // Signal done
    time.Sleep(500 * time.Millisecond)
}</code></pre></p>
<p>---</p>
<h2>Sync Package</h2>
<p>When channels are overkill, use sync primitives:</p>
<h3>WaitGroup</h3>
<p>Wait for multiple goroutines to finish:</p>
<pre><code class="language-go">package main
<p>import (
    &quot;fmt&quot;
    &quot;sync&quot;
    &quot;time&quot;
)</p>
<p>func worker(id int, wg *sync.WaitGroup) {
    defer wg.Done()  // Decrement counter when done
    
    fmt.Printf(&quot;Worker %d starting\n&quot;, id)
    time.Sleep(time.Second)
    fmt.Printf(&quot;Worker %d done\n&quot;, id)
}</p>
<p>func main() {
    var wg sync.WaitGroup
    
    for i := 1; i &lt;= 5; i++ {
        wg.Add(1)  // Increment counter
        go worker(i, &amp;wg)
    }
    
    wg.Wait()  // Block until counter is 0
    fmt.Println(&quot;All workers completed&quot;)
}</code></pre></p>
<h3>Mutex (Mutual Exclusion)</h3>
<p>Protect shared data:</p>
<pre><code class="language-go">package main
<p>import (
    &quot;fmt&quot;
    &quot;sync&quot;
)</p>
<p>type SafeCounter struct {
    mu    sync.Mutex
    count int
}</p>
<p>func (c *SafeCounter) Increment() {
    c.mu.Lock()
    defer c.mu.Unlock()
    c.count++
}</p>
<p>func (c *SafeCounter) Value() int {
    c.mu.Lock()
    defer c.mu.Unlock()
    return c.count
}</p>
<p>func main() {
    counter := SafeCounter{}
    var wg sync.WaitGroup
    
    // 1000 goroutines incrementing counter
    for i := 0; i &lt; 1000; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            counter.Increment()
        }()
    }
    
    wg.Wait()
    fmt.Println(&quot;Final count:&quot;, counter.Value())  // 1000
}</code></pre></p>
<h3>RWMutex (Read-Write Mutex)</h3>
<p>Allow multiple readers or one writer:</p>
<pre><code class="language-go">type SafeMap struct {
    mu   sync.RWMutex
    data map[string]int
}
<p>func (m *SafeMap) Get(key string) (int, bool) {
    m.mu.RLock()  // Read lock (multiple readers OK)
    defer m.mu.RUnlock()
    val, ok := m.data[key]
    return val, ok
}</p>
<p>func (m *SafeMap) Set(key string, value int) {
    m.mu.Lock()  // Write lock (exclusive)
    defer m.mu.Unlock()
    m.data[key] = value
}</code></pre></p>
<h3>Once</h3>
<p>Execute something exactly once:</p>
<pre><code class="language-go">package main
<p>import (
    &quot;fmt&quot;
    &quot;sync&quot;
)</p>
<p>var (
    instance *Singleton
    once     sync.Once
)</p>
<p>type Singleton struct {
    data string
}</p>
<p>func GetInstance() *Singleton {
    once.Do(func() {
        fmt.Println(&quot;Creating singleton instance&quot;)
        instance = &amp;Singleton{data: &quot;singleton&quot;}
    })
    return instance
}</p>
<p>func main() {
    var wg sync.WaitGroup
    
    for i := 0; i &lt; 10; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            s := GetInstance()
            fmt.Println(s.data)
        }()
    }
    
    wg.Wait()
}</p>
<p>// Output: &quot;Creating singleton instance&quot; printed only once</code></pre></p>
<p>---</p>
<h2>Context Package</h2>
<p>Manage cancellation, deadlines, and request-scoped values:</p>
<h3>Context Basics</h3>
<pre><code class="language-go">package main
<p>import (
    &quot;context&quot;
    &quot;fmt&quot;
    &quot;time&quot;
)</p>
<p>func doWork(ctx context.Context, name string) {
    for {
        select {
        case &lt;-ctx.Done():
            fmt.Printf(&quot;%s: cancelled (%v)\n&quot;, name, ctx.Err())
            return
        default:
            fmt.Printf(&quot;%s: working...\n&quot;, name)
            time.Sleep(500 * time.Millisecond)
        }
    }
}</p>
<p>func main() {
    // Context with timeout
    ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)
    defer cancel()
    
    go doWork(ctx, &quot;Worker1&quot;)
    go doWork(ctx, &quot;Worker2&quot;)
    
    time.Sleep(3 * time.Second)
}</code></pre></p>
<h3>Context Types</h3>
<pre><code class="language-go">// 1. Background context (root context)
ctx := context.Background()
<p>// 2. Context with cancellation
ctx, cancel := context.WithCancel(ctx)
cancel()  // Call to cancel</p>
<p>// 3. Context with timeout
ctx, cancel := context.WithTimeout(ctx, 5*time.Second)
defer cancel()</p>
<p>// 4. Context with deadline
deadline := time.Now().Add(10 * time.Second)
ctx, cancel := context.WithDeadline(ctx, deadline)
defer cancel()</p>
<p>// 5. Context with value
ctx = context.WithValue(ctx, &quot;userID&quot;, 12345)
userID := ctx.Value(&quot;userID&quot;).(int)</code></pre></p>
<h3>Real-World Context Example</h3>
<pre><code class="language-go">package main
<p>import (
    &quot;context&quot;
    &quot;fmt&quot;
    &quot;net/http&quot;
    &quot;time&quot;
)</p>
<p>func fetchData(ctx context.Context, url string) (string, error) {
    req, err := http.NewRequestWithContext(ctx, &quot;GET&quot;, url, nil)
    if err != nil {
        return &quot;&quot;, err
    }
    
    client := &amp;http.Client{}
    resp, err := client.Do(req)
    if err != nil {
        return &quot;&quot;, err
    }
    defer resp.Body.Close()
    
    return fmt.Sprintf(&quot;Status: %d&quot;, resp.StatusCode), nil
}</p>
<p>func main() {
    ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)
    defer cancel()
    
    result, err := fetchData(ctx, &quot;https://api.example.com/data&quot;)
    if err != nil {
        fmt.Println(&quot;Error:&quot;, err)
        return
    }
    
    fmt.Println(result)
}</code></pre></p>
<p>---</p>
<h2>Common Concurrency Patterns</h2>
<h3>1. Timeout Pattern</h3>
<pre><code class="language-go">func DoWithTimeout(timeout time.Duration) (string, error) {
    resultCh := make(chan string)
    errCh := make(chan error)
    
    go func() {
        // Simulate long operation
        time.Sleep(3 * time.Second)
        resultCh &lt;- &quot;success&quot;
    }()
    
    select {
    case result := &lt;-resultCh:
        return result, nil
    case err := &lt;-errCh:
        return &quot;&quot;, err
    case &lt;-time.After(timeout):
        return &quot;&quot;, fmt.Errorf(&quot;operation timed out&quot;)
    }
}
<p>result, err := DoWithTimeout(2 * time.Second)
// Returns timeout error</code></pre></p>
<h3>2. Rate Limiting Pattern</h3>
<pre><code class="language-go">func rateLimitedWorker(requests &lt;-chan int, results chan&lt;- int) {
    limiter := time.Tick(200 * time.Millisecond)  // Max 5 per second
    
    for req := range requests {
        &lt;-limiter  // Wait for rate limiter
        results &lt;- processRequest(req)
    }
}</code></pre>
<h3>3. Debounce Pattern</h3>
<pre><code class="language-go">func debounce(interval time.Duration, input &lt;-chan string, output chan&lt;- string) {
    var item string
    timer := time.NewTimer(interval)
    timer.Stop()
    
    for {
        select {
        case item = &lt;-input:
            timer.Reset(interval)
        case &lt;-timer.C:
            output &lt;- item
        }
    }
}</code></pre>
<h3>4. Retry Pattern</h3>
<pre><code class="language-go">func retryOperation(maxRetries int, operation func() error) error {
    var err error
    
    for i := 0; i &lt; maxRetries; i++ {
        err = operation()
        if err == nil {
            return nil
        }
        
        fmt.Printf(&quot;Retry %d/%d failed: %v\n&quot;, i+1, maxRetries, err)
        time.Sleep(time.Second * time.Duration(i+1))  // Exponential backoff
    }
    
    return fmt.Errorf(&quot;operation failed after %d retries: %w&quot;, maxRetries, err)
}</code></pre>
<p>---</p>
<h2>Race Conditions & How to Avoid Them</h2>
<h3>What is a Race Condition?</h3>
<p>When multiple goroutines access shared data concurrently and at least one modifies it:</p>
<pre><code class="language-go">// ‚ùå Race condition
var counter int
<p>func increment() {
    counter++  // Not atomic! Read, increment, write
}</p>
<p>func main() {
    for i := 0; i &lt; 1000; i++ {
        go increment()
    }
    
    time.Sleep(time.Second)
    fmt.Println(counter)  // Unpredictable result (not 1000)
}</code></pre></p>
<h3>Detecting Races</h3>
<pre><code class="language-bash"># Run with race detector
go run -race main.go
<h1>Build with race detector</h1>
go build -race main.go
<h1>Test with race detector</h1>
go test -race ./...</code></pre>
<h3>Solution 1: Mutex</h3>
<pre><code class="language-go">// ‚úÖ Use mutex
var (
    counter int
    mu      sync.Mutex
)
<p>func increment() {
    mu.Lock()
    counter++
    mu.Unlock()
}</code></pre></p>
<h3>Solution 2: Channels</h3>
<pre><code class="language-go">// ‚úÖ Use channels
func main() {
    counter := 0
    done := make(chan bool)
    
    increment := make(chan bool)
    
    go func() {
        for range increment {
            counter++
        }
        done &lt;- true
    }()
    
    for i := 0; i &lt; 1000; i++ {
        increment &lt;- true
    }
    
    close(increment)
    &lt;-done
    fmt.Println(counter)  // Always 1000
}</code></pre>
<h3>Solution 3: Atomic Operations</h3>
<pre><code class="language-go">import &quot;sync/atomic&quot;
<p>var counter int64</p>
<p>func increment() {
    atomic.AddInt64(&amp;counter, 1)
}</p>
<p>func main() {
    for i := 0; i &lt; 1000; i++ {
        go increment()
    }
    
    time.Sleep(time.Second)
    fmt.Println(atomic.LoadInt64(&amp;counter))  // Always 1000
}</code></pre></p>
<p>---</p>
<h2>Best Practices</h2>
<h3>1. Don't Communicate by Sharing Memory; Share Memory by Communicating</h3>
<pre><code class="language-go">// ‚ùå Bad: Shared memory
var sharedMap = make(map[string]int)
var mu sync.Mutex
<p>func badUpdate(key string, value int) {
    mu.Lock()
    sharedMap[key] = value
    mu.Unlock()
}</p>
<p>// ‚úÖ Good: Communicate via channels
type Update struct {
    Key   string
    Value int
}</p>
<p>func goodWorker(updates &lt;-chan Update) {
    localMap := make(map[string]int)
    for update := range updates {
        localMap[update.Key] = update.Value
    }
}</code></pre></p>
<h3>2. Always Close Channels (When Appropriate)</h3>
<pre><code class="language-go">// ‚úÖ Producer closes channel
func producer(ch chan&lt;- int) {
    defer close(ch)
    
    for i := 0; i &lt; 10; i++ {
        ch &lt;- i
    }
}
<p>// Consumer uses range (stops when closed)
func consumer(ch &lt;-chan int) {
    for value := range ch {
        fmt.Println(value)
    }
}</code></pre></p>
<h3>3. Use Context for Cancellation</h3>
<pre><code class="language-go">// ‚úÖ Pass context for cancellation
func worker(ctx context.Context) {
    for {
        select {
        case &lt;-ctx.Done():
            return
        default:
            // Do work
        }
    }
}</code></pre>
<h3>4. Avoid Goroutine Leaks</h3>
<pre><code class="language-go">// ‚ùå Goroutine leak
func leak() {
    ch := make(chan int)
    go func() {
        val := &lt;-ch  // Waits forever if nothing sent
        fmt.Println(val)
    }()
    // Goroutine never exits!
}
<p>// ‚úÖ Use timeout or context
func noLeak(ctx context.Context) {
    ch := make(chan int)
    go func() {
        select {
        case val := &lt;-ch:
            fmt.Println(val)
        case &lt;-ctx.Done():
            return
        }
    }()
}</code></pre></p>
<h3>5. Size Buffered Channels Carefully</h3>
<pre><code class="language-go">// ‚ùå Too large buffer (memory waste)
ch := make(chan int, 1000000)
<p>// ‚úÖ Size based on actual needs
ch := make(chan int, runtime.NumCPU())</code></pre></p>
<p>---</p>
<h2>Interview Questions</h2>
<h3>Q1: What's the difference between concurrency and parallelism?</h3>
<strong>Answer:</strong> Concurrency is about dealing with multiple things at once (design/structure), while parallelism is about doing multiple things at once (execution). Go programs are concurrent by design but may or may not execute in parallel depending on available CPU cores and GOMAXPROCS setting.
<h3>Q2: When would you use a buffered vs unbuffered channel?</h3>
<strong>Answer:</strong>
<li><strong>Unbuffered:</strong> Default choice. Provides synchronization - sender blocks until receiver reads</li>
<li><strong>Buffered:</strong> When you know capacity needed, want to decouple sender/receiver timing, or implementing producer-consumer with known queue size</li>
<h3>Q3: Explain how <code>select</code> works with multiple channels</h3>
<strong>Answer:</strong> <code>select</code> blocks until one of its cases can proceed. If multiple cases are ready, it chooses one at random. With a <code>default</code> case, select never blocks.
<h3>Q4: How do you prevent goroutine leaks?</h3>
<strong>Answer:</strong>
<li>Always provide a way to stop goroutines (context, done channel)</li>
<li>Use timeouts for operations</li>
<li>Close channels when done sending</li>
<li>Be careful with blocking operations</li>
<h3>Q5: What's the difference between <code>sync.Mutex</code> and <code>sync.RWMutex</code>?</h3>
<strong>Answer:</strong>
<li><code>Mutex</code>: Exclusive lock for both read and write</li>
<li><code>RWMutex</code>: Multiple readers OR one writer (better for read-heavy workloads)</li>
<h3>Q6: How does the race detector work?</h3>
<strong>Answer:</strong> It instruments your code to track memory accesses and detects when multiple goroutines access the same memory location without synchronization, and at least one is a write. Run with <code>go run -race</code> or <code>go test -race</code>.
<p>---</p>
<h2>Hands-On Exercise</h2>
<h3>Task: Build a Concurrent URL Checker</h3>
<p>Build a program that checks multiple URLs concurrently and reports their status.</p>
<strong>Requirements:</strong>
1. Accept list of URLs
2. Check each URL concurrently (max 10 concurrent checks)
3. Report which URLs are up/down
4. Calculate total time taken
5. Handle timeouts (2 seconds per URL)
<strong>Starter Code:</strong>
<pre><code class="language-go">package main
<p>import (
    &quot;context&quot;
    &quot;fmt&quot;
    &quot;net/http&quot;
    &quot;sync&quot;
    &quot;time&quot;
)</p>
<p>type Result struct {
    URL    string
    Status string
    Code   int
    Error  error
}</p>
<p>// TODO: Implement concurrent URL checker
func checkURL(ctx context.Context, url string) Result {
    // Check if URL is accessible
    // Return Result with status
    return Result{}
}</p>
<p>// TODO: Implement worker pool
func checkURLsConcurrently(urls []string, maxWorkers int) []Result {
    // Use worker pool pattern
    // Return slice of results
    return nil
}</p>
<p>func main() {
    urls := []string{
        &quot;https://google.com&quot;,
        &quot;https://github.com&quot;,
        &quot;https://stackoverflow.com&quot;,
        &quot;https://invalid-url-12345.com&quot;,
        &quot;https://golang.org&quot;,
        &quot;https://reddit.com&quot;,
        &quot;https://twitter.com&quot;,
        &quot;https://linkedin.com&quot;,
    }
    
    start := time.Now()
    
    // TODO: Check URLs concurrently
    results := checkURLsConcurrently(urls, 5)
    
    // Print results
    for _, result := range results {
        if result.Error != nil {
            fmt.Printf(&quot;‚ùå %s - ERROR: %v\n&quot;, result.URL, result.Error)
        } else {
            fmt.Printf(&quot;‚úÖ %s - %s (Code: %d)\n&quot;, result.URL, result.Status, result.Code)
        }
    }
    
    fmt.Printf(&quot;\nCompleted in: %v\n&quot;, time.Since(start))
}</code></pre></p>
<strong>Expected Output:</strong>
<pre><code class="language-text">‚úÖ https://google.com - OK (Code: 200)
‚úÖ https://github.com - OK (Code: 200)
‚úÖ https://stackoverflow.com - OK (Code: 200)
‚ùå https://invalid-url-12345.com - ERROR: timeout
‚úÖ https://golang.org - OK (Code: 200)
‚úÖ https://reddit.com - OK (Code: 200)
‚úÖ https://twitter.com - OK (Code: 200)
‚úÖ https://linkedin.com - OK (Code: 200)
<p>Completed in: 2.3s</code></pre></p>
<strong>Bonus Challenges:</strong>
1. Add retry logic (3 attempts)
2. Implement rate limiting
3. Add progress indicator
4. Save results to file
<p>---</p>
<h2>üìö Additional Resources</h2>
<li>[Go Concurrency Patterns](https://go.dev/blog/pipelines)</li>
<li>[Advanced Go Concurrency Patterns](https://go.dev/blog/io2013-talk-concurrency)</li>
<li>[Context Package](https://go.dev/blog/context)</li>
<li>[Share Memory by Communicating](https://go.dev/blog/codelab-share)</li>
<p>---</p>
<h2>‚úÖ Module Checklist</h2>
<p>Before moving to the next module, ensure you can:</p>
<li>[ ] Launch and manage goroutines</li>
<li>[ ] Create and use channels (buffered and unbuffered)</li>
<li>[ ] Use select statement for multiplexing</li>
<li>[ ] Implement common patterns (pipeline, fan-out/fan-in, worker pool)</li>
<li>[ ] Use sync package (WaitGroup, Mutex, RWMutex)</li>
<li>[ ] Work with context for cancellation and timeouts</li>
<li>[ ] Detect and fix race conditions</li>
<li>[ ] Complete the hands-on exercise</li></ul>
<p>---</p>
<strong>Next Module:</strong> [03_Go_REST_APIs.md](./03_Go_REST_APIs.md) - Build production-ready HTTP services! üåê

    </div>
    

    <div class="module-content" id="module-3">
        <h1>Module 03: REST APIs with Go üåê</h1>
<h2>Build Production-Ready HTTP Services</h2>
<strong>Duration:</strong> 4-5 hours  
<strong>Prerequisites:</strong> Module 01 (Fundamentals), Module 02 (Concurrency)  
<strong>Outcome:</strong> Create scalable REST APIs with proper routing, middleware, and error handling
<p>---</p>
<h2>üìö Table of Contents</h2>
<p>1. [REST API Fundamentals](#rest-api-fundamentals)
2. [net/http Package](#nethttp-package)
3. [Routing](#routing)
4. [HTTP Methods & Status Codes](#http-methods--status-codes)
5. [Request Handling](#request-handling)
6. [Response Handling](#response-handling)
7. [Middleware](#middleware)
8. [Error Handling](#error-handling)
9. [Request Validation](#request-validation)
10. [Popular Frameworks](#popular-frameworks)
11. [Best Practices](#best-practices)
12. [Interview Questions](#interview-questions)
13. [Hands-On Exercise](#hands-on-exercise)</p>
<p>---</p>
<h2>REST API Fundamentals</h2>
<h3>What is REST?</h3>
<strong>REST</strong> (Representational State Transfer) is an architectural style for designing networked applications.
<strong>Key Principles:</strong>
1. <strong>Stateless</strong> - Each request contains all information needed
2. <strong>Client-Server</strong> - Separation of concerns
3. <strong>Cacheable</strong> - Responses can be cached
4. <strong>Uniform Interface</strong> - Consistent API design
5. <strong>Layered System</strong> - Architecture can have multiple layers
<h3>HTTP Methods (CRUD)</h3>
<p>| Method | Operation | Idempotent | Safe |
|--------|-----------|------------|------|
| GET | Read | ‚úÖ | ‚úÖ |
| POST | Create | ‚ùå | ‚ùå |
| PUT | Update/Replace | ‚úÖ | ‚ùå |
| PATCH | Partial Update | ‚ùå | ‚ùå |
| DELETE | Delete | ‚úÖ | ‚ùå |</p>
<h3>RESTful URL Design</h3>
<pre><code class="language-text">‚úÖ Good:
GET    /api/v1/users          # List users
GET    /api/v1/users/123      # Get user 123
POST   /api/v1/users          # Create user
PUT    /api/v1/users/123      # Update user 123
DELETE /api/v1/users/123      # Delete user 123
<p>‚ùå Bad:
GET    /api/v1/getUsers
POST   /api/v1/createUser
GET    /api/v1/user?action=delete&amp;id=123</code></pre></p>
<p>---</p>
<h2>net/http Package</h2>
<p>Go's standard library has everything you need for HTTP servers:</p>
<h3>Basic HTTP Server</h3>
<pre><code class="language-go">package main
<p>import (
    &quot;fmt&quot;
    &quot;log&quot;
    &quot;net/http&quot;
)</p>
<p>func main() {
    // Handle route
    http.HandleFunc(&quot;/&quot;, func(w http.ResponseWriter, r *http.Request) {
        fmt.Fprintf(w, &quot;Hello, World!&quot;)
    })
    
    // Start server
    log.Println(&quot;Server starting on :8080&quot;)
    log.Fatal(http.ListenAndServe(&quot;:8080&quot;, nil))
}</code></pre></p>
<h3>Multiple Routes</h3>
<pre><code class="language-go">package main
<p>import (
    &quot;encoding/json&quot;
    &quot;log&quot;
    &quot;net/http&quot;
)</p>
<p>type Response struct {
    Message string <code>json:&quot;message&quot;</code>
    Status  int    <code>json:&quot;status&quot;</code>
}</p>
<p>func homeHandler(w http.ResponseWriter, r *http.Request) {
    w.Header().Set(&quot;Content-Type&quot;, &quot;application/json&quot;)
    json.NewEncoder(w).Encode(Response{
        Message: &quot;Welcome to the API&quot;,
        Status:  200,
    })
}</p>
<p>func healthHandler(w http.ResponseWriter, r *http.Request) {
    w.Header().Set(&quot;Content-Type&quot;, &quot;application/json&quot;)
    w.WriteHeader(http.StatusOK)
    json.NewEncoder(w).Encode(Response{
        Message: &quot;Server is healthy&quot;,
        Status:  200,
    })
}</p>
<p>func main() {
    http.HandleFunc(&quot;/&quot;, homeHandler)
    http.HandleFunc(&quot;/health&quot;, healthHandler)
    
    log.Println(&quot;Server starting on :8080&quot;)
    log.Fatal(http.ListenAndServe(&quot;:8080&quot;, nil))
}</code></pre></p>
<h3>Custom Server Configuration</h3>
<pre><code class="language-go">package main
<p>import (
    &quot;log&quot;
    &quot;net/http&quot;
    &quot;time&quot;
)</p>
<p>func main() {
    mux := http.NewServeMux()
    mux.HandleFunc(&quot;/&quot;, homeHandler)
    
    // Custom server with timeouts
    server := &amp;http.Server{
        Addr:         &quot;:8080&quot;,
        Handler:      mux,
        ReadTimeout:  15 * time.Second,
        WriteTimeout: 15 * time.Second,
        IdleTimeout:  60 * time.Second,
    }
    
    log.Println(&quot;Server starting on :8080&quot;)
    log.Fatal(server.ListenAndServe())
}</code></pre></p>
<p>---</p>
<h2>Routing</h2>
<h3>Using http.ServeMux (Standard Library)</h3>
<pre><code class="language-go">package main
<p>import (
    &quot;fmt&quot;
    &quot;net/http&quot;
)</p>
<p>func main() {
    mux := http.NewServeMux()
    
    // Exact match
    mux.HandleFunc(&quot;/users&quot;, usersHandler)
    
    // Prefix match (catches /api/*, /api/users/*, etc.)
    mux.HandleFunc(&quot;/api/&quot;, apiHandler)
    
    http.ListenAndServe(&quot;:8080&quot;, mux)
}</p>
<p>func usersHandler(w http.ResponseWriter, r *http.Request) {
    fmt.Fprintf(w, &quot;Users endpoint&quot;)
}</p>
<p>func apiHandler(w http.ResponseWriter, r *http.Request) {
    fmt.Fprintf(w, &quot;API endpoint: %s&quot;, r.URL.Path)
}</code></pre></p>
<strong>Limitations of ServeMux:</strong>
<ul><li>No URL parameters (e.g., <code>/users/:id</code>)</li>
<li>No method-based routing</li>
<li>Limited pattern matching</li>
<h3>Using gorilla/mux (Popular Router)</h3>
<pre><code class="language-go">package main
<p>import (
    &quot;encoding/json&quot;
    &quot;log&quot;
    &quot;net/http&quot;
    
    &quot;github.com/gorilla/mux&quot;
)</p>
<p>type User struct {
    ID   string <code>json:&quot;id&quot;</code>
    Name string <code>json:&quot;name&quot;</code>
}</p>
<p>func main() {
    r := mux.NewRouter()
    
    // Method-specific routing
    r.HandleFunc(&quot;/users&quot;, getUsers).Methods(&quot;GET&quot;)
    r.HandleFunc(&quot;/users&quot;, createUser).Methods(&quot;POST&quot;)
    
    // URL parameters
    r.HandleFunc(&quot;/users/{id}&quot;, getUser).Methods(&quot;GET&quot;)
    r.HandleFunc(&quot;/users/{id}&quot;, updateUser).Methods(&quot;PUT&quot;)
    r.HandleFunc(&quot;/users/{id}&quot;, deleteUser).Methods(&quot;DELETE&quot;)
    
    // Subrouters
    api := r.PathPrefix(&quot;/api/v1&quot;).Subrouter()
    api.HandleFunc(&quot;/products&quot;, getProducts).Methods(&quot;GET&quot;)
    
    log.Fatal(http.ListenAndServe(&quot;:8080&quot;, r))
}</p>
<p>func getUser(w http.ResponseWriter, r *http.Request) {
    // Extract URL parameter
    vars := mux.Vars(r)
    id := vars[&quot;id&quot;]
    
    // Mock user
    user := User{ID: id, Name: &quot;John Doe&quot;}
    
    w.Header().Set(&quot;Content-Type&quot;, &quot;application/json&quot;)
    json.NewEncoder(w).Encode(user)
}</p>
<p>func getUsers(w http.ResponseWriter, r *http.Request) {
    users := []User{
        {ID: &quot;1&quot;, Name: &quot;Alice&quot;},
        {ID: &quot;2&quot;, Name: &quot;Bob&quot;},
    }
    w.Header().Set(&quot;Content-Type&quot;, &quot;application/json&quot;)
    json.NewEncoder(w).Encode(users)
}</p>
<p>func createUser(w http.ResponseWriter, r *http.Request) {
    var user User
    if err := json.NewDecoder(r.Body).Decode(&amp;user); err != nil {
        http.Error(w, err.Error(), http.StatusBadRequest)
        return
    }
    
    w.WriteHeader(http.StatusCreated)
    json.NewEncoder(w).Encode(user)
}</p>
<p>func updateUser(w http.ResponseWriter, r *http.Request) {
    vars := mux.Vars(r)
    id := vars[&quot;id&quot;]
    
    var user User
    if err := json.NewDecoder(r.Body).Decode(&amp;user); err != nil {
        http.Error(w, err.Error(), http.StatusBadRequest)
        return
    }
    
    user.ID = id
    json.NewEncoder(w).Encode(user)
}</p>
<p>func deleteUser(w http.ResponseWriter, r *http.Request) {
    vars := mux.Vars(r)
    id := vars[&quot;id&quot;]
    
    w.WriteHeader(http.StatusNoContent)
    // In real app, delete from database
}</p>
<p>func getProducts(w http.ResponseWriter, r *http.Request) {
    fmt.Fprintf(w, &quot;Products endpoint&quot;)
}</code></pre></p>
<p>---</p>
<h2>HTTP Methods & Status Codes</h2>
<h3>Common Status Codes</h3>
<pre><code class="language-go">// 2xx Success
http.StatusOK                  // 200
http.StatusCreated             // 201
http.StatusAccepted            // 202
http.StatusNoContent           // 204
<p>// 3xx Redirection
http.StatusMovedPermanently    // 301
http.StatusFound               // 302
http.StatusNotModified         // 304</p>
<p>// 4xx Client Errors
http.StatusBadRequest          // 400
http.StatusUnauthorized        // 401
http.StatusForbidden           // 403
http.StatusNotFound            // 404
http.StatusConflict            // 409
http.StatusUnprocessableEntity // 422</p>
<p>// 5xx Server Errors
http.StatusInternalServerError // 500
http.StatusBadGateway          // 502
http.StatusServiceUnavailable  // 503</code></pre></p>
<h3>Method-Based Routing</h3>
<pre><code class="language-go">func userHandler(w http.ResponseWriter, r *http.Request) {
    switch r.Method {
    case http.MethodGet:
        getUser(w, r)
    case http.MethodPost:
        createUser(w, r)
    case http.MethodPut:
        updateUser(w, r)
    case http.MethodDelete:
        deleteUser(w, r)
    default:
        http.Error(w, &quot;Method not allowed&quot;, http.StatusMethodNotAllowed)
    }
}</code></pre>
<p>---</p>
<h2>Request Handling</h2>
<h3>Reading Query Parameters</h3>
<pre><code class="language-go">func searchHandler(w http.ResponseWriter, r *http.Request) {
    // Parse query parameters
    query := r.URL.Query()
    
    // Get single value
    name := query.Get(&quot;name&quot;)        // ?name=alice
    
    // Get multiple values
    tags := query[&quot;tag&quot;]             // ?tag=go&amp;tag=api
    
    // With defaults
    page := query.Get(&quot;page&quot;)
    if page == &quot;&quot; {
        page = &quot;1&quot;
    }
    
    fmt.Fprintf(w, &quot;Search: name=%s, tags=%v, page=%s&quot;, name, tags, page)
}</code></pre>
<h3>Reading Request Body (JSON)</h3>
<pre><code class="language-go">type CreateUserRequest struct {
    Name  string <code>json:&quot;name&quot;</code>
    Email string <code>json:&quot;email&quot;</code>
    Age   int    <code>json:&quot;age&quot;</code>
}
<p>func createUser(w http.ResponseWriter, r *http.Request) {
    var req CreateUserRequest
    
    // Decode JSON body
    if err := json.NewDecoder(r.Body).Decode(&amp;req); err != nil {
        http.Error(w, &quot;Invalid JSON&quot;, http.StatusBadRequest)
        return
    }
    defer r.Body.Close()
    
    // Validate
    if req.Name == &quot;&quot; {
        http.Error(w, &quot;Name is required&quot;, http.StatusBadRequest)
        return
    }
    
    // Process request...
    w.WriteHeader(http.StatusCreated)
    json.NewEncoder(w).Encode(req)
}</code></pre></p>
<h3>Reading Headers</h3>
<pre><code class="language-go">func headerHandler(w http.ResponseWriter, r *http.Request) {
    // Get specific header
    userAgent := r.Header.Get(&quot;User-Agent&quot;)
    contentType := r.Header.Get(&quot;Content-Type&quot;)
    
    // Get authorization token
    authHeader := r.Header.Get(&quot;Authorization&quot;)
    
    // Check if header exists
    if _, ok := r.Header[&quot;X-Custom-Header&quot;]; ok {
        // Header exists
    }
    
    fmt.Fprintf(w, &quot;User-Agent: %s&quot;, userAgent)
}</code></pre>
<h3>Reading Cookies</h3>
<pre><code class="language-go">func cookieHandler(w http.ResponseWriter, r *http.Request) {
    // Get specific cookie
    cookie, err := r.Cookie(&quot;session_id&quot;)
    if err != nil {
        if err == http.ErrNoCookie {
            http.Error(w, &quot;No session cookie&quot;, http.StatusUnauthorized)
            return
        }
        http.Error(w, &quot;Error reading cookie&quot;, http.StatusInternalServerError)
        return
    }
    
    fmt.Fprintf(w, &quot;Session ID: %s&quot;, cookie.Value)
}</code></pre>
<p>---</p>
<h2>Response Handling</h2>
<h3>Writing JSON Response</h3>
<pre><code class="language-go">type APIResponse struct {
    Success bool        <code>json:&quot;success&quot;</code>
    Data    interface{} <code>json:&quot;data,omitempty&quot;</code>
    Error   string      <code>json:&quot;error,omitempty&quot;</code>
}
<p>func respondJSON(w http.ResponseWriter, status int, payload interface{}) {
    response, err := json.Marshal(payload)
    if err != nil {
        w.WriteHeader(http.StatusInternalServerError)
        w.Write([]byte(<code>{&quot;success&quot;:false,&quot;error&quot;:&quot;Internal server error&quot;}</code>))
        return
    }
    
    w.Header().Set(&quot;Content-Type&quot;, &quot;application/json&quot;)
    w.WriteHeader(status)
    w.Write(response)
}</p>
<p>func respondError(w http.ResponseWriter, status int, message string) {
    respondJSON(w, status, APIResponse{
        Success: false,
        Error:   message,
    })
}</p>
<p>func respondSuccess(w http.ResponseWriter, data interface{}) {
    respondJSON(w, http.StatusOK, APIResponse{
        Success: true,
        Data:    data,
    })
}</p>
<p>// Usage
func getUserHandler(w http.ResponseWriter, r *http.Request) {
    user := User{ID: &quot;1&quot;, Name: &quot;Alice&quot;}
    respondSuccess(w, user)
}</code></pre></p>
<h3>Setting Headers</h3>
<pre><code class="language-go">func apiHandler(w http.ResponseWriter, r *http.Request) {
    // Set content type
    w.Header().Set(&quot;Content-Type&quot;, &quot;application/json&quot;)
    
    // Set custom headers
    w.Header().Set(&quot;X-API-Version&quot;, &quot;v1&quot;)
    w.Header().Set(&quot;X-Request-ID&quot;, &quot;abc123&quot;)
    
    // Set CORS headers
    w.Header().Set(&quot;Access-Control-Allow-Origin&quot;, &quot;*&quot;)
    w.Header().Set(&quot;Access-Control-Allow-Methods&quot;, &quot;GET, POST, PUT, DELETE&quot;)
    
    // Set caching headers
    w.Header().Set(&quot;Cache-Control&quot;, &quot;no-cache, no-store, must-revalidate&quot;)
    
    json.NewEncoder(w).Encode(map[string]string{&quot;status&quot;: &quot;ok&quot;})
}</code></pre>
<h3>Setting Cookies</h3>
<pre><code class="language-go">func loginHandler(w http.ResponseWriter, r *http.Request) {
    // Create session cookie
    cookie := &amp;http.Cookie{
        Name:     &quot;session_id&quot;,
        Value:    &quot;abc123xyz&quot;,
        Path:     &quot;/&quot;,
        MaxAge:   3600,  // 1 hour
        HttpOnly: true,  // Not accessible via JavaScript
        Secure:   true,  // Only sent over HTTPS
        SameSite: http.SameSiteStrictMode,
    }
    
    http.SetCookie(w, cookie)
    
    respondSuccess(w, map[string]string{&quot;message&quot;: &quot;Logged in&quot;})
}
<p>func logoutHandler(w http.ResponseWriter, r *http.Request) {
    // Delete cookie by setting MaxAge to -1
    cookie := &amp;http.Cookie{
        Name:   &quot;session_id&quot;,
        Value:  &quot;&quot;,
        Path:   &quot;/&quot;,
        MaxAge: -1,
    }
    
    http.SetCookie(w, cookie)
    respondSuccess(w, map[string]string{&quot;message&quot;: &quot;Logged out&quot;})
}</code></pre></p>
<p>---</p>
<h2>Middleware</h2>
<p>Middleware wraps handlers to add cross-cutting concerns:</p>
<h3>Basic Middleware Pattern</h3>
<pre><code class="language-go">// Middleware signature
type Middleware func(http.HandlerFunc) http.HandlerFunc
<p>// Example: Logging middleware
func loggingMiddleware(next http.HandlerFunc) http.HandlerFunc {
    return func(w http.ResponseWriter, r *http.Request) {
        start := time.Now()
        
        // Call next handler
        next(w, r)
        
        // Log after handler completes
        log.Printf(&quot;%s %s %v&quot;, r.Method, r.URL.Path, time.Since(start))
    }
}</p>
<p>// Usage
http.HandleFunc(&quot;/users&quot;, loggingMiddleware(usersHandler))</code></pre></p>
<h3>Common Middleware Examples</h3>
<pre><code class="language-go">// 1. Authentication Middleware
func authMiddleware(next http.HandlerFunc) http.HandlerFunc {
    return func(w http.ResponseWriter, r *http.Request) {
        token := r.Header.Get(&quot;Authorization&quot;)
        
        if token == &quot;&quot; {
            http.Error(w, &quot;Unauthorized&quot;, http.StatusUnauthorized)
            return
        }
        
        // Validate token (simplified)
        if !isValidToken(token) {
            http.Error(w, &quot;Invalid token&quot;, http.StatusUnauthorized)
            return
        }
        
        next(w, r)
    }
}
<p>// 2. CORS Middleware
func corsMiddleware(next http.HandlerFunc) http.HandlerFunc {
    return func(w http.ResponseWriter, r *http.Request) {
        w.Header().Set(&quot;Access-Control-Allow-Origin&quot;, &quot;*&quot;)
        w.Header().Set(&quot;Access-Control-Allow-Methods&quot;, &quot;GET, POST, PUT, DELETE, OPTIONS&quot;)
        w.Header().Set(&quot;Access-Control-Allow-Headers&quot;, &quot;Content-Type, Authorization&quot;)
        
        if r.Method == &quot;OPTIONS&quot; {
            w.WriteHeader(http.StatusOK)
            return
        }
        
        next(w, r)
    }
}</p>
<p>// 3. Rate Limiting Middleware
func rateLimitMiddleware(next http.HandlerFunc) http.HandlerFunc {
    limiter := time.Tick(100 * time.Millisecond)  // 10 requests per second
    
    return func(w http.ResponseWriter, r *http.Request) {
        &lt;-limiter  // Wait for rate limiter
        next(w, r)
    }
}</p>
<p>// 4. Request ID Middleware
func requestIDMiddleware(next http.HandlerFunc) http.HandlerFunc {
    return func(w http.ResponseWriter, r *http.Request) {
        requestID := uuid.New().String()
        w.Header().Set(&quot;X-Request-ID&quot;, requestID)
        
        // Add to context for use in handlers
        ctx := context.WithValue(r.Context(), &quot;requestID&quot;, requestID)
        next(w, r.WithContext(ctx))
    }
}</p>
<p>// 5. Recovery Middleware (Panic Recovery)
func recoveryMiddleware(next http.HandlerFunc) http.HandlerFunc {
    return func(w http.ResponseWriter, r *http.Request) {
        defer func() {
            if err := recover(); err != nil {
                log.Printf(&quot;Panic: %v&quot;, err)
                http.Error(w, &quot;Internal Server Error&quot;, http.StatusInternalServerError)
            }
        }()
        
        next(w, r)
    }
}</code></pre></p>
<h3>Chain Multiple Middleware</h3>
<pre><code class="language-go">// Chain middleware together
func chain(f http.HandlerFunc, middlewares ...Middleware) http.HandlerFunc {
    for _, m := range middlewares {
        f = m(f)
    }
    return f
}
<p>// Usage
func main() {
    http.HandleFunc(&quot;/api/users&quot;, chain(
        usersHandler,
        loggingMiddleware,
        authMiddleware,
        corsMiddleware,
    ))
    
    http.ListenAndServe(&quot;:8080&quot;, nil)
}</code></pre></p>
<h3>Middleware with gorilla/mux</h3>
<pre><code class="language-go">func main() {
    r := mux.NewRouter()
    
    // Apply middleware to all routes
    r.Use(loggingMiddleware)
    r.Use(corsMiddleware)
    
    // Apply to specific subrouter
    api := r.PathPrefix(&quot;/api&quot;).Subrouter()
    api.Use(authMiddleware)
    
    api.HandleFunc(&quot;/users&quot;, usersHandler)
    
    http.ListenAndServe(&quot;:8080&quot;, r)
}</code></pre>
<p>---</p>
<h2>Error Handling</h2>
<h3>Custom Error Types</h3>
<pre><code class="language-go">type APIError struct {
    StatusCode int    <code>json:&quot;-&quot;</code>
    Message    string <code>json:&quot;message&quot;</code>
    Detail     string <code>json:&quot;detail,omitempty&quot;</code>
}
<p>func (e *APIError) Error() string {
    return e.Message
}</p>
<p>// Predefined errors
var (
    ErrNotFound = &amp;APIError{
        StatusCode: http.StatusNotFound,
        Message:    &quot;Resource not found&quot;,
    }
    
    ErrUnauthorized = &amp;APIError{
        StatusCode: http.StatusUnauthorized,
        Message:    &quot;Unauthorized&quot;,
    }
    
    ErrBadRequest = &amp;APIError{
        StatusCode: http.StatusBadRequest,
        Message:    &quot;Bad request&quot;,
    }
)</p>
<p>// Error handler
func handleError(w http.ResponseWriter, err error) {
    if apiErr, ok := err.(*APIError); ok {
        respondError(w, apiErr.StatusCode, apiErr.Message)
        return
    }
    
    // Unknown error
    log.Printf(&quot;Internal error: %v&quot;, err)
    respondError(w, http.StatusInternalServerError, &quot;Internal server error&quot;)
}</p>
<p>// Usage in handler
func getUserHandler(w http.ResponseWriter, r *http.Request) {
    user, err := getUserFromDB(id)
    if err != nil {
        if err == sql.ErrNoRows {
            handleError(w, ErrNotFound)
            return
        }
        handleError(w, err)
        return
    }
    
    respondSuccess(w, user)
}</code></pre></p>
<p>---</p>
<h2>Request Validation</h2>
<h3>Manual Validation</h3>
<pre><code class="language-go">type CreateUserRequest struct {
    Name  string <code>json:&quot;name&quot;</code>
    Email string <code>json:&quot;email&quot;</code>
    Age   int    <code>json:&quot;age&quot;</code>
}
<p>func (r *CreateUserRequest) Validate() error {
    if r.Name == &quot;&quot; {
        return &amp;APIError{
            StatusCode: http.StatusBadRequest,
            Message:    &quot;name is required&quot;,
        }
    }
    
    if len(r.Name) &lt; 3 {
        return &amp;APIError{
            StatusCode: http.StatusBadRequest,
            Message:    &quot;name must be at least 3 characters&quot;,
        }
    }
    
    if r.Email == &quot;&quot; {
        return &amp;APIError{
            StatusCode: http.StatusBadRequest,
            Message:    &quot;email is required&quot;,
        }
    }
    
    // Simple email validation
    if !strings.Contains(r.Email, &quot;@&quot;) {
        return &amp;APIError{
            StatusCode: http.StatusBadRequest,
            Message:    &quot;invalid email format&quot;,
        }
    }
    
    if r.Age &lt; 18 || r.Age &gt; 120 {
        return &amp;APIError{
            StatusCode: http.StatusBadRequest,
            Message:    &quot;age must be between 18 and 120&quot;,
        }
    }
    
    return nil
}</p>
<p>func createUserHandler(w http.ResponseWriter, r *http.Request) {
    var req CreateUserRequest
    if err := json.NewDecoder(r.Body).Decode(&amp;req); err != nil {
        handleError(w, ErrBadRequest)
        return
    }
    
    if err := req.Validate(); err != nil {
        handleError(w, err)
        return
    }
    
    // Process valid request...
    respondSuccess(w, req)
}</code></pre></p>
<h3>Using Validator Library</h3>
<pre><code class="language-go">import &quot;github.com/go-playground/validator/v10&quot;
<p>type CreateUserRequest struct {
    Name  string <code>json:&quot;name&quot; validate:&quot;required,min=3,max=50&quot;</code>
    Email string <code>json:&quot;email&quot; validate:&quot;required,email&quot;</code>
    Age   int    <code>json:&quot;age&quot; validate:&quot;required,gte=18,lte=120&quot;</code>
}</p>
<p>var validate = validator.New()</p>
<p>func createUserHandler(w http.ResponseWriter, r *http.Request) {
    var req CreateUserRequest
    if err := json.NewDecoder(r.Body).Decode(&amp;req); err != nil {
        handleError(w, ErrBadRequest)
        return
    }
    
    if err := validate.Struct(req); err != nil {
        respondError(w, http.StatusBadRequest, err.Error())
        return
    }
    
    respondSuccess(w, req)
}</code></pre></p>
<p>---</p>
<h2>Popular Frameworks</h2>
<h3>1. Gin (Fast & Popular)</h3>
<pre><code class="language-go">import &quot;github.com/gin-gonic/gin&quot;
<p>func main() {
    r := gin.Default()
    
    r.GET(&quot;/users&quot;, getUsers)
    r.GET(&quot;/users/:id&quot;, getUser)
    r.POST(&quot;/users&quot;, createUser)
    
    r.Run(&quot;:8080&quot;)
}</p>
<p>func getUser(c *gin.Context) {
    id := c.Param(&quot;id&quot;)
    c.JSON(200, gin.H{
        &quot;id&quot;:   id,
        &quot;name&quot;: &quot;Alice&quot;,
    })
}</code></pre></p>
<h3>2. Echo (Minimalist)</h3>
<pre><code class="language-go">import &quot;github.com/labstack/echo/v4&quot;
<p>func main() {
    e := echo.New()
    
    e.GET(&quot;/users/:id&quot;, getUser)
    e.Start(&quot;:8080&quot;)
}</p>
<p>func getUser(c echo.Context) error {
    id := c.Param(&quot;id&quot;)
    return c.JSON(200, map[string]string{
        &quot;id&quot;:   id,
        &quot;name&quot;: &quot;Alice&quot;,
    })
}</code></pre></p>
<h3>3. Fiber (Express-like)</h3>
<pre><code class="language-go">import &quot;github.com/gofiber/fiber/v2&quot;
<p>func main() {
    app := fiber.New()
    
    app.Get(&quot;/users/:id&quot;, getUser)
    app.Listen(&quot;:8080&quot;)
}</p>
<p>func getUser(c *fiber.Ctx) error {
    id := c.Params(&quot;id&quot;)
    return c.JSON(fiber.Map{
        &quot;id&quot;:   id,
        &quot;name&quot;: &quot;Alice&quot;,
    })
}</code></pre></p>
<p>---</p>
<h2>Best Practices</h2>
<h3>1. Use Proper HTTP Methods</h3>
<pre><code class="language-go">// ‚úÖ RESTful design
GET    /users       // List users
POST   /users       // Create user
GET    /users/:id   // Get user
PUT    /users/:id   // Update user
DELETE /users/:id   // Delete user
<p>// ‚ùå Non-RESTful
GET /getUsers
POST /createUser</code></pre></p>
<h3>2. Return Appropriate Status Codes</h3>
<pre><code class="language-go">// ‚úÖ Correct
w.WriteHeader(http.StatusCreated)      // 201 for created
w.WriteHeader(http.StatusNoContent)    // 204 for successful delete
w.WriteHeader(http.StatusNotFound)     // 404 for not found
<p>// ‚ùå Returning 200 for everything</code></pre></p>
<h3>3. Use Structured Logging</h3>
<pre><code class="language-go">import &quot;go.uber.org/zap&quot;
<p>logger, _ := zap.NewProduction()
defer logger.Sync()</p>
<p>logger.Info(&quot;User created&quot;,
    zap.String(&quot;user_id&quot;, &quot;123&quot;),
    zap.String(&quot;method&quot;, &quot;POST&quot;),
)</code></pre></p>
<h3>4. Handle Timeouts</h3>
<pre><code class="language-go">ctx, cancel := context.WithTimeout(r.Context(), 5*time.Second)
defer cancel()
<p>// Use ctx in database calls, HTTP requests, etc.</code></pre></p>
<h3>5. Validate Input</h3>
<pre><code class="language-go">// Always validate and sanitize user input
if req.Email == &quot;&quot; || !isValidEmail(req.Email) {
    return ErrBadRequest
}</code></pre>
<p>---</p>
<h2>Interview Questions</h2>
<strong>Q1: What's the difference between PUT and PATCH?</strong>
<strong>Answer:</strong> 
<li><strong>PUT</strong> replaces the entire resource (all fields must be provided)</li>
<li><strong>PATCH</strong> partially updates the resource (only provided fields are updated)</li>
<strong>Q2: How do you handle CORS in Go?</strong>
<strong>Answer:</strong> Set appropriate headers in middleware or handler:
<pre><code class="language-go">w.Header().Set(&quot;Access-Control-Allow-Origin&quot;, &quot;*&quot;)
w.Header().Set(&quot;Access-Control-Allow-Methods&quot;, &quot;GET, POST, PUT, DELETE&quot;)
w.Header().Set(&quot;Access-Control-Allow-Headers&quot;, &quot;Content-Type, Authorization&quot;)</code></pre>
<strong>Q3: What's the difference between http.Error and writing custom JSON errors?</strong>
<strong>Answer:</strong> <code>http.Error</code> sends plain text. For APIs, custom JSON errors provide:
<li>Structured error format</li>
<li>Error codes</li>
<li>Additional context</li>
<li>Better client parsing</li>
<strong>Q4: How do you implement middleware in Go?</strong>
<strong>Answer:</strong> Wrap handlers with functions that take and return <code>http.HandlerFunc</code>:
<pre><code class="language-go">func middleware(next http.HandlerFunc) http.HandlerFunc {
    return func(w http.ResponseWriter, r *http.Request) {
        // Before
        next(w, r)
        // After
    }
}</code></pre>
<p>---</p>
<h2>Hands-On Exercise</h2>
<h3>Task: Build a Complete REST API for a Todo Application</h3>
<strong>Requirements:</strong>
1. CRUD operations for todos
2. Proper error handling
3. Input validation
4. Middleware (logging, CORS, auth)
5. Structured JSON responses
6. In-memory storage (slice)
<strong>API Endpoints:</strong>
<pre><code class="language-text">GET    /api/todos           # List all todos
GET    /api/todos/:id       # Get todo by ID
POST   /api/todos           # Create todo
PUT    /api/todos/:id       # Update todo
DELETE /api/todos/:id       # Delete todo</code></pre>
<strong>Starter Code:</strong>
<pre><code class="language-go">package main
<p>import (
    &quot;encoding/json&quot;
    &quot;log&quot;
    &quot;net/http&quot;
    &quot;sync&quot;
    
    &quot;github.com/gorilla/mux&quot;
)</p>
<p>type Todo struct {
    ID        string <code>json:&quot;id&quot;</code>
    Title     string <code>json:&quot;title&quot;</code>
    Completed bool   <code>json:&quot;completed&quot;</code>
}</p>
<p>type TodoStore struct {
    mu    sync.RWMutex
    todos map[string]Todo
}</p>
<p>var store = &amp;TodoStore{
    todos: make(map[string]Todo),
}</p>
<p>// TODO: Implement handlers
func getTodos(w http.ResponseWriter, r *http.Request) {
    // Return all todos
}</p>
<p>func getTodo(w http.ResponseWriter, r *http.Request) {
    // Return single todo
}</p>
<p>func createTodo(w http.ResponseWriter, r *http.Request) {
    // Create new todo
}</p>
<p>func updateTodo(w http.ResponseWriter, r *http.Request) {
    // Update existing todo
}</p>
<p>func deleteTodo(w http.ResponseWriter, r *http.Request) {
    // Delete todo
}</p>
<p>// TODO: Implement middleware
func loggingMiddleware(next http.Handler) http.Handler {
    // Log requests
    return nil
}</p>
<p>func main() {
    r := mux.NewRouter()
    
    // TODO: Set up routes
    
    log.Println(&quot;Server starting on :8080&quot;)
    log.Fatal(http.ListenAndServe(&quot;:8080&quot;, r))
}</code></pre></p>
<strong>Test with curl:</strong>
<pre><code class="language-bash"># Create
curl -X POST http://localhost:8080/api/todos \
  -H &quot;Content-Type: application/json&quot; \
  -d &#039;{&quot;title&quot;:&quot;Learn Go&quot;,&quot;completed&quot;:false}&#039;
<h1>List</h1>
curl http://localhost:8080/api/todos
<h1>Get one</h1>
curl http://localhost:8080/api/todos/1
<h1>Update</h1>
curl -X PUT http://localhost:8080/api/todos/1 \
  -H &quot;Content-Type: application/json&quot; \
  -d &#039;{&quot;title&quot;:&quot;Learn Go&quot;,&quot;completed&quot;:true}&#039;
<h1>Delete</h1>
curl -X DELETE http://localhost:8080/api/todos/1</code></pre>
<p>---</p>
<h2>üìö Additional Resources</h2>
<li>[Go net/http Documentation](https://pkg.go.dev/net/http)</li>
<li>[Gorilla Mux](https://github.com/gorilla/mux)</li>
<li>[REST API Best Practices](https://restfulapi.net/)</li>
<li>[HTTP Status Codes](https://httpstatuses.com/)</li>
<p>---</p>
<h2>‚úÖ Module Checklist</h2>
<p>Before moving to the next module, ensure you can:</p>
<li>[ ] Build HTTP servers with net/http</li>
<li>[ ] Implement RESTful routing</li>
<li>[ ] Handle different HTTP methods</li>
<li>[ ] Read requests (query params, body, headers)</li>
<li>[ ] Write JSON responses</li>
<li>[ ] Create and use middleware</li>
<li>[ ] Implement proper error handling</li>
<li>[ ] Validate input data</li>
<li>[ ] Use popular routers (gorilla/mux)</li>
<li>[ ] Complete the hands-on exercise</li></ul>
<p>---</p>
<strong>Next Module:</strong> [04_Go_Database_Integration.md](./04_Go_Database_Integration.md) - Connect to databases! üóÑÔ∏è

    </div>
    

    <div class="module-content" id="module-4">
        <h1>Module 04: Database Integration with Go üóÑÔ∏è</h1>
<h2>Connect Go Applications to Databases</h2>
<strong>Duration:</strong> 4-5 hours  
<strong>Prerequisites:</strong> Module 01-03 (Fundamentals, Concurrency, REST APIs)  
<strong>Outcome:</strong> Build database-backed applications with proper connection management
<p>---</p>
<h2>üìö Table of Contents</h2>
<p>1. [Database Basics](#database-basics)
2. [database/sql Package](#databasesql-package)
3. [PostgreSQL Integration](#postgresql-integration)
4. [GORM (ORM Framework)](#gorm-orm-framework)
5. [Connection Pooling](#connection-pooling)
6. [Transactions](#transactions)
7. [Migrations](#migrations)
8. [Redis Integration](#redis-integration)
9. [MongoDB Integration](#mongodb-integration)
10. [Best Practices](#best-practices)
11. [Interview Questions](#interview-questions)
12. [Hands-On Exercise](#hands-on-exercise)</p>
<p>---</p>
<h2>Database Basics</h2>
<h3>SQL vs NoSQL</h3>
<p>| Feature | SQL | NoSQL |
|---------|-----|-------|
| Schema | Fixed | Flexible |
| Scaling | Vertical | Horizontal |
| Examples | PostgreSQL, MySQL | MongoDB, Redis |
| Best For | Structured data, ACID | Unstructured, high throughput |</p>
<h3>Popular Go Database Drivers</h3>
<pre><code class="language-bash"># PostgreSQL
go get github.com/lib/pq
<h1>MySQL</h1>
go get github.com/go-sql-driver/mysql
<h1>SQLite</h1>
go get github.com/mattn/go-sqlite3
<h1>MongoDB</h1>
go get go.mongodb.org/mongo-driver/mongo
<h1>Redis</h1>
go get github.com/go-redis/redis/v8</code></pre>
<p>---</p>
<h2>database/sql Package</h2>
<p>Go's standard library provides a generic interface for SQL databases:</p>
<h3>Basic Connection</h3>
<pre><code class="language-go">package main
<p>import (
    &quot;database/sql&quot;
    &quot;fmt&quot;
    &quot;log&quot;
    
    _ &quot;github.com/lib/pq&quot;  // PostgreSQL driver
)</p>
<p>func main() {
    // Connection string
    connStr := &quot;host=localhost port=5432 user=postgres password=secret dbname=mydb sslmode=disable&quot;
    
    // Open connection
    db, err := sql.Open(&quot;postgres&quot;, connStr)
    if err != nil {
        log.Fatal(err)
    }
    defer db.Close()
    
    // Test connection
    if err := db.Ping(); err != nil {
        log.Fatal(err)
    }
    
    fmt.Println(&quot;Successfully connected to database!&quot;)
}</code></pre></p>
<h3>Query Single Row</h3>
<pre><code class="language-go">type User struct {
    ID    int
    Name  string
    Email string
    Age   int
}
<p>func getUserByID(db *sql.DB, id int) (*User, error) {
    user := &amp;User{}
    
    query := <code>SELECT id, name, email, age FROM users WHERE id = $1</code>
    
    err := db.QueryRow(query, id).Scan(&amp;user.ID, &amp;user.Name, &amp;user.Email, &amp;user.Age)
    if err != nil {
        if err == sql.ErrNoRows {
            return nil, fmt.Errorf(&quot;user not found&quot;)
        }
        return nil, err
    }
    
    return user, nil
}</p>
<p>// Usage
user, err := getUserByID(db, 1)
if err != nil {
    log.Fatal(err)
}
fmt.Printf(&quot;User: %+v\n&quot;, user)</code></pre></p>
<h3>Query Multiple Rows</h3>
<pre><code class="language-go">func getAllUsers(db *sql.DB) ([]User, error) {
    query := <code>SELECT id, name, email, age FROM users ORDER BY id</code>
    
    rows, err := db.Query(query)
    if err != nil {
        return nil, err
    }
    defer rows.Close()  // Important!
    
    var users []User
    for rows.Next() {
        var user User
        if err := rows.Scan(&amp;user.ID, &amp;user.Name, &amp;user.Email, &amp;user.Age); err != nil {
            return nil, err
        }
        users = append(users, user)
    }
    
    // Check for errors during iteration
    if err := rows.Err(); err != nil {
        return nil, err
    }
    
    return users, nil
}</code></pre>
<h3>Insert Data</h3>
<pre><code class="language-go">func createUser(db *sql.DB, name, email string, age int) (int, error) {
    query := <code>
        INSERT INTO users (name, email, age) 
        VALUES ($1, $2, $3) 
        RETURNING id
    </code>
    
    var id int
    err := db.QueryRow(query, name, email, age).Scan(&amp;id)
    if err != nil {
        return 0, err
    }
    
    return id, nil
}
<p>// Usage
userID, err := createUser(db, &quot;Alice&quot;, &quot;alice@example.com&quot;, 30)
if err != nil {
    log.Fatal(err)
}
fmt.Printf(&quot;Created user with ID: %d\n&quot;, userID)</code></pre></p>
<h3>Update Data</h3>
<pre><code class="language-go">func updateUser(db *sql.DB, id int, name, email string, age int) error {
    query := <code>
        UPDATE users 
        SET name = $1, email = $2, age = $3 
        WHERE id = $4
    </code>
    
    result, err := db.Exec(query, name, email, age, id)
    if err != nil {
        return err
    }
    
    // Check how many rows were affected
    rowsAffected, err := result.RowsAffected()
    if err != nil {
        return err
    }
    
    if rowsAffected == 0 {
        return fmt.Errorf(&quot;user not found&quot;)
    }
    
    return nil
}</code></pre>
<h3>Delete Data</h3>
<pre><code class="language-go">func deleteUser(db *sql.DB, id int) error {
    query := <code>DELETE FROM users WHERE id = $1</code>
    
    result, err := db.Exec(query, id)
    if err != nil {
        return err
    }
    
    rowsAffected, err := result.RowsAffected()
    if err != nil {
        return err
    }
    
    if rowsAffected == 0 {
        return fmt.Errorf(&quot;user not found&quot;)
    }
    
    return nil
}</code></pre>
<p>---</p>
<h2>PostgreSQL Integration</h2>
<h3>Complete CRUD Example</h3>
<pre><code class="language-go">package main
<p>import (
    &quot;database/sql&quot;
    &quot;fmt&quot;
    &quot;log&quot;
    &quot;time&quot;
    
    _ &quot;github.com/lib/pq&quot;
)</p>
<p>type User struct {
    ID        int       <code>json:&quot;id&quot;</code>
    Name      string    <code>json:&quot;name&quot;</code>
    Email     string    <code>json:&quot;email&quot;</code>
    Age       int       <code>json:&quot;age&quot;</code>
    CreatedAt time.Time <code>json:&quot;created_at&quot;</code>
    UpdatedAt time.Time <code>json:&quot;updated_at&quot;</code>
}</p>
<p>type UserStore struct {
    db *sql.DB
}</p>
<p>func NewUserStore(db *sql.DB) *UserStore {
    return &amp;UserStore{db: db}
}</p>
<p>// Create
func (s *UserStore) Create(user *User) error {
    query := <code>
        INSERT INTO users (name, email, age, created_at, updated_at)
        VALUES ($1, $2, $3, $4, $5)
        RETURNING id
    </code>
    
    now := time.Now()
    err := s.db.QueryRow(
        query,
        user.Name,
        user.Email,
        user.Age,
        now,
        now,
    ).Scan(&amp;user.ID)
    
    if err != nil {
        return fmt.Errorf(&quot;failed to create user: %w&quot;, err)
    }
    
    user.CreatedAt = now
    user.UpdatedAt = now
    return nil
}</p>
<p>// Read
func (s *UserStore) GetByID(id int) (*User, error) {
    user := &amp;User{}
    query := <code>
        SELECT id, name, email, age, created_at, updated_at
        FROM users
        WHERE id = $1
    </code>
    
    err := s.db.QueryRow(query, id).Scan(
        &amp;user.ID,
        &amp;user.Name,
        &amp;user.Email,
        &amp;user.Age,
        &amp;user.CreatedAt,
        &amp;user.UpdatedAt,
    )
    
    if err == sql.ErrNoRows {
        return nil, fmt.Errorf(&quot;user not found&quot;)
    }
    if err != nil {
        return nil, fmt.Errorf(&quot;failed to get user: %w&quot;, err)
    }
    
    return user, nil
}</p>
<p>// List with pagination
func (s *UserStore) List(limit, offset int) ([]User, error) {
    query := <code>
        SELECT id, name, email, age, created_at, updated_at
        FROM users
        ORDER BY id
        LIMIT $1 OFFSET $2
    </code>
    
    rows, err := s.db.Query(query, limit, offset)
    if err != nil {
        return nil, fmt.Errorf(&quot;failed to list users: %w&quot;, err)
    }
    defer rows.Close()
    
    var users []User
    for rows.Next() {
        var user User
        if err := rows.Scan(
            &amp;user.ID,
            &amp;user.Name,
            &amp;user.Email,
            &amp;user.Age,
            &amp;user.CreatedAt,
            &amp;user.UpdatedAt,
        ); err != nil {
            return nil, fmt.Errorf(&quot;failed to scan user: %w&quot;, err)
        }
        users = append(users, user)
    }
    
    return users, rows.Err()
}</p>
<p>// Update
func (s *UserStore) Update(user *User) error {
    query := <code>
        UPDATE users
        SET name = $1, email = $2, age = $3, updated_at = $4
        WHERE id = $5
    </code>
    
    user.UpdatedAt = time.Now()
    result, err := s.db.Exec(
        query,
        user.Name,
        user.Email,
        user.Age,
        user.UpdatedAt,
        user.ID,
    )
    
    if err != nil {
        return fmt.Errorf(&quot;failed to update user: %w&quot;, err)
    }
    
    rows, err := result.RowsAffected()
    if err != nil {
        return err
    }
    if rows == 0 {
        return fmt.Errorf(&quot;user not found&quot;)
    }
    
    return nil
}</p>
<p>// Delete
func (s *UserStore) Delete(id int) error {
    query := <code>DELETE FROM users WHERE id = $1</code>
    
    result, err := s.db.Exec(query, id)
    if err != nil {
        return fmt.Errorf(&quot;failed to delete user: %w&quot;, err)
    }
    
    rows, err := result.RowsAffected()
    if err != nil {
        return err
    }
    if rows == 0 {
        return fmt.Errorf(&quot;user not found&quot;)
    }
    
    return nil
}</p>
<p>func main() {
    // Connect to database
    connStr := &quot;host=localhost port=5432 user=postgres password=secret dbname=mydb sslmode=disable&quot;
    db, err := sql.Open(&quot;postgres&quot;, connStr)
    if err != nil {
        log.Fatal(err)
    }
    defer db.Close()
    
    // Create store
    store := NewUserStore(db)
    
    // Create user
    user := &amp;User{
        Name:  &quot;Alice&quot;,
        Email: &quot;alice@example.com&quot;,
        Age:   30,
    }
    
    if err := store.Create(user); err != nil {
        log.Fatal(err)
    }
    fmt.Printf(&quot;Created user: %+v\n&quot;, user)
    
    // Get user
    retrieved, err := store.GetByID(user.ID)
    if err != nil {
        log.Fatal(err)
    }
    fmt.Printf(&quot;Retrieved user: %+v\n&quot;, retrieved)
    
    // Update user
    user.Age = 31
    if err := store.Update(user); err != nil {
        log.Fatal(err)
    }
    fmt.Println(&quot;Updated user&quot;)
    
    // List users
    users, err := store.List(10, 0)
    if err != nil {
        log.Fatal(err)
    }
    fmt.Printf(&quot;Found %d users\n&quot;, len(users))
}</code></pre></p>
<p>---</p>
<h2>GORM (ORM Framework)</h2>
<p>GORM is the most popular Go ORM, providing a higher-level abstraction:</p>
<h3>Installation</h3>
<pre><code class="language-bash">go get -u gorm.io/gorm
go get -u gorm.io/driver/postgres</code></pre>
<h3>Basic Usage</h3>
<pre><code class="language-go">package main
<p>import (
    &quot;fmt&quot;
    &quot;log&quot;
    &quot;time&quot;
    
    &quot;gorm.io/driver/postgres&quot;
    &quot;gorm.io/gorm&quot;
)</p>
<p>type User struct {
    ID        uint           <code>gorm:&quot;primaryKey&quot;</code>
    Name      string         <code>gorm:&quot;size:100;not null&quot;</code>
    Email     string         <code>gorm:&quot;size:100;uniqueIndex;not null&quot;</code>
    Age       int            <code>gorm:&quot;not null&quot;</code>
    CreatedAt time.Time
    UpdatedAt time.Time
    DeletedAt gorm.DeletedAt <code>gorm:&quot;index&quot;</code>  // Soft delete
}</p>
<p>func main() {
    // Connect
    dsn := &quot;host=localhost user=postgres password=secret dbname=mydb port=5432 sslmode=disable&quot;
    db, err := gorm.Open(postgres.Open(dsn), &amp;gorm.Config{})
    if err != nil {
        log.Fatal(err)
    }
    
    // Auto-migrate schema
    db.AutoMigrate(&amp;User{})
    
    // Create
    user := User{Name: &quot;Alice&quot;, Email: &quot;alice@example.com&quot;, Age: 30}
    result := db.Create(&amp;user)
    if result.Error != nil {
        log.Fatal(result.Error)
    }
    fmt.Printf(&quot;Created user with ID: %d\n&quot;, user.ID)
    
    // Read
    var foundUser User
    db.First(&amp;foundUser, user.ID)  // Find by primary key
    fmt.Printf(&quot;Found user: %+v\n&quot;, foundUser)
    
    // Update
    db.Model(&amp;foundUser).Update(&quot;Age&quot;, 31)
    // Or update multiple fields
    db.Model(&amp;foundUser).Updates(User{Name: &quot;Alice Smith&quot;, Age: 32})
    
    // Delete (soft delete if DeletedAt field exists)
    db.Delete(&amp;foundUser)
    
    // Permanently delete
    db.Unscoped().Delete(&amp;foundUser)
}</code></pre></p>
<h3>Advanced GORM Queries</h3>
<pre><code class="language-go">// Find with conditions
var users []User
db.Where(&quot;age &gt; ?&quot;, 25).Find(&amp;users)
db.Where(&quot;name LIKE ?&quot;, &quot;A%&quot;).Find(&amp;users)
<p>// First, Last, Take
var user User
db.First(&amp;user)  // ORDER BY id ASC LIMIT 1
db.Last(&amp;user)   // ORDER BY id DESC LIMIT 1
db.Take(&amp;user)   // No ordering</p>
<p>// Select specific fields
db.Select(&quot;name&quot;, &quot;age&quot;).Find(&amp;users)</p>
<p>// Order and limit
db.Order(&quot;age desc&quot;).Limit(10).Find(&amp;users)</p>
<p>// Count
var count int64
db.Model(&amp;User{}).Where(&quot;age &gt; ?&quot;, 25).Count(&amp;count)</p>
<p>// Group and Having
type Result struct {
    Age   int
    Count int
}
var results []Result
db.Model(&amp;User{}).Select(&quot;age, count(*)&quot;).Group(&quot;age&quot;).Having(&quot;count(*) &gt; ?&quot;, 1).Scan(&amp;results)</p>
<p>// Pagination
var users []User
page := 1
pageSize := 10
offset := (page - 1) * pageSize
db.Offset(offset).Limit(pageSize).Find(&amp;users)</p>
<p>// Raw SQL
var users []User
db.Raw(&quot;SELECT * FROM users WHERE age &gt; ?&quot;, 25).Scan(&amp;users)</p>
<p>// Exec raw SQL
db.Exec(&quot;UPDATE users SET age = age + 1 WHERE id = ?&quot;, 1)</code></pre></p>
<h3>Associations</h3>
<pre><code class="language-go">// One-to-Many
type User struct {
    gorm.Model
    Name  string
    Posts []Post
}
<p>type Post struct {
    gorm.Model
    Title  string
    UserID uint
    User   User
}</p>
<p>// Create with association
user := User{
    Name: &quot;Alice&quot;,
    Posts: []Post{
        {Title: &quot;First Post&quot;},
        {Title: &quot;Second Post&quot;},
    },
}
db.Create(&amp;user)</p>
<p>// Preload associations
var users []User
db.Preload(&quot;Posts&quot;).Find(&amp;users)</p>
<p>// Many-to-Many
type User struct {
    gorm.Model
    Name  string
    Roles []Role <code>gorm:&quot;many2many:user_roles;&quot;</code>
}</p>
<p>type Role struct {
    gorm.Model
    Name  string
    Users []User <code>gorm:&quot;many2many:user_roles;&quot;</code>
}</code></pre></p>
<p>---</p>
<h2>Connection Pooling</h2>
<h3>Configure Connection Pool</h3>
<pre><code class="language-go">import &quot;time&quot;
<p>func setupDB() (*sql.DB, error) {
    db, err := sql.Open(&quot;postgres&quot;, connStr)
    if err != nil {
        return nil, err
    }
    
    // Set maximum number of open connections
    db.SetMaxOpenConns(25)
    
    // Set maximum number of idle connections
    db.SetMaxIdleConns(25)
    
    // Set maximum lifetime of a connection
    db.SetConnMaxLifetime(5 * time.Minute)
    
    // Set maximum idle time
    db.SetConnMaxIdleTime(5 * time.Minute)
    
    // Test connection
    if err := db.Ping(); err != nil {
        return nil, err
    }
    
    return db, nil
}</code></pre></p>
<h3>Connection Pool Stats</h3>
<pre><code class="language-go">stats := db.Stats()
fmt.Printf(&quot;Open connections: %d\n&quot;, stats.OpenConnections)
fmt.Printf(&quot;In use: %d\n&quot;, stats.InUse)
fmt.Printf(&quot;Idle: %d\n&quot;, stats.Idle)
fmt.Printf(&quot;Wait count: %d\n&quot;, stats.WaitCount)
fmt.Printf(&quot;Wait duration: %v\n&quot;, stats.WaitDuration)</code></pre>
<p>---</p>
<h2>Transactions</h2>
<h3>Basic Transaction</h3>
<pre><code class="language-go">func transferMoney(db *sql.DB, fromID, toID int, amount float64) error {
    // Begin transaction
    tx, err := db.Begin()
    if err != nil {
        return err
    }
    
    // Defer rollback (no-op if commit succeeds)
    defer tx.Rollback()
    
    // Deduct from sender
    _, err = tx.Exec(&quot;UPDATE accounts SET balance = balance - $1 WHERE id = $2&quot;, amount, fromID)
    if err != nil {
        return err
    }
    
    // Add to receiver
    _, err = tx.Exec(&quot;UPDATE accounts SET balance = balance + $1 WHERE id = $2&quot;, amount, toID)
    if err != nil {
        return err
    }
    
    // Commit transaction
    if err = tx.Commit(); err != nil {
        return err
    }
    
    return nil
}</code></pre>
<h3>Transaction with Context</h3>
<pre><code class="language-go">func transferMoneyWithContext(ctx context.Context, db *sql.DB, fromID, toID int, amount float64) error {
    tx, err := db.BeginTx(ctx, nil)
    if err != nil {
        return err
    }
    defer tx.Rollback()
    
    // Check context cancellation
    select {
    case &lt;-ctx.Done():
        return ctx.Err()
    default:
    }
    
    // Perform operations...
    
    return tx.Commit()
}</code></pre>
<h3>GORM Transactions</h3>
<pre><code class="language-go">// Automatic transaction
err := db.Transaction(func(tx *gorm.DB) error {
    // Create user
    if err := tx.Create(&amp;user).Error; err != nil {
        return err  // Rollback
    }
    
    // Create profile
    if err := tx.Create(&amp;profile).Error; err != nil {
        return err  // Rollback
    }
    
    return nil  // Commit
})
<p>// Manual transaction
tx := db.Begin()
defer func() {
    if r := recover(); r != nil {
        tx.Rollback()
    }
}()</p>
<p>if err := tx.Create(&amp;user).Error; err != nil {
    tx.Rollback()
    return err
}</p>
<p>if err := tx.Create(&amp;profile).Error; err != nil {
    tx.Rollback()
    return err
}</p>
<p>tx.Commit()</code></pre></p>
<p>---</p>
<h2>Migrations</h2>
<h3>Using golang-migrate</h3>
<pre><code class="language-bash">go install -tags &#039;postgres&#039; github.com/golang-migrate/migrate/v4/cmd/migrate@latest</code></pre>
<pre><code class="language-bash"># Create migration
migrate create -ext sql -dir db/migrations -seq create_users_table
<h1>This creates:</h1>
<h1>db/migrations/000001_create_users_table.up.sql</h1>
<h1>db/migrations/000001_create_users_table.down.sql</code></pre></h1>
<strong>Up migration (000001_create_users_table.up.sql):</strong>
<pre><code class="language-sql">CREATE TABLE users (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    age INTEGER NOT NULL,
    created_at TIMESTAMP NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMP NOT NULL DEFAULT NOW()
);
<p>CREATE INDEX idx_users_email ON users(email);</code></pre></p>
<strong>Down migration (000001_create_users_table.down.sql):</strong>
<pre><code class="language-sql">DROP TABLE IF EXISTS users;</code></pre>
<pre><code class="language-bash"># Run migrations
migrate -path db/migrations -database &quot;postgres://user:pass@localhost:5432/mydb?sslmode=disable&quot; up
<h1>Rollback</h1>
migrate -path db/migrations -database &quot;postgres://...&quot; down
<h1>Migrate to specific version</h1>
migrate -path db/migrations -database &quot;postgres://...&quot; goto 2</code></pre>
<h3>GORM Auto-Migration</h3>
<pre><code class="language-go">// Auto-migrate (development only!)
db.AutoMigrate(&amp;User{}, &amp;Post{}, &amp;Comment{})
<p>// Check if table exists
if !db.Migrator().HasTable(&amp;User{}) {
    db.Migrator().CreateTable(&amp;User{})
}</p>
<p>// Add column
db.Migrator().AddColumn(&amp;User{}, &quot;active&quot;)</p>
<p>// Drop column
db.Migrator().DropColumn(&amp;User{}, &quot;age&quot;)</code></pre></p>
<p>---</p>
<h2>Redis Integration</h2>
<pre><code class="language-go">package main
<p>import (
    &quot;context&quot;
    &quot;fmt&quot;
    &quot;time&quot;
    
    &quot;github.com/go-redis/redis/v8&quot;
)</p>
<p>var ctx = context.Background()</p>
<p>func main() {
    // Connect to Redis
    rdb := redis.NewClient(&amp;redis.Options{
        Addr:     &quot;localhost:6379&quot;,
        Password: &quot;&quot;,
        DB:       0,
    })
    
    // Ping
    pong, err := rdb.Ping(ctx).Result()
    fmt.Println(pong, err)
    
    // Set key
    err = rdb.Set(ctx, &quot;key&quot;, &quot;value&quot;, 0).Err()
    if err != nil {
        panic(err)
    }
    
    // Get key
    val, err := rdb.Get(ctx, &quot;key&quot;).Result()
    if err != nil {
        panic(err)
    }
    fmt.Println(&quot;key:&quot;, val)
    
    // Set with expiration
    err = rdb.Set(ctx, &quot;session:123&quot;, &quot;user_data&quot;, 10*time.Minute).Err()
    
    // Check if key exists
    exists, err := rdb.Exists(ctx, &quot;key&quot;).Result()
    fmt.Println(&quot;exists:&quot;, exists)
    
    // Delete key
    err = rdb.Del(ctx, &quot;key&quot;).Err()
    
    // Hash operations
    err = rdb.HSet(ctx, &quot;user:1&quot;, &quot;name&quot;, &quot;Alice&quot;, &quot;age&quot;, 30).Err()
    name, err := rdb.HGet(ctx, &quot;user:1&quot;, &quot;name&quot;).Result()
    all, err := rdb.HGetAll(ctx, &quot;user:1&quot;).Result()
    
    // List operations
    err = rdb.LPush(ctx, &quot;queue&quot;, &quot;task1&quot;, &quot;task2&quot;).Err()
    task, err := rdb.RPop(ctx, &quot;queue&quot;).Result()
    
    // Set operations
    err = rdb.SAdd(ctx, &quot;tags&quot;, &quot;go&quot;, &quot;redis&quot;, &quot;database&quot;).Err()
    members, err := rdb.SMembers(ctx, &quot;tags&quot;).Result()
    
    // Sorted set
    err = rdb.ZAdd(ctx, &quot;leaderboard&quot;, &amp;redis.Z{Score: 100, Member: &quot;player1&quot;}).Err()
    top, err := rdb.ZRevRange(ctx, &quot;leaderboard&quot;, 0, 9).Result()
}</code></pre></p>
<p>---</p>
<h2>MongoDB Integration</h2>
<pre><code class="language-go">package main
<p>import (
    &quot;context&quot;
    &quot;fmt&quot;
    &quot;log&quot;
    &quot;time&quot;
    
    &quot;go.mongodb.org/mongo-driver/bson&quot;
    &quot;go.mongodb.org/mongo-driver/bson/primitive&quot;
    &quot;go.mongodb.org/mongo-driver/mongo&quot;
    &quot;go.mongodb.org/mongo-driver/mongo/options&quot;
)</p>
<p>type User struct {
    ID        primitive.ObjectID <code>bson:&quot;_id,omitempty&quot;</code>
    Name      string             <code>bson:&quot;name&quot;</code>
    Email     string             <code>bson:&quot;email&quot;</code>
    Age       int                <code>bson:&quot;age&quot;</code>
    CreatedAt time.Time          <code>bson:&quot;created_at&quot;</code>
}</p>
<p>func main() {
    ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
    defer cancel()
    
    // Connect
    client, err := mongo.Connect(ctx, options.Client().ApplyURI(&quot;mongodb://localhost:27017&quot;))
    if err != nil {
        log.Fatal(err)
    }
    defer client.Disconnect(ctx)
    
    // Get collection
    collection := client.Database(&quot;mydb&quot;).Collection(&quot;users&quot;)
    
    // Insert one
    user := User{
        Name:      &quot;Alice&quot;,
        Email:     &quot;alice@example.com&quot;,
        Age:       30,
        CreatedAt: time.Now(),
    }
    result, err := collection.InsertOne(ctx, user)
    fmt.Printf(&quot;Inserted ID: %v\n&quot;, result.InsertedID)
    
    // Find one
    var foundUser User
    err = collection.FindOne(ctx, bson.M{&quot;email&quot;: &quot;alice@example.com&quot;}).Decode(&amp;foundUser)
    fmt.Printf(&quot;Found: %+v\n&quot;, foundUser)
    
    // Find many
    cursor, err := collection.Find(ctx, bson.M{&quot;age&quot;: bson.M{&quot;$gt&quot;: 25}})
    defer cursor.Close(ctx)
    
    var users []User
    if err = cursor.All(ctx, &amp;users); err != nil {
        log.Fatal(err)
    }
    fmt.Printf(&quot;Found %d users\n&quot;, len(users))
    
    // Update
    update := bson.M{&quot;$set&quot;: bson.M{&quot;age&quot;: 31}}
    _, err = collection.UpdateOne(ctx, bson.M{&quot;email&quot;: &quot;alice@example.com&quot;}, update)
    
    // Delete
    _, err = collection.DeleteOne(ctx, bson.M{&quot;email&quot;: &quot;alice@example.com&quot;})
}</code></pre></p>
<p>---</p>
<h2>Best Practices</h2>
<h3>1. Always Use Context</h3>
<pre><code class="language-go">// ‚úÖ With timeout
ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
defer cancel()
<p>rows, err := db.QueryContext(ctx, query)</code></pre></p>
<h3>2. Close Resources</h3>
<pre><code class="language-go">// ‚úÖ Always defer Close()
rows, err := db.Query(query)
if err != nil {
    return err
}
defer rows.Close()  // Important!
<p>for rows.Next() {
    // Process rows
}</code></pre></p>
<h3>3. Handle sql.ErrNoRows</h3>
<pre><code class="language-go">// ‚úÖ Check for no rows
err := db.QueryRow(query, id).Scan(&amp;user)
if err == sql.ErrNoRows {
    return nil, fmt.Errorf(&quot;user not found&quot;)
}
if err != nil {
    return nil, err
}</code></pre>
<h3>4. Use Prepared Statements</h3>
<pre><code class="language-go">// ‚úÖ For repeated queries
stmt, err := db.Prepare(&quot;SELECT * FROM users WHERE id = $1&quot;)
defer stmt.Close()
<p>for _, id := range userIDs {
    var user User
    err = stmt.QueryRow(id).Scan(&amp;user.ID, &amp;user.Name)
}</code></pre></p>
<h3>5. Separate Data Layer</h3>
<pre><code class="language-go">// ‚úÖ Repository pattern
type UserRepository interface {
    Create(user *User) error
    GetByID(id int) (*User, error)
    Update(user *User) error
    Delete(id int) error
}
<p>type PostgresUserRepository struct {
    db *sql.DB
}</p>
<p>func (r *PostgresUserRepository) Create(user *User) error {
    // Implementation
}</code></pre></p>
<p>---</p>
<h2>Interview Questions</h2>
<strong>Q1: What's the difference between Query and Exec?</strong>
<strong>Answer:</strong>
<ul><li><code>Query/QueryRow</code>: For SELECT statements, returns rows</li>
<li><code>Exec</code>: For INSERT/UPDATE/DELETE, returns affected rows count</li>
<strong>Q2: Why use connection pooling?</strong>
<strong>Answer:</strong> Reusing connections improves performance by avoiding the overhead of creating new connections for each request. Also limits max connections to prevent overwhelming the database.
<strong>Q3: What's the difference between sql.DB and sql.Tx?</strong>
<strong>Answer:</strong>
<li><code>sql.DB</code>: Connection pool, thread-safe, use for regular queries</li>
<li><code>sql.Tx</code>: Transaction, not thread-safe, use for atomic operations</li>
<strong>Q4: GORM vs database/sql?</strong>
<strong>Answer:</strong>
<li><strong>GORM</strong>: Higher-level, faster development, auto-migrations, associations</li>
<li><strong>database/sql</strong>: Lower-level, more control, better performance, no magic</li>
<strong>Q5: How to handle NULL values?</strong>
<strong>Answer:</strong> Use sql.Null types:
<pre><code class="language-go">var name sql.NullString
err := db.QueryRow(&quot;SELECT name FROM users WHERE id = $1&quot;, id).Scan(&amp;name)
if name.Valid {
    fmt.Println(name.String)
}</code></pre>
<p>---</p>
<h2>Hands-On Exercise</h2>
<h3>Task: Build a Blog API with PostgreSQL</h3>
<strong>Requirements:</strong>
1. Users table with authentication
2. Posts table (belongs to user)
3. Comments table (belongs to post and user)
4. CRUD operations for all tables
5. Transaction for creating post with tags
6. Pagination and filtering
<strong>Schema:</strong>
<pre><code class="language-sql">CREATE TABLE users (
    id SERIAL PRIMARY KEY,
    username VARCHAR(50) UNIQUE NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    created_at TIMESTAMP DEFAULT NOW()
);
<p>CREATE TABLE posts (
    id SERIAL PRIMARY KEY,
    user_id INTEGER REFERENCES users(id),
    title VARCHAR(200) NOT NULL,
    content TEXT NOT NULL,
    published BOOLEAN DEFAULT false,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);</p>
<p>CREATE TABLE comments (
    id SERIAL PRIMARY KEY,
    post_id INTEGER REFERENCES posts(id) ON DELETE CASCADE,
    user_id INTEGER REFERENCES users(id),
    content TEXT NOT NULL,
    created_at TIMESTAMP DEFAULT NOW()
);</code></pre></p>
<strong>Implement:</strong>
<li>User registration and login</li>
<li>Create/Read/Update/Delete posts</li>
<li>Add comments to posts</li>
<li>List posts with author information</li>
<li>Search posts by title</li>
<p>---</p>
<h2>üìö Additional Resources</h2>
<li>[Go database/sql Tutorial](https://go.dev/doc/database/sql-tutorial)</li>
<li>[GORM Documentation](https://gorm.io/)</li>
<li>[golang-migrate](https://github.com/golang-migrate/migrate)</li>
<li>[sqlx Package](https://github.com/jmoiron/sqlx)</li>
<p>---</p>
<h2>‚úÖ Module Checklist</h2>
<li>[ ] Connect to PostgreSQL with database/sql</li>
<li>[ ] Perform CRUD operations</li>
<li>[ ] Use GORM for ORM operations</li>
<li>[ ] Configure connection pooling</li>
<li>[ ] Implement transactions</li>
<li>[ ] Run database migrations</li>
<li>[ ] Integrate Redis for caching</li>
<li>[ ] Work with MongoDB</li>
<li>[ ] Complete the hands-on exercise</li></ul>
<p>---</p>
<strong>Next Module:</strong> [05_Go_Testing_Best_Practices.md](./05_Go_Testing_Best_Practices.md) - Write bulletproof tests! ‚úÖ

    </div>
    

    <div class="module-content" id="module-5">
        <h1>Module 05: Go Testing & Best Practices ‚úÖ</h1>
<h2>Write Bulletproof, Production-Ready Tests</h2>
<strong>Duration:</strong> 3-4 hours  
<strong>Prerequisites:</strong> Module 01-04 (All Go fundamentals)  
<strong>Outcome:</strong> Master Go's testing framework and write comprehensive test suites
<p>---</p>
<h2>üìö Table of Contents</h2>
<p>1. [Testing Fundamentals](#testing-fundamentals)
2. [Writing Unit Tests](#writing-unit-tests)
3. [Table-Driven Tests](#table-driven-tests)
4. [Test Coverage](#test-coverage)
5. [Mocking & Interfaces](#mocking--interfaces)
6. [HTTP Testing](#http-testing)
7. [Database Testing](#database-testing)
8. [Benchmarking](#benchmarking)
9. [Testing Best Practices](#testing-best-practices)
10. [Interview Questions](#interview-questions)
11. [Hands-On Exercise](#hands-on-exercise)</p>
<p>---</p>
<h2>Testing Fundamentals</h2>
<h3>Why Test?</h3>
<p>‚úÖ <strong>Benefits:</strong>
<ul><li>Catch bugs early</li>
<li>Enable refactoring with confidence</li>
<li>Document behavior</li>
<li>Improve code design</li>
<li>Reduce debugging time</li></p>
<h3>Test File Naming</h3>
<pre><code class="language-bash"># Source file
calculator.go
<h1>Test file (must end with _test.go)</h1>
calculator_test.go</code></pre>
<h3>Running Tests</h3>
<pre><code class="language-bash"># Run all tests
go test
<h1>Run tests with verbose output</h1>
go test -v
<h1>Run specific test</h1>
go test -run TestAdd
<h1>Run tests in all subdirectories</h1>
go test ./...
<h1>Run with coverage</h1>
go test -cover
<h1>Generate coverage report</h1>
go test -coverprofile=coverage.out
go tool cover -html=coverage.out</code></pre>
<p>---</p>
<h2>Writing Unit Tests</h2>
<h3>Basic Test</h3>
<pre><code class="language-go">// calculator.go
package calculator
<p>func Add(a, b int) int {
    return a + b
}</p>
<p>func Subtract(a, b int) int {
    return a - b
}</p>
<p>func Multiply(a, b int) int {
    return a * b
}</p>
<p>func Divide(a, b int) (int, error) {
    if b == 0 {
        return 0, fmt.Errorf(&quot;division by zero&quot;)
    }
    return a / b, nil
}</code></pre></p>
<pre><code class="language-go">// calculator_test.go
package calculator
<p>import &quot;testing&quot;</p>
<p>func TestAdd(t *testing.T) {
    result := Add(2, 3)
    expected := 5
    
    if result != expected {
        t.Errorf(&quot;Add(2, 3) = %d; want %d&quot;, result, expected)
    }
}</p>
<p>func TestSubtract(t *testing.T) {
    result := Subtract(5, 3)
    expected := 2
    
    if result != expected {
        t.Errorf(&quot;Subtract(5, 3) = %d; want %d&quot;, result, expected)
    }
}</p>
<p>func TestDivide(t *testing.T) {
    // Test successful division
    result, err := Divide(10, 2)
    if err != nil {
        t.Fatalf(&quot;Divide(10, 2) unexpected error: %v&quot;, err)
    }
    if result != 5 {
        t.Errorf(&quot;Divide(10, 2) = %d; want 5&quot;, result)
    }
    
    // Test division by zero
    _, err = Divide(10, 0)
    if err == nil {
        t.Error(&quot;Divide(10, 0) expected error, got nil&quot;)
    }
}</code></pre></p>
<h3>Test Helper Functions</h3>
<pre><code class="language-go">// Helper function
func assertEqual(t *testing.T, got, want int) {
    t.Helper()  // Marks this as helper, shows correct line number in errors
    if got != want {
        t.Errorf(&quot;got %d, want %d&quot;, got, want)
    }
}
<p>func TestWithHelper(t *testing.T) {
    result := Add(2, 3)
    assertEqual(t, result, 5)
}</code></pre></p>
<h3>Subtests</h3>
<pre><code class="language-go">func TestMath(t *testing.T) {
    t.Run(&quot;Addition&quot;, func(t *testing.T) {
        if Add(2, 3) != 5 {
            t.Error(&quot;Addition failed&quot;)
        }
    })
    
    t.Run(&quot;Subtraction&quot;, func(t *testing.T) {
        if Subtract(5, 3) != 2 {
            t.Error(&quot;Subtraction failed&quot;)
        }
    })
    
    t.Run(&quot;Division by zero&quot;, func(t *testing.T) {
        _, err := Divide(10, 0)
        if err == nil {
            t.Error(&quot;Expected error for division by zero&quot;)
        }
    })
}</code></pre>
<p>---</p>
<h2>Table-Driven Tests</h2>
<p>Best practice for testing multiple cases:</p>
<h3>Basic Table-Driven Test</h3>
<pre><code class="language-go">func TestAdd(t *testing.T) {
    tests := []struct {
        name     string
        a, b     int
        expected int
    }{
        {&quot;positive numbers&quot;, 2, 3, 5},
        {&quot;negative numbers&quot;, -2, -3, -5},
        {&quot;mixed signs&quot;, -2, 3, 1},
        {&quot;with zero&quot;, 0, 5, 5},
        {&quot;both zero&quot;, 0, 0, 0},
    }
    
    for _, tt := range tests {
        t.Run(tt.name, func(t *testing.T) {
            result := Add(tt.a, tt.b)
            if result != tt.expected {
                t.Errorf(&quot;Add(%d, %d) = %d; want %d&quot;, 
                    tt.a, tt.b, result, tt.expected)
            }
        })
    }
}</code></pre>
<h3>Advanced Table-Driven Test</h3>
<pre><code class="language-go">func TestDivide(t *testing.T) {
    tests := []struct {
        name      string
        a, b      int
        want      int
        wantError bool
    }{
        {
            name:      &quot;normal division&quot;,
            a:         10,
            b:         2,
            want:      5,
            wantError: false,
        },
        {
            name:      &quot;division by zero&quot;,
            a:         10,
            b:         0,
            want:      0,
            wantError: true,
        },
        {
            name:      &quot;negative numbers&quot;,
            a:         -10,
            b:         2,
            want:      -5,
            wantError: false,
        },
    }
    
    for _, tt := range tests {
        t.Run(tt.name, func(t *testing.T) {
            got, err := Divide(tt.a, tt.b)
            
            if (err != nil) != tt.wantError {
                t.Errorf(&quot;Divide() error = %v, wantError %v&quot;, err, tt.wantError)
                return
            }
            
            if !tt.wantError &amp;&amp; got != tt.want {
                t.Errorf(&quot;Divide() = %v, want %v&quot;, got, tt.want)
            }
        })
    }
}</code></pre>
<p>---</p>
<h2>Test Coverage</h2>
<h3>Generate Coverage Report</h3>
<pre><code class="language-bash"># Run tests with coverage
go test -cover
<h1>Output: coverage: 85.7% of statements</h1>
<h1>Generate detailed coverage profile</h1>
go test -coverprofile=coverage.out
<h1>View coverage in browser</h1>
go tool cover -html=coverage.out
<h1>Coverage by function</h1>
go tool cover -func=coverage.out</code></pre>
<h3>Coverage Example</h3>
<pre><code class="language-go">// user.go
package user
<p>type User struct {
    Name  string
    Email string
    Age   int
}</p>
<p>func (u *User) IsAdult() bool {
    return u.Age &gt;= 18
}</p>
<p>func (u *User) IsValid() bool {
    return u.Name != &quot;&quot; &amp;&amp; u.Email != &quot;&quot; &amp;&amp; u.Age &gt; 0
}</p>
<p>// user_test.go
func TestUser(t *testing.T) {
    t.Run(&quot;IsAdult&quot;, func(t *testing.T) {
        tests := []struct {
            name string
            age  int
            want bool
        }{
            {&quot;adult&quot;, 25, true},
            {&quot;minor&quot;, 15, false},
            {&quot;exactly 18&quot;, 18, true},
        }
        
        for _, tt := range tests {
            t.Run(tt.name, func(t *testing.T) {
                user := &amp;User{Age: tt.age}
                if got := user.IsAdult(); got != tt.want {
                    t.Errorf(&quot;IsAdult() = %v, want %v&quot;, got, tt.want)
                }
            })
        }
    })
    
    t.Run(&quot;IsValid&quot;, func(t *testing.T) {
        tests := []struct {
            name string
            user User
            want bool
        }{
            {&quot;valid user&quot;, User{&quot;Alice&quot;, &quot;alice@test.com&quot;, 25}, true},
            {&quot;no name&quot;, User{&quot;&quot;, &quot;alice@test.com&quot;, 25}, false},
            {&quot;no email&quot;, User{&quot;Alice&quot;, &quot;&quot;, 25}, false},
            {&quot;zero age&quot;, User{&quot;Alice&quot;, &quot;alice@test.com&quot;, 0}, false},
        }
        
        for _, tt := range tests {
            t.Run(tt.name, func(t *testing.T) {
                if got := tt.user.IsValid(); got != tt.want {
                    t.Errorf(&quot;IsValid() = %v, want %v&quot;, got, tt.want)
                }
            })
        }
    })
}</code></pre></p>
<p>---</p>
<h2>Mocking & Interfaces</h2>
<h3>Interface-Based Mocking</h3>
<pre><code class="language-go">// storage.go
package storage
<p>type UserStore interface {
    GetUser(id int) (*User, error)
    SaveUser(user *User) error
}</p>
<p>type User struct {
    ID   int
    Name string
}</p>
<p>// Real implementation
type PostgresStore struct {
    db *sql.DB
}</p>
<p>func (s *PostgresStore) GetUser(id int) (*User, error) {
    // Real database query
    var user User
    err := s.db.QueryRow(&quot;SELECT id, name FROM users WHERE id = $1&quot;, id).
        Scan(&amp;user.ID, &amp;user.Name)
    return &amp;user, err
}</p>
<p>func (s *PostgresStore) SaveUser(user *User) error {
    // Real database insert
    _, err := s.db.Exec(&quot;INSERT INTO users (name) VALUES ($1)&quot;, user.Name)
    return err
}</code></pre></p>
<pre><code class="language-go">// storage_test.go
package storage
<p>import (
    &quot;errors&quot;
    &quot;testing&quot;
)</p>
<p>// Mock implementation
type MockUserStore struct {
    users map[int]*User
    err   error
}</p>
<p>func (m *MockUserStore) GetUser(id int) (*User, error) {
    if m.err != nil {
        return nil, m.err
    }
    user, ok := m.users[id]
    if !ok {
        return nil, errors.New(&quot;user not found&quot;)
    }
    return user, nil
}</p>
<p>func (m *MockUserStore) SaveUser(user *User) error {
    if m.err != nil {
        return m.err
    }
    m.users[user.ID] = user
    return nil
}</p>
<p>// Service using the interface
type UserService struct {
    store UserStore
}</p>
<p>func (s *UserService) GetUserName(id int) (string, error) {
    user, err := s.store.GetUser(id)
    if err != nil {
        return &quot;&quot;, err
    }
    return user.Name, nil
}</p>
<p>// Test with mock
func TestUserService_GetUserName(t *testing.T) {
    // Setup mock
    mock := &amp;MockUserStore{
        users: map[int]*User{
            1: {ID: 1, Name: &quot;Alice&quot;},
            2: {ID: 2, Name: &quot;Bob&quot;},
        },
    }
    
    service := &amp;UserService{store: mock}
    
    tests := []struct {
        name    string
        userID  int
        want    string
        wantErr bool
    }{
        {&quot;existing user&quot;, 1, &quot;Alice&quot;, false},
        {&quot;another user&quot;, 2, &quot;Bob&quot;, false},
        {&quot;non-existent user&quot;, 999, &quot;&quot;, true},
    }
    
    for _, tt := range tests {
        t.Run(tt.name, func(t *testing.T) {
            got, err := service.GetUserName(tt.userID)
            if (err != nil) != tt.wantErr {
                t.Errorf(&quot;GetUserName() error = %v, wantErr %v&quot;, err, tt.wantErr)
                return
            }
            if got != tt.want {
                t.Errorf(&quot;GetUserName() = %v, want %v&quot;, got, tt.want)
            }
        })
    }
}</code></pre></p>
<h3>Using testify/mock</h3>
<pre><code class="language-go">import (
    &quot;github.com/stretchr/testify/mock&quot;
    &quot;github.com/stretchr/testify/assert&quot;
)
<p>// Mock with testify
type MockUserStore struct {
    mock.Mock
}</p>
<p>func (m *MockUserStore) GetUser(id int) (*User, error) {
    args := m.Called(id)
    if args.Get(0) == nil {
        return nil, args.Error(1)
    }
    return args.Get(0).(*User), args.Error(1)
}</p>
<p>func TestWithTestify(t *testing.T) {
    // Setup mock
    mockStore := new(MockUserStore)
    mockStore.On(&quot;GetUser&quot;, 1).Return(&amp;User{ID: 1, Name: &quot;Alice&quot;}, nil)
    
    service := &amp;UserService{store: mockStore}
    
    // Test
    name, err := service.GetUserName(1)
    
    // Assertions
    assert.NoError(t, err)
    assert.Equal(t, &quot;Alice&quot;, name)
    mockStore.AssertExpectations(t)
}</code></pre></p>
<p>---</p>
<h2>HTTP Testing</h2>
<h3>Testing HTTP Handlers</h3>
<pre><code class="language-go">// handlers.go
package api
<p>import (
    &quot;encoding/json&quot;
    &quot;net/http&quot;
)</p>
<p>type Response struct {
    Message string <code>json:&quot;message&quot;</code>
    Status  int    <code>json:&quot;status&quot;</code>
}</p>
<p>func HealthHandler(w http.ResponseWriter, r *http.Request) {
    w.Header().Set(&quot;Content-Type&quot;, &quot;application/json&quot;)
    w.WriteHeader(http.StatusOK)
    json.NewEncoder(w).Encode(Response{
        Message: &quot;OK&quot;,
        Status:  200,
    })
}</p>
<p>func GetUserHandler(w http.ResponseWriter, r *http.Request) {
    if r.Method != http.MethodGet {
        http.Error(w, &quot;Method not allowed&quot;, http.StatusMethodNotAllowed)
        return
    }
    
    user := map[string]interface{}{
        &quot;id&quot;:   1,
        &quot;name&quot;: &quot;Alice&quot;,
    }
    
    w.Header().Set(&quot;Content-Type&quot;, &quot;application/json&quot;)
    json.NewEncoder(w).Encode(user)
}</code></pre></p>
<pre><code class="language-go">// handlers_test.go
package api
<p>import (
    &quot;encoding/json&quot;
    &quot;net/http&quot;
    &quot;net/http/httptest&quot;
    &quot;testing&quot;
)</p>
<p>func TestHealthHandler(t *testing.T) {
    // Create request
    req := httptest.NewRequest(http.MethodGet, &quot;/health&quot;, nil)
    
    // Create response recorder
    rr := httptest.NewRecorder()
    
    // Call handler
    HealthHandler(rr, req)
    
    // Check status code
    if status := rr.Code; status != http.StatusOK {
        t.Errorf(&quot;handler returned wrong status code: got %v want %v&quot;,
            status, http.StatusOK)
    }
    
    // Check response body
    var response Response
    if err := json.NewDecoder(rr.Body).Decode(&amp;response); err != nil {
        t.Fatalf(&quot;couldn&#039;t decode response: %v&quot;, err)
    }
    
    if response.Message != &quot;OK&quot; {
        t.Errorf(&quot;unexpected message: got %v want OK&quot;, response.Message)
    }
}</p>
<p>func TestGetUserHandler(t *testing.T) {
    tests := []struct {
        name       string
        method     string
        wantStatus int
    }{
        {&quot;GET request&quot;, http.MethodGet, http.StatusOK},
        {&quot;POST request&quot;, http.MethodPost, http.StatusMethodNotAllowed},
        {&quot;PUT request&quot;, http.MethodPut, http.StatusMethodNotAllowed},
    }
    
    for _, tt := range tests {
        t.Run(tt.name, func(t *testing.T) {
            req := httptest.NewRequest(tt.method, &quot;/users/1&quot;, nil)
            rr := httptest.NewRecorder()
            
            GetUserHandler(rr, req)
            
            if rr.Code != tt.wantStatus {
                t.Errorf(&quot;handler returned wrong status: got %v want %v&quot;,
                    rr.Code, tt.wantStatus)
            }
        })
    }
}</code></pre></p>
<h3>Testing HTTP Server</h3>
<pre><code class="language-go">func TestServer(t *testing.T) {
    // Create test server
    ts := httptest.NewServer(http.HandlerFunc(HealthHandler))
    defer ts.Close()
    
    // Make request
    resp, err := http.Get(ts.URL + &quot;/health&quot;)
    if err != nil {
        t.Fatalf(&quot;couldn&#039;t make request: %v&quot;, err)
    }
    defer resp.Body.Close()
    
    // Check response
    if resp.StatusCode != http.StatusOK {
        t.Errorf(&quot;expected status OK, got %v&quot;, resp.Status)
    }
}</code></pre>
<p>---</p>
<h2>Database Testing</h2>
<h3>Using In-Memory SQLite</h3>
<pre><code class="language-go">import (
    &quot;database/sql&quot;
    &quot;testing&quot;
    _ &quot;github.com/mattn/go-sqlite3&quot;
)
<p>func setupTestDB(t *testing.T) *sql.DB {
    db, err := sql.Open(&quot;sqlite3&quot;, &quot;:memory:&quot;)
    if err != nil {
        t.Fatalf(&quot;couldn&#039;t open test database: %v&quot;, err)
    }
    
    // Create schema
    schema := <code>
        CREATE TABLE users (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            name TEXT NOT NULL,
            email TEXT UNIQUE NOT NULL
        );
    </code>
    
    if _, err := db.Exec(schema); err != nil {
        t.Fatalf(&quot;couldn&#039;t create schema: %v&quot;, err)
    }
    
    return db
}</p>
<p>func TestUserStore_Create(t *testing.T) {
    db := setupTestDB(t)
    defer db.Close()
    
    store := NewUserStore(db)
    
    user := &amp;User{
        Name:  &quot;Alice&quot;,
        Email: &quot;alice@test.com&quot;,
    }
    
    err := store.Create(user)
    if err != nil {
        t.Fatalf(&quot;couldn&#039;t create user: %v&quot;, err)
    }
    
    if user.ID == 0 {
        t.Error(&quot;user ID not set&quot;)
    }
    
    // Verify user was created
    retrieved, err := store.GetByID(user.ID)
    if err != nil {
        t.Fatalf(&quot;couldn&#039;t retrieve user: %v&quot;, err)
    }
    
    if retrieved.Name != user.Name {
        t.Errorf(&quot;name mismatch: got %v want %v&quot;, retrieved.Name, user.Name)
    }
}</code></pre></p>
<h3>Using Test Containers</h3>
<pre><code class="language-go">import (
    &quot;context&quot;
    &quot;testing&quot;
    &quot;github.com/testcontainers/testcontainers-go&quot;
    &quot;github.com/testcontainers/testcontainers-go/wait&quot;
)
<p>func setupPostgresContainer(t *testing.T) *sql.DB {
    ctx := context.Background()
    
    req := testcontainers.ContainerRequest{
        Image:        &quot;postgres:14&quot;,
        ExposedPorts: []string{&quot;5432/tcp&quot;},
        Env: map[string]string{
            &quot;POSTGRES_PASSWORD&quot;: &quot;password&quot;,
            &quot;POSTGRES_DB&quot;:       &quot;testdb&quot;,
        },
        WaitingFor: wait.ForLog(&quot;database system is ready to accept connections&quot;),
    }
    
    container, err := testcontainers.GenericContainer(ctx, testcontainers.GenericContainerRequest{
        ContainerRequest: req,
        Started:          true,
    })
    if err != nil {
        t.Fatalf(&quot;couldn&#039;t start container: %v&quot;, err)
    }
    
    t.Cleanup(func() {
        container.Terminate(ctx)
    })
    
    // Get connection details and connect to database
    // ... (implementation)
    
    return db
}</code></pre></p>
<p>---</p>
<h2>Benchmarking</h2>
<h3>Basic Benchmark</h3>
<pre><code class="language-go">// Benchmark function must start with Benchmark
func BenchmarkAdd(b *testing.B) {
    for i := 0; i &lt; b.N; i++ {
        Add(2, 3)
    }
}
<p>func BenchmarkStringConcat(b *testing.B) {
    for i := 0; i &lt; b.N; i++ {
        _ = &quot;hello&quot; + &quot; &quot; + &quot;world&quot;
    }
}</p>
<p>func BenchmarkStringBuilderConcat(b *testing.B) {
    for i := 0; i &lt; b.N; i++ {
        var sb strings.Builder
        sb.WriteString(&quot;hello&quot;)
        sb.WriteString(&quot; &quot;)
        sb.WriteString(&quot;world&quot;)
        _ = sb.String()
    }
}</code></pre></p>
<pre><code class="language-bash"># Run benchmarks
go test -bench=.
<h1>Output:</h1>
<h1>BenchmarkAdd-8                  1000000000    0.25 ns/op</h1>
<h1>BenchmarkStringConcat-8         50000000      30.5 ns/op</h1>
<h1>BenchmarkStringBuilderConcat-8  100000000     10.2 ns/op</code></pre></h1>
<h3>Benchmark with Setup</h3>
<pre><code class="language-go">func BenchmarkLargeSlice(b *testing.B) {
    // Setup (not timed)
    data := make([]int, 1000000)
    for i := range data {
        data[i] = i
    }
    
    // Reset timer to exclude setup time
    b.ResetTimer()
    
    // Benchmark loop
    for i := 0; i &lt; b.N; i++ {
        sum := 0
        for _, v := range data {
            sum += v
        }
    }
}</code></pre>
<h3>Memory Benchmarks</h3>
<pre><code class="language-go">func BenchmarkAllocation(b *testing.B) {
    b.ReportAllocs()  // Report memory allocations
    
    for i := 0; i &lt; b.N; i++ {
        _ = make([]int, 1000)
    }
}</code></pre>
<pre><code class="language-bash"># Run with memory stats
go test -bench=. -benchmem
<h1>Output:</h1>
<h1>BenchmarkAllocation-8    500000    3000 ns/op    8192 B/op    1 allocs/op</code></pre></h1>
<p>---</p>
<h2>Testing Best Practices</h2>
<h3>1. Test One Thing Per Test</h3>
<pre><code class="language-go">// ‚ùå Bad: Testing multiple things
func TestUser(t *testing.T) {
    user := &amp;User{Name: &quot;Alice&quot;, Age: 25}
    if !user.IsValid() {
        t.Error(&quot;user should be valid&quot;)
    }
    if !user.IsAdult() {
        t.Error(&quot;user should be adult&quot;)
    }
}
<p>// ‚úÖ Good: Separate tests
func TestUser_IsValid(t *testing.T) {
    user := &amp;User{Name: &quot;Alice&quot;, Age: 25}
    if !user.IsValid() {
        t.Error(&quot;user should be valid&quot;)
    }
}</p>
<p>func TestUser_IsAdult(t *testing.T) {
    user := &amp;User{Name: &quot;Alice&quot;, Age: 25}
    if !user.IsAdult() {
        t.Error(&quot;user should be adult&quot;)
    }
}</code></pre></p>
<h3>2. Use Table-Driven Tests</h3>
<pre><code class="language-go">// ‚úÖ Good: Table-driven for multiple cases
func TestAdd(t *testing.T) {
    tests := []struct {
        name string
        a, b int
        want int
    }{
        {&quot;positive&quot;, 2, 3, 5},
        {&quot;negative&quot;, -2, -3, -5},
        {&quot;zero&quot;, 0, 0, 0},
    }
    
    for _, tt := range tests {
        t.Run(tt.name, func(t *testing.T) {
            if got := Add(tt.a, tt.b); got != tt.want {
                t.Errorf(&quot;got %d, want %d&quot;, got, tt.want)
            }
        })
    }
}</code></pre>
<h3>3. Use t.Helper() for Test Helpers</h3>
<pre><code class="language-go">// ‚úÖ Mark helper functions
func assertEqual(t *testing.T, got, want interface{}) {
    t.Helper()  // Shows actual test line in error
    if got != want {
        t.Errorf(&quot;got %v, want %v&quot;, got, want)
    }
}</code></pre>
<h3>4. Clean Up Resources</h3>
<pre><code class="language-go">func TestWithCleanup(t *testing.T) {
    // Setup
    file, err := os.CreateTemp(&quot;&quot;, &quot;test&quot;)
    if err != nil {
        t.Fatal(err)
    }
    
    // Cleanup (always runs, even if test fails)
    t.Cleanup(func() {
        os.Remove(file.Name())
    })
    
    // Test code...
}</code></pre>
<h3>5. Use Parallel Tests When Possible</h3>
<pre><code class="language-go">func TestParallel(t *testing.T) {
    tests := []struct {
        name string
        // ...
    }{
        // test cases
    }
    
    for _, tt := range tests {
        tt := tt  // Capture range variable
        t.Run(tt.name, func(t *testing.T) {
            t.Parallel()  // Run tests in parallel
            // Test code...
        })
    }
}</code></pre>
<p>---</p>
<h2>Interview Questions</h2>
<strong>Q1: What's the difference between t.Error and t.Fatal?</strong>
<strong>Answer:</strong>
<li><code>t.Error</code>: Reports error but continues test</li>
<li><code>t.Fatal</code>: Reports error and stops test immediately</li>
<strong>Q2: How do you test unexported functions?</strong>
<strong>Answer:</strong> Test files in the same package can access unexported functions. For external testing, create a test package with <code>_test</code> suffix or export the function.
<strong>Q3: What is table-driven testing?</strong>
<strong>Answer:</strong> A pattern where test cases are defined in a slice of structs, then iterated over. Benefits: less code duplication, easier to add cases, clearer test structure.
<strong>Q4: How do you measure test coverage?</strong>
<strong>Answer:</strong> <code>go test -cover</code> or <code>go test -coverprofile=coverage.out</code> followed by <code>go tool cover -html=coverage.out</code>
<strong>Q5: What's the purpose of benchmarking?</strong>
<strong>Answer:</strong> Measure performance (execution time, memory allocations) to identify bottlenecks and compare implementations.
<p>---</p>
<h2>Hands-On Exercise</h2>
<h3>Task: Test a User Management System</h3>
<strong>Given this code:</strong>
<pre><code class="language-go">package user
<p>type User struct {
    ID       int
    Username string
    Email    string
    Age      int
}</p>
<p>type UserService struct {
    store UserStore
}</p>
<p>type UserStore interface {
    Create(user *User) error
    GetByID(id int) (*User, error)
    GetByUsername(username string) (*User, error)
    Update(user *User) error
    Delete(id int) error
}</p>
<p>func (s *UserService) Register(username, email string, age int) (*User, error) {
    // Validate
    if username == &quot;&quot; || email == &quot;&quot; {
        return nil, errors.New(&quot;username and email required&quot;)
    }
    if age &lt; 18 {
        return nil, errors.New(&quot;must be 18 or older&quot;)
    }
    
    // Check if username exists
    existing, _ := s.store.GetByUsername(username)
    if existing != nil {
        return nil, errors.New(&quot;username already exists&quot;)
    }
    
    // Create user
    user := &amp;User{
        Username: username,
        Email:    email,
        Age:      age,
    }
    
    if err := s.store.Create(user); err != nil {
        return nil, err
    }
    
    return user, nil
}</code></pre></p>
<strong>Requirements:</strong>
1. Write table-driven tests for validation
2. Create mock UserStore
3. Test all success and error cases
4. Achieve >90% coverage
5. Add benchmarks for Register function
<p>---</p>
<h2>üìö Additional Resources</h2>
<li>[Go Testing Documentation](https://pkg.go.dev/testing)</li>
<li>[Table Driven Tests](https://dave.cheney.net/2013/06/09/writing-table-driven-tests-in-go)</li>
<li>[testify Package](https://github.com/stretchr/testify)</li>
<li>[gomock](https://github.com/golang/mock)</li>
<p>---</p>
<h2>‚úÖ Module Checklist</h2>
<li>[ ] Write basic unit tests</li>
<li>[ ] Implement table-driven tests</li>
<li>[ ] Generate and analyze test coverage</li>
<li>[ ] Create mocks using interfaces</li>
<li>[ ] Test HTTP handlers</li>
<li>[ ] Test database operations</li>
<li>[ ] Write benchmarks</li>
<li>[ ] Follow testing best practices</li>
<li>[ ] Complete the hands-on exercise</li>
<p>---</p>
<h2>üéâ Congratulations!</h2>
<p>You've completed the <strong>Go Programming</strong> section! You now have a solid foundation in:
<li>Go fundamentals and syntax</li>
<li>Concurrent programming with goroutines</li>
<li>Building REST APIs</li>
<li>Database integration</li>
<li>Writing comprehensive tests</li></ul></p>
<strong>Next Section:</strong> [Module 06: Kubernetes Architecture](./06_Kubernetes_Architecture.md) - Master container orchestration! ‚ò∏Ô∏è

    </div>
    

    <div class="module-content" id="module-6">
        <h1>Module 06: Kubernetes Architecture ‚ò∏Ô∏è</h1>
<h2>Master Container Orchestration at Scale</h2>
<strong>Duration:</strong> 4-5 hours  
<strong>Prerequisites:</strong> Basic Docker knowledge, Module 01-05 (Go fundamentals)  
<strong>Outcome:</strong> Understand Kubernetes architecture and how all components work together
<p>---</p>
<h2>üìö Table of Contents</h2>
<p>1. [What is Kubernetes?](#what-is-kubernetes)
2. [Kubernetes Architecture Overview](#kubernetes-architecture-overview)
3. [Control Plane Components](#control-plane-components)
4. [Node Components](#node-components)
5. [Kubernetes Objects](#kubernetes-objects)
6. [How Everything Works Together](#how-everything-works-together)
7. [Installation Options](#installation-options)
8. [kubectl Basics](#kubectl-basics)
9. [Best Practices](#best-practices)
10. [Interview Questions](#interview-questions)
11. [Hands-On Exercise](#hands-on-exercise)</p>
<p>---</p>
<h2>What is Kubernetes?</h2>
<h3>Definition</h3>
<strong>Kubernetes (K8s)</strong> is an open-source container orchestration platform that automates:
<ul><li><strong>Deployment</strong> of containerized applications</li>
<li><strong>Scaling</strong> (horizontal and vertical)</li>
<li><strong>Management</strong> (health checks, updates, rollbacks)</li>
<li><strong>Networking</strong> (service discovery, load balancing)</li>
<li><strong>Storage</strong> (persistent volumes)</li>
<h3>Why Kubernetes?</h3>
<p>‚úÖ <strong>Benefits:</strong>
<li><strong>Auto-healing</strong>: Automatically restarts failed containers</li>
<li><strong>Horizontal scaling</strong>: Scale applications up/down based on load</li>
<li><strong>Service discovery</strong>: Automatic DNS and load balancing</li>
<li><strong>Rolling updates</strong>: Zero-downtime deployments</li>
<li><strong>Secret management</strong>: Secure handling of credentials</li>
<li><strong>Resource optimization</strong>: Efficient bin-packing of containers</li></p>
<h3>Who Uses Kubernetes?</h3>
<p>üè¢ <strong>Production Users:</strong>
<li>Google (created K8s, runs billions of containers)</li>
<li>Spotify (manages 300+ microservices)</li>
<li>Airbnb (runs 1000s of services across clusters)</li>
<li>Pinterest (migrated from EC2 to K8s)</li>
<li>Netflix, Uber, Twitter, and thousands more</li></p>
<p>---</p>
<h2>Kubernetes Architecture Overview</h2>
<h3>High-Level Architecture</h3>
<pre><code class="language-text">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    CONTROL PLANE                        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ   etcd   ‚îÇ  ‚îÇ API      ‚îÇ  ‚îÇScheduler ‚îÇ  ‚îÇ Control‚îÇ ‚îÇ
‚îÇ  ‚îÇ (DB)     ‚îÇ  ‚îÇ Server   ‚îÇ  ‚îÇ          ‚îÇ  ‚îÇManager ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
                          ‚îÇ API calls
                          ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    WORKER NODES                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ
‚îÇ  ‚îÇ   Node 1           ‚îÇ  ‚îÇ   Node 2           ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ   kubelet    ‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ   kubelet    ‚îÇ  ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ   kube-proxy ‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ   kube-proxy ‚îÇ  ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ   Container  ‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ   Container  ‚îÇ  ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ   Runtime    ‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ   Runtime    ‚îÇ  ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Pod  ‚îÇ ‚îÇ Pod  ‚îÇ‚îÇ  ‚îÇ  ‚îÇ Pod  ‚îÇ ‚îÇ Pod  ‚îÇ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ        ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</code></pre>
<h3>Two Main Parts</h3>
<p>1. <strong>Control Plane</strong> (Master)
   - Brain of the cluster
   - Makes scheduling decisions
   - Detects and responds to events
   - Usually runs on dedicated master nodes</p>
<p>2. <strong>Worker Nodes</strong>
   - Run application workloads (Pods)
   - Execute instructions from control plane
   - Report status back to control plane</p>
<p>---</p>
<h2>Control Plane Components</h2>
<h3>1. API Server (<code>kube-apiserver</code>)</h3>
<strong>The front door to Kubernetes</strong>
<pre><code class="language-bash"># All kubectl commands go through API server
kubectl get pods
<h1>‚Üí HTTP GET /api/v1/namespaces/default/pods</h1>
<p>kubectl create deployment nginx --image=nginx
<h1>‚Üí HTTP POST /apis/apps/v1/namespaces/default/deployments</code></pre></h1></p>
<strong>Responsibilities:</strong>
<li>Exposes Kubernetes API (REST)</li>
<li>Authentication and authorization</li>
<li>Validates and processes API requests</li>
<li>Updates etcd with cluster state</li>
<li>Only component that talks to etcd</li>
<strong>Key Features:</strong>
<pre><code class="language-yaml"># API server supports:
<li>RESTful API (GET, POST, PUT, DELETE)</li>
<li>Watch mechanism (streaming updates)</li>
<li>Admission controllers (validation, mutation)</li>
<li>API versioning (v1, v1beta1, etc.)</code></pre></li>
<h3>2. etcd</h3>
<strong>Distributed key-value store - the cluster's database</strong>
<pre><code class="language-bash"># etcd stores everything:
/registry/pods/default/nginx-abc123
/registry/services/default/my-service
/registry/deployments/default/web-app
/registry/secrets/default/db-password</code></pre>
<strong>Characteristics:</strong>
<li><strong>Consistency</strong>: Uses Raft consensus algorithm</li>
<li><strong>Reliability</strong>: Distributed (typically 3-5 nodes)</li>
<li><strong>Performance</strong>: Fast reads, consistent writes</li>
<li><strong>Watch API</strong>: Notifies on changes</li>
<strong>What's Stored:</strong>
<pre><code class="language-text">‚úÖ Pods
‚úÖ Services
‚úÖ ConfigMaps
‚úÖ Secrets
‚úÖ Deployments
‚úÖ Namespaces
‚úÖ All cluster state</code></pre>
<strong>Critical Note:</strong> üî¥
<pre><code class="language-bash"># etcd is CRITICAL - if etcd dies, cluster is dead
<h1>Always backup etcd!</h1>
etcdctl snapshot save backup.db</code></pre>
<h3>3. Scheduler (<code>kube-scheduler</code>)</h3>
<strong>Decides which node runs each Pod</strong>
<pre><code class="language-text">User creates Pod ‚Üí API Server ‚Üí Scheduler watches for unscheduled Pods
                                      ‚Üì
                        Finds best node using:
                        - Resource requirements (CPU, memory)
                        - Node affinity rules
                        - Taints and tolerations
                        - Data locality
                        - Inter-pod affinity
                                      ‚Üì
                        Binds Pod to selected Node</code></pre>
<strong>Scheduling Algorithm:</strong>
<pre><code class="language-go">// Simplified scheduling logic
func SchedulePod(pod *Pod, nodes []Node) Node {
    // 1. Filtering (Predicate) - Remove invalid nodes
    feasibleNodes := filter(nodes, func(n Node) bool {
        return n.HasEnoughResources(pod) &amp;&amp;
               n.MatchesNodeSelector(pod) &amp;&amp;
               !n.HasConflictingTaint(pod)
    })
    
    // 2. Scoring (Priority) - Rank remaining nodes
    scores := scoreNodes(feasibleNodes, pod)
    
    // 3. Select highest scoring node
    return selectBestNode(scores)
}</code></pre>
<strong>Example: Pod Scheduling</strong>
<pre><code class="language-yaml">apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - name: nginx
    image: nginx
    resources:
      requests:
        cpu: &quot;500m&quot;      # Scheduler needs 0.5 CPU available
        memory: &quot;256Mi&quot;  # and 256MB memory
      limits:
        cpu: &quot;1&quot;
        memory: &quot;512Mi&quot;
  nodeSelector:
    disktype: ssd      # Only nodes with SSD</code></pre>
<h3>4. Controller Manager (<code>kube-controller-manager</code>)</h3>
<strong>Runs multiple controllers that watch and reconcile cluster state</strong>
<strong>Key Controllers:</strong>
<pre><code class="language-yaml">1. Node Controller:
   - Monitors node health
   - Evicts pods from unhealthy nodes
   
2. Replication Controller:
   - Ensures correct number of pod replicas
   
3. Deployment Controller:
   - Manages Deployments (rolling updates, rollbacks)
   
4. Service Controller:
   - Creates cloud load balancers for Services
   
5. Endpoint Controller:
   - Populates Endpoints (joins Services and Pods)
   
6. Job Controller:
   - Runs one-off tasks
   
7. CronJob Controller:
   - Schedules recurring jobs</code></pre>
<strong>Reconciliation Loop:</strong>
<pre><code class="language-go">// All controllers follow this pattern
for {
    desiredState := getDesiredStateFromAPI()
    currentState := getActualStateFromCluster()
    
    if currentState != desiredState {
        takeActionToReconcile()
    }
    
    sleep(reconciliationInterval)
}</code></pre>
<strong>Example: Deployment Controller</strong>
<pre><code class="language-yaml"># Desired state: 3 replicas
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx
spec:
  replicas: 3  # ‚Üê Desired state
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.21</code></pre>
<pre><code class="language-text">Controller sees: 2 pods running (Current state)
Desired state: 3 replicas
Action: Create 1 more pod
<p>Controller sees: 4 pods running
Desired state: 3 replicas  
Action: Delete 1 pod</code></pre></p>
<h3>5. Cloud Controller Manager</h3>
<strong>Integrates with cloud providers (AWS, GCP, Azure)</strong>
<pre><code class="language-yaml">Responsibilities:
<li>Node Controller: Check cloud provider if node deleted</li>
<li>Route Controller: Set up routes in cloud network</li>
<li>Service Controller: Create cloud load balancers</li>
<li>Volume Controller: Create/attach/mount cloud volumes</li>
<h1>Example: AWS Load Balancer</h1>
apiVersion: v1
kind: Service
metadata:
  name: web
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-type: nlb
spec:
  type: LoadBalancer  # Cloud controller creates AWS NLB
  selector:
    app: web
  ports:
  - port: 80</code></pre>
<p>---</p>
<h2>Node Components</h2>
<h3>1. kubelet</h3>
<strong>Node agent - ensures containers are running</strong>
<pre><code class="language-text">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            kubelet                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ 1. Watches API Server        ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ    for Pods assigned to node ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ 2. Talks to Container        ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ    Runtime (Docker/containerd)‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ 3. Reports Pod status back   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ    to API Server             ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ 4. Monitors Pod health       ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ    (liveness/readiness)      ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</code></pre>
<strong>Key Responsibilities:</strong>
<pre><code class="language-bash">‚úÖ Pod lifecycle management
‚úÖ Mount volumes to pods
‚úÖ Download secrets
‚úÖ Execute container health checks
‚úÖ Report metrics (CPU, memory usage)
‚úÖ Execute pod lifecycle hooks</code></pre>
<strong>Example: kubelet in action</strong>
<pre><code class="language-yaml"># API Server assigns this Pod to node-1
apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - name: nginx
    image: nginx
    livenessProbe:     # kubelet runs this check
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 3
      periodSeconds: 3</code></pre>
<pre><code class="language-bash"># kubelet on node-1:
1. Sees new Pod assignment
2. Pulls nginx image
3. Creates container
4. Starts liveness probe (HTTP GET / every 3s)
5. Reports &quot;Running&quot; status to API Server</code></pre>
<h3>2. kube-proxy</h3>
<strong>Manages network rules for Pod communication</strong>
<pre><code class="language-text">Service: web (ClusterIP: 10.96.1.100)
         ‚Üì
kube-proxy creates iptables rules:
         ‚Üì
Traffic to 10.96.1.100:80
         ‚Üì
Load balanced to:
  - Pod 1: 192.168.1.10:8080
  - Pod 2: 192.168.1.11:8080
  - Pod 3: 192.168.1.12:8080</code></pre>
<strong>Modes:</strong>
<p>1. <strong>iptables mode</strong> (default):
<pre><code class="language-bash"># kube-proxy creates iptables rules
sudo iptables-save | grep &quot;my-service&quot;
<h1>-A KUBE-SVC-XXX -m statistic --mode random --probability 0.33 -j KUBE-SEP-POD1</h1>
<h1>-A KUBE-SVC-XXX -m statistic --mode random --probability 0.50 -j KUBE-SEP-POD2</h1>
<h1>-A KUBE-SVC-XXX -j KUBE-SEP-POD3</code></pre></h1></p>
<p>2. <strong>IPVS mode</strong> (higher performance):
<pre><code class="language-bash"># Better for clusters with many services
ipvsadm -Ln
<h1>TCP  10.96.1.100:80 rr</h1>
<h1>  -&gt; 192.168.1.10:8080  Masq    1      0          0</h1>
<h1>  -&gt; 192.168.1.11:8080  Masq    1      0          0</code></pre></h1></p>
<h3>3. Container Runtime</h3>
<strong>Actually runs containers (Docker, containerd, CRI-O)</strong>
<pre><code class="language-bash"># Kubernetes doesn&#039;t run containers directly
<h1>It uses Container Runtime Interface (CRI)</h1>
<p>kubelet ‚Üí CRI ‚Üí containerd ‚Üí runc ‚Üí Container</p>
<h1>Most common runtimes:</h1>
1. containerd (Docker&#039;s core, now standalone)
2. CRI-O (RedHat&#039;s lightweight runtime)  
3. Docker (deprecated in K8s 1.24+, use containerd)</code></pre>
<strong>Container Runtime Interface:</strong>
<pre><code class="language-go">// CRI defines standard interface
type RuntimeService interface {
    // Pod operations
    RunPodSandbox(config *PodSandboxConfig) (string, error)
    StopPodSandbox(podSandboxID string) error
    
    // Container operations
    CreateContainer(podSandboxID string, config *ContainerConfig) (string, error)
    StartContainer(containerID string) error
    StopContainer(containerID string, timeout int64) error
    RemoveContainer(containerID string) error
}</code></pre>
<p>---</p>
<h2>Kubernetes Objects</h2>
<h3>Core Objects</h3>
<pre><code class="language-yaml"># 1. Pod - Smallest deployable unit
apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - name: nginx
    image: nginx:1.21
<p>---
<h1>2. Service - Exposes Pods to network</h1>
apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  selector:
    app: nginx
  ports:
  - port: 80
    targetPort: 8080</p>
<p>---
<h1>3. Deployment - Manages Pod replicas</h1>
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.21</p>
<p>---
<h1>4. ConfigMap - Configuration data</h1>
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
data:
  database_url: &quot;postgres://db:5432/myapp&quot;
  log_level: &quot;info&quot;</p>
<p>---
<h1>5. Secret - Sensitive data</h1>
apiVersion: v1
kind: Secret
metadata:
  name: db-secret
type: Opaque
data:
  password: cGFzc3dvcmQxMjM=  # base64 encoded</p>
<p>---
<h1>6. Namespace - Virtual cluster</h1>
apiVersion: v1
kind: Namespace
metadata:
  name: production</code></pre></p>
<h3>Object Metadata</h3>
<pre><code class="language-yaml"># All objects have metadata
metadata:
  name: my-app              # Required: object name
  namespace: production     # Optional: namespace (default: &quot;default&quot;)
  labels:                   # Key-value pairs for selection
    app: web
    env: production
    version: v1.2.0
  annotations:              # Non-identifying metadata
    description: &quot;Main web application&quot;
    owner: &quot;platform-team&quot;
    prometheus.io/scrape: &quot;true&quot;</code></pre>
<p>---</p>
<h2>How Everything Works Together</h2>
<h3>Scenario: User Creates a Deployment</h3>
<pre><code class="language-bash">kubectl create deployment nginx --image=nginx --replicas=3</code></pre>
<strong>Step-by-Step Flow:</strong>
<pre><code class="language-text">1. kubectl ‚Üí API Server
   - POST /apis/apps/v1/namespaces/default/deployments
   - Authentication &amp; Authorization
   
2. API Server ‚Üí etcd
   - Stores Deployment object
   - Returns success to kubectl
   
3. Deployment Controller (watching API Server)
   - Sees new Deployment
   - Creates ReplicaSet object
   - API Server ‚Üí etcd (stores ReplicaSet)
   
4. ReplicaSet Controller (watching API Server)
   - Sees new ReplicaSet with replicas=3
   - Creates 3 Pod objects
   - API Server ‚Üí etcd (stores Pods)
   
5. Scheduler (watching for unscheduled Pods)
   - Sees 3 unscheduled Pods
   - Selects best nodes for each Pod
   - Binds Pods to nodes (updates etcd)
   
6. kubelet on each selected node (watching API Server)
   - Sees Pod assigned to its node
   - Tells container runtime to pull nginx image
   - Starts container
   - Reports status to API Server
   
7. kube-proxy on each node
   - Updates network rules if Service exists
   - Enables load balancing to Pods</code></pre>
<h3>Visual Flow</h3>
<pre><code class="language-text">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  kubectl ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ 1. Create Deployment
     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      2. Store      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ API Server ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ etcd ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
      ‚îÇ
      ‚îÇ 3. Watch
      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Deployment Ctrl  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ 4. Create ReplicaSet
     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ReplicaSet Ctrl  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ 5. Create 3 Pods
     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ    Scheduler     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ 6. Bind to Nodes
     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    7. Start Containers    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     kubelet      ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ Container  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                            ‚îÇ  Runtime   ‚îÇ
                                                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</code></pre>
<p>---</p>
<h2>Installation Options</h2>
<h3>1. Local Development</h3>
<pre><code class="language-bash"># Minikube (single-node cluster)
brew install minikube
minikube start
minikube status
<h1>Kind (Kubernetes in Docker)</h1>
brew install kind
kind create cluster
kind get clusters
<h1>Docker Desktop (built-in K8s)</h1>
<h1>Enable in Docker Desktop ‚Üí Preferences ‚Üí Kubernetes</code></pre></h1>
<h3>2. MicroK8s (Lightweight K8s)</h3>
<pre><code class="language-bash"># Ubuntu/Linux
sudo snap install microk8s --classic
<h1>Start MicroK8s</h1>
microk8s start
<h1>Enable addons</h1>
microk8s enable dns storage ingress
<h1>Use kubectl</h1>
microk8s kubectl get nodes</code></pre>
<h3>3. Production Clusters</h3>
<pre><code class="language-bash"># Managed Kubernetes
<li>AWS EKS (Elastic Kubernetes Service)</li>
<li>Google GKE (Google Kubernetes Engine)</li>
<li>Azure AKS (Azure Kubernetes Service)</li>
<li>DigitalOcean DOKS</li>
<h1>Self-Managed</h1>
<li>kubeadm (official K8s installer)</li>
<li>Rancher (management platform)</li>
<li>OpenShift (RedHat&#039;s K8s distribution)</code></pre></li>
<p>---</p>
<h2>kubectl Basics</h2>
<h3>Installation</h3>
<pre><code class="language-bash"># macOS
brew install kubectl
<h1>Linux</h1>
curl -LO &quot;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl&quot;
sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
<h1>Verify</h1>
kubectl version --client</code></pre>
<h3>Essential Commands</h3>
<pre><code class="language-bash"># Cluster info
kubectl cluster-info
kubectl get nodes
kubectl get all --all-namespaces
<h1>Create resources</h1>
kubectl create deployment nginx --image=nginx
kubectl create service clusterip nginx --tcp=80:80
<h1>Get resources</h1>
kubectl get pods
kubectl get pods -o wide    # More details
kubectl get pods -w         # Watch for changes
<h1>Describe (detailed info)</h1>
kubectl describe pod nginx-abc123
kubectl describe node node-1
<h1>Logs</h1>
kubectl logs pod-name
kubectl logs pod-name -f              # Follow logs
kubectl logs pod-name -c container    # Multi-container pod
<h1>Execute commands</h1>
kubectl exec -it pod-name -- /bin/bash
kubectl exec pod-name -- ls /app
<h1>Apply YAML</h1>
kubectl apply -f deployment.yaml
kubectl apply -f ./configs/          # Apply directory
<h1>Delete resources</h1>
kubectl delete pod nginx
kubectl delete deployment nginx
kubectl delete -f deployment.yaml
<h1>Edit resources</h1>
kubectl edit deployment nginx
<h1>Scale</h1>
kubectl scale deployment nginx --replicas=5
<h1>Port forwarding</h1>
kubectl port-forward pod/nginx 8080:80
<h1>Access at http://localhost:8080</code></pre></h1>
<h3>Kubectl Context & Namespaces</h3>
<pre><code class="language-bash"># View contexts (clusters)
kubectl config get-contexts
<h1>Switch context</h1>
kubectl config use-context minikube
<h1>View current context</h1>
kubectl config current-context
<h1>Set default namespace</h1>
kubectl config set-context --current --namespace=production
<h1>List namespaces</h1>
kubectl get namespaces
<h1>Create namespace</h1>
kubectl create namespace staging</code></pre>
<p>---</p>
<h2>Best Practices</h2>
<h3>1. Resource Requests & Limits</h3>
<pre><code class="language-yaml"># Always set resource requests and limits
spec:
  containers:
  - name: app
    resources:
      requests:
        cpu: &quot;100m&quot;      # Guaranteed
        memory: &quot;128Mi&quot;
      limits:
        cpu: &quot;500m&quot;      # Maximum
        memory: &quot;512Mi&quot;</code></pre>
<h3>2. Health Checks</h3>
<pre><code class="language-yaml"># Use liveness and readiness probes
spec:
  containers:
  - name: app
    livenessProbe:      # Restart if fails
      httpGet:
        path: /healthz
        port: 8080
      initialDelaySeconds: 10
      periodSeconds: 5
    readinessProbe:     # Remove from Service if fails
      httpGet:
        path: /ready
        port: 8080
      initialDelaySeconds: 5
      periodSeconds: 3</code></pre>
<h3>3. Use Namespaces</h3>
<pre><code class="language-yaml"># Separate environments/teams
kubectl create namespace dev
kubectl create namespace staging
kubectl create namespace production
<h1>Set resource quotas per namespace</h1>
apiVersion: v1
kind: ResourceQuota
metadata:
  name: compute-quota
  namespace: production
spec:
  hard:
    requests.cpu: &quot;100&quot;
    requests.memory: &quot;200Gi&quot;
    limits.cpu: &quot;200&quot;
    limits.memory: &quot;400Gi&quot;</code></pre>
<h3>4. Labels & Selectors</h3>
<pre><code class="language-yaml"># Use consistent labeling
metadata:
  labels:
    app: web
    tier: frontend
    env: production
    version: v1.2.0</code></pre>
<h3>5. Don't Use Latest Tag</h3>
<pre><code class="language-yaml"># ‚ùå Bad
spec:
  containers:
  - name: app
    image: nginx:latest
<h1>‚úÖ Good</h1>
spec:
  containers:
  - name: app
    image: nginx:1.21.6</code></pre>
<p>---</p>
<h2>Interview Questions</h2>
<strong>Q1: Explain the role of etcd in Kubernetes.</strong>
<strong>Answer:</strong> etcd is the distributed key-value store that serves as Kubernetes' database. It stores all cluster state including Pods, Services, Secrets, and ConfigMaps. Only the API Server communicates with etcd. If etcd fails, the entire cluster becomes read-only and cannot process updates.
<strong>Q2: What's the difference between kubectl and kubelet?</strong>
<strong>Answer:</strong>
<li><strong>kubectl</strong>: Command-line tool for users to interact with the Kubernetes API</li>
<li><strong>kubelet</strong>: Node agent that runs on every worker node and manages pod lifecycle</li>
<strong>Q3: How does the scheduler decide which node to place a Pod on?</strong>
<strong>Answer:</strong> The scheduler uses a two-phase process:
1. <strong>Filtering</strong>: Eliminates nodes that don't meet requirements (resources, node selectors, taints)
2. <strong>Scoring</strong>: Ranks remaining nodes based on priorities (resource balance, affinity rules, etc.)
The Pod is placed on the highest-scoring node.
<strong>Q4: What happens if the control plane goes down?</strong>
<strong>Answer:</strong> Existing Pods continue running (kubelet is autonomous), but you cannot:
<li>Create new Pods</li>
<li>Update existing resources</li>
<li>Schedule new workloads</li>
<li>Scale deployments</li>
The cluster becomes read-only until the control plane recovers.
<strong>Q5: Explain the reconciliation loop pattern.</strong>
<strong>Answer:</strong> Controllers continuously compare desired state (from etcd via API Server) with actual state (from cluster). When they differ, the controller takes action to reconcile, bringing actual state to match desired state. This loop runs continuously, making K8s self-healing.
<p>---</p>
<h2>Hands-On Exercise</h2>
<h3>Task: Deploy a Multi-Tier Application</h3>
<strong>Objective:</strong> Deploy a web app with:
<li>Frontend (nginx)</li>
<li>Backend (API server)</li>
<li>Database (PostgreSQL)</li>
<strong>Steps:</strong>
<pre><code class="language-bash"># 1. Create namespace
kubectl create namespace webapp
<h1>2. Deploy PostgreSQL</h1>
kubectl apply -f - &lt;&lt;EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: postgres
  namespace: webapp
spec:
  replicas: 1
  selector:
    matchLabels:
      app: postgres
  template:
    metadata:
      labels:
        app: postgres
    spec:
      containers:
      - name: postgres
        image: postgres:14
        env:
        - name: POSTGRES_PASSWORD
          value: mysecretpassword
        ports:
        - containerPort: 5432
---
apiVersion: v1
kind: Service
metadata:
  name: postgres
  namespace: webapp
spec:
  selector:
    app: postgres
  ports:
  - port: 5432
EOF
<h1>3. Verify deployment</h1>
kubectl get pods -n webapp
kubectl get services -n webapp
<h1>4. Check logs</h1>
kubectl logs -n webapp deployment/postgres
<h1>5. Test connectivity</h1>
kubectl run -it --rm debug --image=postgres:14 --restart=Never -n webapp -- psql -h postgres -U postgres</code></pre>
<strong>Verification:</strong>
1. All components running
2. Services accessible
3. Understand how scheduler placed Pods
4. View architecture with <code>kubectl get all -n webapp</code>
<p>---</p>
<h2>üìö Additional Resources</h2>
<li>[Official Kubernetes Docs](https://kubernetes.io/docs/)</li>
<li>[Kubernetes Components](https://kubernetes.io/docs/concepts/overview/components/)</li>
<li>[kubectl Cheat Sheet](https://kubernetes.io/docs/reference/kubectl/cheatsheet/)</li>
<li>[Kubernetes The Hard Way](https://github.com/kelseyhightower/kubernetes-the-hard-way)</li>
<p>---</p>
<h2>‚úÖ Module Checklist</h2>
<li>[ ] Understand Kubernetes architecture (control plane + nodes)</li>
<li>[ ] Know what each component does (API Server, etcd, scheduler, etc.)</li>
<li>[ ] Explain the reconciliation loop pattern</li>
<li>[ ] Install a local Kubernetes cluster</li>
<li>[ ] Master essential kubectl commands</li>
<li>[ ] Understand how Pods are scheduled</li>
<li>[ ] Deploy a multi-tier application</li>
<li>[ ] Complete the hands-on exercise</li></ul>
<p>---</p>
<strong>Next Module:</strong> [Module 07: Kubernetes Core CRDs](./07_Kubernetes_Workloads_CRDs.md) - Master Pods, Deployments, StatefulSets, and more! üöÄ

    </div>
    

    <div class="module-content" id="module-7">
        <h1>Module 07: Kubernetes Workloads & CRDs üéØ</h1>
<h2>Master All Core Custom Resource Definitions</h2>
<strong>Duration:</strong> 5-6 hours  
<strong>Prerequisites:</strong> Module 06 (K8s Architecture)  
<strong>Outcome:</strong> Deep understanding of all 7 core workload types and when to use each
<p>---</p>
<h2>üìö Table of Contents</h2>
<p>1. [Understanding CRDs](#understanding-crds)
2. [Pods - The Fundamental Unit](#pods---the-fundamental-unit)
3. [ReplicaSets - Replica Management](#replicasets---replica-management)
4. [Deployments - Declarative Updates](#deployments---declarative-updates)
5. [StatefulSets - Stateful Applications](#statefulsets---stateful-applications)
6. [DaemonSets - Node-Level Workloads](#daemonsets---node-level-workloads)
7. [Jobs - Run-to-Completion](#jobs---run-to-completion)
8. [CronJobs - Scheduled Tasks](#cronjobs---scheduled-tasks)
9. [Comparison & When to Use What](#comparison--when-to-use-what)
10. [Interview Questions](#interview-questions)
11. [Hands-On Exercise](#hands-on-exercise)</p>
<p>---</p>
<h2>Understanding CRDs</h2>
<h3>What are Custom Resource Definitions?</h3>
<strong>CRD (Custom Resource Definition)</strong> extends Kubernetes API with custom objects.
<pre><code class="language-text">Built-in Resources:        Custom Resources (via CRDs):
<ul><li>Pods                     - PostgreSQL (operator)</li>
<li>Services                 - Prometheus (operator)</li>
<li>Deployments              - Certificate (cert-manager)</li>
<li>ConfigMaps               - VirtualService (Istio)</code></pre></li>
<h3>Core Workload CRDs</h3>
<pre><code class="language-yaml"># 7 Core Workload Types in Kubernetes
<p>1. Pod              # Single instance, ephemeral
2. ReplicaSet       # Maintains replica count (rarely used directly)
3. Deployment       # Declarative updates, rollbacks (MOST COMMON)
4. StatefulSet      # Stateful apps (databases, Kafka)
5. DaemonSet        # One pod per node (logging, monitoring)
6. Job              # Run-to-completion tasks
7. CronJob          # Scheduled jobs</code></pre></p>
<p>---</p>
<h2>Pods - The Fundamental Unit</h2>
<h3>What is a Pod?</h3>
<strong>Smallest deployable unit</strong> in Kubernetes. Can contain one or more containers.
<pre><code class="language-text">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           Pod                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  Container  ‚îÇ  ‚îÇ Container‚îÇ ‚îÇ
‚îÇ  ‚îÇ  (nginx)    ‚îÇ  ‚îÇ (sidecar)‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ  Shared:                        ‚îÇ
‚îÇ  - Network namespace (localhost)‚îÇ
‚îÇ  - Storage volumes              ‚îÇ
‚îÇ  - IPC namespace                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</code></pre>
<h3>Basic Pod</h3>
<pre><code class="language-yaml">apiVersion: v1
kind: Pod
metadata:
  name: nginx-pod
  labels:
    app: nginx
    env: production
spec:
  containers:
  - name: nginx
    image: nginx:1.21
    ports:
    - containerPort: 80
    resources:
      requests:
        cpu: &quot;100m&quot;
        memory: &quot;128Mi&quot;
      limits:
        cpu: &quot;500m&quot;
        memory: &quot;512Mi&quot;</code></pre>
<pre><code class="language-bash"># Create pod
kubectl apply -f pod.yaml
<h1>Get pod details</h1>
kubectl get pod nginx-pod
kubectl describe pod nginx-pod
<h1>Logs</h1>
kubectl logs nginx-pod
<h1>Execute command</h1>
kubectl exec -it nginx-pod -- /bin/bash
<h1>Delete pod</h1>
kubectl delete pod nginx-pod</code></pre>
<h3>Multi-Container Pod (Sidecar Pattern)</h3>
<pre><code class="language-yaml">apiVersion: v1
kind: Pod
metadata:
  name: web-with-logger
spec:
  containers:
  # Main application
  - name: web-app
    image: nginx:1.21
    ports:
    - containerPort: 80
    volumeMounts:
    - name: shared-logs
      mountPath: /var/log/nginx
  
  # Sidecar: Log processor
  - name: log-processor
    image: busybox:1.35
    command: [&quot;/bin/sh&quot;]
    args: [&quot;-c&quot;, &quot;tail -f /logs/access.log&quot;]
    volumeMounts:
    - name: shared-logs
      mountPath: /logs
  
  # Shared volume between containers
  volumes:
  - name: shared-logs
    emptyDir: {}</code></pre>
<strong>Sidecar Use Cases:</strong>
<li>Log forwarding (Fluentd, Filebeat)</li>
<li>Service mesh proxy (Envoy, Istio)</li>
<li>Configuration sync</li>
<li>Monitoring agents</li>
<h3>Init Containers</h3>
<pre><code class="language-yaml">apiVersion: v1
kind: Pod
metadata:
  name: myapp-pod
spec:
  # Init containers run BEFORE main containers
  initContainers:
  - name: init-database
    image: busybox:1.35
    command: [&#039;sh&#039;, &#039;-c&#039;, &#039;until nslookup postgres-service; do echo waiting for postgres; sleep 2; done&#039;]
  
  - name: init-migrations
    image: myapp:1.0
    command: [&#039;python&#039;, &#039;manage.py&#039;, &#039;migrate&#039;]
  
  # Main container starts only after init containers succeed
  containers:
  - name: myapp
    image: myapp:1.0
    ports:
    - containerPort: 8080</code></pre>
<h3>Pod Lifecycle</h3>
<pre><code class="language-text">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Pending  ‚îÇ  Pod accepted, waiting for scheduling
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ
     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Running  ‚îÇ  All containers started successfully
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ
     ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
     ‚îÇ        ‚îÇ Succeeded ‚îÇ  All containers exited with 0
     ‚îÇ        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ
     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ  Failed   ‚îÇ  Container exited with error
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
<p>Other States:
<li>Unknown: Communication lost with node</li>
<li>CrashLoopBackOff: Container keeps crashing</li>
<li>ImagePullBackOff: Can&#039;t pull container image</code></pre></li></p>
<h3>Pod Restart Policies</h3>
<pre><code class="language-yaml">spec:
  restartPolicy: Always    # Default: Always restart (for Deployments)
  # OR
  restartPolicy: OnFailure # Restart only if exits with error (for Jobs)
  # OR
  restartPolicy: Never     # Never restart (for one-off tasks)</code></pre>
<h3>Health Checks</h3>
<pre><code class="language-yaml">spec:
  containers:
  - name: app
    image: myapp:1.0
    
    # Liveness Probe: Restart if fails
    livenessProbe:
      httpGet:
        path: /healthz
        port: 8080
      initialDelaySeconds: 30
      periodSeconds: 10
      failureThreshold: 3
    
    # Readiness Probe: Remove from Service if fails
    readinessProbe:
      httpGet:
        path: /ready
        port: 8080
      initialDelaySeconds: 5
      periodSeconds: 5
    
    # Startup Probe: For slow-starting containers
    startupProbe:
      httpGet:
        path: /startup
        port: 8080
      failureThreshold: 30
      periodSeconds: 10</code></pre>
<strong>Probe Types:</strong>
<pre><code class="language-yaml"># HTTP GET
livenessProbe:
  httpGet:
    path: /health
    port: 8080
    httpHeaders:
    - name: Custom-Header
      value: Awesome
<h1>TCP Socket</h1>
livenessProbe:
  tcpSocket:
    port: 3306
  initialDelaySeconds: 15
<h1>Command Execution</h1>
livenessProbe:
  exec:
    command:
    - cat
    - /tmp/healthy
  initialDelaySeconds: 5</code></pre>
<p>---</p>
<h2>ReplicaSets - Replica Management</h2>
<h3>What is a ReplicaSet?</h3>
<p>Ensures a specified number of pod replicas are running at all times.</p>
<pre><code class="language-yaml">apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: nginx-replicaset
spec:
  replicas: 3  # Desired number of pods
  
  # Label selector: Which pods to manage
  selector:
    matchLabels:
      app: nginx
  
  # Pod template: How to create new pods
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.21
        ports:
        - containerPort: 80</code></pre>
<pre><code class="language-bash"># Create ReplicaSet
kubectl apply -f replicaset.yaml
<h1>Get ReplicaSets</h1>
kubectl get replicaset
kubectl get rs  # Short form
<h1>Output:</h1>
<h1>NAME               DESIRED   CURRENT   READY   AGE</h1>
<h1>nginx-replicaset   3         3         3       1m</h1>
<h1>Scale ReplicaSet</h1>
kubectl scale replicaset nginx-replicaset --replicas=5
<h1>Delete ReplicaSet (and its pods)</h1>
kubectl delete replicaset nginx-replicaset</code></pre>
<h3>How ReplicaSets Work</h3>
<pre><code class="language-text">User: Create ReplicaSet with replicas=3
<p>ReplicaSet Controller:
1. Watches API Server for ReplicaSet objects
2. Counts pods matching label selector (app=nginx)
3. Found 0 pods, need 3 ‚Üí Create 3 pods
4. Continuously monitors:
   - If pod deleted ‚Üí Create new one
   - If manual pod created ‚Üí Delete extra pod
   - Always maintains exactly 3 replicas</code></pre></p>
<h3>Label Selectors</h3>
<pre><code class="language-yaml"># Match Labels (equality-based)
selector:
  matchLabels:
    app: nginx
    tier: frontend
<h1>Match Expressions (set-based)</h1>
selector:
  matchExpressions:
  - key: app
    operator: In
    values:
    - nginx
    - apache
  - key: tier
    operator: NotIn
    values:
    - database
  - key: environment
    operator: Exists  # Key must exist (any value)</code></pre>
<h3>Why You Rarely Use ReplicaSets Directly</h3>
<p>‚ùå <strong>Don't use ReplicaSets directly</strong> because:
<li>No rolling update mechanism</li>
<li>No rollback capability</li>
<li>No deployment history</li></p>
<p>‚úÖ <strong>Use Deployments instead</strong> - they manage ReplicaSets for you with:
<li>Rolling updates</li>
<li>Rollback support</li>
<li>Update strategies</li>
<li>Revision history</li></p>
<p>---</p>
<h2>Deployments - Declarative Updates</h2>
<h3>What is a Deployment?</h3>
<strong>Most common workload type</strong> - manages ReplicaSets and provides declarative updates.
<pre><code class="language-text">Deployment ‚Üí Creates/Manages ‚Üí ReplicaSet ‚Üí Creates/Manages ‚Üí Pods</code></pre>
<h3>Basic Deployment</h3>
<pre><code class="language-yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  
  # Update strategy
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1        # Max pods above desired count during update
      maxUnavailable: 1  # Max pods unavailable during update
  
  # Pod template
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.21
        ports:
        - containerPort: 80
        resources:
          requests:
            cpu: &quot;100m&quot;
            memory: &quot;128Mi&quot;
          limits:
            cpu: &quot;500m&quot;
            memory: &quot;512Mi&quot;</code></pre>
<pre><code class="language-bash"># Create deployment
kubectl apply -f deployment.yaml
<h1>Get deployments</h1>
kubectl get deployments
kubectl get deploy  # Short form
<h1>Output:</h1>
<h1>NAME               READY   UP-TO-DATE   AVAILABLE   AGE</h1>
<h1>nginx-deployment   3/3     3            3           2m</h1>
<h1>View ReplicaSets created by Deployment</h1>
kubectl get replicaset
<h1>View Pods</h1>
kubectl get pods</code></pre>
<h3>Rolling Updates</h3>
<pre><code class="language-bash"># Update image
kubectl set image deployment/nginx-deployment nginx=nginx:1.22
<h1>Watch rollout status</h1>
kubectl rollout status deployment/nginx-deployment
<h1>Output:</h1>
<h1>Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 1 out of 3 new replicas have been updated...</h1>
<h1>Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 2 out of 3 new replicas have been updated...</h1>
<h1>Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 1 old replicas are pending termination...</h1>
<h1>deployment &quot;nginx-deployment&quot; successfully rolled out</code></pre></h1>
<strong>Rolling Update Process:</strong>
<pre><code class="language-text">Initial State: 3 pods (v1.21)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ v1.21‚îÇ ‚îÇv1.21‚îÇ ‚îÇv1.21‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
<p>Step 1: Create new pod (v1.22)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇv1.21‚îÇ ‚îÇv1.21‚îÇ ‚îÇv1.21‚îÇ ‚îÇv1.22‚îÇ  maxSurge=1 allows 4 pods
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>Step 2: Wait for new pod Ready, then delete old pod
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇv1.21‚îÇ ‚îÇv1.21‚îÇ ‚îÇv1.22‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>Step 3: Repeat until all updated
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇv1.22‚îÇ ‚îÇv1.22‚îÇ ‚îÇv1.22‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</code></pre></p>
<h3>Rollback</h3>
<pre><code class="language-bash"># View rollout history
kubectl rollout history deployment/nginx-deployment
<h1>Output:</h1>
<h1>REVISION  CHANGE-CAUSE</h1>
<h1>1         &lt;none&gt;</h1>
<h1>2         Image updated to nginx:1.22</h1>
<h1>Rollback to previous version</h1>
kubectl rollout undo deployment/nginx-deployment
<h1>Rollback to specific revision</h1>
kubectl rollout undo deployment/nginx-deployment --to-revision=1
<h1>Pause rollout (stop mid-update)</h1>
kubectl rollout pause deployment/nginx-deployment
<h1>Resume rollout</h1>
kubectl rollout resume deployment/nginx-deployment</code></pre>
<h3>Update Strategies</h3>
<p>#### 1. RollingUpdate (Default)</p>
<pre><code class="language-yaml">strategy:
  type: RollingUpdate
  rollingUpdate:
    maxSurge: 25%         # Can be percentage or absolute number
    maxUnavailable: 25%   # Can be percentage or absolute number</code></pre>
<strong>Example with 10 replicas:</strong>
<li><code>maxSurge: 3</code> ‚Üí Can have up to 13 pods during update</li>
<li><code>maxUnavailable: 2</code> ‚Üí Min 8 pods must be available</li>
<p>#### 2. Recreate</p>
<pre><code class="language-yaml">strategy:
  type: Recreate  # Kill all old pods, then create new ones</code></pre>
<strong>Use Cases:</strong>
<li>When you can't run old and new versions simultaneously</li>
<li>Database schema changes</li>
<li>Resource constraints</li>
<h3>Scaling</h3>
<pre><code class="language-bash"># Imperative scaling
kubectl scale deployment nginx-deployment --replicas=5
<h1>Declarative scaling (edit YAML)</h1>
kubectl edit deployment nginx-deployment
<h1>Change replicas: 3 to replicas: 5</h1>
<h1>Autoscaling (HPA - Horizontal Pod Autoscaler)</h1>
kubectl autoscale deployment nginx-deployment --min=3 --max=10 --cpu-percent=80</code></pre>
<h3>Deployment Use Cases</h3>
<p>‚úÖ <strong>Perfect for:</strong>
<li>Stateless applications (web servers, APIs)</li>
<li>Microservices</li>
<li>Any app that can have multiple identical replicas</li>
<li>Applications requiring rolling updates</li></p>
<p>‚ùå <strong>Not suitable for:</strong>
<li>Stateful apps requiring stable network identity (use StatefulSet)</li>
<li>Node-level daemons (use DaemonSet)</li>
<li>Batch jobs (use Job/CronJob)</li></p>
<p>---</p>
<h2>StatefulSets - Stateful Applications</h2>
<h3>What is a StatefulSet?</h3>
<p>For <strong>stateful applications</strong> that require:
<li><strong>Stable network identity</strong> (predictable DNS names)</li>
<li><strong>Stable persistent storage</strong> (volumes tied to specific pods)</li>
<li><strong>Ordered deployment and scaling</strong></li>
<li><strong>Ordered rolling updates</strong></li></p>
<pre><code class="language-yaml">apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgresql
spec:
  serviceName: &quot;postgres&quot;  # Headless service for stable network identity
  replicas: 3
  selector:
    matchLabels:
      app: postgres
  
  template:
    metadata:
      labels:
        app: postgres
    spec:
      containers:
      - name: postgres
        image: postgres:14
        ports:
        - containerPort: 5432
        env:
        - name: POSTGRES_PASSWORD
          value: mysecretpassword
        volumeMounts:
        - name: postgres-storage
          mountPath: /var/lib/postgresql/data
  
  # Volume Claim Template: Creates PVC for each pod
  volumeClaimTemplates:
  - metadata:
      name: postgres-storage
    spec:
      accessModes: [ &quot;ReadWriteOnce&quot; ]
      resources:
        requests:
          storage: 10Gi</code></pre>
<h3>StatefulSet Pod Naming</h3>
<pre><code class="language-text">Deployment:  nginx-deployment-abc123-xyz789  (random hash)
StatefulSet: postgresql-0, postgresql-1, postgresql-2  (predictable)
<h1>DNS names (with headless service)</h1>
postgresql-0.postgres.default.svc.cluster.local
postgresql-1.postgres.default.svc.cluster.local
postgresql-2.postgres.default.svc.cluster.local</code></pre>
<h3>Headless Service for StatefulSet</h3>
<pre><code class="language-yaml">apiVersion: v1
kind: Service
metadata:
  name: postgres
spec:
  clusterIP: None  # Headless service
  selector:
    app: postgres
  ports:
  - port: 5432</code></pre>
<pre><code class="language-bash"># With headless service, each pod gets DNS entry
nslookup postgresql-0.postgres.default.svc.cluster.local
<h1>Returns: 10.244.1.5</h1>
<h1>Normal service returns VIP, headless returns actual pod IPs</code></pre></h1>
<h3>Ordered Operations</h3>
<pre><code class="language-bash"># Creating Pods
kubectl apply -f statefulset.yaml
<h1>Pods created sequentially:</h1>
1. postgresql-0 created ‚Üí Wait until Running and Ready
2. postgresql-1 created ‚Üí Wait until Running and Ready
3. postgresql-2 created ‚Üí Done
<h1>Deleting Pods (reverse order)</h1>
kubectl delete statefulset postgresql
<h1>Pods deleted sequentially:</h1>
1. postgresql-2 deleted ‚Üí Wait until terminated
2. postgresql-1 deleted ‚Üí Wait until terminated
3. postgresql-0 deleted ‚Üí Done</code></pre>
<h3>Scaling StatefulSet</h3>
<pre><code class="language-bash"># Scale up (sequential)
kubectl scale statefulset postgresql --replicas=5
<h1>Creates: postgresql-3, then postgresql-4</h1>
<h1>Scale down (reverse sequential)</h1>
kubectl scale statefulset postgresql --replicas=2
<h1>Deletes: postgresql-4, then postgresql-3</code></pre></h1>
<h3>Persistent Storage</h3>
<pre><code class="language-yaml"># Each pod gets its own PVC
kubectl get pvc
<h1>NAME                         STATUS   VOLUME                                     </h1>
<h1>postgres-storage-postgresql-0   Bound    pvc-abc123...</h1>
<h1>postgres-storage-postgresql-1   Bound    pvc-def456...</h1>
<h1>postgres-storage-postgresql-2   Bound    pvc-ghi789...</h1>
<h1>If pod postgresql-1 is deleted and recreated,</h1>
<h1>it gets the SAME PVC (postgres-storage-postgresql-1)</h1>
<h1>Data persists across pod restarts!</code></pre></h1>
<h3>StatefulSet Update Strategy</h3>
<pre><code class="language-yaml">spec:
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      partition: 0  # Only update pods with ordinal &gt;= partition</code></pre>
<pre><code class="language-bash"># Update strategy examples
<h1>1. Update all pods (default)</h1>
kubectl set image statefulset/postgresql postgres=postgres:15
<h1>Pods updated in reverse order:</h1>
<h1>postgresql-2 ‚Üí postgresql-1 ‚Üí postgresql-0</h1>
<h1>2. Canary rollout (test on one pod first)</h1>
kubectl patch statefulset postgresql -p &#039;{&quot;spec&quot;:{&quot;updateStrategy&quot;:{&quot;rollingUpdate&quot;:{&quot;partition&quot;:2}}}}&#039;
kubectl set image statefulset/postgresql postgres=postgres:15
<h1>Only postgresql-2 updated (ordinal &gt;= 2)</h1>
<h1>If successful, update all</h1>
kubectl patch statefulset postgresql -p &#039;{&quot;spec&quot;:{&quot;updateStrategy&quot;:{&quot;rollingUpdate&quot;:{&quot;partition&quot;:0}}}}&#039;</code></pre>
<h3>StatefulSet Use Cases</h3>
<p>‚úÖ <strong>Perfect for:</strong>
<li>Databases (PostgreSQL, MySQL, MongoDB)</li>
<li>Distributed systems (Kafka, Elasticsearch, Redis cluster)</li>
<li>Applications requiring stable identity</li>
<li>Master-slave configurations</li></p>
<p>‚ùå <strong>Not suitable for:</strong>
<li>Stateless applications (use Deployment)</li>
<li>Node-level daemons (use DaemonSet)</li></p>
<p>---</p>
<h2>DaemonSets - Node-Level Workloads</h2>
<h3>What is a DaemonSet?</h3>
<p>Ensures <strong>one pod runs on every node</strong> (or selected nodes).</p>
<pre><code class="language-text">Cluster with 5 nodes:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇNode 1‚îÇ  ‚îÇNode 2‚îÇ  ‚îÇNode 3‚îÇ  ‚îÇNode 4‚îÇ  ‚îÇNode 5‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îò
    ‚îÇ         ‚îÇ         ‚îÇ         ‚îÇ         ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Pod   ‚îÇ ‚îÇ Pod   ‚îÇ ‚îÇ Pod   ‚îÇ ‚îÇ Pod   ‚îÇ ‚îÇ Pod   ‚îÇ
‚îÇ(logger)‚îÇ(logger)‚îÇ(logger)‚îÇ(logger)‚îÇ(logger)‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
<p>New node added? ‚Üí Pod automatically scheduled
Node removed? ‚Üí Pod automatically deleted</code></pre></p>
<h3>Basic DaemonSet</h3>
<pre><code class="language-yaml">apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluentd-logger
spec:
  selector:
    matchLabels:
      name: fluentd-logger
  
  template:
    metadata:
      labels:
        name: fluentd-logger
    spec:
      # Tolerations allow running on master nodes
      tolerations:
      - key: node-role.kubernetes.io/master
        effect: NoSchedule
      
      containers:
      - name: fluentd
        image: fluentd:v1.14
        volumeMounts:
        - name: varlog
          mountPath: /var/log
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
      
      # Access host logs
      volumes:
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers</code></pre>
<pre><code class="language-bash"># Create DaemonSet
kubectl apply -f daemonset.yaml
<h1>View DaemonSet</h1>
kubectl get daemonset
kubectl get ds  # Short form
<h1>Output:</h1>
<h1>NAME              DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   </h1>
<h1>fluentd-logger    5         5         5       5            5           </h1>
<h1>Pods on each node</h1>
kubectl get pods -o wide</code></pre>
<h3>Node Selection</h3>
<pre><code class="language-yaml"># Run on nodes with specific labels
spec:
  template:
    spec:
      nodeSelector:
        disktype: ssd  # Only nodes with label disktype=ssd
<h1>OR use affinity (more flexible)</h1>
spec:
  template:
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: kubernetes.io/os
                operator: In
                values:
                - linux</code></pre>
<h3>Update Strategy</h3>
<pre><code class="language-yaml">spec:
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1  # Update one node at a time</code></pre>
<pre><code class="language-bash"># Update DaemonSet
kubectl set image daemonset/fluentd-logger fluentd=fluentd:v1.15
<h1>Rollout status</h1>
kubectl rollout status daemonset/fluentd-logger</code></pre>
<h3>DaemonSet Use Cases</h3>
<p>‚úÖ <strong>Perfect for:</strong>
<li><strong>Log collectors</strong> (Fluentd, Filebeat, Logstash)</li>
<li><strong>Monitoring agents</strong> (Prometheus Node Exporter, Datadog agent)</li>
<li><strong>Network plugins</strong> (CNI like Calico, Weave)</li>
<li><strong>Storage daemons</strong> (Ceph, GlusterFS)</li>
<li><strong>Security agents</strong> (Falco, Sysdig)</li></p>
<p>---</p>
<h2>Jobs - Run-to-Completion</h2>
<h3>What is a Job?</h3>
<p>Runs pods until <strong>successful completion</strong> (exit code 0).</p>
<pre><code class="language-yaml">apiVersion: batch/v1
kind: Job
metadata:
  name: data-migration
spec:
  # Job completion settings
  completions: 5        # Run 5 successful pods
  parallelism: 2        # Max 2 pods running concurrently
  backoffLimit: 3       # Retry up to 3 times on failure
  activeDeadlineSeconds: 600  # Timeout after 10 minutes
  
  template:
    spec:
      restartPolicy: OnFailure  # Required for Jobs
      containers:
      - name: migration
        image: myapp:1.0
        command: [&quot;python&quot;, &quot;migrate.py&quot;]</code></pre>
<pre><code class="language-bash"># Create job
kubectl apply -f job.yaml
<h1>Watch job progress</h1>
kubectl get jobs -w
<h1>Output:</h1>
<h1>NAME             COMPLETIONS   DURATION   AGE</h1>
<h1>data-migration   0/5           10s        10s</h1>
<h1>data-migration   1/5           25s        25s</h1>
<h1>data-migration   2/5           40s        40s</h1>
<h1>data-migration   5/5           2m         2m</h1>
<h1>View pods created by job</h1>
kubectl get pods --selector=job-name=data-migration</code></pre>
<h3>Job Patterns</h3>
<p>#### Pattern 1: Single Completion</p>
<pre><code class="language-yaml">spec:
  completions: 1  # Default
  parallelism: 1</code></pre>
<p>#### Pattern 2: Parallel Jobs with Fixed Completion Count</p>
<pre><code class="language-yaml">spec:
  completions: 10   # Need 10 successful completions
  parallelism: 3    # Run 3 at a time</code></pre>
<pre><code class="language-text">Progress:
[Pod1][Pod2][Pod3]           ‚Üí 3 running
[Pod1‚úì][Pod2][Pod3‚úì]        ‚Üí 2 complete, 1 running
[Pod4][Pod2][Pod5]           ‚Üí 3 running
...continues until 10 complete</code></pre>
<p>#### Pattern 3: Work Queue (Dynamic Completion)</p>
<pre><code class="language-yaml">spec:
  completions: null  # Unset
  parallelism: 5     # 5 workers processing queue</code></pre>
<pre><code class="language-go">// Worker logic
for {
    task := queue.Dequeue()
    if task == nil {
        break  // Queue empty, exit successfully
    }
    process(task)
}</code></pre>
<h3>Job Cleanup</h3>
<pre><code class="language-yaml">spec:
  ttlSecondsAfterFinished: 3600  # Delete job 1 hour after completion</code></pre>
<pre><code class="language-bash"># Manual cleanup
kubectl delete job data-migration
<h1>This deletes the Job AND all its pods</code></pre></h1>
<h3>Job Use Cases</h3>
<p>‚úÖ <strong>Perfect for:</strong>
<li>Database migrations</li>
<li>Batch processing</li>
<li>Data imports/exports</li>
<li>One-time administrative tasks</li>
<li>Report generation</li></p>
<p>---</p>
<h2>CronJobs - Scheduled Tasks</h2>
<h3>What is a CronJob?</h3>
<p>Creates <strong>Jobs on a schedule</strong> (like Unix cron).</p>
<pre><code class="language-yaml">apiVersion: batch/v1
kind: CronJob
metadata:
  name: backup-database
spec:
  schedule: &quot;0 2 * * *&quot;  # Every day at 2 AM (UTC)
  
  # Concurrency policy
  concurrencyPolicy: Forbid  # Don&#039;t run if previous job still running
  
  # Keep history
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 1
  
  # Job template
  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure
          containers:
          - name: backup
            image: postgres:14
            command:
            - /bin/sh
            - -c
            - pg_dump -h postgres -U admin mydb &gt; /backup/backup-$(date +%Y%m%d).sql
            volumeMounts:
            - name: backup-storage
              mountPath: /backup
          volumes:
          - name: backup-storage
            persistentVolumeClaim:
              claimName: backup-pvc</code></pre>
<h3>Cron Schedule Format</h3>
<pre><code class="language-text"># ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ minute (0 - 59)
<h1>‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ hour (0 - 23)</h1>
<h1>‚îÇ ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ day of month (1 - 31)</h1>
<h1>‚îÇ ‚îÇ ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ month (1 - 12)</h1>
<h1>‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ day of week (0 - 6) (Sunday to Saturday)</h1>
<h1>‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ</h1>
<h1>* * * * *</h1>
<p>Examples:
&quot;0 * * * *&quot;      # Every hour at minute 0
&quot;*/5 * * * *&quot;    # Every 5 minutes
&quot;0 2 * * *&quot;      # Every day at 2 AM
&quot;0 0 * * 0&quot;      # Every Sunday at midnight
&quot;0 9 * * 1-5&quot;    # Weekdays at 9 AM
&quot;0 0 1 * *&quot;      # First day of every month
&quot;0 */6 * * *&quot;    # Every 6 hours</code></pre></p>
<h3>Concurrency Policies</h3>
<pre><code class="language-yaml">spec:
  concurrencyPolicy: Allow    # Allow concurrent jobs (default)
  # OR
  concurrencyPolicy: Forbid   # Skip new run if previous still running
  # OR
  concurrencyPolicy: Replace  # Cancel old job, start new one</code></pre>
<strong>Example Scenarios:</strong>
<pre><code class="language-text">Schedule: &quot;*/1 * * * *&quot; (every minute)
Job duration: 90 seconds
<p>Policy: Allow
‚îú‚îÄ 10:00 - Job 1 starts
‚îú‚îÄ 10:01 - Job 2 starts (Job 1 still running)
‚îî‚îÄ 10:02 - Job 3 starts (Job 1 and 2 still running)</p>
<p>Policy: Forbid
‚îú‚îÄ 10:00 - Job 1 starts
‚îú‚îÄ 10:01 - Skipped (Job 1 still running)
‚îî‚îÄ 10:02 - Job 2 starts (Job 1 finished)</p>
<p>Policy: Replace
‚îú‚îÄ 10:00 - Job 1 starts
‚îú‚îÄ 10:01 - Job 1 killed, Job 2 starts
‚îî‚îÄ 10:02 - Job 2 killed, Job 3 starts</code></pre></p>
<h3>Suspended CronJobs</h3>
<pre><code class="language-yaml">spec:
  suspend: true  # Temporarily disable cron job</code></pre>
<pre><code class="language-bash"># Suspend
kubectl patch cronjob backup-database -p &#039;{&quot;spec&quot;:{&quot;suspend&quot;:true}}&#039;
<h1>Resume</h1>
kubectl patch cronjob backup-database -p &#039;{&quot;spec&quot;:{&quot;suspend&quot;:false}}&#039;</code></pre>
<h3>CronJob Commands</h3>
<pre><code class="language-bash"># Create CronJob
kubectl apply -f cronjob.yaml
<h1>List CronJobs</h1>
kubectl get cronjobs
kubectl get cj  # Short form
<h1>View jobs created by CronJob</h1>
kubectl get jobs --selector=cronjob=backup-database
<h1>Manually trigger job from CronJob</h1>
kubectl create job backup-manual --from=cronjob/backup-database
<h1>View last schedule time</h1>
kubectl get cronjob backup-database -o yaml | grep lastScheduleTime</code></pre>
<h3>CronJob Use Cases</h3>
<p>‚úÖ <strong>Perfect for:</strong>
<li>Database backups</li>
<li>Report generation</li>
<li>Data cleanup/archival</li>
<li>Certificate renewal</li>
<li>Health checks</li>
<li>Periodic data synchronization</li></p>
<p>---</p>
<h2>Comparison & When to Use What</h2>
<h3>Quick Reference Table</h3>
<p>| Workload     | Use Case                          | Replicas      | Scaling | Updates | Stable Identity |
|--------------|-----------------------------------|---------------|---------|---------|-----------------|
| <strong>Pod</strong>      | Testing, debugging                | 1             | Manual  | None    | No              |
| <strong>ReplicaSet</strong> | Rarely used directly            | Multiple      | Manual  | None    | No              |
| <strong>Deployment</strong> | Stateless apps (most common)    | Multiple      | Manual/Auto | Rolling | No         |
| <strong>StatefulSet</strong> | Stateful apps (databases)      | Multiple      | Manual  | Ordered | Yes             |
| <strong>DaemonSet</strong> | Node-level agents                | 1 per node    | Auto    | Rolling | No              |
| <strong>Job</strong>      | One-off tasks                     | 1 or more     | N/A     | N/A     | No              |
| <strong>CronJob</strong>  | Scheduled tasks                   | 1 or more     | N/A     | N/A     | No              |</p>
<h3>Decision Tree</h3>
<pre><code class="language-text">Need to run a workload?
‚îÇ
‚îú‚îÄ One pod per node? ‚Üí DaemonSet
‚îÇ
‚îú‚îÄ One-time task?
‚îÇ  ‚îú‚îÄ Run once ‚Üí Job
‚îÇ  ‚îî‚îÄ Run on schedule ‚Üí CronJob
‚îÇ
‚îî‚îÄ Long-running service?
   ‚îú‚îÄ Stateless (web server, API)? ‚Üí Deployment
   ‚îî‚îÄ Stateful (database, message queue)? ‚Üí StatefulSet</code></pre>
<h3>Real-World Examples</h3>
<pre><code class="language-yaml"># Web Application (Deployment)
<li>Frontend: React app ‚Üí Deployment (3 replicas)</li>
<li>Backend API: Go service ‚Üí Deployment (5 replicas)</li>
<h1>Databases (StatefulSet)</h1>
<li>PostgreSQL cluster ‚Üí StatefulSet (3 replicas)</li>
<li>MongoDB replica set ‚Üí StatefulSet (3 replicas)</li>
<li>Kafka cluster ‚Üí StatefulSet (3 brokers)</li>
<h1>Infrastructure (DaemonSet)</h1>
<li>Fluentd log collector ‚Üí DaemonSet</li>
<li>Prometheus Node Exporter ‚Üí DaemonSet</li>
<li>Calico network plugin ‚Üí DaemonSet</li>
<h1>Batch Processing (Job)</h1>
<li>Database migration ‚Üí Job</li>
<li>Data import ‚Üí Job</li>
<h1>Scheduled Tasks (CronJob)</h1>
<li>Daily backup ‚Üí CronJob (schedule: &quot;0 2 * * *&quot;)</li>
<li>Hourly cleanup ‚Üí CronJob (schedule: &quot;0 * * * *&quot;)</code></pre></li>
<p>---</p>
<h2>Interview Questions</h2>
<strong>Q1: What's the difference between Deployment and StatefulSet?</strong>
<strong>Answer:</strong>
<li><strong>Deployment</strong>: Stateless apps, random pod names, no stable network identity, any pod can be replaced</li>
<li><strong>StatefulSet</strong>: Stateful apps, predictable pod names (name-0, name-1), stable network identity, ordered operations, persistent storage tied to specific pods</li>
<strong>Q2: When would you use a DaemonSet?</strong>
<strong>Answer:</strong> When you need exactly one pod per node, typically for:
<li>Log collection (Fluentd)</li>
<li>Monitoring (Prometheus Node Exporter)</li>
<li>Network plugins (CNI)</li>
<li>Storage daemons</li>
Any infrastructure component that must run on every node.
<strong>Q3: Explain the difference between Job completions and parallelism.</strong>
<strong>Answer:</strong>
<li><code>completions</code>: Total number of successful pod executions needed</li>
<li><code>parallelism</code>: Max number of pods running concurrently</li>
Example: <code>completions=10, parallelism=3</code> runs 3 pods at a time until 10 total successes.
<strong>Q4: What happens during a rolling update of a Deployment?</strong>
<strong>Answer:</strong>
1. Creates new ReplicaSet with updated pod template
2. Gradually scales up new ReplicaSet (respecting maxSurge)
3. Gradually scales down old ReplicaSet (respecting maxUnavailable)
4. Process continues until all pods updated
5. Old ReplicaSet kept for rollback (scaled to 0)
<strong>Q5: Why use StatefulSet volumeClaimTemplates instead of a single PVC?</strong>
<strong>Answer:</strong> volumeClaimTemplates creates a unique PVC for each pod. If using a single PVC:
<li>All pods would share the same storage (data conflicts)</li>
<li>Can't use ReadWriteOnce volumes (only one pod can mount)</li>
<li>No data isolation between replicas</li>
Each StatefulSet pod needs its own persistent storage.
<p>---</p>
<h2>Hands-On Exercise</h2>
<h3>Task: Deploy Complete Application Stack</h3>
<strong>Deploy a realistic application with all workload types:</strong>
<pre><code class="language-yaml"># 1. Deployment: Web Frontend
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: frontend
  template:
    metadata:
      labels:
        app: frontend
    spec:
      containers:
      - name: nginx
        image: nginx:1.21
        ports:
        - containerPort: 80
<p>---
<h1>2. StatefulSet: Database</h1>
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres
spec:
  serviceName: postgres
  replicas: 1
  selector:
    matchLabels:
      app: postgres
  template:
    metadata:
      labels:
        app: postgres
    spec:
      containers:
      - name: postgres
        image: postgres:14
        env:
        - name: POSTGRES_PASSWORD
          value: password123
        ports:
        - containerPort: 5432</p>
<p>---
<h1>3. DaemonSet: Log Collector</h1>
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluentd
spec:
  selector:
    matchLabels:
      name: fluentd
  template:
    metadata:
      labels:
        name: fluentd
    spec:
      containers:
      - name: fluentd
        image: fluent/fluentd:v1.14
        volumeMounts:
        - name: varlog
          mountPath: /var/log
      volumes:
      - name: varlog
        hostPath:
          path: /var/log</p>
<p>---
<h1>4. CronJob: Database Backup</h1>
apiVersion: batch/v1
kind: CronJob
metadata:
  name: backup
spec:
  schedule: &quot;*/5 * * * *&quot;  # Every 5 minutes for testing
  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure
          containers:
          - name: backup
            image: postgres:14
            command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;echo &#039;Backup completed at $(date)&#039;&quot;]</code></pre></p>
<strong>Tasks:</strong>
1. Deploy all resources
2. Verify each workload type is running
3. Scale the Deployment to 5 replicas
4. Check CronJob creates Jobs every 5 minutes
5. Verify DaemonSet has one pod per node
6. Test StatefulSet pod has stable name after deletion
<pre><code class="language-bash"># Solution commands
kubectl apply -f stack.yaml
kubectl get all
kubectl scale deployment frontend --replicas=5
kubectl get cronjobs
kubectl get daemonsets
kubectl delete pod postgres-0 &amp;&amp; kubectl get pods -w</code></pre>
<p>---</p>
<h2>üìö Additional Resources</h2>
<li>[Kubernetes Workloads](https://kubernetes.io/docs/concepts/workloads/)</li>
<li>[Deployments](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/)</li>
<li>[StatefulSets](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/)</li>
<li>[DaemonSets](https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/)</li>
<li>[Jobs](https://kubernetes.io/docs/concepts/workloads/controllers/job/)</li>
<li>[CronJobs](https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/)</li>
<p>---</p>
<h2>‚úÖ Module Checklist</h2>
<li>[ ] Understand all 7 core CRDs and their purposes</li>
<li>[ ] Know when to use Deployment vs StatefulSet</li>
<li>[ ] Configure health checks (liveness, readiness, startup)</li>
<li>[ ] Implement rolling updates and rollbacks</li>
<li>[ ] Deploy StatefulSet with persistent storage</li>
<li>[ ] Create DaemonSet for node-level workloads</li>
<li>[ ] Schedule tasks with CronJobs</li>
<li>[ ] Complete multi-workload hands-on exercise</li></ul>
<p>---</p>
<strong>Next Module:</strong> [Module 08: Kubernetes Networking](./08_Kubernetes_Networking.md) - Master Services, Ingress, and NetworkPolicies! üåê

    </div>
    

    <div class="module-content" id="module-8">
        <h1>Module 08: Kubernetes Networking üåê</h1>
<h2>Master Service Discovery, Load Balancing & Network Security</h2>
<strong>Duration:</strong> 4-5 hours  
<strong>Prerequisites:</strong> Module 06-07 (K8s Architecture & Workloads)  
<strong>Outcome:</strong> Understand how pods communicate and expose services to external traffic
<p>---</p>
<h2>üìö Table of Contents</h2>
<p>1. [Kubernetes Networking Model](#kubernetes-networking-model)
2. [Services - Service Discovery](#services---service-discovery)
3. [Service Types](#service-types)
4. [Ingress - HTTP Load Balancing](#ingress---http-load-balancing)
5. [NetworkPolicies - Security](#networkpolicies---security)
6. [DNS in Kubernetes](#dns-in-kubernetes)
7. [CNI - Container Network Interface](#cni---container-network-interface)
8. [Interview Questions](#interview-questions)
9. [Hands-On Exercise](#hands-on-exercise)</p>
<p>---</p>
<h2>Kubernetes Networking Model</h2>
<h3>Core Requirements</h3>
<p>Kubernetes networking has <strong>4 fundamental rules:</strong></p>
<pre><code class="language-yaml">1. Pod-to-Pod Communication:
   - Every pod can communicate with every other pod
   - Without NAT (pods see real source IP)
   - Across all nodes in the cluster
<p>2. Pod-to-Service Communication:
   - Pods discover services via DNS or environment variables
   - Services load-balance traffic to pods</p>
<p>3. External-to-Service Communication:
   - External clients access services via NodePort, LoadBalancer, or Ingress</p>
<p>4. Network Policies (optional):
   - Control traffic between pods (firewall rules)</code></pre></p>
<h3>Network Architecture</h3>
<pre><code class="language-text">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  External Traffic                    ‚îÇ
‚îÇ         (Internet, Corporate Network)                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Ingress Controller                       ‚îÇ
‚îÇ         (nginx, traefik, HAProxy)                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   Services                            ‚îÇ
‚îÇ  (ClusterIP, NodePort, LoadBalancer)                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ                      ‚îÇ
     ‚ñº                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Pod 1  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  Pod 2  ‚îÇ
‚îÇ 10.1.1.2‚îÇ            ‚îÇ 10.1.1.3‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ                      ‚îÇ
     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚ñº
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ  Pod 3     ‚îÇ
         ‚îÇ 10.1.2.1   ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</code></pre>
<p>---</p>
<h2>Services - Service Discovery</h2>
<h3>Why Services?</h3>
<strong>Problem:</strong> Pods are ephemeral (can be deleted, rescheduled, scaled)
<ul><li>Pod IPs change</li>
<li>Need stable endpoint</li>
<li>Need load balancing</li>
<strong>Solution:</strong> Service provides:
<li><strong>Stable IP and DNS name</strong></li>
<li><strong>Load balancing</strong> across pod replicas</li>
<li><strong>Service discovery</strong></li>
<h3>Service Basics</h3>
<pre><code class="language-yaml">apiVersion: v1
kind: Service
metadata:
  name: web-service
spec:
  selector:
    app: web  # Select pods with this label
  ports:
  - protocol: TCP
    port: 80        # Service port
    targetPort: 8080  # Pod port
  type: ClusterIP   # Default type</code></pre>
<pre><code class="language-bash"># Create service
kubectl apply -f service.yaml
<h1>Get services</h1>
kubectl get services
kubectl get svc  # Short form
<h1>Output:</h1>
<h1>NAME          TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE</h1>
<h1>web-service   ClusterIP   10.96.100.50   &lt;none&gt;        80/TCP    1m</h1>
<h1>Describe service</h1>
kubectl describe service web-service</code></pre>
<h3>How Services Work</h3>
<pre><code class="language-text">User creates Service with selector: app=web
         ‚Üì
API Server stores Service
         ‚Üì
Endpoint Controller watches:
1. Finds all Pods with label app=web
2. Gets their IP addresses
3. Creates Endpoints object
<p>Example Endpoints:
<li>10.244.1.5:8080 (pod-1)</li>
<li>10.244.2.3:8080 (pod-2)</li>
<li>10.244.2.7:8080 (pod-3)</li>
         ‚Üì
kube-proxy on each node:
<li>Creates iptables/IPVS rules</li>
<li>Load balances traffic to pod IPs</code></pre></li></p>
<pre><code class="language-bash"># View endpoints
kubectl get endpoints web-service
<h1>NAME          ENDPOINTS                                AGE</h1>
<h1>web-service   10.244.1.5:8080,10.244.2.3:8080...      1m</code></pre></h1>
<h3>Service Without Selector (External Service)</h3>
<pre><code class="language-yaml"># Service pointing to external database
apiVersion: v1
kind: Service
metadata:
  name: external-database
spec:
  ports:
  - protocol: TCP
    port: 5432
---
<h1>Manually create endpoints</h1>
apiVersion: v1
kind: Endpoints
metadata:
  name: external-database
subsets:
<li>addresses:</li>
  - ip: 192.168.1.100  # External DB IP
  ports:
  - port: 5432</code></pre>
<p>---</p>
<h2>Service Types</h2>
<h3>1. ClusterIP (Default)</h3>
<strong>Internal-only access</strong> - Exposes service on cluster-internal IP.
<pre><code class="language-yaml">apiVersion: v1
kind: Service
metadata:
  name: backend
spec:
  type: ClusterIP
  selector:
    app: backend
  ports:
  - port: 80
    targetPort: 8080</code></pre>
<pre><code class="language-text">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         Kubernetes Cluster       ‚îÇ
‚îÇ                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ Pod ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ Service ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ     ‚îÇ         ‚îÇClusterIP‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ10.96.x.x‚îÇ   ‚îÇ
‚îÇ                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                       ‚îÇ          ‚îÇ
‚îÇ                       ‚ñº          ‚îÇ
‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ              ‚îÇPod 1‚îÇ ‚îÇPod 2‚îÇ    ‚îÇ
‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
   ‚ùå Not accessible from outside</code></pre>
<strong>Use Cases:</strong>
<li>Internal microservices</li>
<li>Databases</li>
<li>Cache servers</li>
<li>Any service that shouldn't be exposed externally</li>
<h3>2. NodePort</h3>
<strong>Exposes service on each node's IP at a static port.</strong>
<pre><code class="language-yaml">apiVersion: v1
kind: Service
metadata:
  name: web-nodeport
spec:
  type: NodePort
  selector:
    app: web
  ports:
  - port: 80          # ClusterIP port
    targetPort: 8080  # Pod port
    nodePort: 30080   # External port (30000-32767)</code></pre>
<pre><code class="language-text">External Traffic
      ‚îÇ
      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Node IP: 192.168.1.10:30080   ‚îÇ
‚îÇ   Node IP: 192.168.1.11:30080   ‚îÇ
‚îÇ   Node IP: 192.168.1.12:30080   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚ñº
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ Service ‚îÇ
         ‚îÇNodePort ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚ñº
      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
      ‚îÇPod 1‚îÇ ‚îÇPod 2‚îÇ
      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</code></pre>
<pre><code class="language-bash"># Access service
curl http://192.168.1.10:30080  # Any node IP
curl http://192.168.1.11:30080  # Works from any node</code></pre>
<strong>Use Cases:</strong>
<li>Development/testing</li>
<li>Direct access to services</li>
<li>When LoadBalancer is not available</li>
<strong>Limitations:</strong>
<li>Only one service per port</li>
<li>Port range limited (30000-32767)</li>
<li>Must handle node failures manually</li>
<h3>3. LoadBalancer</h3>
<strong>Provisions external load balancer</strong> (cloud provider).
<pre><code class="language-yaml">apiVersion: v1
kind: Service
metadata:
  name: web-lb
spec:
  type: LoadBalancer
  selector:
    app: web
  ports:
  - port: 80
    targetPort: 8080</code></pre>
<pre><code class="language-bash">kubectl get service web-lb
<h1>NAME     TYPE           CLUSTER-IP     EXTERNAL-IP      PORT(S)</h1>
<h1>web-lb   LoadBalancer   10.96.100.50   203.0.113.42     80:31234/TCP</code></pre></h1>
<pre><code class="language-text">External Traffic
      ‚îÇ
      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Cloud Load Balancer ‚îÇ  ‚Üê Provisioned by cloud provider
‚îÇ  (AWS ELB, GCP LB)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
           ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Service ‚îÇ
    ‚îÇ   Type:  ‚îÇ
    ‚îÇLoadBalan-‚îÇ
    ‚îÇ   cer    ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
           ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇPod 1‚îÇ ‚îÇPod 2‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</code></pre>
<strong>Cloud Provider Examples:</strong>
<pre><code class="language-yaml"># AWS - Network Load Balancer
apiVersion: v1
kind: Service
metadata:
  name: web
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-type: &quot;nlb&quot;
spec:
  type: LoadBalancer
  selector:
    app: web
  ports:
  - port: 80
<p>---
<h1>GCP - Internal Load Balancer</h1>
apiVersion: v1
kind: Service
metadata:
  name: internal-app
  annotations:
    cloud.google.com/load-balancer-type: &quot;Internal&quot;
spec:
  type: LoadBalancer
  selector:
    app: internal-app
  ports:
  - port: 80</code></pre></p>
<strong>Use Cases:</strong>
<li>Production applications</li>
<li>Need external access with HA</li>
<li>Cloud-managed load balancing</li>
<strong>Cost Consideration:</strong>
<li>Each LoadBalancer service = One cloud load balancer</li>
<li>Can be expensive (consider Ingress for multiple services)</li>
<h3>4. ExternalName</h3>
<strong>Maps service to DNS name</strong> (CNAME record).
<pre><code class="language-yaml">apiVersion: v1
kind: Service
metadata:
  name: external-api
spec:
  type: ExternalName
  externalName: api.external-service.com</code></pre>
<pre><code class="language-bash"># Inside cluster, pods can access:
curl http://external-api.default.svc.cluster.local
<h1>‚Üí Resolves to api.external-service.com</code></pre></h1>
<strong>Use Cases:</strong>
<li>Accessing external services</li>
<li>Service migration (gradual cutover)</li>
<li>Multi-cluster communication</li>
<h3>Session Affinity</h3>
<pre><code class="language-yaml"># Stick client to same pod (session persistence)
spec:
  sessionAffinity: ClientIP
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 10800  # 3 hours</code></pre>
<p>---</p>
<h2>Ingress - HTTP Load Balancing</h2>
<h3>Why Ingress?</h3>
<strong>Problem:</strong> LoadBalancer services are expensive (one per service).
<strong>Solution:</strong> Ingress provides:
<li><strong>HTTP/HTTPS routing</strong> to multiple services</li>
<li><strong>TLS termination</strong></li>
<li><strong>Name-based virtual hosting</strong></li>
<li><strong>Path-based routing</strong></li>
<li>One load balancer for many services</li>
<h3>Ingress Architecture</h3>
<pre><code class="language-text">External Traffic (HTTP/HTTPS)
        ‚îÇ
        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Ingress Resource  ‚îÇ  ‚Üê Routing rules (YAML)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Ingress Controller ‚îÇ  ‚Üê Implementation (nginx, traefik, HAProxy)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ         ‚îÇ
    ‚ñº         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇService1‚îÇ ‚îÇService2‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</code></pre>
<h3>Install Ingress Controller</h3>
<pre><code class="language-bash"># Install nginx ingress controller
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.8.1/deploy/static/provider/cloud/deploy.yaml
<h1>Verify installation</h1>
kubectl get pods -n ingress-nginx
kubectl get service -n ingress-nginx</code></pre>
<h3>Basic Ingress</h3>
<pre><code class="language-yaml">apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: web-ingress
spec:
  rules:
  - host: myapp.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: web-service
            port:
              number: 80</code></pre>
<pre><code class="language-bash"># Create ingress
kubectl apply -f ingress.yaml
<h1>Get ingress</h1>
kubectl get ingress
<h1>Output:</h1>
<h1>NAME          CLASS    HOSTS               ADDRESS        PORTS   AGE</h1>
<h1>web-ingress   &lt;none&gt;   myapp.example.com   203.0.113.42   80      1m</h1>
<h1>Access application</h1>
curl http://myapp.example.com</code></pre>
<h3>Path-Based Routing</h3>
<pre><code class="language-yaml">apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: multi-path-ingress
spec:
  rules:
  - host: api.example.com
    http:
      paths:
      - path: /users
        pathType: Prefix
        backend:
          service:
            name: user-service
            port:
              number: 80
      
      - path: /products
        pathType: Prefix
        backend:
          service:
            name: product-service
            port:
              number: 80
      
      - path: /orders
        pathType: Prefix
        backend:
          service:
            name: order-service
            port:
              number: 80</code></pre>
<pre><code class="language-text">Requests:
api.example.com/users     ‚Üí user-service
api.example.com/products  ‚Üí product-service
api.example.com/orders    ‚Üí order-service</code></pre>
<h3>Host-Based Routing</h3>
<pre><code class="language-yaml">apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: multi-host-ingress
spec:
  rules:
  - host: web.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: web-frontend
            port:
              number: 80
  
  - host: api.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: api-backend
            port:
              number: 80</code></pre>
<h3>TLS/HTTPS</h3>
<pre><code class="language-yaml">apiVersion: v1
kind: Secret
metadata:
  name: tls-secret
type: kubernetes.io/tls
data:
  tls.crt: &lt;base64-encoded-cert&gt;
  tls.key: &lt;base64-encoded-key&gt;
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: tls-ingress
spec:
  tls:
  - hosts:
    - myapp.example.com
    secretName: tls-secret
  rules:
  - host: myapp.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: web-service
            port:
              number: 80</code></pre>
<pre><code class="language-bash"># Create TLS secret from files
kubectl create secret tls tls-secret \
  --cert=path/to/cert.crt \
  --key=path/to/key.key
<h1>Access with HTTPS</h1>
curl https://myapp.example.com</code></pre>
<h3>Ingress Annotations</h3>
<pre><code class="language-yaml">metadata:
  annotations:
    # Rewrite URL
    nginx.ingress.kubernetes.io/rewrite-target: /$2
    
    # CORS
    nginx.ingress.kubernetes.io/enable-cors: &quot;true&quot;
    
    # Rate limiting
    nginx.ingress.kubernetes.io/limit-rps: &quot;10&quot;
    
    # Authentication
    nginx.ingress.kubernetes.io/auth-type: basic
    nginx.ingress.kubernetes.io/auth-secret: basic-auth
    
    # Websocket support
    nginx.ingress.kubernetes.io/websocket-services: chat-service</code></pre>
<p>---</p>
<h2>NetworkPolicies - Security</h2>
<h3>What are NetworkPolicies?</h3>
<strong>Firewall rules</strong> for pods - control traffic flow.
<pre><code class="language-yaml"># Default behavior: All traffic allowed
<h1>With NetworkPolicy: Deny by default, allow explicitly</code></pre></h1>
<h3>Default Deny All</h3>
<pre><code class="language-yaml"># Deny all ingress traffic
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: deny-all-ingress
spec:
  podSelector: {}  # Applies to all pods
  policyTypes:
  - Ingress
<p>---
<h1>Deny all egress traffic</h1>
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: deny-all-egress
spec:
  podSelector: {}
  policyTypes:
  - Egress</code></pre></p>
<h3>Allow Specific Traffic</h3>
<pre><code class="language-yaml">apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-frontend-to-backend
spec:
  podSelector:
    matchLabels:
      app: backend  # Apply to backend pods
  
  policyTypes:
  - Ingress
  
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: frontend  # Only from frontend pods
    ports:
    - protocol: TCP
      port: 8080</code></pre>
<pre><code class="language-text">Before NetworkPolicy:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Frontend ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ Backend  ‚îÇ  ‚úÖ Allowed
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Pod X  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ Backend  ‚îÇ  ‚úÖ Allowed
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>After NetworkPolicy:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Frontend ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ Backend  ‚îÇ  ‚úÖ Allowed (explicitly)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Pod X  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ Backend  ‚îÇ  ‚ùå Denied
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</code></pre></p>
<h3>Namespace Selector</h3>
<pre><code class="language-yaml">apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-from-production
spec:
  podSelector:
    matchLabels:
      app: database
  
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          env: production  # Only from production namespace
    ports:
    - protocol: TCP
      port: 5432</code></pre>
<h3>IP Block (External Traffic)</h3>
<pre><code class="language-yaml">apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-external-ips
spec:
  podSelector:
    matchLabels:
      app: web
  
  ingress:
  - from:
    - ipBlock:
        cidr: 203.0.113.0/24  # Allow from this IP range
        except:
        - 203.0.113.5/32      # Except this IP</code></pre>
<h3>Egress Rules</h3>
<pre><code class="language-yaml">apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-backend-egress
spec:
  podSelector:
    matchLabels:
      app: backend
  
  policyTypes:
  - Egress
  
  egress:
  # Allow DNS
  - to:
    - namespaceSelector:
        matchLabels:
          name: kube-system
    ports:
    - protocol: UDP
      port: 53
  
  # Allow database
  - to:
    - podSelector:
        matchLabels:
          app: postgres
    ports:
    - protocol: TCP
      port: 5432
  
  # Allow external API
  - to:
    - ipBlock:
        cidr: 0.0.0.0/0
    ports:
    - protocol: TCP
      port: 443</code></pre>
<h3>Three-Tier Application Policy</h3>
<pre><code class="language-yaml"># Frontend: Allow from internet, talk to backend
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: frontend-policy
spec:
  podSelector:
    matchLabels:
      tier: frontend
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - ports:
    - protocol: TCP
      port: 80
  egress:
  - to:
    - podSelector:
        matchLabels:
          tier: backend
<p>---
<h1>Backend: Only from frontend, talk to database</h1>
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: backend-policy
spec:
  podSelector:
    matchLabels:
      tier: backend
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          tier: frontend
    ports:
    - protocol: TCP
      port: 8080
  egress:
  - to:
    - podSelector:
        matchLabels:
          tier: database</p>
<p>---
<h1>Database: Only from backend</h1>
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: database-policy
spec:
  podSelector:
    matchLabels:
      tier: database
  policyTypes:
  - Ingress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          tier: backend
    ports:
    - protocol: TCP
      port: 5432</code></pre></p>
<p>---</p>
<h2>DNS in Kubernetes</h2>
<h3>Service DNS</h3>
<pre><code class="language-bash"># Full DNS name format:
&lt;service-name&gt;.&lt;namespace&gt;.svc.&lt;cluster-domain&gt;
<h1>Examples:</h1>
web-service.default.svc.cluster.local
postgres.production.svc.cluster.local</code></pre>
<h3>DNS Resolution</h3>
<pre><code class="language-yaml"># Service in same namespace
curl http://web-service
<h1>Service in different namespace</h1>
curl http://web-service.production
<h1>Fully qualified (always works)</h1>
curl http://web-service.production.svc.cluster.local</code></pre>
<h3>Pod DNS</h3>
<pre><code class="language-bash"># Pods get DNS name:
&lt;pod-ip-with-dashes&gt;.&lt;namespace&gt;.pod.&lt;cluster-domain&gt;
<h1>Example: Pod with IP 10.244.1.5</h1>
10-244-1-5.default.pod.cluster.local</code></pre>
<h3>Headless Service DNS</h3>
<pre><code class="language-yaml"># StatefulSet with headless service
apiVersion: v1
kind: Service
metadata:
  name: postgres
spec:
  clusterIP: None  # Headless
  selector:
    app: postgres</code></pre>
<pre><code class="language-bash"># Each pod gets DNS entry:
postgres-0.postgres.default.svc.cluster.local
postgres-1.postgres.default.svc.cluster.local
postgres-2.postgres.default.svc.cluster.local</code></pre>
<h3>Custom DNS Configuration</h3>
<pre><code class="language-yaml">spec:
  dnsPolicy: ClusterFirst  # Default
  # OR
  dnsPolicy: Default       # Use node&#039;s DNS
  # OR
  dnsPolicy: None          # Custom DNS
  dnsConfig:
    nameservers:
    - 8.8.8.8
    - 8.8.4.4
    searches:
    - my.domain.com
    options:
    - name: ndots
      value: &quot;2&quot;</code></pre>
<p>---</p>
<h2>CNI - Container Network Interface</h2>
<h3>What is CNI?</h3>
<strong>Pluggable networking layer</strong> - provides IP addresses and routing for pods.
<h3>Popular CNI Plugins</h3>
<pre><code class="language-yaml">1. Calico:
   - Network policies
   - BGP routing
   - Enterprise features
<p>2. Flannel:
   - Simple overlay network
   - Easy to set up
   - Good for beginners</p>
<p>3. Weave Net:
   - Automatic mesh network
   - Encryption support
   - Multi-cloud</p>
<p>4. Cilium:
   - eBPF-based
   - High performance
   - Advanced security</p>
<p>5. AWS VPC CNI:
   - Native AWS networking
   - Pod gets VPC IP
   - Better integration</code></pre></p>
<h3>CNI Installation Example</h3>
<pre><code class="language-bash"># Install Calico
kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml
<h1>Verify CNI</h1>
kubectl get pods -n kube-system | grep calico
<h1>Check node network</h1>
kubectl get nodes -o wide</code></pre>
<p>---</p>
<h2>Interview Questions</h2>
<strong>Q1: What's the difference between ClusterIP, NodePort, and LoadBalancer?</strong>
<strong>Answer:</strong>
<li><strong>ClusterIP</strong>: Internal-only, cluster IP, default type</li>
<li><strong>NodePort</strong>: Exposes on each node's IP at static port (30000-32767), accessible externally</li>
<li><strong>LoadBalancer</strong>: Provisions cloud load balancer, full external access with HA</li>
<strong>Q2: Why use Ingress instead of multiple LoadBalancer services?</strong>
<strong>Answer:</strong> Cost and efficiency. Each LoadBalancer service creates a cloud load balancer ($$$). Ingress uses one load balancer to route to multiple services based on hostname/path, significantly reducing costs.
<strong>Q3: How do NetworkPolicies work?</strong>
<strong>Answer:</strong> NetworkPolicies are namespace-scoped firewall rules. They use label selectors to define which pods rules apply to and which traffic is allowed (ingress/egress). By default, all traffic is allowed; NetworkPolicies deny by default and allow explicitly.
<strong>Q4: Explain service discovery in Kubernetes.</strong>
<strong>Answer:</strong> Services provide stable DNS names (<service>.<namespace>.svc.cluster.local). The Endpoint Controller watches pods matching service selectors and updates Endpoints. kube-proxy creates iptables/IPVS rules for load balancing. Pods can resolve service names via cluster DNS (CoreDNS).
<strong>Q5: What is a headless service and when would you use it?</strong>
<strong>Answer:</strong> Headless service (clusterIP: None) doesn't load balance. Instead, DNS returns all pod IPs. Used with StatefulSets for stable network identities, allowing direct pod-to-pod communication (e.g., database clusters, peer-to-peer systems).
<p>---</p>
<h2>Hands-On Exercise</h2>
<h3>Task: Deploy Multi-Tier App with Networking</h3>
<pre><code class="language-yaml"># 1. Deploy frontend
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 2
  selector:
    matchLabels:
      app: frontend
      tier: frontend
  template:
    metadata:
      labels:
        app: frontend
        tier: frontend
    spec:
      containers:
      - name: nginx
        image: nginx:1.21
        ports:
        - containerPort: 80
<p>---
<h1>2. Frontend Service (ClusterIP)</h1>
apiVersion: v1
kind: Service
metadata:
  name: frontend
spec:
  selector:
    app: frontend
  ports:
  - port: 80</p>
<p>---
<h1>3. Backend Deployment</h1>
apiVersion: apps/v1
kind: Deployment
metadata:
  name: backend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: backend
      tier: backend
  template:
    metadata:
      labels:
        app: backend
        tier: backend
    spec:
      containers:
      - name: api
        image: hashicorp/http-echo:0.2.3
        args:
        - &quot;-text=Backend API v1.0&quot;
        ports:
        - containerPort: 5678</p>
<p>---
<h1>4. Backend Service</h1>
apiVersion: v1
kind: Service
metadata:
  name: backend
spec:
  selector:
    app: backend
  ports:
  - port: 80
    targetPort: 5678</p>
<p>---
<h1>5. Ingress</h1>
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: app-ingress
spec:
  rules:
  - host: myapp.local
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: frontend
            port:
              number: 80
      - path: /api
        pathType: Prefix
        backend:
          service:
            name: backend
            port:
              number: 80</p>
<p>---
<h1>6. NetworkPolicy: Backend only from Frontend</h1>
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: backend-policy
spec:
  podSelector:
    matchLabels:
      tier: backend
  policyTypes:
  - Ingress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          tier: frontend
    ports:
    - protocol: TCP
      port: 5678</code></pre></p>
<strong>Tasks:</strong>
1. Deploy all resources
2. Verify services are created
3. Test frontend can reach backend
4. Test external pod cannot reach backend
5. Access via Ingress
<pre><code class="language-bash"># Deploy
kubectl apply -f app.yaml
<h1>Verify</h1>
kubectl get all
kubectl get ingress
kubectl get networkpolicies
<h1>Test connectivity</h1>
kubectl exec -it &lt;frontend-pod&gt; -- curl http://backend
kubectl run test --image=busybox --rm -it -- wget -O- http://backend
<h1>(should fail with NetworkPolicy)</h1>
<h1>Add /etc/hosts entry</h1>
echo &quot;127.0.0.1 myapp.local&quot; | sudo tee -a /etc/hosts
<h1>Access via Ingress</h1>
curl http://myapp.local
curl http://myapp.local/api</code></pre>
<p>---</p>
<h2>üìö Additional Resources</h2>
<li>[Kubernetes Services](https://kubernetes.io/docs/concepts/services-networking/service/)</li>
<li>[Ingress](https://kubernetes.io/docs/concepts/services-networking/ingress/)</li>
<li>[Network Policies](https://kubernetes.io/docs/concepts/services-networking/network-policies/)</li>
<li>[DNS for Services and Pods](https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/)</li>
<p>---</p>
<h2>‚úÖ Module Checklist</h2>
<li>[ ] Understand Kubernetes networking model</li>
<li>[ ] Create Services (ClusterIP, NodePort, LoadBalancer)</li>
<li>[ ] Configure Ingress for HTTP routing</li>
<li>[ ] Implement NetworkPolicies for security</li>
<li>[ ] Use DNS for service discovery</li>
<li>[ ] Complete multi-tier networking exercise</li></ul>
<p>---</p>
<strong>Next Module:</strong> [Module 09: Kubernetes Storage](./09_Kubernetes_Storage.md) - Master PersistentVolumes, StorageClasses, and StatefulSet storage! üíæ

    </div>
    

    <div class="module-content" id="module-9">
        <h1>Module 09: Kubernetes Storage üíæ</h1>
<h2>Master Persistent Volumes, StorageClasses & Stateful Storage</h2>
<strong>Duration:</strong> 3-4 hours  
<strong>Prerequisites:</strong> Module 06-08 (K8s Architecture, Workloads, Networking)  
<strong>Outcome:</strong> Implement persistent storage for stateful applications
<p>---</p>
<h2>üìö Table of Contents</h2>
<p>1. [Storage Challenges in Kubernetes](#storage-challenges-in-kubernetes)
2. [Volumes - Pod Storage](#volumes---pod-storage)
3. [PersistentVolumes (PV)](#persistentvolumes-pv)
4. [PersistentVolumeClaims (PVC)](#persistentvolumeclaims-pvc)
5. [StorageClasses - Dynamic Provisioning](#storageclasses---dynamic-provisioning)
6. [StatefulSet Storage](#statefulset-storage)
7. [CSI - Container Storage Interface](#csi---container-storage-interface)
8. [Interview Questions](#interview-questions)
9. [Hands-On Exercise](#hands-on-exercise)</p>
<p>---</p>
<h2>Storage Challenges in Kubernetes</h2>
<h3>Why is Storage Hard?</h3>
<pre><code class="language-text">Problem 1: Pod Ephemeral
<ul><li>Pod dies ‚Üí Container filesystem deleted</li>
<li>Need persistent storage</li>
<p>Problem 2: Node Failure
<li>Pod rescheduled to different node</li>
<li>Must access same data</li></p>
<p>Problem 3: Cloud Portability
<li>AWS EBS, GCP PD, Azure Disk</li>
<li>Need abstraction layer</code></pre></li></p>
<h3>Kubernetes Storage Solutions</h3>
<pre><code class="language-text">1. Volumes: Temporary storage (pod lifetime)
2. PersistentVolumes: Cluster-level storage resource
3. PersistentVolumeClaims: Request for storage
4. StorageClasses: Dynamic provisioning</code></pre>
<p>---</p>
<h2>Volumes - Pod Storage</h2>
<h3>emptyDir - Temporary Storage</h3>
<pre><code class="language-yaml">apiVersion: v1
kind: Pod
metadata:
  name: test-pod
spec:
  containers:
  - name: app
    image: nginx
    volumeMounts:
    - name: cache-volume
      mountPath: /cache
  
  - name: sidecar
    image: busybox
    command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;while true; do echo $(date) &gt;&gt; /cache/log.txt; sleep 5; done&quot;]
    volumeMounts:
    - name: cache-volume
      mountPath: /cache
  
  volumes:
  - name: cache-volume
    emptyDir: {}  # Deleted when pod dies</code></pre>
<strong>Use Cases:</strong> Scratch space, cache, sharing data between containers
<h3>hostPath - Node Storage</h3>
<pre><code class="language-yaml">volumes:
<li>name: host-volume</li>
  hostPath:
    path: /data
    type: Directory  # Must exist on node</code></pre>
<p>‚ö†Ô∏è <strong>Warning:</strong> Ties pod to specific node, security risk</p>
<h3>configMap & secret Volumes</h3>
<pre><code class="language-yaml">volumes:
<li>name: config</li>
  configMap:
    name: app-config
<li>name: credentials</li>
  secret:
    secretName: db-secret</code></pre>
<p>---</p>
<h2>PersistentVolumes (PV)</h2>
<h3>What is a PersistentVolume?</h3>
<strong>Cluster resource</strong> representing storage (admin provisioned or dynamically created).
<pre><code class="language-yaml">apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-nfs
spec:
  capacity:
    storage: 10Gi
  
  accessModes:
  - ReadWriteMany
  
  persistentVolumeReclaimPolicy: Retain
  
  storageClassName: slow
  
  nfs:
    server: 192.168.1.100
    path: /exports/data</code></pre>
<h3>Access Modes</h3>
<pre><code class="language-yaml">accessModes:
<li>ReadWriteOnce (RWO)   # Single node can mount read-write</li>
<li>ReadOnlyMany (ROX)    # Multiple nodes can mount read-only</li>
<li>ReadWriteMany (RWX)   # Multiple nodes can mount read-write</li>
<li>ReadWriteOncePod      # Single pod (K8s 1.22+)</code></pre></li>
<p>| Storage Type | RWO | ROX | RWX |
|--------------|-----|-----|-----|
| AWS EBS      | ‚úÖ  | ‚ùå  | ‚ùå  |
| GCP PD       | ‚úÖ  | ‚úÖ  | ‚ùå  |
| Azure Disk   | ‚úÖ  | ‚ùå  | ‚ùå  |
| NFS          | ‚úÖ  | ‚úÖ  | ‚úÖ  |
| CephFS       | ‚úÖ  | ‚úÖ  | ‚úÖ  |</p>
<h3>Reclaim Policies</h3>
<pre><code class="language-yaml">persistentVolumeReclaimPolicy: Retain   # Manual cleanup
<h1>OR</h1>
persistentVolumeReclaimPolicy: Delete   # Auto-delete (default)
<h1>OR</h1>
persistentVolumeReclaimPolicy: Recycle  # Deprecated</code></pre>
<h3>PV Lifecycle</h3>
<pre><code class="language-text">1. Provisioning
   - Static: Admin creates PV manually
   - Dynamic: StorageClass creates automatically
<p>2. Binding
   - PVC requests storage
   - K8s finds matching PV
   - PVC bound to PV</p>
<p>3. Using
   - Pod mounts PVC
   - Read/write data</p>
<p>4. Releasing
   - PVC deleted
   - PV status: Released</p>
<p>5. Reclaiming
   - Retain: Admin must manually clean
   - Delete: Storage deleted automatically</code></pre></p>
<p>---</p>
<h2>PersistentVolumeClaims (PVC)</h2>
<h3>What is a PVC?</h3>
<strong>Request for storage</strong> by users - abstracts away storage implementation.
<pre><code class="language-yaml">apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: my-pvc
spec:
  accessModes:
  - ReadWriteOnce
  
  resources:
    requests:
      storage: 5Gi
  
  storageClassName: fast</code></pre>
<pre><code class="language-bash"># Create PVC
kubectl apply -f pvc.yaml
<h1>View PVC</h1>
kubectl get pvc
<h1>NAME     STATUS   VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS</h1>
<h1>my-pvc   Bound    pv-123   5Gi        RWO            fast</h1>
<h1>View PV</h1>
kubectl get pv</code></pre>
<h3>Using PVC in Pod</h3>
<pre><code class="language-yaml">apiVersion: v1
kind: Pod
metadata:
  name: app-pod
spec:
  containers:
  - name: app
    image: nginx
    volumeMounts:
    - name: data
      mountPath: /usr/share/nginx/html
  
  volumes:
  - name: data
    persistentVolumeClaim:
      claimName: my-pvc</code></pre>
<h3>PVC Status</h3>
<pre><code class="language-text">Pending   # Waiting for binding
Bound     # Successfully bound to PV
Lost      # PV lost/failed</code></pre>
<p>---</p>
<h2>StorageClasses - Dynamic Provisioning</h2>
<h3>What is a StorageClass?</h3>
<strong>Template for dynamic PV provisioning</strong> - automatically creates PVs on demand.
<pre><code class="language-yaml">apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: fast-ssd
provisioner: kubernetes.io/aws-ebs
parameters:
  type: gp3
  iops: &quot;3000&quot;
  encrypted: &quot;true&quot;
volumeBindingMode: WaitForFirstConsumer
reclaimPolicy: Delete</code></pre>
<h3>Cloud Provider StorageClasses</h3>
<p>#### AWS EBS</p>
<pre><code class="language-yaml">apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: aws-ebs
provisioner: ebs.csi.aws.com
parameters:
  type: gp3           # General Purpose SSD
  # type: io2        # Provisioned IOPS
  # type: st1        # Throughput Optimized HDD
  encrypted: &quot;true&quot;
  fsType: ext4
volumeBindingMode: WaitForFirstConsumer</code></pre>
<p>#### GCP Persistent Disk</p>
<pre><code class="language-yaml">apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: gcp-pd
provisioner: pd.csi.storage.gke.io
parameters:
  type: pd-ssd        # SSD
  # type: pd-standard # HDD
  replication-type: regional-pd</code></pre>
<p>#### Azure Disk</p>
<pre><code class="language-yaml">apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: azure-disk
provisioner: disk.csi.azure.com
parameters:
  storageaccounttype: Premium_LRS
  kind: Managed</code></pre>
<h3>Dynamic Provisioning Flow</h3>
<pre><code class="language-text">1. User creates PVC with storageClassName: fast-ssd
2. K8s finds StorageClass &quot;fast-ssd&quot;
3. StorageClass provisioner creates PV (AWS EBS, GCP PD, etc.)
4. PV automatically bound to PVC
5. User uses PVC in pod</code></pre>
<pre><code class="language-yaml"># PVC requesting dynamic provisioning
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: dynamic-pvc
spec:
  accessModes:
  - ReadWriteOnce
  storageClassName: fast-ssd  # Uses StorageClass
  resources:
    requests:
      storage: 10Gi</code></pre>
<h3>Volume Binding Modes</h3>
<pre><code class="language-yaml"># Immediate: Provision PV immediately
volumeBindingMode: Immediate
<h1>WaitForFirstConsumer: Wait until pod scheduled</h1>
volumeBindingMode: WaitForFirstConsumer  # Recommended</code></pre>
<strong>Why WaitForFirstConsumer?</strong>
<pre><code class="language-text">Pod scheduled to zone us-east-1a
PV created in same zone
Avoids cross-zone attachment issues</code></pre>
<p>---</p>
<h2>StatefulSet Storage</h2>
<h3>volumeClaimTemplates</h3>
<pre><code class="language-yaml">apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres
spec:
  serviceName: postgres
  replicas: 3
  selector:
    matchLabels:
      app: postgres
  template:
    metadata:
      labels:
        app: postgres
    spec:
      containers:
      - name: postgres
        image: postgres:14
        ports:
        - containerPort: 5432
        volumeMounts:
        - name: data
          mountPath: /var/lib/postgresql/data
  
  # Creates PVC for each replica
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: [ &quot;ReadWriteOnce&quot; ]
      storageClassName: fast-ssd
      resources:
        requests:
          storage: 10Gi</code></pre>
<strong>Result:</strong>
<pre><code class="language-bash">kubectl get pvc
<h1>NAME              STATUS   VOLUME    CAPACITY</h1>
<h1>data-postgres-0   Bound    pv-abc    10Gi</h1>
<h1>data-postgres-1   Bound    pv-def    10Gi</h1>
<h1>data-postgres-2   Bound    pv-ghi    10Gi</h1>
<h1>Each pod gets its own PVC!</h1>
<h1>If postgres-1 dies, new pod reattaches to data-postgres-1</code></pre></h1>
<h3>Expanding StatefulSet Storage</h3>
<pre><code class="language-yaml"># 1. StorageClass must support volume expansion
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: expandable
provisioner: kubernetes.io/aws-ebs
allowVolumeExpansion: true  # Enable expansion</code></pre>
<pre><code class="language-bash"># 2. Edit PVC to increase size
kubectl edit pvc data-postgres-0
<h1>Change: storage: 10Gi ‚Üí storage: 20Gi</h1>
<h1>3. Delete and recreate pod</h1>
kubectl delete pod postgres-0
<h1>New pod gets expanded volume</code></pre></h1>
<p>---</p>
<h2>CSI - Container Storage Interface</h2>
<h3>What is CSI?</h3>
<strong>Standard interface</strong> for storage drivers - allows third-party storage providers.
<pre><code class="language-text">Before CSI: Storage code in K8s core (AWS, GCP, Azure)
With CSI: External drivers, easier to add new storage
<p>Popular CSI Drivers:
<li>AWS EBS CSI</li>
<li>GCP PD CSI</li>
<li>Azure Disk CSI</li>
<li>Longhorn (Rancher)</li>
<li>Rook/Ceph</li>
<li>OpenEBS</li>
<li>Portworx</code></pre></li></p>
<h3>Install CSI Driver (AWS EBS Example)</h3>
<pre><code class="language-bash"># Add IAM permissions
<h1>Deploy CSI driver</h1>
kubectl apply -k &quot;github.com/kubernetes-sigs/aws-ebs-csi-driver/deploy/kubernetes/overlays/stable/?ref=release-1.20&quot;
<h1>Verify</h1>
kubectl get pods -n kube-system | grep ebs-csi
<h1>Create StorageClass</h1>
kubectl apply -f - &lt;&lt;EOF
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: ebs-sc
provisioner: ebs.csi.aws.com
volumeBindingMode: WaitForFirstConsumer
parameters:
  type: gp3
EOF</code></pre>
<p>---</p>
<h2>Interview Questions</h2>
<strong>Q1: What's the difference between PV and PVC?</strong>
<strong>Answer:</strong>
<li><strong>PV (PersistentVolume)</strong>: Cluster resource representing actual storage (admin or dynamic provisioner creates)</li>
<li><strong>PVC (PersistentVolumeClaim)</strong>: User request for storage (abstracts implementation details)</li>
Analogy: PV = physical hard drive, PVC = storage request form
<strong>Q2: Explain dynamic provisioning vs static provisioning.</strong>
<strong>Answer:</strong>
<li><strong>Static</strong>: Admin manually creates PVs, users claim them with PVCs</li>
<li><strong>Dynamic</strong>: User creates PVC with StorageClass, K8s automatically provisions PV</li>
Dynamic is preferred - more automated, scalable, cloud-native.
<strong>Q3: What are access modes and why do they matter?</strong>
<strong>Answer:</strong>
<li><strong>RWO (ReadWriteOnce)</strong>: One node can mount (most common, block storage)</li>
<li><strong>ROX (ReadOnlyMany)</strong>: Multiple nodes read-only</li>
<li><strong>RWX (ReadWriteMany)</strong>: Multiple nodes read-write (requires network storage like NFS)</li>
Matters because AWS EBS only supports RWO - can't share between pods on different nodes.
<strong>Q4: Why use volumeClaimTemplates in StatefulSets?</strong>
<strong>Answer:</strong> Each StatefulSet pod needs its own persistent storage with stable identity. volumeClaimTemplates automatically creates a unique PVC for each replica (data-postgres-0, data-postgres-1). If pod dies, new pod reattaches to same PVC, preserving data.
<strong>Q5: What is WaitForFirstConsumer and why use it?</strong>
<strong>Answer:</strong> Volume binding mode that delays PV provisioning until pod is scheduled. Ensures PV is created in same availability zone as pod, avoiding cross-zone attachment failures (especially important in cloud environments).
<p>---</p>
<h2>Hands-On Exercise</h2>
<h3>Task: Deploy Stateful WordPress with MySQL</h3>
<pre><code class="language-yaml"># 1. StorageClass
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: standard
provisioner: kubernetes.io/no-provisioner  # Use hostPath for local
volumeBindingMode: WaitForFirstConsumer
<p>---
<h1>2. MySQL PV</h1>
apiVersion: v1
kind: PersistentVolume
metadata:
  name: mysql-pv
spec:
  capacity:
    storage: 5Gi
  accessModes:
  - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: standard
  hostPath:
    path: /tmp/data/mysql</p>
<p>---
<h1>3. MySQL PVC</h1>
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mysql-pvc
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi
  storageClassName: standard</p>
<p>---
<h1>4. MySQL Deployment</h1>
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mysql
spec:
  selector:
    matchLabels:
      app: mysql
  template:
    metadata:
      labels:
        app: mysql
    spec:
      containers:
      - name: mysql
        image: mysql:8.0
        env:
        - name: MYSQL_ROOT_PASSWORD
          value: password123
        - name: MYSQL_DATABASE
          value: wordpress
        ports:
        - containerPort: 3306
        volumeMounts:
        - name: mysql-storage
          mountPath: /var/lib/mysql
      volumes:
      - name: mysql-storage
        persistentVolumeClaim:
          claimName: mysql-pvc</p>
<p>---
<h1>5. MySQL Service</h1>
apiVersion: v1
kind: Service
metadata:
  name: mysql
spec:
  selector:
    app: mysql
  ports:
  - port: 3306</p>
<p>---
<h1>6. WordPress PVC</h1>
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: wordpress-pvc
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi
  storageClassName: standard</p>
<p>---
<h1>7. WordPress Deployment</h1>
apiVersion: apps/v1
kind: Deployment
metadata:
  name: wordpress
spec:
  selector:
    matchLabels:
      app: wordpress
  template:
    metadata:
      labels:
        app: wordpress
    spec:
      containers:
      - name: wordpress
        image: wordpress:6.0-apache
        env:
        - name: WORDPRESS_DB_HOST
          value: mysql
        - name: WORDPRESS_DB_PASSWORD
          value: password123
        ports:
        - containerPort: 80
        volumeMounts:
        - name: wordpress-storage
          mountPath: /var/www/html
      volumes:
      - name: wordpress-storage
        persistentVolumeClaim:
          claimName: wordpress-pvc</p>
<p>---
<h1>8. WordPress Service</h1>
apiVersion: v1
kind: Service
metadata:
  name: wordpress
spec:
  type: NodePort
  selector:
    app: wordpress
  ports:
  - port: 80
    nodePort: 30080</code></pre></p>
<strong>Tasks:</strong>
1. Deploy all resources
2. Verify PVs and PVCs are bound
3. Access WordPress
4. Delete pod, verify data persists
5. Check MySQL data survived
<pre><code class="language-bash"># Deploy
kubectl apply -f wordpress.yaml
<h1>Verify storage</h1>
kubectl get pv,pvc
kubectl get pods
<h1>Access WordPress</h1>
minikube service wordpress  # Or http://&lt;node-ip&gt;:30080
<h1>Test persistence</h1>
kubectl delete pod -l app=wordpress
kubectl delete pod -l app=mysql
<h1>Wait for pods to recreate</h1>
<h1>WordPress config should still exist</code></pre></h1>
<p>---</p>
<h2>üìö Additional Resources</h2>
<li>[Persistent Volumes](https://kubernetes.io/docs/concepts/storage/persistent-volumes/)</li>
<li>[Storage Classes](https://kubernetes.io/docs/concepts/storage/storage-classes/)</li>
<li>[Dynamic Volume Provisioning](https://kubernetes.io/docs/concepts/storage/dynamic-provisioning/)</li>
<li>[CSI Drivers](https://kubernetes-csi.github.io/docs/drivers.html)</li>
<p>---</p>
<h2>‚úÖ Module Checklist</h2>
<li>[ ] Understand PV vs PVC concepts</li>
<li>[ ] Create static PVs and PVCs</li>
<li>[ ] Configure StorageClasses for dynamic provisioning</li>
<li>[ ] Use volumeClaimTemplates in StatefulSets</li>
<li>[ ] Deploy stateful application with persistent storage</li>
<li>[ ] Complete WordPress + MySQL exercise</li></ul>
<p>---</p>
<strong>Next Module:</strong> [Module 10: Kubernetes Configuration](./10_Kubernetes_Configuration.md) - Master ConfigMaps, Secrets, and environment variables! üîê

    </div>
    

    <div class="module-content" id="module-10">
        <h1>Module 10: Kubernetes Configuration Management üîê</h1>
<h2>Master ConfigMaps, Secrets & Application Configuration</h2>
<strong>Duration:</strong> 2-3 hours  
<strong>Prerequisites:</strong> Module 06-09 (K8s fundamentals)  
<strong>Outcome:</strong> Externalize configuration and manage secrets securely
<p>---</p>
<h2>üìö Table of Contents</h2>
<p>1. [Configuration Challenges](#configuration-challenges)
2. [ConfigMaps](#configmaps)
3. [Secrets](#secrets)
4. [Environment Variables](#environment-variables)
5. [Best Practices](#best-practices)
6. [Interview Questions](#interview-questions)
7. [Hands-On Exercise](#hands-on-exercise)</p>
<p>---</p>
<h2>Configuration Challenges</h2>
<h3>12-Factor App Principle</h3>
<pre><code class="language-text">III. Config
Store config in the environment
Separate code from configuration</code></pre>
<h3>Kubernetes Configuration Options</h3>
<pre><code class="language-yaml">1. ConfigMaps      # Non-sensitive config
2. Secrets         # Sensitive data (passwords, tokens)
3. Environment Variables
4. Command-line arguments
5. Configuration files (mounted volumes)</code></pre>
<p>---</p>
<h2>ConfigMaps</h2>
<h3>What is a ConfigMap?</h3>
<strong>Store non-sensitive configuration</strong> as key-value pairs.
<h3>Creating ConfigMaps</h3>
<p>#### From Literals</p>
<pre><code class="language-bash">kubectl create configmap app-config \
  --from-literal=database_url=postgres://db:5432/myapp \
  --from-literal=log_level=info \
  --from-literal=max_connections=100</code></pre>
<p>#### From File</p>
<pre><code class="language-bash"># config.properties
database_url=postgres://db:5432/myapp
log_level=info
max_connections=100
<p>kubectl create configmap app-config --from-file=config.properties</code></pre></p>
<p>#### From YAML</p>
<pre><code class="language-yaml">apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
data:
  database_url: &quot;postgres://db:5432/myapp&quot;
  log_level: &quot;info&quot;
  max_connections: &quot;100&quot;
  
  # Multi-line configuration
  app.conf: |
    server {
      listen 80;
      server_name example.com;
      
      location / {
        proxy_pass http://backend:8080;
      }
    }</code></pre>
<h3>Using ConfigMaps</h3>
<p>#### As Environment Variables</p>
<pre><code class="language-yaml">apiVersion: v1
kind: Pod
metadata:
  name: app-pod
spec:
  containers:
  - name: app
    image: myapp:1.0
    
    # Option 1: Individual keys
    env:
    - name: DATABASE_URL
      valueFrom:
        configMapKeyRef:
          name: app-config
          key: database_url
    
    # Option 2: All keys
    envFrom:
    - configMapRef:
        name: app-config</code></pre>
<p>#### As Volume</p>
<pre><code class="language-yaml">apiVersion: v1
kind: Pod
metadata:
  name: app-pod
spec:
  containers:
  - name: app
    image: nginx
    volumeMounts:
    - name: config
      mountPath: /etc/config
      readOnly: true
  
  volumes:
  - name: config
    configMap:
      name: app-config</code></pre>
<pre><code class="language-bash"># Inside pod, files created for each key:
/etc/config/database_url
/etc/config/log_level
/etc/config/max_connections
/etc/config/app.conf</code></pre>
<p>#### Specific Keys as Files</p>
<pre><code class="language-yaml">volumes:
<ul><li>name: config</li>
  configMap:
    name: app-config
    items:
    - key: app.conf
      path: nginx.conf  # Custom filename</code></pre>
<h3>Updating ConfigMaps</h3>
<pre><code class="language-bash"># Edit ConfigMap
kubectl edit configmap app-config
<h1>Or apply updated YAML</h1>
kubectl apply -f configmap.yaml</code></pre>
<strong>‚ö†Ô∏è Important:</strong> Pods don't automatically reload ConfigMaps!
<pre><code class="language-bash"># Must restart pods to see changes
kubectl rollout restart deployment/myapp
<h1>Or use tools like Reloader:</h1>
<h1>github.com/stakater/Reloader</code></pre></h1>
<p>---</p>
<h2>Secrets</h2>
<h3>What is a Secret?</h3>
<strong>Store sensitive data</strong> (passwords, tokens, certificates) - base64 encoded.
<h3>Secret Types</h3>
<pre><code class="language-yaml">Opaque                # Generic secret (default)
kubernetes.io/tls     # TLS certificates
kubernetes.io/dockerconfigjson  # Docker registry credentials
kubernetes.io/basic-auth        # Basic authentication
kubernetes.io/ssh-auth          # SSH keys
kubernetes.io/service-account-token  # Service account token</code></pre>
<h3>Creating Secrets</h3>
<p>#### From Literals</p>
<pre><code class="language-bash">kubectl create secret generic db-secret \
  --from-literal=username=admin \
  --from-literal=password=secretpass123</code></pre>
<p>#### From Files</p>
<pre><code class="language-bash"># db-credentials.txt
username=admin
password=secretpass123
<p>kubectl create secret generic db-secret \
  --from-file=db-credentials.txt</code></pre></p>
<p>#### From YAML</p>
<pre><code class="language-yaml">apiVersion: v1
kind: Secret
metadata:
  name: db-secret
type: Opaque
data:
  username: YWRtaW4=           # base64: admin
  password: c2VjcmV0cGFzczEyMw==  # base64: secretpass123</code></pre>
<pre><code class="language-bash"># Base64 encoding
echo -n &quot;admin&quot; | base64
<h1>YWRtaW4=</h1>
<p>echo -n &quot;secretpass123&quot; | base64
<h1>c2VjcmV0cGFzczEyMw==</h1></p>
<h1>Decoding</h1>
echo &quot;YWRtaW4=&quot; | base64 --decode
<h1>admin</code></pre></h1>
<p>#### StringData (No Encoding Needed)</p>
<pre><code class="language-yaml">apiVersion: v1
kind: Secret
metadata:
  name: db-secret
type: Opaque
stringData:  # Plain text, K8s encodes automatically
  username: admin
  password: secretpass123</code></pre>
<h3>Using Secrets</h3>
<p>#### As Environment Variables</p>
<pre><code class="language-yaml">apiVersion: v1
kind: Pod
metadata:
  name: app-pod
spec:
  containers:
  - name: app
    image: myapp:1.0
    env:
    - name: DB_USERNAME
      valueFrom:
        secretKeyRef:
          name: db-secret
          key: username
    - name: DB_PASSWORD
      valueFrom:
        secretKeyRef:
          name: db-secret
          key: password</code></pre>
<p>#### As Volume (Recommended)</p>
<pre><code class="language-yaml">apiVersion: v1
kind: Pod
metadata:
  name: app-pod
spec:
  containers:
  - name: app
    image: myapp:1.0
    volumeMounts:
    - name: secret-volume
      mountPath: /etc/secrets
      readOnly: true  # Important!
  
  volumes:
  - name: secret-volume
    secret:
      secretName: db-secret</code></pre>
<pre><code class="language-bash"># Inside pod:
cat /etc/secrets/username  # admin
cat /etc/secrets/password  # secretpass123</code></pre>
<h3>TLS Secrets</h3>
<pre><code class="language-bash"># Create TLS secret
kubectl create secret tls tls-secret \
  --cert=path/to/tls.crt \
  --key=path/to/tls.key</code></pre>
<pre><code class="language-yaml"># Use in Ingress
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: secure-ingress
spec:
  tls:
  - hosts:
    - myapp.example.com
    secretName: tls-secret
  rules:
  - host: myapp.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: web
            port:
              number: 80</code></pre>
<h3>Docker Registry Secret</h3>
<pre><code class="language-bash"># Create docker-registry secret
kubectl create secret docker-registry regcred \
  --docker-server=https://index.docker.io/v1/ \
  --docker-username=myusername \
  --docker-password=mypassword \
  --docker-email=my@email.com</code></pre>
<pre><code class="language-yaml"># Use in Pod
spec:
  containers:
  - name: app
    image: private-registry.com/myapp:1.0
  
  imagePullSecrets:
  - name: regcred</code></pre>
<p>---</p>
<h2>Environment Variables</h2>
<h3>Sources of Environment Variables</h3>
<pre><code class="language-yaml">apiVersion: v1
kind: Pod
metadata:
  name: env-demo
spec:
  containers:
  - name: app
    image: myapp:1.0
    env:
    
    # 1. Literal value
    - name: ENVIRONMENT
      value: &quot;production&quot;
    
    # 2. Pod metadata
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: POD_NAMESPACE
      valueFrom:
        fieldRef:
          fieldPath: metadata.namespace
    - name: POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
    
    # 3. Container resources
    - name: CPU_LIMIT
      valueFrom:
        resourceFieldRef:
          containerName: app
          resource: limits.cpu
    
    # 4. ConfigMap
    - name: DATABASE_URL
      valueFrom:
        configMapKeyRef:
          name: app-config
          key: database_url
    
    # 5. Secret
    - name: DB_PASSWORD
      valueFrom:
        secretKeyRef:
          name: db-secret
          key: password</code></pre>
<h3>Load All ConfigMap/Secret Keys</h3>
<pre><code class="language-yaml">spec:
  containers:
  - name: app
    image: myapp:1.0
    
    # All ConfigMap keys as env vars
    envFrom:
    - configMapRef:
        name: app-config
    
    # All Secret keys as env vars
    - secretRef:
        name: db-secret</code></pre>
<p>---</p>
<h2>Best Practices</h2>
<h3>1. Don't Commit Secrets to Git</h3>
<pre><code class="language-bash"># ‚ùå Bad: Secrets in code
password: &quot;mysecret123&quot;
<h1>‚úÖ Good: External secret management</h1>
<li>Use Kubernetes Secrets</li>
<li>Use external tools (Vault, AWS Secrets Manager)</li>
<li>GitOps: Sealed Secrets, SOPS</code></pre></li>
<h3>2. Use Volumes for Secrets</h3>
<pre><code class="language-yaml"># ‚úÖ Recommended: Volume mount
volumeMounts:
<li>name: secret</li>
  mountPath: /etc/secrets
  readOnly: true
<h1>‚ö†Ô∏è Less secure: Environment variable</h1>
<h1>(visible in ps, logs, /proc)</h1>
env:
<li>name: PASSWORD</li>
  valueFrom:
    secretKeyRef:
      name: secret
      key: password</code></pre>
<h3>3. Principle of Least Privilege</h3>
<pre><code class="language-yaml"># Create separate secrets for different components
db-secret      # Only for database pods
api-key-secret # Only for API pods
tls-secret     # Only for Ingress</code></pre>
<h3>4. Immutable ConfigMaps/Secrets</h3>
<pre><code class="language-yaml">apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
immutable: true  # Cannot be changed
data:
  config: &quot;value&quot;</code></pre>
<strong>Benefits:</strong>
<li>Performance (kubelet doesn't watch for changes)</li>
<li>Safety (prevents accidental updates)</li>
<li>For updates: Create new ConfigMap, update Deployment</li>
<h3>5. Use Namespaces for Isolation</h3>
<pre><code class="language-bash"># Production secrets in production namespace
kubectl create secret generic db-secret \
  --from-literal=password=prod123 \
  -n production
<h1>Dev secrets in dev namespace</h1>
kubectl create secret generic db-secret \
  --from-literal=password=dev123 \
  -n dev</code></pre>
<h3>6. External Secret Management</h3>
<pre><code class="language-yaml"># Tools for enterprise secret management:
<li>HashiCorp Vault</li>
<li>AWS Secrets Manager</li>
<li>Azure Key Vault</li>
<li>GCP Secret Manager</li>
<li>External Secrets Operator (ESO)</code></pre></li>
<strong>Example: External Secrets Operator</strong>
<pre><code class="language-yaml">apiVersion: external-secrets.io/v1beta1
kind: ExternalSecret
metadata:
  name: database-secret
spec:
  refreshInterval: 1h
  secretStoreRef:
    name: vault-backend
    kind: SecretStore
  target:
    name: db-secret
  data:
  - secretKey: password
    remoteRef:
      key: secret/database
      property: password</code></pre>
<p>---</p>
<h2>Interview Questions</h2>
<strong>Q1: What's the difference between ConfigMap and Secret?</strong>
<strong>Answer:</strong>
<li><strong>ConfigMap</strong>: Non-sensitive config (URLs, feature flags), stored as plain text</li>
<li><strong>Secret</strong>: Sensitive data (passwords, tokens), base64 encoded, can be encrypted at rest</li>
Both used similarly but Secrets have additional security measures (encryption, RBAC restrictions).
<strong>Q2: Why use volumes instead of environment variables for secrets?</strong>
<strong>Answer:</strong> Security. Environment variables are:
<li>Visible in <code>kubectl describe pod</code></li>
<li>Visible in container <code>/proc</code> filesystem</li>
<li>Can leak in logs if application prints env</li>
Volumes are more secure, harder to accidentally expose, and support hot-reloading.
<strong>Q3: How do you update a ConfigMap without downtime?</strong>
<strong>Answer:</strong> Two approaches:
1. <strong>In-place update</strong>: Edit ConfigMap, rollout restart deployment (brief restart)
2. <strong>Blue-green</strong>: Create new ConfigMap (app-config-v2), update Deployment to use it, delete old ConfigMap (zero downtime)
<strong>Q4: What is base64 encoding and is it secure?</strong>
<strong>Answer:</strong> Base64 is encoding (not encryption) - converts binary to ASCII text. Not secure - easily decoded. Kubernetes Secrets use base64 for convenience (storing binary data), not security. For real security, enable encryption at rest in etcd.
<strong>Q5: How would you manage secrets in a GitOps workflow?</strong>
<strong>Answer:</strong> Use sealed secrets or SOPS:
<li><strong>Sealed Secrets</strong>: Encrypt secrets with public key, commit encrypted version, controller decrypts in cluster</li>
<li><strong>SOPS</strong>: Encrypt files with KMS/PGP, commit encrypted files, decrypt during apply</li>
Never commit plain secrets to Git.
<p>---</p>
<h2>Hands-On Exercise</h2>
<h3>Task: Configure Multi-Environment Application</h3>
<pre><code class="language-yaml"># 1. Development ConfigMap
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
  namespace: dev
data:
  environment: &quot;development&quot;
  database_url: &quot;postgres://db:5432/myapp_dev&quot;
  log_level: &quot;debug&quot;
  feature_flag_new_ui: &quot;true&quot;
<p>---
<h1>2. Production ConfigMap</h1>
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
  namespace: prod
data:
  environment: &quot;production&quot;
  database_url: &quot;postgres://db-prod:5432/myapp&quot;
  log_level: &quot;error&quot;
  feature_flag_new_ui: &quot;false&quot;</p>
<p>---
<h1>3. Database Secret (dev)</h1>
apiVersion: v1
kind: Secret
metadata:
  name: db-secret
  namespace: dev
type: Opaque
stringData:
  username: &quot;devuser&quot;
  password: &quot;devpass123&quot;</p>
<p>---
<h1>4. Database Secret (prod)</h1>
apiVersion: v1
kind: Secret
metadata:
  name: db-secret
  namespace: prod
type: Opaque
stringData:
  username: &quot;produser&quot;
  password: &quot;prod_secure_pass_xyz&quot;</p>
<p>---
<h1>5. Application Deployment</h1>
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
spec:
  replicas: 2
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: app
        image: busybox:1.35
        command: [&quot;/bin/sh&quot;, &quot;-c&quot;]
        args:
        - |
          echo &quot;Environment: $ENVIRONMENT&quot;
          echo &quot;Database: $DATABASE_URL&quot;
          echo &quot;Log Level: $LOG_LEVEL&quot;
          echo &quot;DB User: $(cat /etc/secrets/username)&quot;
          echo &quot;New UI: $FEATURE_FLAG_NEW_UI&quot;
          sleep 3600
        
        # Environment variables from ConfigMap
        envFrom:
        - configMapRef:
            name: app-config
        
        # Secret as volume
        volumeMounts:
        - name: db-credentials
          mountPath: /etc/secrets
          readOnly: true
      
      volumes:
      - name: db-credentials
        secret:
          secretName: db-secret</code></pre></p>
<strong>Tasks:</strong>
<pre><code class="language-bash"># 1. Create namespaces
kubectl create namespace dev
kubectl create namespace prod
<h1>2. Deploy to dev</h1>
kubectl apply -f config.yaml -n dev
<h1>3. Deploy to prod</h1>
kubectl apply -f config.yaml -n prod
<h1>4. Verify configurations</h1>
kubectl exec -it -n dev deployment/myapp -- env | grep -E &quot;ENVIRONMENT|DATABASE&quot;
kubectl exec -it -n prod deployment/myapp -- env | grep -E &quot;ENVIRONMENT|DATABASE&quot;
<h1>5. Check secrets</h1>
kubectl exec -it -n dev deployment/myapp -- cat /etc/secrets/username
kubectl exec -it -n prod deployment/myapp -- cat /etc/secrets/username
<h1>6. Update ConfigMap</h1>
kubectl edit configmap app-config -n dev
<h1>Change log_level: debug ‚Üí log_level: info</h1>
<h1>7. Restart to see changes</h1>
kubectl rollout restart deployment/myapp -n dev</code></pre>
<p>---</p>
<h2>üìö Additional Resources</h2>
<li>[ConfigMaps](https://kubernetes.io/docs/concepts/configuration/configmap/)</li>
<li>[Secrets](https://kubernetes.io/docs/concepts/configuration/secret/)</li>
<li>[Managing Secrets](https://kubernetes.io/docs/tasks/configmap-secret/)</li>
<li>[External Secrets Operator](https://external-secrets.io/)</li>
<p>---</p>
<h2>‚úÖ Module Checklist</h2>
<li>[ ] Create and use ConfigMaps</li>
<li>[ ] Create and use Secrets</li>
<li>[ ] Mount configs as volumes</li>
<li>[ ] Use environment variables</li>
<li>[ ] Implement multi-environment configuration</li>
<li>[ ] Understand security best practices</li></ul>
<p>---</p>
<strong>Next Module:</strong> [Module 11: Kubernetes Tools](./11_Kubernetes_Tools.md) - Master kubectl, Helm, kustomize, and essential K8s tools! üõ†Ô∏è

    </div>
    

    <div class="module-content" id="module-11">
        <h1>Module 11: Kubernetes Essential Tools üõ†Ô∏è</h1>
<h2>Master kubectl, Helm, kustomize & Productivity Tools</h2>
<strong>Duration:</strong> 3-4 hours  
<strong>Prerequisites:</strong> Module 06-10 (All K8s fundamentals)  
<strong>Outcome:</strong> Efficient K8s cluster management and application deployment
<p>---</p>
<h2>üìö Table of Contents</h2>
<p>1. [kubectl Advanced](#kubectl-advanced)
2. [Helm - Package Manager](#helm---package-manager)
3. [kustomize - Configuration Management](#kustomize---configuration-management)
4. [k9s - Terminal UI](#k9s---terminal-ui)
5. [kubectx & kubens](#kubectx--kubens)
6. [stern - Multi-Pod Logs](#stern---multi-pod-logs)
7. [Other Essential Tools](#other-essential-tools)
8. [Interview Questions](#interview-questions)
9. [Hands-On Exercise](#hands-on-exercise)</p>
<p>---</p>
<h2>kubectl Advanced</h2>
<h3>Productivity Shortcuts</h3>
<pre><code class="language-bash"># Aliases
alias k=kubectl
alias kgp=&quot;kubectl get pods&quot;
alias kgd=&quot;kubectl get deployments&quot;
alias kgs=&quot;kubectl get services&quot;
alias kga=&quot;kubectl get all&quot;
alias kaf=&quot;kubectl apply -f&quot;
alias kdel=&quot;kubectl delete&quot;
<h1>Shell completion</h1>
source &lt;(kubectl completion bash)  # bash
source &lt;(kubectl completion zsh)   # zsh</code></pre>
<h3>Advanced Get Commands</h3>
<pre><code class="language-bash"># Custom columns
kubectl get pods -o custom-columns=NAME:.metadata.name,STATUS:.status.phase,NODE:.spec.nodeName
<h1>JSONPath</h1>
kubectl get pods -o jsonpath=&#039;{.items[*].metadata.name}&#039;
kubectl get pods -o jsonpath=&#039;{range .items[*]}{.metadata.name}{&quot;\t&quot;}{.status.podIP}{&quot;\n&quot;}{end}&#039;
<h1>Sort by creation time</h1>
kubectl get pods --sort-by=.metadata.creationTimestamp
<h1>Filter by label</h1>
kubectl get pods -l app=nginx,tier=frontend
<h1>Show labels</h1>
kubectl get pods --show-labels
<h1>Watch resources</h1>
kubectl get pods -w</code></pre>
<h3>Resource Management</h3>
<pre><code class="language-bash"># Top (requires metrics-server)
kubectl top nodes
kubectl top pods
kubectl top pods --containers
<h1>Drain node (for maintenance)</h1>
kubectl drain node-1 --ignore-daemonsets --delete-emptydir-data
<h1>Cordon (prevent scheduling)</h1>
kubectl cordon node-1
<h1>Uncordon</h1>
kubectl uncordon node-1
<h1>Taint node</h1>
kubectl taint nodes node-1 key=value:NoSchedule
<h1>Remove taint</h1>
kubectl taint nodes node-1 key:NoSchedule-</code></pre>
<h3>Debugging</h3>
<pre><code class="language-bash"># Describe (detailed info)
kubectl describe pod nginx-abc123
<h1>Logs</h1>
kubectl logs pod-name
kubectl logs pod-name -f              # Follow
kubectl logs pod-name --previous      # Previous container (if crashed)
kubectl logs pod-name -c container    # Specific container
kubectl logs -l app=nginx             # All pods with label
<h1>Execute commands</h1>
kubectl exec -it pod-name -- /bin/bash
kubectl exec pod-name -- ls /app
kubectl exec pod-name -- env
<h1>Port forward</h1>
kubectl port-forward pod-name 8080:80
kubectl port-forward service/web 8080:80
<h1>Copy files</h1>
kubectl cp pod-name:/path/to/file ./local-file
kubectl cp ./local-file pod-name:/path/to/file
<h1>Debug with ephemeral container (K8s 1.23+)</h1>
kubectl debug pod-name -it --image=busybox --target=container-name</code></pre>
<h3>Apply Strategies</h3>
<pre><code class="language-bash"># Apply (declarative)
kubectl apply -f deployment.yaml
<h1>Create (imperative, fails if exists)</h1>
kubectl create -f deployment.yaml
<h1>Replace (delete and recreate)</h1>
kubectl replace -f deployment.yaml
<h1>Patch (update specific fields)</h1>
kubectl patch deployment nginx -p &#039;{&quot;spec&quot;:{&quot;replicas&quot;:5}}&#039;
<h1>Edit (interactive)</h1>
kubectl edit deployment nginx
<h1>Dry run</h1>
kubectl apply -f deployment.yaml --dry-run=client
kubectl apply -f deployment.yaml --dry-run=server
<h1>Diff before apply</h1>
kubectl diff -f deployment.yaml</code></pre>
<h3>Context & Namespaces</h3>
<pre><code class="language-bash"># View contexts
kubectl config get-contexts
<h1>Current context</h1>
kubectl config current-context
<h1>Switch context</h1>
kubectl config use-context minikube
<h1>Set default namespace</h1>
kubectl config set-context --current --namespace=production
<h1>Create namespace</h1>
kubectl create namespace dev
<h1>All namespaces</h1>
kubectl get pods --all-namespaces
kubectl get pods -A  # Short form</code></pre>
<p>---</p>
<h2>Helm - Package Manager</h2>
<h3>What is Helm?</h3>
<strong>Kubernetes package manager</strong> - manages charts (pre-configured K8s resources).
<pre><code class="language-text">Helm = apt/yum for Kubernetes
<p>Chart = Package (nginx, postgresql, prometheus)
Release = Deployed instance
Repository = Chart storage</code></pre></p>
<h3>Installation</h3>
<pre><code class="language-bash"># macOS
brew install helm
<h1>Linux</h1>
curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
<h1>Verify</h1>
helm version</code></pre>
<h3>Helm Commands</h3>
<pre><code class="language-bash"># Add repository
helm repo add bitnami https://charts.bitnami.com/bitnami
helm repo add stable https://charts.helm.sh/stable
<h1>Update repositories</h1>
helm repo update
<h1>Search charts</h1>
helm search repo nginx
helm search hub wordpress
<h1>Install chart</h1>
helm install my-nginx bitnami/nginx
<h1>Install with custom values</h1>
helm install my-db bitnami/postgresql \
  --set auth.postgresPassword=secretpass \
  --set primary.persistence.size=20Gi
<h1>Install from values file</h1>
helm install my-app ./my-chart -f values.yaml
<h1>List releases</h1>
helm list
helm list --all-namespaces
<h1>Get release info</h1>
helm status my-nginx
helm get values my-nginx
helm get manifest my-nginx
<h1>Upgrade release</h1>
helm upgrade my-nginx bitnami/nginx --set replicaCount=3
<h1>Rollback</h1>
helm rollback my-nginx 1  # Rollback to revision 1
<h1>Uninstall</h1>
helm uninstall my-nginx
<h1>History</h1>
helm history my-nginx</code></pre>
<h3>Creating Helm Charts</h3>
<pre><code class="language-bash"># Create chart scaffold
helm create my-app
<h1>Directory structure:</h1>
my-app/
‚îú‚îÄ‚îÄ Chart.yaml           # Chart metadata
‚îú‚îÄ‚îÄ values.yaml          # Default values
‚îú‚îÄ‚îÄ charts/              # Dependencies
‚îî‚îÄ‚îÄ templates/           # K8s manifests (templated)
    ‚îú‚îÄ‚îÄ deployment.yaml
    ‚îú‚îÄ‚îÄ service.yaml
    ‚îú‚îÄ‚îÄ ingress.yaml
    ‚îî‚îÄ‚îÄ _helpers.tpl     # Template helpers</code></pre>
<strong>Chart.yaml:</strong>
<pre><code class="language-yaml">apiVersion: v2
name: my-app
description: A Helm chart for my application
type: application
version: 1.0.0
appVersion: &quot;1.0&quot;</code></pre>
<strong>values.yaml:</strong>
<pre><code class="language-yaml">replicaCount: 3
<p>image:
  repository: nginx
  tag: 1.21
  pullPolicy: IfNotPresent</p>
<p>service:
  type: ClusterIP
  port: 80</p>
<p>ingress:
  enabled: false
  className: nginx
  hosts:
    - host: myapp.example.com
      paths:
        - path: /
          pathType: Prefix</p>
<p>resources:
  limits:
    cpu: 500m
    memory: 512Mi
  requests:
    cpu: 100m
    memory: 128Mi</code></pre></p>
<strong>templates/deployment.yaml:</strong>
<pre><code class="language-yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include &quot;my-app.fullname&quot; . }}
  labels:
    {{- include &quot;my-app.labels&quot; . | nindent 4 }}
spec:
  replicas: {{ .Values.replicaCount }}
  selector:
    matchLabels:
      {{- include &quot;my-app.selectorLabels&quot; . | nindent 6 }}
  template:
    metadata:
      labels:
        {{- include &quot;my-app.selectorLabels&quot; . | nindent 8 }}
    spec:
      containers:
      - name: {{ .Chart.Name }}
        image: &quot;{{ .Values.image.repository }}:{{ .Values.image.tag }}&quot;
        imagePullPolicy: {{ .Values.image.pullPolicy }}
        ports:
        - containerPort: 80
        resources:
          {{- toYaml .Values.resources | nindent 12 }}</code></pre>
<pre><code class="language-bash"># Package chart
helm package my-app
<h1>Install local chart</h1>
helm install my-release ./my-app
<h1>Template (render without installing)</h1>
helm template my-release ./my-app
<h1>Lint</h1>
helm lint my-app</code></pre>
<h3>Helm Best Practices</h3>
<pre><code class="language-yaml"># 1. Use values.yaml for configuration
<h1>‚ùå Hardcoded:</h1>
replicas: 3
<h1>‚úÖ Parameterized:</h1>
replicas: {{ .Values.replicaCount }}
<h1>2. Use _helpers.tpl for reusable templates</h1>
{{- define &quot;my-app.fullname&quot; -}}
{{- printf &quot;%s-%s&quot; .Release.Name .Chart.Name | trunc 63 | trimSuffix &quot;-&quot; }}
{{- end }}
<h1>3. Always set resource limits</h1>
resources:
  {{- toYaml .Values.resources | nindent 12 }}
<h1>4. Use if/else for optional resources</h1>
{{- if .Values.ingress.enabled }}
apiVersion: networking.k8s.io/v1
kind: Ingress
...
{{- end }}
<h1>5. Version your charts</h1>
version: 1.2.3  # Chart version
appVersion: &quot;2.0.1&quot;  # Application version</code></pre>
<p>---</p>
<h2>kustomize - Configuration Management</h2>
<h3>What is kustomize?</h3>
<strong>Customize K8s manifests</strong> without templates - uses overlays and patches.
<pre><code class="language-text">Base ‚Üí Common configuration
Overlays ‚Üí Environment-specific changes (dev, staging, prod)</code></pre>
<h3>Installation</h3>
<pre><code class="language-bash"># Built into kubectl (1.14+)
kubectl kustomize ./
<h1>Standalone</h1>
brew install kustomize</code></pre>
<h3>Directory Structure</h3>
<pre><code class="language-text">my-app/
‚îú‚îÄ‚îÄ base/
‚îÇ   ‚îú‚îÄ‚îÄ deployment.yaml
‚îÇ   ‚îú‚îÄ‚îÄ service.yaml
‚îÇ   ‚îî‚îÄ‚îÄ kustomization.yaml
‚îî‚îÄ‚îÄ overlays/
    ‚îú‚îÄ‚îÄ dev/
    ‚îÇ   ‚îú‚îÄ‚îÄ kustomization.yaml
    ‚îÇ   ‚îî‚îÄ‚îÄ replica-patch.yaml
    ‚îú‚îÄ‚îÄ staging/
    ‚îÇ   ‚îî‚îÄ‚îÄ kustomization.yaml
    ‚îî‚îÄ‚îÄ production/
        ‚îî‚îÄ‚îÄ kustomization.yaml</code></pre>
<h3>Base Configuration</h3>
<strong>base/kustomization.yaml:</strong>
<pre><code class="language-yaml">apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
<p>resources:
<ul><li>deployment.yaml</li>
<li>service.yaml</li></p>
<p>commonLabels:
  app: myapp</code></pre></p>
<strong>base/deployment.yaml:</strong>
<pre><code class="language-yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
spec:
  replicas: 1
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: app
        image: myapp:latest
        resources:
          requests:
            cpu: 100m
            memory: 128Mi</code></pre>
<h3>Overlays (Environment-Specific)</h3>
<strong>overlays/dev/kustomization.yaml:</strong>
<pre><code class="language-yaml">apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
<p>bases:
<li>../../base</li></p>
<p>namePrefix: dev-</p>
<p>namespace: development</p>
<p>replicas:
<li>name: myapp</li>
  count: 1</p>
<p>images:
<li>name: myapp</li>
  newTag: dev-latest</p>
<p>configMapGenerator:
<li>name: app-config</li>
  literals:
  - environment=development
  - log_level=debug</code></pre></p>
<strong>overlays/production/kustomization.yaml:</strong>
<pre><code class="language-yaml">apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
<p>bases:
<li>../../base</li></p>
<p>namePrefix: prod-</p>
<p>namespace: production</p>
<p>replicas:
<li>name: myapp</li>
  count: 5</p>
<p>images:
<li>name: myapp</li>
  newTag: v1.2.3</p>
<p>configMapGenerator:
<li>name: app-config</li>
  literals:
  - environment=production
  - log_level=error</p>
<p>patchesStrategicMerge:
<li>|-</li>
  apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: myapp
  spec:
    template:
      spec:
        containers:
        - name: app
          resources:
            limits:
              cpu: 2
              memory: 2Gi
            requests:
              cpu: 500m
              memory: 512Mi</code></pre></p>
<h3>Using kustomize</h3>
<pre><code class="language-bash"># Preview output
kubectl kustomize overlays/dev
kubectl kustomize overlays/production
<h1>Apply</h1>
kubectl apply -k overlays/dev
kubectl apply -k overlays/production
<h1>Diff</h1>
kubectl diff -k overlays/production</code></pre>
<h3>kustomize Capabilities</h3>
<pre><code class="language-yaml"># 1. Replace image tags
images:
<li>name: myapp</li>
  newName: myregistry/myapp
  newTag: v2.0.0
<h1>2. Add common labels</h1>
commonLabels:
  app: myapp
  team: platform
<h1>3. Add name prefix/suffix</h1>
namePrefix: staging-
nameSuffix: -v1
<h1>4. Generate ConfigMaps/Secrets</h1>
configMapGenerator:
<li>name: config</li>
  files:
  - app.conf
  literals:
  - key=value
<p>secretGenerator:
<li>name: secret</li>
  literals:
  - password=secret123</p>
<h1>5. Patches</h1>
patchesStrategicMerge:
<li>patch.yaml</li>
<p>patchesJson6902:
<li>target:</li>
    kind: Deployment
    name: myapp
  patch: |-
    - op: replace
      path: /spec/replicas
      value: 3</code></pre></p>
<p>---</p>
<h2>k9s - Terminal UI</h2>
<h3>What is k9s?</h3>
<strong>Terminal-based UI</strong> for managing Kubernetes clusters - interactive and fast.
<h3>Installation</h3>
<pre><code class="language-bash"># macOS
brew install k9s
<h1>Linux</h1>
curl -sS https://webinstall.dev/k9s | bash
<h1>Run</h1>
k9s</code></pre>
<h3>Key Shortcuts</h3>
<pre><code class="language-text">Navigation:
:pods        # View pods
:deploy      # View deployments
:svc         # View services
:ns          # View namespaces
/            # Filter by name
Ctrl-a       # All namespaces
<p>Actions:
d            # Describe resource
e            # Edit resource
l            # View logs
s            # Shell into pod
y            # View YAML
Ctrl-k       # Delete resource
Ctrl-d       # Delete pod</p>
<p>Other:
?            # Help
:q or Ctrl-c # Quit
:ctx         # Switch context
:pulse       # View cluster metrics</code></pre></p>
<p>---</p>
<h2>kubectx & kubens</h2>
<h3>kubectx - Switch Contexts</h3>
<pre><code class="language-bash"># Install
brew install kubectx
<h1>List contexts</h1>
kubectx
<h1>Switch context</h1>
kubectx minikube
kubectx production
<h1>Previous context</h1>
kubectx -
<h1>Rename context</h1>
kubectx new-name=old-name</code></pre>
<h3>kubens - Switch Namespaces</h3>
<pre><code class="language-bash"># List namespaces
kubens
<h1>Switch namespace</h1>
kubens development
kubens production
<h1>Previous namespace</h1>
kubens -</code></pre>
<p>---</p>
<h2>stern - Multi-Pod Logs</h2>
<h3>What is stern?</h3>
<strong>Tail logs from multiple pods</strong> simultaneously with color coding.
<h3>Installation</h3>
<pre><code class="language-bash"># macOS
brew install stern
<h1>Linux</h1>
wget https://github.com/stern/stern/releases/download/v1.25.0/stern_1.25.0_linux_amd64.tar.gz</code></pre>
<h3>Usage</h3>
<pre><code class="language-bash"># All pods matching pattern
stern nginx
<h1>Specific namespace</h1>
stern nginx -n production
<h1>All containers in pod</h1>
stern nginx --all-namespaces
<h1>Since timestamp</h1>
stern nginx --since 15m
<h1>Include/exclude containers</h1>
stern nginx --container app
stern nginx --exclude-container sidecar
<h1>Custom output</h1>
stern nginx --template &#039;{{color .PodColor .PodName}} {{.Message}}&#039;
<h1>Follow specific deployment</h1>
stern -l app=nginx</code></pre>
<p>---</p>
<h2>Other Essential Tools</h2>
<h3>1. kubeseal - Sealed Secrets</h3>
<pre><code class="language-bash"># Encrypt secrets for Git
brew install kubeseal
<h1>Install controller</h1>
kubectl apply -f https://github.com/bitnami-labs/sealed-secrets/releases/download/v0.23.0/controller.yaml
<h1>Create sealed secret</h1>
echo -n &quot;secretvalue&quot; | kubectl create secret generic mysecret \
  --dry-run=client --from-file=password=/dev/stdin -o yaml | \
  kubeseal -o yaml &gt; sealed-secret.yaml
<h1>Apply (controller decrypts)</h1>
kubectl apply -f sealed-secret.yaml</code></pre>
<h3>2. kube-ps1 - Context in Prompt</h3>
<pre><code class="language-bash"># Install
brew install kube-ps1
<h1>Add to .bashrc/.zshrc</h1>
source &quot;/opt/homebrew/opt/kube-ps1/share/kube-ps1.sh&quot;
PS1=&#039;$(kube_ps1)&#039;$PS1
<h1>Shows: (‚éà |minikube:default)</code></pre></h1>
<h3>3. kubectl-tree - Resource Hierarchy</h3>
<pre><code class="language-bash"># Install
brew install kubectl-tree
<h1>View resource tree</h1>
kubectl tree deployment myapp</code></pre>
<h3>4. popeye - Cluster Scanner</h3>
<pre><code class="language-bash"># Install
brew install derailed/popeye/popeye
<h1>Scan cluster</h1>
popeye
<h1>Saves report</h1>
popeye -o html &gt; report.html</code></pre>
<p>---</p>
<h2>Interview Questions</h2>
<strong>Q1: What's the difference between Helm and kustomize?</strong>
<strong>Answer:</strong>
<li><strong>Helm</strong>: Template-based, package manager, good for third-party apps, uses Go templates</li>
<li><strong>kustomize</strong>: Patch-based, built into kubectl, no templates, overlays for environments</li>
Use Helm for complex apps/dependencies, kustomize for simpler customization.
<strong>Q2: When would you use <code>kubectl apply</code> vs <code>kubectl create</code>?</strong>
<strong>Answer:</strong>
<li><strong>apply</strong>: Declarative, idempotent, can update existing resources, recommended for GitOps</li>
<li><strong>create</strong>: Imperative, fails if resource exists, one-time creation</li>
Always use <code>apply</code> for production (infrastructure as code).
<strong>Q3: How do you troubleshoot a pod that's CrashLoopBackOff?</strong>
<strong>Answer:</strong>
1. <code>kubectl describe pod</code> - check events
2. <code>kubectl logs pod-name --previous</code> - see why it crashed
3. <code>kubectl get pod -o yaml</code> - check configuration
4. <code>kubectl exec -it pod -- sh</code> - debug if running
Common causes: wrong image, missing dependencies, incorrect command, resource limits.
<strong>Q4: Explain Helm's rollback mechanism.</strong>
<strong>Answer:</strong> Helm tracks release revisions in Secrets. Each upgrade creates new revision. <code>helm rollback</code> reverts to previous revision by applying old manifest. Can rollback to any revision with <code>helm rollback release-name revision-number</code>.
<strong>Q5: What are the advantages of kustomize's overlay approach?</strong>
<strong>Answer:</strong>
<li>No templates (pure YAML)</li>
<li>DRY principle (don't repeat base config)</li>
<li>Git-friendly (can diff changes)</li>
<li>Built into kubectl</li>
<li>Environment-specific overlays without duplication</li>
Perfect for GitOps workflows.
<p>---</p>
<h2>Hands-On Exercise</h2>
<h3>Task: Deploy App Using Multiple Tools</h3>
<pre><code class="language-bash"># 1. Create namespace with kubens
kubens -c my-app
<h1>2. Create kustomize structure</h1>
mkdir -p my-app/{base,overlays/dev,overlays/prod}
<h1>3. Create base/deployment.yaml</h1>
cat &lt;&lt;EOF &gt; my-app/base/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx
spec:
  replicas: 1
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.21
EOF
<h1>4. Create base/kustomization.yaml</h1>
cat &lt;&lt;EOF &gt; my-app/base/kustomization.yaml
resources:
<li>deployment.yaml</li>
EOF
<h1>5. Create overlays/dev/kustomization.yaml</h1>
cat &lt;&lt;EOF &gt; my-app/overlays/dev/kustomization.yaml
bases:
<li>../../base</li>
namePrefix: dev-
replicas:
<li>name: nginx</li>
  count: 1
EOF
<h1>6. Create overlays/prod/kustomization.yaml</h1>
cat &lt;&lt;EOF &gt; my-app/overlays/prod/kustomization.yaml
bases:
<li>../../base</li>
namePrefix: prod-
replicas:
<li>name: nginx</li>
  count: 5
EOF
<h1>7. Apply with kustomize</h1>
kubectl apply -k my-app/overlays/dev
<h1>8. View with k9s</h1>
k9s
<h1>9. Check logs with stern</h1>
stern nginx
<h1>10. Install Helm chart</h1>
helm repo add bitnami https://charts.bitnami.com/bitnami
helm install my-redis bitnami/redis
<h1>11. View all resources</h1>
kubectl get all
<h1>12. Clean up</h1>
kubectl delete -k my-app/overlays/dev
helm uninstall my-redis</code></pre>
<p>---</p>
<h2>üìö Additional Resources</h2>
<li>[kubectl Cheat Sheet](https://kubernetes.io/docs/reference/kubectl/cheatsheet/)</li>
<li>[Helm Documentation](https://helm.sh/docs/)</li>
<li>[kustomize Documentation](https://kustomize.io/)</li>
<li>[k9s GitHub](https://github.com/derailed/k9s)</li>
<p>---</p>
<h2>‚úÖ Module Checklist</h2>
<li>[ ] Master advanced kubectl commands</li>
<li>[ ] Create and deploy Helm charts</li>
<li>[ ] Use kustomize for multi-environment configs</li>
<li>[ ] Install and use k9s for cluster management</li>
<li>[ ] Use kubectx/kubens for context switching</li>
<li>[ ] Tail logs with stern</li>
<li>[ ] Complete hands-on exercise with all tools</li>
<p>---</p>
<h2>üéâ Kubernetes Section Complete!</h2>
<strong>Congratulations!</strong> You've mastered Kubernetes fundamentals:
<li>‚úÖ Architecture & Components</li>
<li>‚úÖ All 7 Core Workload Types</li>
<li>‚úÖ Networking (Services, Ingress, NetworkPolicies)</li>
<li>‚úÖ Storage (PV, PVC, StorageClasses)</li>
<li>‚úÖ Configuration (ConfigMaps, Secrets)</li>
<li>‚úÖ Essential Tools (kubectl, Helm, kustomize, k9s)</li></ul>
<strong>Next Section:</strong> [Module 12: Infrastructure - Server Setup](./12_Infrastructure_Server_Setup.md) - Learn bare metal, VMs, networking, and infrastructure basics! üñ•Ô∏è

    </div>
    

    <div class="module-content" id="module-12">
        <h1>Module 12: Infrastructure & Server Setup üñ•Ô∏è</h1>
<h2>From Bare Metal to Cloud - Complete Infrastructure Guide</h2>
<strong>Duration:</strong> 4-5 hours  
<strong>Prerequisites:</strong> Basic networking knowledge  
<strong>Outcome:</strong> Understand server provisioning, networking, DNS, and infrastructure fundamentals
<p>---</p>
<h2>üìö Table of Contents</h2>
<p>1. [Infrastructure Overview](#infrastructure-overview)
2. [Bare Metal Servers](#bare-metal-servers)
3. [Virtual Machines](#virtual-machines)
4. [Networking Fundamentals](#networking-fundamentals)
5. [DNS & FQDN](#dns--fqdn)
6. [Static IP Configuration](#static-ip-configuration)
7. [OVA Deployment](#ova-deployment)
8. [MicroK8s Setup](#microk8s-setup)
9. [Best Practices](#best-practices)
10. [Interview Questions](#interview-questions)
11. [Hands-On Exercise](#hands-on-exercise)</p>
<p>---</p>
<h2>Infrastructure Overview</h2>
<h3>Infrastructure Types</h3>
<pre><code class="language-text">1. On-Premises (Physical)
   ‚îú‚îÄ‚îÄ Bare Metal Servers
   ‚îú‚îÄ‚îÄ Own Data Center
   ‚îî‚îÄ‚îÄ Full control, high capital cost
<p>2. Virtualization
   ‚îú‚îÄ‚îÄ VMware vSphere
   ‚îú‚îÄ‚îÄ Hyper-V
   ‚îú‚îÄ‚îÄ KVM/Proxmox
   ‚îî‚îÄ‚îÄ Better resource utilization</p>
<p>3. Cloud (IaaS)
   ‚îú‚îÄ‚îÄ AWS EC2
   ‚îú‚îÄ‚îÄ Google Compute Engine
   ‚îú‚îÄ‚îÄ Azure VMs
   ‚îî‚îÄ‚îÄ Pay-as-you-go, high operational flexibility</p>
<p>4. Container Platforms
   ‚îú‚îÄ‚îÄ Kubernetes
   ‚îú‚îÄ‚îÄ Docker Swarm
   ‚îî‚îÄ‚îÄ Orchestration layer</code></pre></p>
<p>---</p>
<h2>Bare Metal Servers</h2>
<h3>What is Bare Metal?</h3>
<strong>Physical server</strong> without virtualization layer - direct hardware access.
<h3>Server Procurement</h3>
<pre><code class="language-bash"># 1. Specifications
CPU: 16+ cores (Intel Xeon, AMD EPYC)
RAM: 64GB+ DDR4 ECC
Storage: 
  - 2x 500GB NVMe (OS, RAID 1)
  - 4x 2TB SSD (Data, RAID 10)
Network: 2x 10GbE (bonded)
IPMI/BMC: Remote management
<h1>2. Vendors</h1>
<ul><li>Dell PowerEdge</li>
<li>HP ProLiant</li>
<li>Supermicro</li>
<li>Lenovo ThinkSystem</code></pre></li>
<h3>BIOS Configuration</h3>
<pre><code class="language-text">1. Boot Order
   - Network PXE (for automation)
   - Primary disk
   - USB
<p>2. Virtualization
   - Intel VT-x / AMD-V: Enabled
   - Intel VT-d / AMD-Vi: Enabled (IOMMU)</p>
<p>3. Power Management
   - Performance mode for production
   - Balanced for efficiency</p>
<p>4. IPMI/iLO/iDRAC
   - Set IP address
   - Enable remote console
   - Configure users</code></pre></p>
<h3>OS Installation (Ubuntu Server Example)</h3>
<pre><code class="language-bash"># 1. Download Ubuntu Server 22.04 LTS
wget https://releases.ubuntu.com/22.04/ubuntu-22.04.3-live-server-amd64.iso
<h1>2. Create bootable USB</h1>
sudo dd if=ubuntu-22.04.3-live-server-amd64.iso of=/dev/sdb bs=4M status=progress
<h1>3. Boot from USB and install</h1>
<h1>- Hostname: server01.example.com</h1>
<h1>- Username: admin</h1>
<h1>- Install OpenSSH server</h1>
<h1>- LVM for disk management</h1>
<h1>4. Post-install configuration</h1>
sudo apt update &amp;&amp; sudo apt upgrade -y
sudo apt install -y vim git curl wget htop net-tools
<h1>5. Configure static IP (covered later)</code></pre></h1>
<p>---</p>
<h2>Virtual Machines</h2>
<h3>Hypervisor Types</h3>
<pre><code class="language-text">Type 1 (Bare Metal):
<li>VMware ESXi</li>
<li>Proxmox VE</li>
<li>Microsoft Hyper-V</li>
<li>KVM</li>
Runs directly on hardware
<p>Type 2 (Hosted):
<li>VMware Workstation</li>
<li>VirtualBox</li>
<li>Parallels</li>
Runs on host OS</code></pre></p>
<h3>Proxmox VE Setup</h3>
<pre><code class="language-bash"># 1. Download Proxmox ISO
<h1>https://www.proxmox.com/en/downloads</h1>
<h1>2. Install on bare metal server</h1>
<h1>- Management interface: 192.168.1.100</h1>
<h1>- Gateway: 192.168.1.1</h1>
<h1>- DNS: 8.8.8.8</h1>
<h1>3. Access web UI</h1>
https://192.168.1.100:8006
<h1>4. Create VM via CLI</h1>
qm create 100 \
  --name ubuntu-vm \
  --memory 4096 \
  --cores 2 \
  --net0 virtio,bridge=vmbr0 \
  --scsi0 local-lvm:32 \
  --cdrom local:iso/ubuntu-22.04-server-amd64.iso \
  --boot order=scsi0
<h1>5. Start VM</h1>
qm start 100
<h1>6. VNC console</h1>
qm vncproxy 100</code></pre>
<h3>VMware ESXi</h3>
<pre><code class="language-bash"># 1. Install ESXi on server
<h1>2. Access via vSphere Client</h1>
<h1>Create VM via PowerCLI:</h1>
New-VM -Name &quot;web-server&quot; \
  -VMHost &quot;esxi01.example.com&quot; \
  -Datastore &quot;datastore1&quot; \
  -DiskGB 50 \
  -MemoryGB 8 \
  -NumCpu 4 \
  -NetworkName &quot;VM Network&quot; \
  -GuestId &quot;ubuntu64Guest&quot;
<h1>Start VM</h1>
Start-VM -VM &quot;web-server&quot;</code></pre>
<h3>KVM/QEMU (Linux)</h3>
<pre><code class="language-bash"># 1. Install KVM
sudo apt install -y qemu-kvm libvirt-daemon-system libvirt-clients bridge-utils virt-manager
<h1>2. Verify installation</h1>
sudo systemctl status libvirtd
sudo virsh list --all
<h1>3. Create VM</h1>
virt-install \
  --name ubuntu-vm \
  --ram 4096 \
  --vcpus 2 \
  --disk path=/var/lib/libvirt/images/ubuntu-vm.qcow2,size=20 \
  --os-variant ubuntu22.04 \
  --network bridge=br0 \
  --graphics vnc \
  --cdrom /path/to/ubuntu-22.04-server-amd64.iso
<h1>4. Manage VMs</h1>
virsh list --all
virsh start ubuntu-vm
virsh shutdown ubuntu-vm
virsh console ubuntu-vm</code></pre>
<p>---</p>
<h2>Networking Fundamentals</h2>
<h3>OSI Model & TCP/IP</h3>
<pre><code class="language-text">OSI Layer          TCP/IP           Protocols
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
7. Application  ‚îÄ‚îê
6. Presentation  ‚îú‚îÄ Application   HTTP, DNS, SSH
5. Session      ‚îÄ‚îò
<p>4. Transport    ‚îÄ‚îÄ‚îÄ Transport     TCP, UDP</p>
<p>3. Network      ‚îÄ‚îÄ‚îÄ Internet      IP, ICMP, IGMP</p>
<p>2. Data Link    ‚îÄ‚îê
1. Physical     ‚îÄ‚î¥‚îÄ Link          Ethernet, ARP</code></pre></p>
<h3>IP Addressing</h3>
<pre><code class="language-bash"># IPv4 Classes
Class A: 10.0.0.0/8        (10.0.0.0 - 10.255.255.255)
Class B: 172.16.0.0/12     (172.16.0.0 - 172.31.255.255)
Class C: 192.168.0.0/16    (192.168.0.0 - 192.168.255.255)
<h1>CIDR Notation</h1>
192.168.1.0/24  = 256 IPs (192.168.1.0 - 192.168.1.255)
192.168.1.0/25  = 128 IPs (192.168.1.0 - 192.168.1.127)
192.168.1.0/26  = 64 IPs  (192.168.1.0 - 192.168.1.63)
<h1>Subnet Mask</h1>
/24 = 255.255.255.0
/16 = 255.255.0.0
/8  = 255.0.0.0</code></pre>
<h3>Network Configuration (Ubuntu)</h3>
<pre><code class="language-yaml"># /etc/netplan/00-installer-config.yaml
network:
  version: 2
  renderer: networkd
  ethernets:
    ens18:
      addresses:
        - 192.168.1.100/24
      routes:
        - to: default
          via: 192.168.1.1
      nameservers:
        addresses:
          - 8.8.8.8
          - 8.8.4.4
        search:
          - example.com</code></pre>
<pre><code class="language-bash"># Apply configuration
sudo netplan apply
<h1>Test connectivity</h1>
ping 192.168.1.1
ping google.com
<h1>View routing table</h1>
ip route show
<h1>View network interfaces</h1>
ip addr show</code></pre>
<h3>VLANs</h3>
<pre><code class="language-bash"># Create VLAN interface
sudo ip link add link eth0 name eth0.10 type vlan id 10
sudo ip addr add 192.168.10.100/24 dev eth0.10
sudo ip link set dev eth0.10 up
<h1>Persistent configuration (netplan)</h1>
network:
  version: 2
  vlans:
    vlan10:
      id: 10
      link: eth0
      addresses: [192.168.10.100/24]</code></pre>
<h3>Network Bonding (Link Aggregation)</h3>
<pre><code class="language-yaml"># /etc/netplan/01-netcfg.yaml
network:
  version: 2
  ethernets:
    eth0:
      dhcp4: no
    eth1:
      dhcp4: no
  
  bonds:
    bond0:
      interfaces: [eth0, eth1]
      addresses: [192.168.1.100/24]
      routes:
        - to: default
          via: 192.168.1.1
      parameters:
        mode: 802.3ad  # LACP
        lacp-rate: fast
        mii-monitor-interval: 100</code></pre>
<p>---</p>
<h2>DNS & FQDN</h2>
<h3>DNS Hierarchy</h3>
<pre><code class="language-text">Root (.)
  ‚Üì
TLD (.com, .org, .net)
  ‚Üì
Domain (example.com)
  ‚Üì
Subdomain (www.example.com, api.example.com)
<p>FQDN: Fully Qualified Domain Name
Example: server01.datacenter.example.com.</code></pre></p>
<h3>DNS Record Types</h3>
<pre><code class="language-bash"># A Record (IPv4)
server01.example.com.  IN  A  192.168.1.100
<h1>AAAA Record (IPv6)</h1>
server01.example.com.  IN  AAAA  2001:db8::1
<h1>CNAME (Alias)</h1>
www.example.com.  IN  CNAME  server01.example.com.
<h1>MX (Mail Exchange)</h1>
example.com.  IN  MX  10 mail.example.com.
<h1>TXT (Text/SPF/DKIM)</h1>
example.com.  IN  TXT  &quot;v=spf1 mx ~all&quot;
<h1>PTR (Reverse DNS)</h1>
100.1.168.192.in-addr.arpa.  IN  PTR  server01.example.com.
<h1>SRV (Service)</h1>
_http._tcp.example.com.  IN  SRV  10 60 80 server01.example.com.</code></pre>
<h3>BIND9 DNS Server Setup</h3>
<pre><code class="language-bash"># 1. Install BIND9
sudo apt install -y bind9 bind9utils bind9-doc
<h1>2. Configure zone (/etc/bind/named.conf.local)</h1>
zone &quot;example.com&quot; {
    type master;
    file &quot;/etc/bind/zones/db.example.com&quot;;
};
<p>zone &quot;1.168.192.in-addr.arpa&quot; {
    type master;
    file &quot;/etc/bind/zones/db.192.168.1&quot;;
};</p>
<h1>3. Create forward zone (/etc/bind/zones/db.example.com)</h1>
cat &lt;&lt;EOF | sudo tee /etc/bind/zones/db.example.com
\$TTL    604800
@       IN      SOA     ns1.example.com. admin.example.com. (
                              3         ; Serial
                         604800         ; Refresh
                          86400         ; Retry
                        2419200         ; Expire
                         604800 )       ; Negative Cache TTL
;
@       IN      NS      ns1.example.com.
@       IN      A       192.168.1.10
ns1     IN      A       192.168.1.10
server01 IN     A       192.168.1.100
server02 IN     A       192.168.1.101
www     IN      CNAME   server01
api     IN      A       192.168.1.102
EOF
<h1>4. Create reverse zone (/etc/bind/zones/db.192.168.1)</h1>
cat &lt;&lt;EOF | sudo tee /etc/bind/zones/db.192.168.1
\$TTL    604800
@       IN      SOA     ns1.example.com. admin.example.com. (
                              3         ; Serial
                         604800         ; Refresh
                          86400         ; Retry
                        2419200         ; Expire
                         604800 )       ; Negative Cache TTL
;
@       IN      NS      ns1.example.com.
10      IN      PTR     ns1.example.com.
100     IN      PTR     server01.example.com.
101     IN      PTR     server02.example.com.
EOF
<h1>5. Check configuration</h1>
sudo named-checkconf
sudo named-checkzone example.com /etc/bind/zones/db.example.com
<h1>6. Restart BIND</h1>
sudo systemctl restart bind9
<h1>7. Test DNS</h1>
dig @localhost server01.example.com
nslookup server01.example.com localhost</code></pre>
<h3>/etc/hosts (Local DNS)</h3>
<pre><code class="language-bash"># /etc/hosts
127.0.0.1       localhost
192.168.1.100   server01.example.com server01
192.168.1.101   server02.example.com server02
192.168.1.102   api.example.com api
<h1>Test</h1>
ping server01
ping api.example.com</code></pre>
<p>---</p>
<h2>Static IP Configuration</h2>
<h3>Ubuntu/Debian (Netplan)</h3>
<pre><code class="language-yaml"># /etc/netplan/01-netcfg.yaml
network:
  version: 2
  renderer: networkd
  ethernets:
    ens18:
      dhcp4: no
      dhcp6: no
      addresses:
        - 192.168.1.100/24
      routes:
        - to: default
          via: 192.168.1.1
      nameservers:
        addresses:
          - 192.168.1.10    # Internal DNS
          - 8.8.8.8         # Google DNS
        search:
          - example.com
          - datacenter.example.com</code></pre>
<pre><code class="language-bash"># Apply
sudo netplan apply
<h1>Debug</h1>
sudo netplan --debug apply
sudo networkctl status</code></pre>
<h3>CentOS/RHEL (NetworkManager)</h3>
<pre><code class="language-bash"># /etc/sysconfig/network-scripts/ifcfg-eth0
TYPE=Ethernet
BOOTPROTO=static
NAME=eth0
DEVICE=eth0
ONBOOT=yes
IPADDR=192.168.1.100
NETMASK=255.255.255.0
GATEWAY=192.168.1.1
DNS1=8.8.8.8
DNS2=8.8.4.4
DOMAIN=example.com
<h1>Restart network</h1>
sudo systemctl restart NetworkManager</code></pre>
<h3>Cloud-Init (Cloud Servers)</h3>
<pre><code class="language-yaml"># /etc/cloud/cloud.cfg.d/99-custom-networking.cfg
network:
  version: 2
  ethernets:
    eth0:
      addresses:
        - 203.0.113.100/24
      routes:
        - to: default
          via: 203.0.113.1
      nameservers:
        addresses: [8.8.8.8, 8.8.4.4]
<h1>Disable cloud-init network config</h1>
echo &#039;network: {config: disabled}&#039; | sudo tee /etc/cloud/cloud.cfg.d/99-disable-network-config.cfg</code></pre>
<p>---</p>
<h2>OVA Deployment</h2>
<h3>What is OVA?</h3>
<strong>Open Virtualization Appliance</strong> - pre-configured VM image (OVF + VMDK).
<h3>Deploy OVA (VMware)</h3>
<pre><code class="language-bash"># 1. Download OVA
wget https://example.com/appliance.ova
<h1>2. Deploy via ovftool</h1>
ovftool \
  --name=&quot;MyAppliance&quot; \
  --datastore=&quot;datastore1&quot; \
  --network=&quot;VM Network&quot; \
  --powerOn \
  appliance.ova \
  vi://username@vcenter.example.com/datacenter/host/cluster
<h1>3. Or use vSphere Client</h1>
<h1>File ‚Üí Deploy OVF Template ‚Üí Select OVA ‚Üí Configure ‚Üí Finish</code></pre></h1>
<h3>Deploy OVA (VirtualBox)</h3>
<pre><code class="language-bash"># CLI
VBoxManage import appliance.ova \
  --vsys 0 \
  --vmname &quot;MyVM&quot; \
  --cpus 2 \
  --memory 4096
<h1>GUI: File ‚Üí Import Appliance</code></pre></h1>
<h3>Create OVA</h3>
<pre><code class="language-bash"># Export VM to OVA (VMware)
ovftool \
  --acceptAllEulas \
  vi://username@vcenter.example.com/datacenter/vm/MyVM \
  MyVM.ova
<h1>VirtualBox</h1>
VBoxManage export MyVM -o MyVM.ova</code></pre>
<p>---</p>
<h2>MicroK8s Setup</h2>
<h3>What is MicroK8s?</h3>
<strong>Lightweight Kubernetes</strong> - single-node or multi-node, perfect for edge/IoT/development.
<h3>Installation</h3>
<pre><code class="language-bash"># 1. Install MicroK8s (Ubuntu)
sudo snap install microk8s --classic --channel=1.28
<h1>2. Add user to group</h1>
sudo usermod -a -G microk8s $USER
sudo chown -R $USER ~/.kube
newgrp microk8s
<h1>3. Check status</h1>
microk8s status --wait-ready
<h1>4. Enable addons</h1>
microk8s enable dns storage ingress dashboard metrics-server
<h1>5. Alias kubectl</h1>
alias kubectl=&#039;microk8s kubectl&#039;
<h1>6. Get nodes</h1>
kubectl get nodes</code></pre>
<h3>Multi-Node Cluster</h3>
<pre><code class="language-bash"># On master node:
microk8s add-node
<h1>Output:</h1>
<h1>microk8s join 192.168.1.100:25000/abc123xyz</h1>
<h1>On worker nodes:</h1>
microk8s join 192.168.1.100:25000/abc123xyz
<h1>Verify cluster</h1>
kubectl get nodes</code></pre>
<h3>Configuration</h3>
<pre><code class="language-bash"># View kubeconfig
microk8s config
<h1>Export for external access</h1>
microk8s config &gt; ~/.kube/config
<h1>Enable HA (3+ nodes)</h1>
microk8s enable ha-cluster
<h1>Enable community addons</h1>
microk8s enable community
microk8s enable portainer
microk8s enable prometheus</code></pre>
<p>---</p>
<h2>Best Practices</h2>
<h3>1. Network Segmentation</h3>
<pre><code class="language-text">DMZ:          Public-facing servers (web)
Application:  Backend services
Database:     Data tier
Management:   Admin access (IPMI, SSH)</code></pre>
<h3>2. Security Hardening</h3>
<pre><code class="language-bash"># SSH hardening
sudo sed -i &#039;s/#PermitRootLogin yes/PermitRootLogin no/&#039; /etc/ssh/sshd_config
sudo sed -i &#039;s/#PasswordAuthentication yes/PasswordAuthentication no/&#039; /etc/ssh/sshd_config
<h1>Firewall</h1>
sudo ufw allow 22/tcp
sudo ufw allow 80/tcp
sudo ufw allow 443/tcp
sudo ufw enable
<h1>Fail2ban</h1>
sudo apt install -y fail2ban
sudo systemctl enable fail2ban</code></pre>
<h3>3. Monitoring & Logging</h3>
<pre><code class="language-bash"># Install monitoring agents
<h1>Prometheus Node Exporter</h1>
<h1>Telegraf</h1>
<h1>Filebeat</h1>
<h1>Centralized logging</h1>
<h1>ELK Stack</h1>
<h1>Loki + Promtail</code></pre></h1>
<h3>4. Backup & DR</h3>
<pre><code class="language-bash"># VM snapshots
<h1>Database backups</h1>
<h1>Configuration management (Ansible/Terraform)</h1>
<h1>Offsite backups</code></pre></h1>
<p>---</p>
<h2>Interview Questions</h2>
<strong>Q1: What's the difference between bare metal and virtual machines?</strong>
<strong>Answer:</strong> Bare metal is physical server with direct hardware access - better performance, no hypervisor overhead, but less flexible. VMs run on hypervisor, share physical resources, easier to provision/migrate, better utilization, but slight performance penalty.
<strong>Q2: Explain static IP vs DHCP.</strong>
<strong>Answer:</strong> 
<li>Static IP: Manually configured, doesn't change, used for servers/network devices</li>
<li>DHCP: Automatically assigned by DHCP server, can change, used for clients</li>
Servers need static IPs for predictable DNS/access.
<strong>Q3: What is an FQDN?</strong>
<strong>Answer:</strong> Fully Qualified Domain Name - complete domain name specifying exact location in DNS hierarchy. Example: server01.datacenter.example.com includes hostname (server01), subdomain (datacenter), domain (example), TLD (com).
<strong>Q4: Describe the purpose of reverse DNS (PTR records).</strong>
<strong>Answer:</strong> Maps IP address back to hostname. Used for: email validation (anti-spam), logging (readable hostnames), security auditing. Example: 192.168.1.100 ‚Üí server01.example.com.
<strong>Q5: When would you use an OVA?</strong>
<strong>Answer:</strong> Pre-configured appliances (vendor software like firewalls, routers), template VMs, disaster recovery images, rapid deployment scenarios. Faster than manual VM creation + OS installation + configuration.
<p>---</p>
<h2>Hands-On Exercise</h2>
<h3>Task: Complete Infrastructure Setup</h3>
<pre><code class="language-bash"># 1. Install Ubuntu Server VM
<h1>- Hostname: lab-server01</h1>
<h1>- IP: 192.168.1.100/24</h1>
<h1>- Gateway: 192.168.1.1</h1>
<h1>2. Configure static IP</h1>
sudo nano /etc/netplan/00-installer-config.yaml
<h1>(paste configuration from earlier)</h1>
sudo netplan apply
<h1>3. Set hostname</h1>
sudo hostnamectl set-hostname lab-server01.example.local
<h1>4. Update /etc/hosts</h1>
echo &quot;192.168.1.100 lab-server01.example.local lab-server01&quot; | sudo tee -a /etc/hosts
<h1>5. Install DNS tools</h1>
sudo apt install -y dnsutils net-tools
<h1>6. Test networking</h1>
ping -c 4 192.168.1.1
ping -c 4 google.com
dig google.com
<h1>7. Install MicroK8s</h1>
sudo snap install microk8s --classic
sudo usermod -a -G microk8s $USER
newgrp microk8s
<h1>8. Enable addons</h1>
microk8s enable dns storage ingress
<h1>9. Deploy test app</h1>
microk8s kubectl create deployment nginx --image=nginx
microk8s kubectl expose deployment nginx --port=80 --type=NodePort
<h1>10. Verify</h1>
microk8s kubectl get all
curl http://192.168.1.100:$(microk8s kubectl get svc nginx -o jsonpath=&#039;{.spec.ports[0].nodePort}&#039;)</code></pre>
<p>---</p>
<h2>üìö Additional Resources</h2>
<li>[Linux Networking](https://www.kernel.org/doc/html/latest/networking/index.html)</li>
<li>[BIND9 Documentation](https://bind9.readthedocs.io/)</li>
<li>[MicroK8s Documentation](https://microk8s.io/docs)</li>
<li>[VMware vSphere](https://docs.vmware.com/en/VMware-vSphere/)</li>
<p>---</p>
<h2>‚úÖ Module Checklist</h2>
<li>[ ] Understand bare metal vs virtualization</li>
<li>[ ] Configure static IP addressing</li>
<li>[ ] Set up DNS server and records</li>
<li>[ ] Create FQDN for services</li>
<li>[ ] Deploy OVA appliances</li>
<li>[ ] Install and configure MicroK8s</li>
<li>[ ] Complete infrastructure setup exercise</li></ul>
<p>---</p>
<strong>Next Module:</strong> [Module 13: Terraform - Infrastructure as Code](./13_Terraform_IaC.md) - Automate infrastructure provisioning! ‚ö°

    </div>
    

    <div class="module-content" id="module-13">
        <h1>Module 13: Terraform - Infrastructure as Code üèóÔ∏è</h1>
<h2>Automate Infrastructure Provisioning with Terraform</h2>
<strong>Duration:</strong> 5-6 hours  
<strong>Prerequisites:</strong> Module 12 (Infrastructure Basics), Cloud provider account (AWS/GCP/Azure)  
<strong>Outcome:</strong> Master Terraform for declarative infrastructure management
<p>---</p>
<h2>üìö Table of Contents</h2>
<p>1. [What is Terraform](#what-is-terraform)
2. [HCL Syntax](#hcl-syntax)
3. [Providers](#providers)
4. [Resources & Data Sources](#resources--data-sources)
5. [Variables & Outputs](#variables--outputs)
6. [State Management](#state-management)
7. [Modules](#modules)
8. [Workspaces](#workspaces)
9. [Best Practices](#best-practices)
10. [Interview Questions](#interview-questions)
11. [Hands-On Exercise](#hands-on-exercise)</p>
<p>---</p>
<h2>What is Terraform</h2>
<h3>Infrastructure as Code (IaC)</h3>
<pre><code class="language-text">Traditional Infrastructure:
<ul><li>Manual configuration</li>
<li>Click through UI</li>
<li>Hard to replicate</li>
<li>No version control</li>
<li>Error-prone</li>
<p>Infrastructure as Code:
<li>Declarative configuration</li>
<li>Version controlled</li>
<li>Repeatable</li>
<li>Auditable</li>
<li>Automated</code></pre></li></p>
<h3>Terraform Workflow</h3>
<pre><code class="language-text">1. Write      ‚Üí Define infrastructure in .tf files
2. Init       ‚Üí terraform init (download providers)
3. Plan       ‚Üí terraform plan (preview changes)
4. Apply      ‚Üí terraform apply (create resources)
5. Destroy    ‚Üí terraform destroy (clean up)</code></pre>
<h3>Installation</h3>
<pre><code class="language-bash"># macOS
brew tap hashicorp/tap
brew install hashicorp/tap/terraform
<h1>Ubuntu/Debian</h1>
wget -O- https://apt.releases.hashicorp.com/gpg | sudo gpg --dearmor -o /usr/share/keyrings/hashicorp-archive-keyring.gpg
echo &quot;deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(lsb_release -cs) main&quot; | sudo tee /etc/apt/sources.list.d/hashicorp.list
sudo apt update &amp;&amp; sudo apt install terraform
<h1>Verify</h1>
terraform version</code></pre>
<p>---</p>
<h2>HCL Syntax</h2>
<h3>HashiCorp Configuration Language</h3>
<pre><code class="language-hcl"># Basic structure
&lt;block_type&gt; &quot;&lt;label&gt;&quot; &quot;&lt;label&gt;&quot; {
  argument1 = value1
  argument2 = value2
  
  nested_block {
    argument = value
  }
}</code></pre>
<h3>Example: EC2 Instance</h3>
<pre><code class="language-hcl">resource &quot;aws_instance&quot; &quot;web&quot; {
  ami           = &quot;ami-0c55b159cbfafe1f0&quot;
  instance_type = &quot;t2.micro&quot;
  
  tags = {
    Name = &quot;WebServer&quot;
    Environment = &quot;Production&quot;
  }
}</code></pre>
<h3>Data Types</h3>
<pre><code class="language-hcl"># String
variable &quot;region&quot; {
  type    = string
  default = &quot;us-west-2&quot;
}
<h1>Number</h1>
variable &quot;instance_count&quot; {
  type    = number
  default = 3
}
<h1>Bool</h1>
variable &quot;enable_monitoring&quot; {
  type    = bool
  default = true
}
<h1>List</h1>
variable &quot;availability_zones&quot; {
  type    = list(string)
  default = [&quot;us-west-2a&quot;, &quot;us-west-2b&quot;]
}
<h1>Map</h1>
variable &quot;instance_types&quot; {
  type = map(string)
  default = {
    dev  = &quot;t2.micro&quot;
    prod = &quot;t2.large&quot;
  }
}
<h1>Object</h1>
variable &quot;server_config&quot; {
  type = object({
    name = string
    cpu  = number
    memory = number
  })
}
<h1>Set (unique values)</h1>
variable &quot;security_groups&quot; {
  type = set(string)
}</code></pre>
<h3>Expressions</h3>
<pre><code class="language-hcl"># String interpolation
name = &quot;server-${var.environment}&quot;
<h1>Conditionals</h1>
instance_type = var.environment == &quot;prod&quot; ? &quot;t2.large&quot; : &quot;t2.micro&quot;
<h1>For expressions</h1>
subnet_ids = [for s in var.subnets : s.id]
<h1>Splat</h1>
instance_ids = aws_instance.web[*].id</code></pre>
<p>---</p>
<h2>Providers</h2>
<h3>What are Providers?</h3>
<strong>Providers</strong> are plugins that interact with cloud APIs (AWS, Azure, GCP) or services (GitHub, Datadog).
<h3>Configure AWS Provider</h3>
<pre><code class="language-hcl"># main.tf
terraform {
  required_version = &quot;&gt;= 1.5&quot;
  
  required_providers {
    aws = {
      source  = &quot;hashicorp/aws&quot;
      version = &quot;~&gt; 5.0&quot;
    }
  }
}
<p>provider &quot;aws&quot; {
  region  = &quot;us-west-2&quot;
  profile = &quot;default&quot;  # AWS CLI profile
  
  default_tags {
    tags = {
      ManagedBy   = &quot;Terraform&quot;
      Environment = var.environment
    }
  }
}</code></pre></p>
<h3>Multiple Provider Configurations</h3>
<pre><code class="language-hcl"># Primary region
provider &quot;aws&quot; {
  region = &quot;us-west-2&quot;
}
<h1>Disaster recovery region</h1>
provider &quot;aws&quot; {
  alias  = &quot;dr&quot;
  region = &quot;us-east-1&quot;
}
<h1>Use alias</h1>
resource &quot;aws_instance&quot; &quot;web&quot; {
  provider = aws.dr
  ami      = &quot;ami-12345678&quot;
  instance_type = &quot;t2.micro&quot;
}</code></pre>
<h3>Popular Providers</h3>
<pre><code class="language-hcl"># Google Cloud
provider &quot;google&quot; {
  project = &quot;my-project&quot;
  region  = &quot;us-central1&quot;
}
<h1>Azure</h1>
provider &quot;azurerm&quot; {
  features {}
  subscription_id = &quot;xxx&quot;
}
<h1>Kubernetes</h1>
provider &quot;kubernetes&quot; {
  config_path = &quot;~/.kube/config&quot;
}
<h1>GitHub</h1>
provider &quot;github&quot; {
  token = var.github_token
  owner = &quot;my-org&quot;
}</code></pre>
<p>---</p>
<h2>Resources & Data Sources</h2>
<h3>Resources (Create/Manage)</h3>
<pre><code class="language-hcl"># VPC
resource &quot;aws_vpc&quot; &quot;main&quot; {
  cidr_block           = &quot;10.0.0.0/16&quot;
  enable_dns_hostnames = true
  enable_dns_support   = true
  
  tags = {
    Name = &quot;main-vpc&quot;
  }
}
<h1>Subnet</h1>
resource &quot;aws_subnet&quot; &quot;public&quot; {
  vpc_id                  = aws_vpc.main.id  # Reference
  cidr_block              = &quot;10.0.1.0/24&quot;
  availability_zone       = &quot;us-west-2a&quot;
  map_public_ip_on_launch = true
  
  tags = {
    Name = &quot;public-subnet&quot;
  }
}
<h1>Internet Gateway</h1>
resource &quot;aws_internet_gateway&quot; &quot;main&quot; {
  vpc_id = aws_vpc.main.id
}
<h1>Route Table</h1>
resource &quot;aws_route_table&quot; &quot;public&quot; {
  vpc_id = aws_vpc.main.id
  
  route {
    cidr_block = &quot;0.0.0.0/0&quot;
    gateway_id = aws_internet_gateway.main.id
  }
}
<h1>Route Table Association</h1>
resource &quot;aws_route_table_association&quot; &quot;public&quot; {
  subnet_id      = aws_subnet.public.id
  route_table_id = aws_route_table.public.id
}
<h1>Security Group</h1>
resource &quot;aws_security_group&quot; &quot;web&quot; {
  name        = &quot;web-sg&quot;
  description = &quot;Security group for web servers&quot;
  vpc_id      = aws_vpc.main.id
  
  ingress {
    description = &quot;HTTP&quot;
    from_port   = 80
    to_port     = 80
    protocol    = &quot;tcp&quot;
    cidr_blocks = [&quot;0.0.0.0/0&quot;]
  }
  
  ingress {
    description = &quot;HTTPS&quot;
    from_port   = 443
    to_port     = 443
    protocol    = &quot;tcp&quot;
    cidr_blocks = [&quot;0.0.0.0/0&quot;]
  }
  
  egress {
    from_port   = 0
    to_port     = 0
    protocol    = &quot;-1&quot;
    cidr_blocks = [&quot;0.0.0.0/0&quot;]
  }
}
<h1>EC2 Instance</h1>
resource &quot;aws_instance&quot; &quot;web&quot; {
  ami                    = &quot;ami-0c55b159cbfafe1f0&quot;
  instance_type          = &quot;t2.micro&quot;
  subnet_id              = aws_subnet.public.id
  vpc_security_group_ids = [aws_security_group.web.id]
  
  user_data = &lt;&lt;-EOF
              #!/bin/bash
              yum update -y
              yum install -y httpd
              systemctl start httpd
              systemctl enable httpd
              echo &quot;Hello from Terraform&quot; &gt; /var/www/html/index.html
              EOF
  
  tags = {
    Name = &quot;web-server&quot;
  }
}</code></pre>
<h3>Data Sources (Read Existing)</h3>
<pre><code class="language-hcl"># Get latest Amazon Linux 2 AMI
data &quot;aws_ami&quot; &quot;amazon_linux&quot; {
  most_recent = true
  owners      = [&quot;amazon&quot;]
  
  filter {
    name   = &quot;name&quot;
    values = [&quot;amzn2-ami-hvm-*-x86_64-gp2&quot;]
  }
}
<h1>Use data source</h1>
resource &quot;aws_instance&quot; &quot;web&quot; {
  ami           = data.aws_ami.amazon_linux.id
  instance_type = &quot;t2.micro&quot;
}
<h1>Get existing VPC</h1>
data &quot;aws_vpc&quot; &quot;default&quot; {
  default = true
}
<h1>Get availability zones</h1>
data &quot;aws_availability_zones&quot; &quot;available&quot; {
  state = &quot;available&quot;
}
<h1>Get caller identity</h1>
data &quot;aws_caller_identity&quot; &quot;current&quot; {}
<p>output &quot;account_id&quot; {
  value = data.aws_caller_identity.current.account_id
}</code></pre></p>
<h3>Count & For_Each</h3>
<pre><code class="language-hcl"># Count (for identical resources)
resource &quot;aws_instance&quot; &quot;web&quot; {
  count         = 3
  ami           = &quot;ami-0c55b159cbfafe1f0&quot;
  instance_type = &quot;t2.micro&quot;
  
  tags = {
    Name = &quot;web-${count.index}&quot;
  }
}
<h1>Reference</h1>
output &quot;instance_ips&quot; {
  value = aws_instance.web[*].private_ip
}
<h1>For_each (for unique resources)</h1>
variable &quot;users&quot; {
  type = map(string)
  default = {
    admin = &quot;Administrator&quot;
    dev   = &quot;Developer&quot;
    ops   = &quot;Operations&quot;
  }
}
<p>resource &quot;aws_iam_user&quot; &quot;users&quot; {
  for_each = var.users
  name     = each.key
  
  tags = {
    Role = each.value
  }
}</p>
<h1>Reference</h1>
output &quot;user_arns&quot; {
  value = { for k, v in aws_iam_user.users : k =&gt; v.arn }
}</code></pre>
<p>---</p>
<h2>Variables & Outputs</h2>
<h3>Input Variables</h3>
<pre><code class="language-hcl"># variables.tf
variable &quot;region&quot; {
  description = &quot;AWS region&quot;
  type        = string
  default     = &quot;us-west-2&quot;
}
<p>variable &quot;instance_count&quot; {
  description = &quot;Number of instances&quot;
  type        = number
  default     = 2
  
  validation {
    condition     = var.instance_count &gt;= 1 &amp;&amp; var.instance_count &lt;= 10
    error_message = &quot;Instance count must be between 1 and 10&quot;
  }
}</p>
<p>variable &quot;environment&quot; {
  description = &quot;Environment name&quot;
  type        = string
  
  validation {
    condition     = contains([&quot;dev&quot;, &quot;staging&quot;, &quot;prod&quot;], var.environment)
    error_message = &quot;Environment must be dev, staging, or prod&quot;
  }
}</p>
<p>variable &quot;enable_monitoring&quot; {
  description = &quot;Enable CloudWatch monitoring&quot;
  type        = bool
  default     = true
}</p>
<p>variable &quot;tags&quot; {
  description = &quot;Common tags&quot;
  type        = map(string)
  default     = {}
}</code></pre></p>
<h3>Variable Precedence</h3>
<pre><code class="language-text">1. Command line (-var, -var-file)
2. *.auto.tfvars files
3. terraform.tfvars
4. Environment variables (TF_VAR_*)
5. Default values</code></pre>
<h3>terraform.tfvars</h3>
<pre><code class="language-hcl"># terraform.tfvars
region          = &quot;us-east-1&quot;
instance_count  = 3
environment     = &quot;prod&quot;
enable_monitoring = true
<p>tags = {
  Project = &quot;WebApp&quot;
  Owner   = &quot;DevOps&quot;
}</code></pre></p>
<h3>Output Values</h3>
<pre><code class="language-hcl"># outputs.tf
output &quot;vpc_id&quot; {
  description = &quot;VPC ID&quot;
  value       = aws_vpc.main.id
}
<p>output &quot;instance_ips&quot; {
  description = &quot;Public IPs of instances&quot;
  value       = aws_instance.web[*].public_ip
}</p>
<p>output &quot;security_group_id&quot; {
  description = &quot;Security group ID&quot;
  value       = aws_security_group.web.id
  sensitive   = true
}</p>
<p>output &quot;connection_string&quot; {
  value = &quot;http://${aws_instance.web[0].public_ip}&quot;
}</code></pre></p>
<p>---</p>
<h2>State Management</h2>
<h3>What is State?</h3>
<strong>State file</strong> (<code>terraform.tfstate</code>) tracks resources Terraform manages. Maps configuration to real infrastructure.
<h3>Local State</h3>
<pre><code class="language-hcl"># Default: stored locally
<h1>terraform.tfstate in current directory</h1>
<h1>View state</h1>
terraform show
<h1>List resources</h1>
terraform state list
<h1>Show specific resource</h1>
terraform state show aws_instance.web</code></pre>
<h3>Remote State (S3 Backend)</h3>
<pre><code class="language-hcl"># backend.tf
terraform {
  backend &quot;s3&quot; {
    bucket         = &quot;my-terraform-state&quot;
    key            = &quot;prod/terraform.tfstate&quot;
    region         = &quot;us-west-2&quot;
    encrypt        = true
    dynamodb_table = &quot;terraform-locks&quot;  # State locking
  }
}</code></pre>
<h3>State Locking (DynamoDB)</h3>
<pre><code class="language-hcl"># Create DynamoDB table for locking
resource &quot;aws_dynamodb_table&quot; &quot;terraform_locks&quot; {
  name         = &quot;terraform-locks&quot;
  billing_mode = &quot;PAY_PER_REQUEST&quot;
  hash_key     = &quot;LockID&quot;
  
  attribute {
    name = &quot;LockID&quot;
    type = &quot;S&quot;
  }
}</code></pre>
<h3>State Commands</h3>
<pre><code class="language-bash"># Initialize backend
terraform init -migrate-state
<h1>Pull remote state</h1>
terraform state pull
<h1>Push local state</h1>
terraform state push terraform.tfstate
<h1>Move resource</h1>
terraform state mv aws_instance.web aws_instance.web_server
<h1>Remove resource from state (doesn&#039;t destroy)</h1>
terraform state rm aws_instance.old
<h1>Import existing resource</h1>
terraform import aws_instance.web i-1234567890abcdef0</code></pre>
<p>---</p>
<h2>Modules</h2>
<h3>What are Modules?</h3>
<strong>Modules</strong> are reusable Terraform configurations. Package infrastructure patterns.
<h3>Module Structure</h3>
<pre><code class="language-text">modules/
‚îî‚îÄ‚îÄ vpc/
    ‚îú‚îÄ‚îÄ main.tf
    ‚îú‚îÄ‚îÄ variables.tf
    ‚îú‚îÄ‚îÄ outputs.tf
    ‚îî‚îÄ‚îÄ README.md</code></pre>
<h3>Create VPC Module</h3>
<pre><code class="language-hcl"># modules/vpc/variables.tf
variable &quot;cidr_block&quot; {
  description = &quot;VPC CIDR block&quot;
  type        = string
}
<p>variable &quot;name&quot; {
  description = &quot;VPC name&quot;
  type        = string
}</p>
<p>variable &quot;availability_zones&quot; {
  description = &quot;Availability zones&quot;
  type        = list(string)
}</p>
<h1>modules/vpc/main.tf</h1>
resource &quot;aws_vpc&quot; &quot;this&quot; {
  cidr_block           = var.cidr_block
  enable_dns_hostnames = true
  enable_dns_support   = true
  
  tags = {
    Name = var.name
  }
}
<p>resource &quot;aws_subnet&quot; &quot;public&quot; {
  count             = length(var.availability_zones)
  vpc_id            = aws_vpc.this.id
  cidr_block        = cidrsubnet(var.cidr_block, 8, count.index)
  availability_zone = var.availability_zones[count.index]
  
  map_public_ip_on_launch = true
  
  tags = {
    Name = &quot;${var.name}-public-${count.index + 1}&quot;
  }
}</p>
<p>resource &quot;aws_internet_gateway&quot; &quot;this&quot; {
  vpc_id = aws_vpc.this.id
}</p>
<h1>modules/vpc/outputs.tf</h1>
output &quot;vpc_id&quot; {
  value = aws_vpc.this.id
}
<p>output &quot;public_subnet_ids&quot; {
  value = aws_subnet.public[*].id
}</code></pre></p>
<h3>Use Module</h3>
<pre><code class="language-hcl"># main.tf
module &quot;vpc&quot; {
  source = &quot;./modules/vpc&quot;
  
  cidr_block         = &quot;10.0.0.0/16&quot;
  name               = &quot;main-vpc&quot;
  availability_zones = [&quot;us-west-2a&quot;, &quot;us-west-2b&quot;]
}
<h1>Reference module outputs</h1>
resource &quot;aws_instance&quot; &quot;web&quot; {
  subnet_id = module.vpc.public_subnet_ids[0]
  # ...
}</code></pre>
<h3>Terraform Registry Modules</h3>
<pre><code class="language-hcl"># Use public module from registry
module &quot;vpc&quot; {
  source  = &quot;terraform-aws-modules/vpc/aws&quot;
  version = &quot;5.1.2&quot;
  
  name = &quot;my-vpc&quot;
  cidr = &quot;10.0.0.0/16&quot;
  
  azs             = [&quot;us-west-2a&quot;, &quot;us-west-2b&quot;]
  private_subnets = [&quot;10.0.1.0/24&quot;, &quot;10.0.2.0/24&quot;]
  public_subnets  = [&quot;10.0.101.0/24&quot;, &quot;10.0.102.0/24&quot;]
  
  enable_nat_gateway = true
  enable_vpn_gateway = false
}</code></pre>
<p>---</p>
<h2>Workspaces</h2>
<h3>What are Workspaces?</h3>
<strong>Workspaces</strong> allow multiple state files for same configuration (dev/staging/prod).
<h3>Workspace Commands</h3>
<pre><code class="language-bash"># List workspaces
terraform workspace list
<h1>Create workspace</h1>
terraform workspace new dev
terraform workspace new staging
terraform workspace new prod
<h1>Switch workspace</h1>
terraform workspace select dev
<h1>Show current workspace</h1>
terraform workspace show
<h1>Delete workspace</h1>
terraform workspace delete staging</code></pre>
<h3>Use Workspace in Configuration</h3>
<pre><code class="language-hcl"># Different instance types per workspace
locals {
  instance_type = {
    dev     = &quot;t2.micro&quot;
    staging = &quot;t2.small&quot;
    prod    = &quot;t2.large&quot;
  }
}
<p>resource &quot;aws_instance&quot; &quot;web&quot; {
  ami           = &quot;ami-0c55b159cbfafe1f0&quot;
  instance_type = local.instance_type[terraform.workspace]
  
  tags = {
    Name        = &quot;web-${terraform.workspace}&quot;
    Environment = terraform.workspace
  }
}</code></pre></p>
<p>---</p>
<h2>Best Practices</h2>
<h3>1. Project Structure</h3>
<pre><code class="language-text">terraform-project/
‚îú‚îÄ‚îÄ main.tf              # Main configuration
‚îú‚îÄ‚îÄ variables.tf         # Input variables
‚îú‚îÄ‚îÄ outputs.tf           # Output values
‚îú‚îÄ‚îÄ providers.tf         # Provider configuration
‚îú‚îÄ‚îÄ backend.tf           # Backend configuration
‚îú‚îÄ‚îÄ terraform.tfvars     # Variable values
‚îú‚îÄ‚îÄ modules/             # Reusable modules
‚îÇ   ‚îú‚îÄ‚îÄ vpc/
‚îÇ   ‚îú‚îÄ‚îÄ ec2/
‚îÇ   ‚îî‚îÄ‚îÄ rds/
‚îî‚îÄ‚îÄ environments/        # Environment-specific
    ‚îú‚îÄ‚îÄ dev/
    ‚îÇ   ‚îú‚îÄ‚îÄ main.tf
    ‚îÇ   ‚îî‚îÄ‚îÄ terraform.tfvars
    ‚îî‚îÄ‚îÄ prod/
        ‚îú‚îÄ‚îÄ main.tf
        ‚îî‚îÄ‚îÄ terraform.tfvars</code></pre>
<h3>2. Naming Conventions</h3>
<pre><code class="language-hcl"># Resources: resource_type
aws_instance.web_server
aws_db_instance.postgres_main
<h1>Variables: descriptive, lowercase, underscores</h1>
variable &quot;instance_count&quot; {}
variable &quot;db_password&quot; {}
<h1>Outputs: descriptive</h1>
output &quot;vpc_id&quot; {}
output &quot;instance_public_ips&quot; {}</code></pre>
<h3>3. Version Constraints</h3>
<pre><code class="language-hcl">terraform {
  required_version = &quot;&gt;= 1.5.0&quot;
  
  required_providers {
    aws = {
      source  = &quot;hashicorp/aws&quot;
      version = &quot;~&gt; 5.0&quot;  # &gt;= 5.0.0, &lt; 6.0.0
    }
  }
}</code></pre>
<h3>4. State Management</h3>
<pre><code class="language-text">‚úÖ Use remote backend (S3, Terraform Cloud)
‚úÖ Enable state locking (DynamoDB)
‚úÖ Encrypt state at rest
‚úÖ Never commit state files to Git
‚úÖ Use .gitignore</code></pre>
<h3>5. Sensitive Data</h3>
<pre><code class="language-hcl"># Mark sensitive
variable &quot;db_password&quot; {
  type      = string
  sensitive = true
}
<h1>Use environment variables</h1>
export TF_VAR_db_password=&quot;secretpassword&quot;
<h1>Or use secrets management</h1>
data &quot;aws_secretsmanager_secret_version&quot; &quot;db_password&quot; {
  secret_id = &quot;prod/db/password&quot;
}</code></pre>
<p>---</p>
<h2>Interview Questions</h2>
<strong>Q1: What is Terraform state and why is it important?</strong>
<strong>Answer:</strong> State file maps Terraform configuration to real infrastructure. Contains resource metadata, dependencies, outputs. Critical for:
<li>Tracking what Terraform manages</li>
<li>Planning changes (comparing desired vs current)</li>
<li>Metadata (resource IDs, dependencies)</li>
<li>Performance (caching attributes)</li>
Should use remote backend for team collaboration and locking.
<strong>Q2: Explain the difference between <code>count</code> and <code>for_each</code>.</strong>
<strong>Answer:</strong>
<li><code>count</code>: Creates multiple identical resources, indexed numerically (0, 1, 2...). If you remove middle item, Terraform recreates subsequent resources.</li>
<li><code>for_each</code>: Creates resources keyed by map/set. More stable - removing item doesn't affect others. Better for managing diverse resources.</li>
<strong>Q3: How do you handle secrets in Terraform?</strong>
<strong>Answer:</strong>
1. Never hardcode in .tf files
2. Use environment variables (<code>TF_VAR_*</code>)
3. External secrets management (AWS Secrets Manager, Vault)
4. Mark variables as <code>sensitive = true</code>
5. Use .gitignore for .tfvars files
6. Encrypt remote state
<strong>Q4: What are Terraform modules and when would you use them?</strong>
<strong>Answer:</strong> Modules are reusable Terraform configurations. Use for:
<li>Encapsulating patterns (VPC setup, EKS cluster)</li>
<li>DRY principle (don't repeat yourself)</li>
<li>Standardization across teams</li>
<li>Versioning infrastructure patterns</li>
<li>Sharing via Terraform Registry</li>
<strong>Q5: How does Terraform handle dependencies?</strong>
<strong>Answer:</strong> 
<li><strong>Implicit</strong>: Referencing resource attributes (e.g., <code>aws_vpc.main.id</code>)</li>
<li><strong>Explicit</strong>: <code>depends_on</code> meta-argument</li>
<li>Terraform builds dependency graph, applies in correct order</li>
<li>Destroys in reverse order</li>
<p>---</p>
<h2>Hands-On Exercise</h2>
<h3>Task: Deploy 3-Tier AWS Infrastructure</h3>
<pre><code class="language-hcl"># main.tf
terraform {
  required_version = &quot;&gt;= 1.5&quot;
  required_providers {
    aws = {
      source  = &quot;hashicorp/aws&quot;
      version = &quot;~&gt; 5.0&quot;
    }
  }
}
<p>provider &quot;aws&quot; {
  region = var.region
}</p>
<h1>VPC</h1>
resource &quot;aws_vpc&quot; &quot;main&quot; {
  cidr_block           = var.vpc_cidr
  enable_dns_hostnames = true
  
  tags = {
    Name = &quot;${var.project_name}-vpc&quot;
  }
}
<h1>Public Subnet</h1>
resource &quot;aws_subnet&quot; &quot;public&quot; {
  count                   = 2
  vpc_id                  = aws_vpc.main.id
  cidr_block              = cidrsubnet(var.vpc_cidr, 8, count.index)
  availability_zone       = data.aws_availability_zones.available.names[count.index]
  map_public_ip_on_launch = true
  
  tags = {
    Name = &quot;${var.project_name}-public-${count.index + 1}&quot;
  }
}
<h1>Private Subnet</h1>
resource &quot;aws_subnet&quot; &quot;private&quot; {
  count             = 2
  vpc_id            = aws_vpc.main.id
  cidr_block        = cidrsubnet(var.vpc_cidr, 8, count.index + 10)
  availability_zone = data.aws_availability_zones.available.names[count.index]
  
  tags = {
    Name = &quot;${var.project_name}-private-${count.index + 1}&quot;
  }
}
<h1>Internet Gateway</h1>
resource &quot;aws_internet_gateway&quot; &quot;main&quot; {
  vpc_id = aws_vpc.main.id
}
<h1>NAT Gateway</h1>
resource &quot;aws_eip&quot; &quot;nat&quot; {
  domain = &quot;vpc&quot;
}
<p>resource &quot;aws_nat_gateway&quot; &quot;main&quot; {
  allocation_id = aws_eip.nat.id
  subnet_id     = aws_subnet.public[0].id
}</p>
<h1>Route Tables</h1>
resource &quot;aws_route_table&quot; &quot;public&quot; {
  vpc_id = aws_vpc.main.id
  
  route {
    cidr_block = &quot;0.0.0.0/0&quot;
    gateway_id = aws_internet_gateway.main.id
  }
}
<p>resource &quot;aws_route_table_association&quot; &quot;public&quot; {
  count          = 2
  subnet_id      = aws_subnet.public[count.index].id
  route_table_id = aws_route_table.public.id
}</p>
<h1>Web Tier Security Group</h1>
resource &quot;aws_security_group&quot; &quot;web&quot; {
  name   = &quot;${var.project_name}-web-sg&quot;
  vpc_id = aws_vpc.main.id
  
  ingress {
    from_port   = 80
    to_port     = 80
    protocol    = &quot;tcp&quot;
    cidr_blocks = [&quot;0.0.0.0/0&quot;]
  }
  
  egress {
    from_port   = 0
    to_port     = 0
    protocol    = &quot;-1&quot;
    cidr_blocks = [&quot;0.0.0.0/0&quot;]
  }
}
<h1>Web Servers</h1>
resource &quot;aws_instance&quot; &quot;web&quot; {
  count                  = 2
  ami                    = data.aws_ami.amazon_linux.id
  instance_type          = var.instance_type
  subnet_id              = aws_subnet.public[count.index].id
  vpc_security_group_ids = [aws_security_group.web.id]
  
  user_data = &lt;&lt;-EOF
              #!/bin/bash
              yum update -y
              yum install -y httpd
              systemctl start httpd
              echo &quot;Web Server ${count.index + 1}&quot; &gt; /var/www/html/index.html
              EOF
  
  tags = {
    Name = &quot;${var.project_name}-web-${count.index + 1}&quot;
  }
}
<h1>Data Sources</h1>
data &quot;aws_availability_zones&quot; &quot;available&quot; {
  state = &quot;available&quot;
}
<p>data &quot;aws_ami&quot; &quot;amazon_linux&quot; {
  most_recent = true
  owners      = [&quot;amazon&quot;]
  
  filter {
    name   = &quot;name&quot;
    values = [&quot;amzn2-ami-hvm-*-x86_64-gp2&quot;]
  }
}</p>
<h1>variables.tf</h1>
variable &quot;region&quot; {
  default = &quot;us-west-2&quot;
}
<p>variable &quot;project_name&quot; {
  default = &quot;my-app&quot;
}</p>
<p>variable &quot;vpc_cidr&quot; {
  default = &quot;10.0.0.0/16&quot;
}</p>
<p>variable &quot;instance_type&quot; {
  default = &quot;t2.micro&quot;
}</p>
<h1>outputs.tf</h1>
output &quot;vpc_id&quot; {
  value = aws_vpc.main.id
}
<p>output &quot;web_server_ips&quot; {
  value = aws_instance.web[*].public_ip
}</code></pre></p>
<h3>Deploy</h3>
<pre><code class="language-bash"># Initialize
terraform init
<h1>Validate</h1>
terraform validate
<h1>Plan</h1>
terraform plan
<h1>Apply</h1>
terraform apply -auto-approve
<h1>Test</h1>
curl http://$(terraform output -raw web_server_ips | jq -r &#039;.[0]&#039;)
<h1>Destroy</h1>
terraform destroy -auto-approve</code></pre>
<p>---</p>
<h2>üìö Additional Resources</h2>
<li>[Terraform Documentation](https://www.terraform.io/docs)</li>
<li>[Terraform Registry](https://registry.terraform.io/)</li>
<li>[AWS Provider Docs](https://registry.terraform.io/providers/hashicorp/aws/latest/docs)</li>
<li>[Terraform Best Practices](https://www.terraform-best-practices.com/)</li>
<p>---</p>
<h2>‚úÖ Module Checklist</h2>
<li>[ ] Understand IaC principles</li>
<li>[ ] Master HCL syntax</li>
<li>[ ] Configure providers</li>
<li>[ ] Create resources and data sources</li>
<li>[ ] Use variables and outputs</li>
<li>[ ] Manage state with remote backend</li>
<li>[ ] Build reusable modules</li>
<li>[ ] Use workspaces for environments</li>
<li>[ ] Complete 3-tier infrastructure exercise</li></ul>
<p>---</p>
<strong>Next Module:</strong> [Module 14: Ansible - Configuration Management](./14_Ansible_Configuration_Management.md) - Automate server configuration! üîß

    </div>
    

    <div class="module-content" id="module-14">
        <h1>Module 14: Ansible - Configuration Management üîß</h1>
<h2>Automate Server Configuration with Ansible</h2>
<strong>Duration:</strong> 4-5 hours  
<strong>Prerequisites:</strong> Module 12 (Infrastructure), Linux basics, SSH  
<strong>Outcome:</strong> Master Ansible for infrastructure automation and configuration management
<p>---</p>
<h2>üìö Table of Contents</h2>
<p>1. [What is Ansible](#what-is-ansible)
2. [Installation & Setup](#installation--setup)
3. [Inventory](#inventory)
4. [Ad-Hoc Commands](#ad-hoc-commands)
5. [Playbooks](#playbooks)
6. [Roles](#roles)
7. [Variables & Facts](#variables--facts)
8. [Handlers & Templates](#handlers--templates)
9. [Ansible Galaxy](#ansible-galaxy)
10. [Best Practices](#best-practices)
11. [Interview Questions](#interview-questions)
12. [Hands-On Exercise](#hands-on-exercise)</p>
<p>---</p>
<h2>What is Ansible</h2>
<h3>Configuration Management</h3>
<pre><code class="language-text">Manual Configuration:
<ul><li>SSH to each server</li>
<li>Run commands manually</li>
<li>No version control</li>
<li>Hard to scale</li>
<li>Error-prone</li>
<p>Ansible:
<li>Agentless (SSH-based)</li>
<li>Declarative (YAML)</li>
<li>Idempotent (safe to re-run)</li>
<li>Version controlled</li>
<li>Scalable</code></pre></li></p>
<h3>Key Concepts</h3>
<pre><code class="language-yaml">Control Node:   Where Ansible runs (your laptop, CI/CD)
Managed Nodes:  Servers Ansible configures
Inventory:      List of managed nodes
Playbook:       YAML file defining automation
Task:           Single action (install package, copy file)
Module:         Code that executes tasks
Role:           Reusable collection of tasks</code></pre>
<h3>Ansible vs Alternatives</h3>
<pre><code class="language-text">Ansible:     Agentless, Python, push-based
Puppet:      Agent-based, Ruby, pull-based
Chef:        Agent-based, Ruby, pull-based
SaltStack:   Agent/agentless, Python, push/pull
Terraform:   Infrastructure provisioning (IaC)</code></pre>
<p>---</p>
<h2>Installation & Setup</h2>
<h3>Install Ansible</h3>
<pre><code class="language-bash"># macOS
brew install ansible
<h1>Ubuntu/Debian</h1>
sudo apt update
sudo apt install -y software-properties-common
sudo add-apt-repository --yes --update ppa:ansible/ansible
sudo apt install -y ansible
<h1>RHEL/CentOS</h1>
sudo yum install -y ansible
<h1>Python pip</h1>
pip install ansible
<h1>Verify</h1>
ansible --version</code></pre>
<h3>SSH Key Setup</h3>
<pre><code class="language-bash"># Generate SSH key (if not exists)
ssh-keygen -t ed25519 -C &quot;ansible&quot;
<h1>Copy to managed nodes</h1>
ssh-copy-id user@server1.example.com
ssh-copy-id user@server2.example.com
<h1>Test connection</h1>
ssh user@server1.example.com</code></pre>
<h3>Ansible Configuration</h3>
<pre><code class="language-ini"># /etc/ansible/ansible.cfg or ~/.ansible.cfg or ./ansible.cfg
[defaults]
inventory = ./inventory
host_key_checking = False
remote_user = ubuntu
private_key_file = ~/.ssh/id_ed25519
retry_files_enabled = False
gathering = smart
fact_caching = jsonfile
fact_caching_connection = /tmp/ansible_facts
fact_caching_timeout = 3600
<p>[privilege_escalation]
become = True
become_method = sudo
become_user = root
become_ask_pass = False</code></pre></p>
<p>---</p>
<h2>Inventory</h2>
<h3>Static Inventory (INI format)</h3>
<pre><code class="language-ini"># inventory/hosts
[web]
web1.example.com
web2.example.com ansible_host=192.168.1.101
<p>[db]
db1.example.com ansible_host=192.168.1.201
db2.example.com ansible_host=192.168.1.202</p>
<p>[app:children]
web
db</p>
<p>[app:vars]
ansible_user=ubuntu
ansible_port=22</p>
<p>[web:vars]
http_port=80
max_clients=200</code></pre></p>
<h3>YAML Inventory</h3>
<pre><code class="language-yaml"># inventory/hosts.yml
all:
  children:
    web:
      hosts:
        web1.example.com:
        web2.example.com:
          ansible_host: 192.168.1.101
      vars:
        http_port: 80
        max_clients: 200
    
    db:
      hosts:
        db1.example.com:
          ansible_host: 192.168.1.201
        db2.example.com:
          ansible_host: 192.168.1.202
      vars:
        db_port: 5432
    
    app:
      children:
        - web
        - db
      vars:
        ansible_user: ubuntu
        ansible_port: 22</code></pre>
<h3>Dynamic Inventory (AWS EC2)</h3>
<pre><code class="language-yaml"># inventory/aws_ec2.yml
plugin: aws_ec2
regions:
  - us-west-2
filters:
  tag:Environment: production
  instance-state-name: running
keyed_groups:
  - key: tags.Role
    prefix: role
  - key: placement.availability_zone
    prefix: az
hostnames:
  - private-ip-address
compose:
  ansible_host: private_ip_address</code></pre>
<pre><code class="language-bash"># Use dynamic inventory
ansible-inventory -i inventory/aws_ec2.yml --list
ansible-playbook -i inventory/aws_ec2.yml playbook.yml</code></pre>
<p>---</p>
<h2>Ad-Hoc Commands</h2>
<h3>Basic Commands</h3>
<pre><code class="language-bash"># Ping all hosts
ansible all -m ping
<h1>Check uptime</h1>
ansible all -a &quot;uptime&quot;
<h1>Install package (requires sudo)</h1>
ansible web -m apt -a &quot;name=nginx state=present&quot; -b
<h1>Copy file</h1>
ansible all -m copy -a &quot;src=/tmp/file.txt dest=/tmp/file.txt&quot;
<h1>Restart service</h1>
ansible web -m service -a &quot;name=nginx state=restarted&quot; -b
<h1>Get facts</h1>
ansible web -m setup
<h1>Filter facts</h1>
ansible web -m setup -a &quot;filter=ansible_distribution*&quot;</code></pre>
<h3>Common Modules</h3>
<pre><code class="language-bash"># File operations
ansible all -m file -a &quot;path=/tmp/test state=directory mode=0755&quot;
<h1>User management</h1>
ansible all -m user -a &quot;name=deploy state=present shell=/bin/bash&quot; -b
<h1>Execute command</h1>
ansible all -m shell -a &quot;df -h&quot;
<h1>Git clone</h1>
ansible all -m git -a &quot;repo=https://github.com/user/repo.git dest=/opt/app&quot;
<h1>Template</h1>
ansible all -m template -a &quot;src=nginx.conf.j2 dest=/etc/nginx/nginx.conf&quot; -b</code></pre>
<p>---</p>
<h2>Playbooks</h2>
<h3>Basic Playbook</h3>
<pre><code class="language-yaml"># webserver.yml
---
<li>name: Configure web servers</li>
  hosts: web
  become: yes
  
  tasks:
    - name: Install nginx
      apt:
        name: nginx
        state: present
        update_cache: yes
    
    - name: Start nginx
      service:
        name: nginx
        state: started
        enabled: yes
    
    - name: Copy index.html
      copy:
        src: files/index.html
        dest: /var/www/html/index.html
        owner: www-data
        group: www-data
        mode: &#039;0644&#039;</code></pre>
<pre><code class="language-bash"># Run playbook
ansible-playbook webserver.yml
<h1>Check mode (dry-run)</h1>
ansible-playbook webserver.yml --check
<h1>Limit to specific hosts</h1>
ansible-playbook webserver.yml --limit web1.example.com
<h1>Verbose output</h1>
ansible-playbook webserver.yml -vvv</code></pre>
<h3>Variables</h3>
<pre><code class="language-yaml"># playbook-with-vars.yml
---
<li>name: Configure app</li>
  hosts: app
  become: yes
  
  vars:
    app_name: myapp
    app_version: 1.0.0
    app_port: 8080
  
  tasks:
    - name: Create app directory
      file:
        path: &quot;/opt/{{ app_name }}&quot;
        state: directory
    
    - name: Print app info
      debug:
        msg: &quot;Deploying {{ app_name }} version {{ app_version }} on port {{ app_port }}&quot;</code></pre>
<h3>Conditionals</h3>
<pre><code class="language-yaml">---
<li>name: Install packages based on OS</li>
  hosts: all
  become: yes
  
  tasks:
    - name: Install httpd (RedHat)
      yum:
        name: httpd
        state: present
      when: ansible_os_family == &quot;RedHat&quot;
    
    - name: Install apache2 (Debian)
      apt:
        name: apache2
        state: present
      when: ansible_os_family == &quot;Debian&quot;
    
    - name: Ensure service is running
      service:
        name: &quot;{{ &#039;httpd&#039; if ansible_os_family == &#039;RedHat&#039; else &#039;apache2&#039; }}&quot;
        state: started</code></pre>
<h3>Loops</h3>
<pre><code class="language-yaml">---
<li>name: Create multiple users</li>
  hosts: all
  become: yes
  
  tasks:
    - name: Create users
      user:
        name: &quot;{{ item.name }}&quot;
        groups: &quot;{{ item.groups }}&quot;
        shell: /bin/bash
      loop:
        - { name: &#039;alice&#039;, groups: &#039;sudo&#039; }
        - { name: &#039;bob&#039;, groups: &#039;developers&#039; }
        - { name: &#039;charlie&#039;, groups: &#039;developers&#039; }
    
    - name: Install packages
      apt:
        name: &quot;{{ item }}&quot;
        state: present
      loop:
        - vim
        - git
        - htop
        - curl</code></pre>
<h3>Handlers</h3>
<pre><code class="language-yaml">---
<li>name: Configure nginx</li>
  hosts: web
  become: yes
  
  tasks:
    - name: Copy nginx config
      template:
        src: nginx.conf.j2
        dest: /etc/nginx/nginx.conf
      notify: Restart nginx
    
    - name: Copy site config
      template:
        src: site.conf.j2
        dest: /etc/nginx/sites-available/default
      notify: Reload nginx
  
  handlers:
    - name: Restart nginx
      service:
        name: nginx
        state: restarted
    
    - name: Reload nginx
      service:
        name: nginx
        state: reloaded</code></pre>
<p>---</p>
<h2>Roles</h2>
<h3>Role Structure</h3>
<pre><code class="language-text">roles/
‚îî‚îÄ‚îÄ webserver/
    ‚îú‚îÄ‚îÄ tasks/
    ‚îÇ   ‚îî‚îÄ‚îÄ main.yml
    ‚îú‚îÄ‚îÄ handlers/
    ‚îÇ   ‚îî‚îÄ‚îÄ main.yml
    ‚îú‚îÄ‚îÄ templates/
    ‚îÇ   ‚îî‚îÄ‚îÄ nginx.conf.j2
    ‚îú‚îÄ‚îÄ files/
    ‚îÇ   ‚îî‚îÄ‚îÄ index.html
    ‚îú‚îÄ‚îÄ vars/
    ‚îÇ   ‚îî‚îÄ‚îÄ main.yml
    ‚îú‚îÄ‚îÄ defaults/
    ‚îÇ   ‚îî‚îÄ‚îÄ main.yml
    ‚îú‚îÄ‚îÄ meta/
    ‚îÇ   ‚îî‚îÄ‚îÄ main.yml
    ‚îî‚îÄ‚îÄ README.md</code></pre>
<h3>Create Role</h3>
<pre><code class="language-bash"># Create role skeleton
ansible-galaxy role init webserver
<h1>Directory structure created:</h1>
cd webserver
tree</code></pre>
<h3>Role: tasks/main.yml</h3>
<pre><code class="language-yaml"># roles/webserver/tasks/main.yml
---
<li>name: Install nginx</li>
  apt:
    name: nginx
    state: present
    update_cache: yes
<li>name: Copy nginx config</li>
  template:
    src: nginx.conf.j2
    dest: /etc/nginx/nginx.conf
  notify: Restart nginx
<li>name: Copy site config</li>
  template:
    src: site.conf.j2
    dest: /etc/nginx/sites-available/default
  notify: Reload nginx
<li>name: Enable site</li>
  file:
    src: /etc/nginx/sites-available/default
    dest: /etc/nginx/sites-enabled/default
    state: link
<li>name: Start nginx</li>
  service:
    name: nginx
    state: started
    enabled: yes</code></pre>
<h3>Role: handlers/main.yml</h3>
<pre><code class="language-yaml"># roles/webserver/handlers/main.yml
---
<li>name: Restart nginx</li>
  service:
    name: nginx
    state: restarted
<li>name: Reload nginx</li>
  service:
    name: nginx
    state: reloaded</code></pre>
<h3>Role: defaults/main.yml</h3>
<pre><code class="language-yaml"># roles/webserver/defaults/main.yml
---
nginx_port: 80
nginx_worker_processes: auto
nginx_worker_connections: 1024
server_name: localhost
document_root: /var/www/html</code></pre>
<h3>Role: templates/nginx.conf.j2</h3>
<pre><code class="language-jinja2"># roles/webserver/templates/nginx.conf.j2
user www-data;
worker_processes {{ nginx_worker_processes }};
pid /run/nginx.pid;
<p>events {
    worker_connections {{ nginx_worker_connections }};
}</p>
<p>http {
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;</p>
<p>include /etc/nginx/mime.types;
    default_type application/octet-stream;</p>
<p>access_log /var/log/nginx/access.log;
    error_log /var/log/nginx/error.log;</p>
<p>gzip on;</p>
<p>include /etc/nginx/conf.d/*.conf;
    include /etc/nginx/sites-enabled/*;
}</code></pre></p>
<h3>Use Role in Playbook</h3>
<pre><code class="language-yaml"># site.yml
---
<li>name: Configure web servers</li>
  hosts: web
  become: yes
  
  roles:
    - webserver
    
  vars:
    nginx_port: 8080
    server_name: example.com</code></pre>
<pre><code class="language-bash"># Run
ansible-playbook site.yml</code></pre>
<p>---</p>
<h2>Variables & Facts</h2>
<h3>Variable Precedence</h3>
<pre><code class="language-text">1. Command line (-e)
2. Role defaults
3. Inventory (host_vars, group_vars)
4. Playbook vars
5. Role vars
6. Block vars
7. Task vars</code></pre>
<h3>Group Variables</h3>
<pre><code class="language-yaml"># group_vars/web.yml
---
nginx_port: 80
app_env: production
<h1>group_vars/db.yml</h1>
---
db_port: 5432
db_name: myapp</code></pre>
<h3>Host Variables</h3>
<pre><code class="language-yaml"># host_vars/web1.example.com.yml
---
nginx_worker_processes: 4
<h1>host_vars/web2.example.com.yml</h1>
---
nginx_worker_processes: 2</code></pre>
<h3>Facts</h3>
<pre><code class="language-yaml">---
<li>name: Gather and use facts</li>
  hosts: all
  
  tasks:
    - name: Print OS info
      debug:
        msg: &quot;{{ ansible_distribution }} {{ ansible_distribution_version }}&quot;
    
    - name: Print memory
      debug:
        msg: &quot;Total memory: {{ ansible_memtotal_mb }} MB&quot;
    
    - name: Print network info
      debug:
        msg: &quot;IP: {{ ansible_default_ipv4.address }}&quot;</code></pre>
<h3>Custom Facts</h3>
<pre><code class="language-bash"># Create custom fact
cat &lt;&lt;&#039;EOF&#039; | sudo tee /etc/ansible/facts.d/custom.fact
#!/bin/bash
echo &quot;{\&quot;app_version\&quot;: \&quot;1.0.0\&quot;, \&quot;deployment_date\&quot;: \&quot;$(date +%Y-%m-%d)\&quot;}&quot;
EOF
<p>sudo chmod +x /etc/ansible/facts.d/custom.fact</p>
<h1>Use in playbook</h1>
<li>debug:</li>
    msg: &quot;App version: {{ ansible_local.custom.app_version }}&quot;</code></pre>
<p>---</p>
<h2>Handlers & Templates</h2>
<h3>Handlers (Triggered by Tasks)</h3>
<pre><code class="language-yaml">---
<li>name: Configure services</li>
  hosts: app
  become: yes
  
  tasks:
    - name: Copy nginx config
      copy:
        src: nginx.conf
        dest: /etc/nginx/nginx.conf
      notify:
        - Reload nginx
        - Clear cache
    
    - name: Copy php config
      copy:
        src: php.ini
        dest: /etc/php/7.4/fpm/php.ini
      notify: Restart php-fpm
  
  handlers:
    - name: Reload nginx
      service:
        name: nginx
        state: reloaded
    
    - name: Restart php-fpm
      service:
        name: php7.4-fpm
        state: restarted
    
    - name: Clear cache
      command: rm -rf /var/cache/app/*</code></pre>
<h3>Jinja2 Templates</h3>
<pre><code class="language-jinja2">{# templates/app.conf.j2 #}
server {
    listen {{ nginx_port }};
    server_name {{ server_name }};
    
    root {{ document_root }};
    index index.html index.php;
    
    {% if enable_ssl %}
    listen 443 ssl;
    ssl_certificate {{ ssl_cert_path }};
    ssl_certificate_key {{ ssl_key_path }};
    {% endif %}
    
    location / {
        try_files $uri $uri/ =404;
    }
    
    {% for location in custom_locations %}
    location {{ location.path }} {
        proxy_pass {{ location.backend }};
    }
    {% endfor %}
}</code></pre>
<p>---</p>
<h2>Ansible Galaxy</h2>
<h3>What is Ansible Galaxy?</h3>
<strong>Public repository</strong> of community-contributed Ansible roles.
<h3>Install Role from Galaxy</h3>
<pre><code class="language-bash"># Install role
ansible-galaxy role install geerlingguy.nginx
<h1>Install specific version</h1>
ansible-galaxy role install geerlingguy.nginx,3.1.4
<h1>Install from requirements file</h1>
cat &lt;&lt;EOF &gt; requirements.yml
roles:
  - name: geerlingguy.nginx
    version: 3.1.4
  - name: geerlingguy.postgresql
    version: 3.3.1
EOF
<p>ansible-galaxy role install -r requirements.yml</p>
<h1>List installed roles</h1>
ansible-galaxy role list
<h1>Remove role</h1>
ansible-galaxy role remove geerlingguy.nginx</code></pre>
<h3>Use Galaxy Role</h3>
<pre><code class="language-yaml"># site.yml
---
<li>name: Setup web server</li>
  hosts: web
  become: yes
  
  roles:
    - role: geerlingguy.nginx
      nginx_vhosts:
        - listen: &quot;80&quot;
          server_name: &quot;example.com&quot;
          root: &quot;/var/www/html&quot;</code></pre>
<h3>Create & Publish Role</h3>
<pre><code class="language-bash"># Initialize role
ansible-galaxy role init my_role
<h1>Login to Galaxy</h1>
ansible-galaxy login
<h1>Publish (from GitHub repo)</h1>
<h1>Push to GitHub, then import via Galaxy website</code></pre></h1>
<p>---</p>
<h2>Best Practices</h2>
<h3>1. Project Structure</h3>
<pre><code class="language-text">ansible-project/
‚îú‚îÄ‚îÄ ansible.cfg
‚îú‚îÄ‚îÄ inventory/
‚îÇ   ‚îú‚îÄ‚îÄ production/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hosts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ group_vars/
‚îÇ   ‚îî‚îÄ‚îÄ staging/
‚îÇ       ‚îú‚îÄ‚îÄ hosts
‚îÇ       ‚îî‚îÄ‚îÄ group_vars/
‚îú‚îÄ‚îÄ group_vars/
‚îÇ   ‚îú‚îÄ‚îÄ all.yml
‚îÇ   ‚îî‚îÄ‚îÄ web.yml
‚îú‚îÄ‚îÄ host_vars/
‚îÇ   ‚îî‚îÄ‚îÄ web1.example.com.yml
‚îú‚îÄ‚îÄ roles/
‚îÇ   ‚îú‚îÄ‚îÄ common/
‚îÇ   ‚îú‚îÄ‚îÄ webserver/
‚îÇ   ‚îî‚îÄ‚îÄ database/
‚îú‚îÄ‚îÄ playbooks/
‚îÇ   ‚îú‚îÄ‚îÄ site.yml
‚îÇ   ‚îú‚îÄ‚îÄ webservers.yml
‚îÇ   ‚îî‚îÄ‚îÄ databases.yml
‚îú‚îÄ‚îÄ files/
‚îú‚îÄ‚îÄ templates/
‚îî‚îÄ‚îÄ requirements.yml</code></pre>
<h3>2. Idempotency</h3>
<pre><code class="language-yaml"># ‚úÖ Idempotent
<li>name: Ensure nginx is installed</li>
  apt:
    name: nginx
    state: present
<h1>‚ùå Not idempotent</h1>
<li>name: Install nginx</li>
  shell: apt-get install nginx</code></pre>
<h3>3. Use Modules (Not Shell)</h3>
<pre><code class="language-yaml"># ‚úÖ Preferred
<li>name: Create directory</li>
  file:
    path: /opt/app
    state: directory
<h1>‚ùå Avoid</h1>
<li>name: Create directory</li>
  shell: mkdir /opt/app</code></pre>
<h3>4. Vault for Secrets</h3>
<pre><code class="language-bash"># Create encrypted file
ansible-vault create secrets.yml
<h1>Edit encrypted file</h1>
ansible-vault edit secrets.yml
<h1>Encrypt existing file</h1>
ansible-vault encrypt vars.yml
<h1>Decrypt</h1>
ansible-vault decrypt vars.yml
<h1>Run with vault</h1>
ansible-playbook site.yml --ask-vault-pass
<h1>Use password file</h1>
ansible-playbook site.yml --vault-password-file ~/.vault_pass</code></pre>
<h3>5. Tags</h3>
<pre><code class="language-yaml">---
<li>name: Full setup</li>
  hosts: all
  become: yes
  
  tasks:
    - name: Install packages
      apt:
        name: &quot;{{ item }}&quot;
        state: present
      loop:
        - nginx
        - postgresql
      tags:
        - packages
    
    - name: Configure nginx
      template:
        src: nginx.conf.j2
        dest: /etc/nginx/nginx.conf
      tags:
        - config
        - nginx</code></pre>
<pre><code class="language-bash"># Run only specific tags
ansible-playbook site.yml --tags &quot;config&quot;
<h1>Skip tags</h1>
ansible-playbook site.yml --skip-tags &quot;packages&quot;</code></pre>
<p>---</p>
<h2>Interview Questions</h2>
<strong>Q1: What makes Ansible different from Puppet/Chef?</strong>
<strong>Answer:</strong> Ansible is agentless (SSH-based), uses YAML (not Ruby DSL), push-based (vs pull), simpler learning curve. No need to install agents on managed nodes. Idempotent - safe to run multiple times.
<strong>Q2: Explain Ansible's idempotency.</strong>
<strong>Answer:</strong> Idempotent operations produce same result regardless of how many times executed. Ansible modules are designed to be idempotent - running playbook multiple times won't cause unintended changes. Example: <code>apt</code> module checks if package installed before attempting installation.
<strong>Q3: What is the difference between a role and a playbook?</strong>
<strong>Answer:</strong>
<li><strong>Playbook</strong>: YAML file containing plays (tasks to execute)</li>
<li><strong>Role</strong>: Organized collection of tasks, handlers, variables, templates - reusable component</li>
Roles promote modularity, reusability. Playbooks can include multiple roles.
<strong>Q4: How do you handle secrets in Ansible?</strong>
<strong>Answer:</strong> Use Ansible Vault to encrypt sensitive data:
<li><code>ansible-vault create/edit/encrypt/decrypt</code></li>
<li>Store encrypted vars in version control</li>
<li>Pass vault password at runtime (<code>--ask-vault-pass</code>)</li>
<li>Use external secret management (HashiCorp Vault, AWS Secrets Manager)</li>
<strong>Q5: Explain dynamic inventory.</strong>
<strong>Answer:</strong> Dynamic inventory pulls host information from external sources (AWS, GCP, Azure, CMDB) at runtime. Uses scripts/plugins that query cloud APIs. Benefits: Always up-to-date, no manual inventory maintenance, auto-discovers infrastructure.
<p>---</p>
<h2>Hands-On Exercise</h2>
<h3>Task: Configure LAMP Stack</h3>
<pre><code class="language-yaml"># lamp-stack.yml
---
<li>name: Install LAMP stack</li>
  hosts: web
  become: yes
  
  vars:
    mysql_root_password: &quot;SecurePassword123!&quot;
    app_user: www-data
  
  tasks:
    - name: Update apt cache
      apt:
        update_cache: yes
        cache_valid_time: 3600
    
    - name: Install Apache
      apt:
        name: apache2
        state: present
    
    - name: Install MySQL
      apt:
        name:
          - mysql-server
          - python3-pymysql
        state: present
    
    - name: Install PHP
      apt:
        name:
          - php
          - php-mysql
          - libapache2-mod-php
        state: present
    
    - name: Start Apache
      service:
        name: apache2
        state: started
        enabled: yes
    
    - name: Start MySQL
      service:
        name: mysql
        state: started
        enabled: yes
    
    - name: Create database
      mysql_db:
        name: myapp_db
        state: present
        login_unix_socket: /var/run/mysqld/mysqld.sock
    
    - name: Create database user
      mysql_user:
        name: myapp_user
        password: &quot;{{ mysql_root_password }}&quot;
        priv: &#039;myapp_db.*:ALL&#039;
        state: present
        login_unix_socket: /var/run/mysqld/mysqld.sock
    
    - name: Copy PHP info file
      copy:
        content: &quot;&lt;?php phpinfo(); ?&gt;&quot;
        dest: /var/www/html/info.php
        owner: &quot;{{ app_user }}&quot;
        group: &quot;{{ app_user }}&quot;
    
    - name: Test PHP
      uri:
        url: http://localhost/info.php
        return_content: yes
      register: php_test
    
    - name: Display PHP test result
      debug:
        msg: &quot;PHP is working!&quot;
      when: &quot;&#039;PHP Version&#039; in php_test.content&quot;</code></pre>
<pre><code class="language-bash"># Run playbook
ansible-playbook lamp-stack.yml
<h1>Verify</h1>
curl http://web1.example.com/info.php</code></pre>
<p>---</p>
<h2>üìö Additional Resources</h2>
<li>[Ansible Documentation](https://docs.ansible.com/)</li>
<li>[Ansible Galaxy](https://galaxy.ansible.com/)</li>
<li>[Ansible Best Practices](https://docs.ansible.com/ansible/latest/user_guide/playbooks_best_practices.html)</li>
<li>[Jeff Geerling's Ansible Book](https://www.ansiblefordevops.com/)</li>
<p>---</p>
<h2>‚úÖ Module Checklist</h2>
<li>[ ] Understand Ansible architecture</li>
<li>[ ] Create inventory (static & dynamic)</li>
<li>[ ] Write playbooks with tasks, handlers, templates</li>
<li>[ ] Create reusable roles</li>
<li>[ ] Use variables and facts</li>
<li>[ ] Install roles from Ansible Galaxy</li>
<li>[ ] Encrypt secrets with Ansible Vault</li>
<li>[ ] Complete LAMP stack exercise</li></ul>
<p>---</p>
<strong>Next Module:</strong> [Module 15: Database Deep Dive](./15_Database_Deep_Dive.md) - PostgreSQL, Elasticsearch, MinIO! üóÑÔ∏è

    </div>
    

    <div class="module-content" id="module-15">
        <h1>Module 15: Database Deep Dive üóÑÔ∏è</h1>
<h2>PostgreSQL, Elasticsearch, and MinIO - Production Database Systems</h2>
<strong>Duration:</strong> 6-7 hours  
<strong>Prerequisites:</strong> SQL basics, Module 04 (Go Database Integration)  
<strong>Outcome:</strong> Master three critical database technologies for modern applications
<p>---</p>
<h2>üìö Table of Contents</h2>
<p>1. [PostgreSQL](#postgresql)
2. [Elasticsearch](#elasticsearch)
3. [MinIO](#minio)
4. [Database Selection Guide](#database-selection-guide)
5. [Best Practices](#best-practices)
6. [Interview Questions](#interview-questions)
7. [Hands-On Exercise](#hands-on-exercise)</p>
<p>---</p>
<h2>PostgreSQL</h2>
<h3>What is PostgreSQL?</h3>
<strong>Open-source relational database</strong> - ACID compliant, supports complex queries, transactions, JSON, full-text search.
<h3>Installation</h3>
<pre><code class="language-bash"># Ubuntu
sudo apt update
sudo apt install -y postgresql postgresql-contrib
<h1>Start service</h1>
sudo systemctl start postgresql
sudo systemctl enable postgresql
<h1>Switch to postgres user</h1>
sudo -i -u postgres
<h1>Access psql</h1>
psql
<h1>macOS</h1>
brew install postgresql@15
brew services start postgresql@15</code></pre>
<h3>Basic Administration</h3>
<pre><code class="language-sql">-- Create database
CREATE DATABASE myapp;
<p>-- Create user
CREATE USER myapp_user WITH PASSWORD &#039;securepassword&#039;;</p>
<p>-- Grant privileges
GRANT ALL PRIVILEGES ON DATABASE myapp TO myapp_user;</p>
<p>-- Connect to database
\c myapp</p>
<p>-- List databases
\l</p>
<p>-- List tables
\dt</p>
<p>-- Describe table
\d users</p>
<p>-- Quit
\q</code></pre></p>
<h3>Tables & Data Types</h3>
<pre><code class="language-sql">-- Create table
CREATE TABLE users (
    id SERIAL PRIMARY KEY,
    username VARCHAR(50) UNIQUE NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    full_name VARCHAR(100),
    bio TEXT,
    avatar_url VARCHAR(255),
    is_active BOOLEAN DEFAULT true,
    email_verified BOOLEAN DEFAULT false,
    metadata JSONB,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);
<p>-- Indexes
CREATE INDEX idx_users_email ON users(email);
CREATE INDEX idx_users_username ON users(username);
CREATE INDEX idx_users_created_at ON users(created_at);</p>
<p>-- GIN index for JSONB
CREATE INDEX idx_users_metadata ON users USING GIN(metadata);</p>
<p>-- Full-text search index
CREATE INDEX idx_users_bio_fts ON users USING GIN(to_tsvector(&#039;english&#039;, bio));</code></pre></p>
<h3>CRUD Operations</h3>
<pre><code class="language-sql">-- Insert
INSERT INTO users (username, email, password_hash, full_name)
VALUES (&#039;john_doe&#039;, &#039;john@example.com&#039;, &#039;hash123&#039;, &#039;John Doe&#039;);
<p>-- Insert with JSONB
INSERT INTO users (username, email, password_hash, metadata)
VALUES (&#039;jane_doe&#039;, &#039;jane@example.com&#039;, &#039;hash456&#039;, 
        &#039;{&quot;preferences&quot;: {&quot;theme&quot;: &quot;dark&quot;, &quot;language&quot;: &quot;en&quot;}, &quot;badges&quot;: [&quot;verified&quot;, &quot;pro&quot;]}&#039;);</p>
<p>-- Select
SELECT * FROM users WHERE email = &#039;john@example.com&#039;;</p>
<p>-- JSONB queries
SELECT * FROM users WHERE metadata-&gt;&gt;&#039;preferences&#039;-&gt;&gt;&#039;theme&#039; = &#039;dark&#039;;
SELECT * FROM users WHERE metadata-&gt;&#039;badges&#039; ? &#039;verified&#039;;</p>
<p>-- Update
UPDATE users SET bio = &#039;Software Engineer&#039; WHERE username = &#039;john_doe&#039;;</p>
<p>-- Delete
DELETE FROM users WHERE id = 1;</code></pre></p>
<h3>Relationships</h3>
<pre><code class="language-sql">-- Posts table (one-to-many with users)
CREATE TABLE posts (
    id SERIAL PRIMARY KEY,
    user_id INTEGER NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    title VARCHAR(255) NOT NULL,
    content TEXT NOT NULL,
    slug VARCHAR(255) UNIQUE NOT NULL,
    published BOOLEAN DEFAULT false,
    published_at TIMESTAMP WITH TIME ZONE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);
<p>CREATE INDEX idx_posts_user_id ON posts(user_id);
CREATE INDEX idx_posts_slug ON posts(slug);</p>
<p>-- Tags table (many-to-many)
CREATE TABLE tags (
    id SERIAL PRIMARY KEY,
    name VARCHAR(50) UNIQUE NOT NULL
);</p>
<p>CREATE TABLE post_tags (
    post_id INTEGER REFERENCES posts(id) ON DELETE CASCADE,
    tag_id INTEGER REFERENCES tags(id) ON DELETE CASCADE,
    PRIMARY KEY (post_id, tag_id)
);</p>
<p>-- Join query
SELECT p.title, u.username, array_agg(t.name) as tags
FROM posts p
JOIN users u ON p.user_id = u.id
LEFT JOIN post_tags pt ON p.id = pt.post_id
LEFT JOIN tags t ON pt.tag_id = t.id
GROUP BY p.id, u.username;</code></pre></p>
<h3>Transactions</h3>
<pre><code class="language-sql">BEGIN;
<p>UPDATE users SET bio = &#039;Updated bio&#039; WHERE id = 1;
INSERT INTO posts (user_id, title, content, slug) 
VALUES (1, &#039;My Post&#039;, &#039;Content here&#039;, &#039;my-post&#039;);</p>
<p>COMMIT;  -- or ROLLBACK;</p>
<p>-- Savepoints
BEGIN;
UPDATE users SET bio = &#039;First update&#039; WHERE id = 1;
SAVEPOINT sp1;
UPDATE users SET bio = &#039;Second update&#039; WHERE id = 1;
ROLLBACK TO sp1;
COMMIT;</code></pre></p>
<h3>Advanced Features</h3>
<pre><code class="language-sql">-- Views
CREATE VIEW active_users_with_posts AS
SELECT u.id, u.username, u.email, COUNT(p.id) as post_count
FROM users u
LEFT JOIN posts p ON u.id = p.user_id
WHERE u.is_active = true
GROUP BY u.id;
<p>SELECT * FROM active_users_with_posts;</p>
<p>-- Common Table Expressions (CTEs)
WITH user_stats AS (
    SELECT user_id, COUNT(*) as post_count
    FROM posts
    GROUP BY user_id
)
SELECT u.username, COALESCE(us.post_count, 0) as posts
FROM users u
LEFT JOIN user_stats us ON u.id = us.user_id;</p>
<p>-- Window Functions
SELECT 
    username,
    created_at,
    ROW_NUMBER() OVER (ORDER BY created_at) as user_number,
    RANK() OVER (ORDER BY created_at) as user_rank
FROM users;</p>
<p>-- Full-Text Search
SELECT * FROM users 
WHERE to_tsvector(&#039;english&#039;, bio) @@ to_tsquery(&#039;engineer &amp; software&#039;);</code></pre></p>
<h3>Replication</h3>
<pre><code class="language-bash"># Master configuration (postgresql.conf)
wal_level = replica
max_wal_senders = 3
wal_keep_size = 64
<h1>pg_hba.conf</h1>
host replication replicator 192.168.1.0/24 md5
<h1>Create replication user</h1>
CREATE USER replicator REPLICATION LOGIN PASSWORD &#039;password&#039;;
<h1>Slave: Base backup</h1>
pg_basebackup -h master_ip -D /var/lib/postgresql/15/main -U replicator -P -v
<h1>recovery.conf (or postgresql.auto.conf in PG 12+)</h1>
primary_conninfo = &#039;host=master_ip port=5432 user=replicator password=password&#039;
hot_standby = on</code></pre>
<h3>Go + PostgreSQL</h3>
<pre><code class="language-go">package main
<p>import (
    &quot;database/sql&quot;
    &quot;log&quot;
    _ &quot;github.com/lib/pq&quot;
)</p>
<p>func main() {
    connStr := &quot;postgres://myapp_user:securepassword@localhost/myapp?sslmode=disable&quot;
    db, err := sql.Open(&quot;postgres&quot;, connStr)
    if err != nil {
        log.Fatal(err)
    }
    defer db.Close()</p>
<p>// Connection pooling
    db.SetMaxOpenConns(25)
    db.SetMaxIdleConns(25)
    db.SetConnMaxLifetime(5 * time.Minute)</p>
<p>// Insert
    var id int
    err = db.QueryRow(<code>
        INSERT INTO users (username, email, password_hash) 
        VALUES ($1, $2, $3) RETURNING id</code>,
        &quot;john_doe&quot;, &quot;john@example.com&quot;, &quot;hash123&quot;,
    ).Scan(&amp;id)
    if err != nil {
        log.Fatal(err)
    }
    
    // Query
    rows, err := db.Query(&quot;SELECT id, username, email FROM users&quot;)
    if err != nil {
        log.Fatal(err)
    }
    defer rows.Close()</p>
<p>for rows.Next() {
        var id int
        var username, email string
        if err := rows.Scan(&amp;id, &amp;username, &amp;email); err != nil {
            log.Fatal(err)
        }
        log.Printf(&quot;User: %d, %s, %s\n&quot;, id, username, email)
    }
}</code></pre></p>
<p>---</p>
<h2>Elasticsearch</h2>
<h3>What is Elasticsearch?</h3>
<strong>Distributed search and analytics engine</strong> - built on Lucene, RESTful API, real-time search, log analytics.
<h3>Installation</h3>
<pre><code class="language-bash"># Docker (easiest)
docker run -d \
  --name elasticsearch \
  -p 9200:9200 \
  -p 9300:9300 \
  -e &quot;discovery.type=single-node&quot; \
  -e &quot;xpack.security.enabled=false&quot; \
  elasticsearch:8.10.4
<h1>Verify</h1>
curl http://localhost:9200
<h1>Ubuntu</h1>
wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo gpg --dearmor -o /usr/share/keyrings/elasticsearch-keyring.gpg
echo &quot;deb [signed-by=/usr/share/keyrings/elasticsearch-keyring.gpg] https://artifacts.elastic.co/packages/8.x/apt stable main&quot; | sudo tee /etc/apt/sources.list.d/elastic-8.x.list
sudo apt update &amp;&amp; sudo apt install elasticsearch
<p>sudo systemctl start elasticsearch
sudo systemctl enable elasticsearch</code></pre></p>
<h3>Basic Concepts</h3>
<pre><code class="language-text">Index:      Database (collection of documents)
Document:   JSON record
Type:       (Deprecated in ES 7+)
Mapping:    Schema definition
Shard:      Horizontal partition
Replica:    Copy for fault tolerance</code></pre>
<h3>Index Operations</h3>
<pre><code class="language-bash"># Create index
curl -X PUT &quot;localhost:9200/products&quot; -H &#039;Content-Type: application/json&#039; -d&#039;
{
  &quot;settings&quot;: {
    &quot;number_of_shards&quot;: 2,
    &quot;number_of_replicas&quot;: 1
  }
}&#039;
<h1>Get index info</h1>
curl -X GET &quot;localhost:9200/products&quot;
<h1>Delete index</h1>
curl -X DELETE &quot;localhost:9200/products&quot;
<h1>List all indices</h1>
curl -X GET &quot;localhost:9200/_cat/indices?v&quot;</code></pre>
<h3>Mappings (Schema)</h3>
<pre><code class="language-bash"># Define mapping
curl -X PUT &quot;localhost:9200/products&quot; -H &#039;Content-Type: application/json&#039; -d&#039;
{
  &quot;mappings&quot;: {
    &quot;properties&quot;: {
      &quot;name&quot;: {
        &quot;type&quot;: &quot;text&quot;,
        &quot;fields&quot;: {
          &quot;keyword&quot;: {
            &quot;type&quot;: &quot;keyword&quot;
          }
        }
      },
      &quot;description&quot;: {
        &quot;type&quot;: &quot;text&quot;
      },
      &quot;price&quot;: {
        &quot;type&quot;: &quot;float&quot;
      },
      &quot;quantity&quot;: {
        &quot;type&quot;: &quot;integer&quot;
      },
      &quot;category&quot;: {
        &quot;type&quot;: &quot;keyword&quot;
      },
      &quot;tags&quot;: {
        &quot;type&quot;: &quot;keyword&quot;
      },
      &quot;created_at&quot;: {
        &quot;type&quot;: &quot;date&quot;
      },
      &quot;location&quot;: {
        &quot;type&quot;: &quot;geo_point&quot;
      }
    }
  }
}&#039;</code></pre>
<h3>CRUD Operations</h3>
<pre><code class="language-bash"># Index document (with ID)
curl -X PUT &quot;localhost:9200/products/_doc/1&quot; -H &#039;Content-Type: application/json&#039; -d&#039;
{
  &quot;name&quot;: &quot;Laptop&quot;,
  &quot;description&quot;: &quot;High-performance laptop for developers&quot;,
  &quot;price&quot;: 1299.99,
  &quot;quantity&quot;: 50,
  &quot;category&quot;: &quot;electronics&quot;,
  &quot;tags&quot;: [&quot;laptop&quot;, &quot;computers&quot;, &quot;tech&quot;],
  &quot;created_at&quot;: &quot;2024-01-15T10:00:00Z&quot;
}&#039;
<h1>Index without ID (auto-generated)</h1>
curl -X POST &quot;localhost:9200/products/_doc&quot; -H &#039;Content-Type: application/json&#039; -d&#039;
{
  &quot;name&quot;: &quot;Mouse&quot;,
  &quot;price&quot;: 29.99,
  &quot;category&quot;: &quot;accessories&quot;
}&#039;
<h1>Get document</h1>
curl -X GET &quot;localhost:9200/products/_doc/1&quot;
<h1>Update document</h1>
curl -X POST &quot;localhost:9200/products/_update/1&quot; -H &#039;Content-Type: application/json&#039; -d&#039;
{
  &quot;doc&quot;: {
    &quot;price&quot;: 1199.99
  }
}&#039;
<h1>Delete document</h1>
curl -X DELETE &quot;localhost:9200/products/_doc/1&quot;</code></pre>
<h3>Search Queries</h3>
<pre><code class="language-bash"># Match all
curl -X GET &quot;localhost:9200/products/_search&quot; -H &#039;Content-Type: application/json&#039; -d&#039;
{
  &quot;query&quot;: {
    &quot;match_all&quot;: {}
  }
}&#039;
<h1>Match query</h1>
curl -X GET &quot;localhost:9200/products/_search&quot; -H &#039;Content-Type: application/json&#039; -d&#039;
{
  &quot;query&quot;: {
    &quot;match&quot;: {
      &quot;description&quot;: &quot;laptop developers&quot;
    }
  }
}&#039;
<h1>Multi-match</h1>
curl -X GET &quot;localhost:9200/products/_search&quot; -H &#039;Content-Type: application/json&#039; -d&#039;
{
  &quot;query&quot;: {
    &quot;multi_match&quot;: {
      &quot;query&quot;: &quot;laptop&quot;,
      &quot;fields&quot;: [&quot;name&quot;, &quot;description&quot;]
    }
  }
}&#039;
<h1>Term query (exact match)</h1>
curl -X GET &quot;localhost:9200/products/_search&quot; -H &#039;Content-Type: application/json&#039; -d&#039;
{
  &quot;query&quot;: {
    &quot;term&quot;: {
      &quot;category&quot;: &quot;electronics&quot;
    }
  }
}&#039;
<h1>Range query</h1>
curl -X GET &quot;localhost:9200/products/_search&quot; -H &#039;Content-Type: application/json&#039; -d&#039;
{
  &quot;query&quot;: {
    &quot;range&quot;: {
      &quot;price&quot;: {
        &quot;gte&quot;: 100,
        &quot;lte&quot;: 1000
      }
    }
  }
}&#039;
<h1>Bool query (complex)</h1>
curl -X GET &quot;localhost:9200/products/_search&quot; -H &#039;Content-Type: application/json&#039; -d&#039;
{
  &quot;query&quot;: {
    &quot;bool&quot;: {
      &quot;must&quot;: [
        { &quot;match&quot;: { &quot;description&quot;: &quot;laptop&quot; } }
      ],
      &quot;filter&quot;: [
        { &quot;term&quot;: { &quot;category&quot;: &quot;electronics&quot; } },
        { &quot;range&quot;: { &quot;price&quot;: { &quot;lte&quot;: 1500 } } }
      ],
      &quot;should&quot;: [
        { &quot;term&quot;: { &quot;tags&quot;: &quot;gaming&quot; } }
      ],
      &quot;must_not&quot;: [
        { &quot;term&quot;: { &quot;quantity&quot;: 0 } }
      ]
    }
  }
}&#039;</code></pre>
<h3>Aggregations</h3>
<pre><code class="language-bash"># Average price
curl -X GET &quot;localhost:9200/products/_search&quot; -H &#039;Content-Type: application/json&#039; -d&#039;
{
  &quot;size&quot;: 0,
  &quot;aggs&quot;: {
    &quot;avg_price&quot;: {
      &quot;avg&quot;: {
        &quot;field&quot;: &quot;price&quot;
      }
    }
  }
}&#039;
<h1>Group by category</h1>
curl -X GET &quot;localhost:9200/products/_search&quot; -H &#039;Content-Type: application/json&#039; -d&#039;
{
  &quot;size&quot;: 0,
  &quot;aggs&quot;: {
    &quot;categories&quot;: {
      &quot;terms&quot;: {
        &quot;field&quot;: &quot;category&quot;
      },
      &quot;aggs&quot;: {
        &quot;avg_price&quot;: {
          &quot;avg&quot;: {
            &quot;field&quot;: &quot;price&quot;
          }
        }
      }
    }
  }
}&#039;</code></pre>
<h3>Go + Elasticsearch</h3>
<pre><code class="language-go">package main
<p>import (
    &quot;context&quot;
    &quot;encoding/json&quot;
    &quot;log&quot;
    &quot;strings&quot;</p>
<p>&quot;github.com/elastic/go-elasticsearch/v8&quot;
)</p>
<p>type Product struct {
    Name        string   <code>json:&quot;name&quot;</code>
    Description string   <code>json:&quot;description&quot;</code>
    Price       float64  <code>json:&quot;price&quot;</code>
    Category    string   <code>json:&quot;category&quot;</code>
    Tags        []string <code>json:&quot;tags&quot;</code>
}</p>
<p>func main() {
    es, err := elasticsearch.NewDefaultClient()
    if err != nil {
        log.Fatal(err)
    }</p>
<p>// Index document
    product := Product{
        Name:        &quot;Laptop&quot;,
        Description: &quot;High-performance laptop&quot;,
        Price:       1299.99,
        Category:    &quot;electronics&quot;,
        Tags:        []string{&quot;laptop&quot;, &quot;tech&quot;},
    }</p>
<p>data, _ := json.Marshal(product)
    res, err := es.Index(
        &quot;products&quot;,
        strings.NewReader(string(data)),
        es.Index.WithContext(context.Background()),
    )
    if err != nil {
        log.Fatal(err)
    }
    defer res.Body.Close()</p>
<p>// Search
    query := map[string]interface{}{
        &quot;query&quot;: map[string]interface{}{
            &quot;match&quot;: map[string]interface{}{
                &quot;description&quot;: &quot;laptop&quot;,
            },
        },
    }</p>
<p>queryData, _ := json.Marshal(query)
    res, err = es.Search(
        es.Search.WithContext(context.Background()),
        es.Search.WithIndex(&quot;products&quot;),
        es.Search.WithBody(strings.NewReader(string(queryData))),
    )
    if err != nil {
        log.Fatal(err)
    }
    defer res.Body.Close()</p>
<p>var result map[string]interface{}
    json.NewDecoder(res.Body).Decode(&amp;result)
    log.Printf(&quot;Results: %v&quot;, result[&quot;hits&quot;])
}</code></pre></p>
<p>---</p>
<h2>MinIO</h2>
<h3>What is MinIO?</h3>
<strong>S3-compatible object storage</strong> - high-performance, Kubernetes-native, distributed, open-source.
<h3>Installation</h3>
<pre><code class="language-bash"># Docker
docker run -d \
  --name minio \
  -p 9000:9000 \
  -p 9001:9001 \
  -e &quot;MINIO_ROOT_USER=minioadmin&quot; \
  -e &quot;MINIO_ROOT_PASSWORD=minioadmin&quot; \
  -v /data:/data \
  minio/minio server /data --console-address &quot;:9001&quot;
<h1>Access: http://localhost:9001 (admin UI)</h1>
<h1>Linux binary</h1>
wget https://dl.min.io/server/minio/release/linux-amd64/minio
chmod +x minio
./minio server /data --console-address &quot;:9001&quot;
<h1>macOS</h1>
brew install minio/stable/minio
minio server /data</code></pre>
<h3>MinIO Client (mc)</h3>
<pre><code class="language-bash"># Install mc
brew install minio/stable/mc  # macOS
<h1>or</h1>
wget https://dl.min.io/client/mc/release/linux-amd64/mc
chmod +x mc
sudo mv mc /usr/local/bin/
<h1>Configure alias</h1>
mc alias set local http://localhost:9000 minioadmin minioadmin
<h1>List buckets</h1>
mc ls local
<h1>Create bucket</h1>
mc mb local/mybucket
<h1>Upload file</h1>
mc cp file.txt local/mybucket/
<h1>Download file</h1>
mc cp local/mybucket/file.txt ./
<h1>Remove file</h1>
mc rm local/mybucket/file.txt
<h1>Set bucket policy (public)</h1>
mc anonymous set download local/mybucket</code></pre>
<h3>Bucket Operations</h3>
<pre><code class="language-bash"># Create bucket
mc mb local/images
<h1>List objects</h1>
mc ls local/images
<h1>Copy entire directory</h1>
mc cp --recursive ./photos/ local/images/
<h1>Sync directory</h1>
mc mirror ./photos/ local/images/
<h1>Get bucket info</h1>
mc stat local/images
<h1>Remove bucket</h1>
mc rb local/images --force</code></pre>
<h3>Access Policies</h3>
<pre><code class="language-json">// policy.json
{
  &quot;Version&quot;: &quot;2012-10-17&quot;,
  &quot;Statement&quot;: [
    {
      &quot;Effect&quot;: &quot;Allow&quot;,
      &quot;Action&quot;: [
        &quot;s3:GetObject&quot;
      ],
      &quot;Resource&quot;: [
        &quot;arn:aws:s3:::mybucket/*&quot;
      ]
    }
  ]
}</code></pre>
<pre><code class="language-bash"># Apply policy
mc admin policy add local readonly policy.json
mc admin policy set local readonly user=myuser</code></pre>
<h3>Go + MinIO</h3>
<pre><code class="language-go">package main
<p>import (
    &quot;context&quot;
    &quot;log&quot;
    &quot;os&quot;</p>
<p>&quot;github.com/minio/minio-go/v7&quot;
    &quot;github.com/minio/minio-go/v7/pkg/credentials&quot;
)</p>
<p>func main() {
    endpoint := &quot;localhost:9000&quot;
    accessKeyID := &quot;minioadmin&quot;
    secretAccessKey := &quot;minioadmin&quot;
    useSSL := false</p>
<p>// Initialize client
    minioClient, err := minio.New(endpoint, &amp;minio.Options{
        Creds:  credentials.NewStaticV4(accessKeyID, secretAccessKey, &quot;&quot;),
        Secure: useSSL,
    })
    if err != nil {
        log.Fatal(err)
    }</p>
<p>ctx := context.Background()
    bucketName := &quot;mybucket&quot;
    location := &quot;us-east-1&quot;</p>
<p>// Create bucket
    err = minioClient.MakeBucket(ctx, bucketName, minio.MakeBucketOptions{Region: location})
    if err != nil {
        exists, errBucketExists := minioClient.BucketExists(ctx, bucketName)
        if errBucketExists == nil &amp;&amp; exists {
            log.Printf(&quot;Bucket %s already exists\n&quot;, bucketName)
        } else {
            log.Fatal(err)
        }
    }</p>
<p>// Upload file
    objectName := &quot;test.txt&quot;
    filePath := &quot;/tmp/test.txt&quot;
    contentType := &quot;text/plain&quot;</p>
<p>info, err := minioClient.FPutObject(ctx, bucketName, objectName, filePath, minio.PutObjectOptions{
        ContentType: contentType,
    })
    if err != nil {
        log.Fatal(err)
    }
    log.Printf(&quot;Uploaded %s of size %d\n&quot;, objectName, info.Size)</p>
<p>// Download file
    err = minioClient.FGetObject(ctx, bucketName, objectName, &quot;/tmp/downloaded.txt&quot;, minio.GetObjectOptions{})
    if err != nil {
        log.Fatal(err)
    }</p>
<p>// List objects
    for object := range minioClient.ListObjects(ctx, bucketName, minio.ListObjectsOptions{}) {
        if object.Err != nil {
            log.Fatal(object.Err)
        }
        log.Println(object.Key)
    }</p>
<p>// Delete object
    err = minioClient.RemoveObject(ctx, bucketName, objectName, minio.RemoveObjectOptions{})
    if err != nil {
        log.Fatal(err)
    }
}</code></pre></p>
<h3>Presigned URLs</h3>
<pre><code class="language-go">// Generate presigned URL (temporary access)
presignedURL, err := minioClient.PresignedGetObject(
    ctx,
    bucketName,
    objectName,
    time.Hour*24, // expires in 24 hours
    url.Values{},
)
if err != nil {
    log.Fatal(err)
}
log.Println(&quot;Presigned URL:&quot;, presignedURL)</code></pre>
<p>---</p>
<h2>Database Selection Guide</h2>
<h3>When to Use PostgreSQL</h3>
<pre><code class="language-text">‚úÖ Transactional data (banking, e-commerce)
‚úÖ Complex relationships (foreign keys, joins)
‚úÖ ACID compliance required
‚úÖ Structured data with schema
‚úÖ Strong consistency
‚úÖ Full-text search (basic)
<p>Examples: User accounts, orders, inventory</code></pre></p>
<h3>When to Use Elasticsearch</h3>
<pre><code class="language-text">‚úÖ Full-text search
‚úÖ Log analytics (ELK stack)
‚úÖ Real-time analytics
‚úÖ Unstructured/semi-structured data
‚úÖ High read throughput
‚úÖ Aggregations and analytics
<p>Examples: Search engine, log analysis, monitoring</code></pre></p>
<h3>When to Use MinIO</h3>
<pre><code class="language-text">‚úÖ Object storage (files, images, videos)
‚úÖ Backup and archival
‚úÖ S3-compatible API needed
‚úÖ Large binary data
‚úÖ CDN origin storage
‚úÖ Kubernetes-native storage
<p>Examples: User uploads, media files, backups</code></pre></p>
<p>---</p>
<h2>Best Practices</h2>
<h3>PostgreSQL</h3>
<pre><code class="language-sql">-- 1. Use indexes strategically
CREATE INDEX CONCURRENTLY idx_users_email ON users(email);
<p>-- 2. Connection pooling
-- Use pgBouncer or app-level pooling</p>
<p>-- 3. Regular vacuuming
VACUUM ANALYZE;</p>
<p>-- 4. Monitor slow queries
CREATE EXTENSION pg_stat_statements;
SELECT * FROM pg_stat_statements ORDER BY total_exec_time DESC LIMIT 10;</p>
<p>-- 5. Partitioning for large tables
CREATE TABLE logs_2024_01 PARTITION OF logs
FOR VALUES FROM (&#039;2024-01-01&#039;) TO (&#039;2024-02-01&#039;);</code></pre></p>
<h3>Elasticsearch</h3>
<pre><code class="language-text">‚úÖ Use bulk API for indexing
‚úÖ Set appropriate shard count (1-5 per index)
‚úÖ Use aliases for zero-downtime reindex
‚úÖ Monitor cluster health
‚úÖ Use index lifecycle management (ILM)
‚úÖ Optimize mappings (disable _source if not needed)</code></pre>
<h3>MinIO</h3>
<pre><code class="language-text">‚úÖ Use bucket policies for access control
‚úÖ Enable versioning for critical data
‚úÖ Implement lifecycle policies (expire old data)
‚úÖ Use erasure coding for durability
‚úÖ Monitor disk usage
‚úÖ Use presigned URLs for temporary access</code></pre>
<p>---</p>
<h2>Interview Questions</h2>
<strong>Q1: PostgreSQL vs MySQL - key differences?</strong>
<strong>Answer:</strong> PostgreSQL: More standards-compliant, better for complex queries, supports JSON, full-text search, advanced indexing (GiST, GIN), extensible. MySQL: Simpler, faster for simple queries, better replication options, more popular. Both are reliable, choice depends on use case.
<strong>Q2: How does Elasticsearch achieve fast search?</strong>
<strong>Answer:</strong> Inverted index - maps terms to documents (reverse of document-to-terms). Lucene creates index of all unique terms, stores document IDs containing each term. When searching, directly looks up term in index (O(1)), returns matching documents instantly.
<strong>Q3: What is eventual consistency in object storage?</strong>
<strong>Answer:</strong> Updates propagate to all nodes eventually, not immediately. MinIO prioritizes availability and partition tolerance (AP in CAP theorem). Read might return stale data briefly after write. Acceptable for object storage where consistency isn't critical (vs transactional databases requiring strong consistency).
<strong>Q4: Explain sharding in Elasticsearch.</strong>
<strong>Answer:</strong> Horizontal partitioning - splits index across multiple nodes. Each shard is self-contained Lucene index. Benefits: Horizontal scaling, parallel operations, fault tolerance (with replicas). Default 1 shard per index, configurable at creation time.
<strong>Q5: How do you handle file uploads in production?</strong>
<strong>Answer:</strong>
1. Client uploads to app server
2. App validates file (size, type, virus scan)
3. Generate unique filename (UUID)
4. Upload to object storage (MinIO/S3)
5. Store metadata in database (filename, URL, user_id)
6. Return presigned URL or CDN URL to client
Never store files in database (performance), use object storage.
<p>---</p>
<h2>Hands-On Exercise</h2>
<h3>Task: Build Multi-Database Application</h3>
<pre><code class="language-go">// main.go - Integrate all three databases
package main
<p>import (
    &quot;context&quot;
    &quot;database/sql&quot;
    &quot;encoding/json&quot;
    &quot;log&quot;
    &quot;strings&quot;</p>
<p>&quot;github.com/elastic/go-elasticsearch/v8&quot;
    _ &quot;github.com/lib/pq&quot;
    &quot;github.com/minio/minio-go/v7&quot;
    &quot;github.com/minio/minio-go/v7/pkg/credentials&quot;
)</p>
<p>type User struct {
    ID       int    <code>json:&quot;id&quot;</code>
    Username string <code>json:&quot;username&quot;</code>
    Email    string <code>json:&quot;email&quot;</code>
    AvatarURL string <code>json:&quot;avatar_url&quot;</code>
}</p>
<p>func main() {
    // PostgreSQL connection
    db, err := sql.Open(&quot;postgres&quot;, &quot;postgres://user:pass@localhost/myapp?sslmode=disable&quot;)
    if err != nil {
        log.Fatal(err)
    }
    defer db.Close()</p>
<p>// Elasticsearch client
    es, err := elasticsearch.NewDefaultClient()
    if err != nil {
        log.Fatal(err)
    }</p>
<p>// MinIO client
    minioClient, err := minio.New(&quot;localhost:9000&quot;, &amp;minio.Options{
        Creds:  credentials.NewStaticV4(&quot;minioadmin&quot;, &quot;minioadmin&quot;, &quot;&quot;),
        Secure: false,
    })
    if err != nil {
        log.Fatal(err)
    }</p>
<p>ctx := context.Background()</p>
<p>// 1. Create user in PostgreSQL
    var userID int
    err = db.QueryRow(<code>
        INSERT INTO users (username, email, password_hash)
        VALUES ($1, $2, $3) RETURNING id</code>,
        &quot;john_doe&quot;, &quot;john@example.com&quot;, &quot;hash123&quot;,
    ).Scan(&amp;userID)
    if err != nil {
        log.Fatal(err)
    }
    log.Printf(&quot;Created user ID: %d\n&quot;, userID)</p>
<p>// 2. Index user in Elasticsearch (for search)
    user := User{
        ID:       userID,
        Username: &quot;john_doe&quot;,
        Email:    &quot;john@example.com&quot;,
    }
    userData, _ := json.Marshal(user)
    _, err = es.Index(
        &quot;users&quot;,
        strings.NewReader(string(userData)),
        es.Index.WithDocumentID(fmt.Sprintf(&quot;%d&quot;, userID)),
    )
    if err != nil {
        log.Fatal(err)
    }
    log.Println(&quot;Indexed user in Elasticsearch&quot;)</p>
<p>// 3. Upload avatar to MinIO
    bucketName := &quot;avatars&quot;
    minioClient.MakeBucket(ctx, bucketName, minio.MakeBucketOptions{})
    
    objectName := fmt.Sprintf(&quot;user_%d_avatar.jpg&quot;, userID)
    _, err = minioClient.FPutObject(ctx, bucketName, objectName, &quot;/tmp/avatar.jpg&quot;, minio.PutObjectOptions{
        ContentType: &quot;image/jpeg&quot;,
    })
    if err != nil {
        log.Fatal(err)
    }
    
    avatarURL := fmt.Sprintf(&quot;http://localhost:9000/%s/%s&quot;, bucketName, objectName)
    
    // 4. Update user with avatar URL in PostgreSQL
    _, err = db.Exec(&quot;UPDATE users SET avatar_url = $1 WHERE id = $2&quot;, avatarURL, userID)
    if err != nil {
        log.Fatal(err)
    }
    log.Printf(&quot;Updated user avatar: %s\n&quot;, avatarURL)
}</code></pre></p>
<h3>Deployment</h3>
<pre><code class="language-yaml"># docker-compose.yml
version: &#039;3.8&#039;
<p>services:
  postgres:
    image: postgres:15
    environment:
      POSTGRES_PASSWORD: password
      POSTGRES_DB: myapp
    ports:
      - &quot;5432:5432&quot;
    volumes:
      - postgres_data:/var/lib/postgresql/data</p>
<p>elasticsearch:
    image: elasticsearch:8.10.4
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
    ports:
      - &quot;9200:9200&quot;
    volumes:
      - es_data:/usr/share/elasticsearch/data</p>
<p>minio:
    image: minio/minio
    command: server /data --console-address &quot;:9001&quot;
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    ports:
      - &quot;9000:9000&quot;
      - &quot;9001:9001&quot;
    volumes:
      - minio_data:/data</p>
<p>volumes:
  postgres_data:
  es_data:
  minio_data:</code></pre></p>
<pre><code class="language-bash"># Start all databases
docker-compose up -d
<h1>Run application</h1>
go run main.go</code></pre>
<p>---</p>
<h2>üìö Additional Resources</h2>
<ul><li>[PostgreSQL Documentation](https://www.postgresql.org/docs/)</li>
<li>[Elasticsearch Guide](https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html)</li>
<li>[MinIO Documentation](https://min.io/docs/minio/linux/index.html)</li>
<li>[Database Performance Best Practices](https://use-the-index-luke.com/)</li>
<p>---</p>
<h2>‚úÖ Module Checklist</h2>
<li>[ ] Set up PostgreSQL with replication</li>
<li>[ ] Create indexes and optimize queries</li>
<li>[ ] Index and search with Elasticsearch</li>
<li>[ ] Use aggregations for analytics</li>
<li>[ ] Upload and download files with MinIO</li>
<li>[ ] Generate presigned URLs</li>
<li>[ ] Integrate all three databases in Go application</li>
<li>[ ] Complete multi-database exercise</li></ul>
<p>---</p>
<strong>Next Module:</strong> [Module 16: System Design Patterns](./16_System_Design_Patterns.md) - Design scalable systems! üèóÔ∏è

    </div>
    

    <div class="module-content" id="module-16">
        <h1>Module 16: System Design Patterns üèóÔ∏è</h1>
<h2>Design Scalable, Reliable, and Maintainable Systems</h2>
<strong>Duration:</strong> 6-7 hours  
<strong>Prerequisites:</strong> All previous modules, distributed systems basics  
<strong>Outcome:</strong> Master architectural patterns and system design principles for production systems
<p>---</p>
<h2>üìö Table of Contents</h2>
<p>1. [System Design Fundamentals](#system-design-fundamentals)
2. [Scalability](#scalability)
3. [Reliability & Availability](#reliability--availability)
4. [Data Storage Patterns](#data-storage-patterns)
5. [Microservices Patterns](#microservices-patterns)
6. [Caching Strategies](#caching-strategies)
7. [Message Queues](#message-queues)
8. [Case Studies](#case-studies)
9. [Interview Questions](#interview-questions)
10. [Hands-On Exercise](#hands-on-exercise)</p>
<p>---</p>
<h2>System Design Fundamentals</h2>
<h3>Design Principles</h3>
<pre><code class="language-text">1. Scalability:    Handle increasing load
2. Reliability:    Function correctly despite failures
3. Availability:   System remains operational
4. Maintainability: Easy to update and debug
5. Performance:    Respond quickly under load</code></pre>
<h3>CAP Theorem</h3>
<pre><code class="language-text">Choose 2 of 3:
<p>C (Consistency):    All nodes see same data
A (Availability):   System responds to requests
P (Partition Tol):  System works despite network splits</p>
<p>Examples:
<ul><li>CP: PostgreSQL, MongoDB, HBase (consistency over availability)</li>
<li>AP: Cassandra, Riak, DynamoDB (availability over consistency)</li>
<li>CA: Not possible in distributed systems</code></pre></li></p>
<h3>ACID vs BASE</h3>
<pre><code class="language-text">ACID (Traditional Databases):
<li>Atomicity:       All-or-nothing transactions</li>
<li>Consistency:     Valid state transitions</li>
<li>Isolation:       Concurrent transactions don&#039;t interfere</li>
<li>Durability:      Committed data persists</li>
<p>BASE (NoSQL):
<li>Basically Available:      System responds (may be stale)</li>
<li>Soft state:               State may change without input</li>
<li>Eventual consistency:     System becomes consistent over time</code></pre></li></p>
<p>---</p>
<h2>Scalability</h2>
<h3>Vertical vs Horizontal Scaling</h3>
<pre><code class="language-text">Vertical (Scale Up):
‚úÖ Simpler (no code changes)
‚úÖ No data consistency issues
‚ùå Limited (hardware ceiling)
‚ùå Single point of failure
‚ùå Expensive
<p>Horizontal (Scale Out):
‚úÖ Unlimited scaling
‚úÖ Fault tolerant
‚úÖ Cost-effective
‚ùå Complex (load balancing, data distribution)
‚ùå Eventual consistency challenges</code></pre></p>
<h3>Load Balancing</h3>
<pre><code class="language-text">Layer 4 (Transport):
<li>Based on IP, port</li>
<li>Fast (no content inspection)</li>
<li>Examples: AWS NLB, HAProxy</li>
<p>Layer 7 (Application):
<li>Based on HTTP headers, URL, cookies</li>
<li>Content-aware routing</li>
<li>Examples: AWS ALB, Nginx, Envoy</li></p>
<p>Algorithms:
<li>Round Robin</li>
<li>Least Connections</li>
<li>IP Hash</li>
<li>Weighted Round Robin</code></pre></li></p>
<pre><code class="language-nginx"># Nginx load balancer
upstream backend {
    least_conn;  # Algorithm
    server backend1.example.com weight=3;
    server backend2.example.com weight=2;
    server backend3.example.com;
}
<p>server {
    listen 80;
    location / {
        proxy_pass http://backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
}</code></pre></p>
<h3>Database Scaling</h3>
<pre><code class="language-text">1. Replication (Read Scaling)
   Master-Slave: Master writes, slaves read
   Master-Master: Both read/write
<p>2. Sharding (Write Scaling)
   Horizontal partitioning by key
   
   User Sharding:
   - Shard 1: user_id 0-999
   - Shard 2: user_id 1000-1999
   - Shard 3: user_id 2000-2999</p>
<p>3. Partitioning
   Range: By date, ID range
   Hash: Hash function distributes data
   List: Explicit mapping</p>
<p>4. Denormalization
   Duplicate data to avoid joins
   Trade consistency for read performance</code></pre></p>
<p>---</p>
<h2>Reliability & Availability</h2>
<h3>Availability Metrics</h3>
<pre><code class="language-text">Uptime %     Downtime/Year    Downtime/Month
99%          3.65 days        7.2 hours
99.9%        8.76 hours       43.2 minutes
99.99%       52.56 minutes    4.32 minutes
99.999%      5.26 minutes     25.9 seconds
99.9999%     31.5 seconds     2.6 seconds</code></pre>
<h3>Fault Tolerance Patterns</h3>
<p>#### 1. Redundancy</p>
<pre><code class="language-text">Active-Active:
<li>Both instances handle traffic</li>
<li>Load balanced</li>
<li>Higher utilization</li>
<p>Active-Passive:
<li>Primary handles traffic</li>
<li>Secondary on standby</li>
<li>Failover on primary failure</code></pre></li></p>
<p>#### 2. Circuit Breaker</p>
<pre><code class="language-go">// Circuit Breaker Pattern
type CircuitBreaker struct {
    maxFailures  int
    timeout      time.Duration
    failures     int
    lastFailTime time.Time
    state        string // &quot;closed&quot;, &quot;open&quot;, &quot;half-open&quot;
    mu           sync.Mutex
}
<p>func (cb *CircuitBreaker) Call(fn func() error) error {
    cb.mu.Lock()
    defer cb.mu.Unlock()</p>
<p>// Open: Reject calls during timeout
    if cb.state == &quot;open&quot; {
        if time.Since(cb.lastFailTime) &gt; cb.timeout {
            cb.state = &quot;half-open&quot;
            cb.failures = 0
        } else {
            return errors.New(&quot;circuit breaker is open&quot;)
        }
    }</p>
<p>// Try call
    err := fn()
    
    if err != nil {
        cb.failures++
        cb.lastFailTime = time.Now()
        
        if cb.failures &gt;= cb.maxFailures {
            cb.state = &quot;open&quot;
        }
        return err
    }</p>
<p>// Success: Reset
    cb.failures = 0
    cb.state = &quot;closed&quot;
    return nil
}</code></pre></p>
<p>#### 3. Retry with Exponential Backoff</p>
<pre><code class="language-go">func RetryWithBackoff(fn func() error, maxRetries int) error {
    backoff := time.Second
    
    for i := 0; i &lt; maxRetries; i++ {
        err := fn()
        if err == nil {
            return nil
        }
        
        if i &lt; maxRetries-1 {
            time.Sleep(backoff)
            backoff *= 2 // Exponential backoff
        }
    }
    
    return errors.New(&quot;max retries exceeded&quot;)
}</code></pre>
<p>#### 4. Health Checks</p>
<pre><code class="language-go">// HTTP health check endpoint
func healthHandler(w http.ResponseWriter, r *http.Request) {
    // Check database
    if err := db.Ping(); err != nil {
        w.WriteHeader(http.StatusServiceUnavailable)
        json.NewEncoder(w).Encode(map[string]string{
            &quot;status&quot;: &quot;unhealthy&quot;,
            &quot;reason&quot;: &quot;database unreachable&quot;,
        })
        return
    }
    
    // Check Redis
    if _, err := redis.Ping().Result(); err != nil {
        w.WriteHeader(http.StatusServiceUnavailable)
        json.NewEncoder(w).Encode(map[string]string{
            &quot;status&quot;: &quot;unhealthy&quot;,
            &quot;reason&quot;: &quot;redis unreachable&quot;,
        })
        return
    }
    
    w.WriteHeader(http.StatusOK)
    json.NewEncoder(w).Encode(map[string]string{&quot;status&quot;: &quot;healthy&quot;})
}</code></pre>
<p>---</p>
<h2>Data Storage Patterns</h2>
<h3>Database Per Service</h3>
<pre><code class="language-text">Microservice A ‚Üí Database A
Microservice B ‚Üí Database B
Microservice C ‚Üí Database C
<p>‚úÖ Independent scaling
‚úÖ Technology diversity
‚úÖ Fault isolation
‚ùå No joins across services
‚ùå Eventual consistency</code></pre></p>
<h3>Event Sourcing</h3>
<pre><code class="language-text">Traditional:
Store current state (UPDATE users SET balance=100)
<p>Event Sourcing:
Store sequence of events
<li>UserCreated(id=1, balance=0)</li>
<li>DepositMade(id=1, amount=100)</li>
<li>WithdrawalMade(id=1, amount=20)</li></p>
<p>Current state = replay all events</p>
<p>‚úÖ Complete audit log
‚úÖ Time travel (query past state)
‚úÖ Easy debugging
‚ùå Complex queries
‚ùå More storage</code></pre></p>
<h3>CQRS (Command Query Responsibility Segregation)</h3>
<pre><code class="language-text">Command Model (Write):
<li>Optimized for writes</li>
<li>Normalized schema</li>
<li>Validates business rules</li>
<p>Query Model (Read):
<li>Optimized for reads</li>
<li>Denormalized views</li>
<li>Eventually consistent</li></p>
<p>Commands ‚Üí Write DB ‚Üí Events ‚Üí Update Read DB ‚Üí Queries</code></pre></p>
<pre><code class="language-go">// CQRS Example
type CommandHandler struct {
    writeDB *sql.DB
    eventBus *EventBus
}
<p>func (h *CommandHandler) CreateOrder(cmd CreateOrderCommand) error {
    // Validate
    // Write to DB
    _, err := h.writeDB.Exec(&quot;INSERT INTO orders (...) VALUES (...)&quot;)
    if err != nil {
        return err
    }
    
    // Publish event
    h.eventBus.Publish(OrderCreatedEvent{
        OrderID: cmd.OrderID,
        UserID:  cmd.UserID,
        // ...
    })
    
    return nil
}</p>
<p>type QueryHandler struct {
    readDB *sql.DB
}</p>
<p>func (h *QueryHandler) GetOrder(id string) (*Order, error) {
    // Read from optimized read model
    return h.readDB.QueryRow(&quot;SELECT * FROM order_views WHERE id = ?&quot;, id)
}</code></pre></p>
<p>---</p>
<h2>Microservices Patterns</h2>
<h3>Service Discovery</h3>
<pre><code class="language-text">Client-Side:
Client ‚Üí Service Registry (Consul, etcd)
       ‚Üí Get service addresses
       ‚Üí Call service directly
<p>Server-Side:
Client ‚Üí Load Balancer ‚Üí Service Registry
       ‚Üí Routes to service</code></pre></p>
<pre><code class="language-go">// Service registration (Consul)
import &quot;github.com/hashicorp/consul/api&quot;
<p>func registerService() {
    client, _ := api.NewClient(api.DefaultConfig())
    
    registration := &amp;api.AgentServiceRegistration{
        ID:      &quot;api-1&quot;,
        Name:    &quot;api&quot;,
        Port:    8080,
        Address: &quot;192.168.1.10&quot;,
        Check: &amp;api.AgentServiceCheck{
            HTTP:     &quot;http://192.168.1.10:8080/health&quot;,
            Interval: &quot;10s&quot;,
            Timeout:  &quot;2s&quot;,
        },
    }
    
    client.Agent().ServiceRegister(registration)
}</code></pre></p>
<h3>API Gateway</h3>
<pre><code class="language-text">Responsibilities:
<li>Routing</li>
<li>Authentication</li>
<li>Rate limiting</li>
<li>Request/response transformation</li>
<li>Aggregation (multiple services ‚Üí single response)</li>
<p>Examples: Kong, AWS API Gateway, Traefik</code></pre></p>
<h3>Saga Pattern (Distributed Transactions)</h3>
<pre><code class="language-text">Problem: No ACID transactions across services
<p>Choreography (Event-Driven):
Order Service ‚Üí OrderCreated event
Payment Service ‚Üí PaymentProcessed event
Inventory Service ‚Üí InventoryReserved event</p>
<p>If Payment fails ‚Üí PaymentFailed event
Inventory Service compensates ‚Üí InventoryReleased event</p>
<p>Orchestration (Coordinator):
Saga Orchestrator coordinates:
1. CreateOrder
2. ProcessPayment
3. ReserveInventory
4. ShipOrder</p>
<p>If step fails, orchestrator triggers compensating actions</code></pre></p>
<p>---</p>
<h2>Caching Strategies</h2>
<h3>Cache Patterns</h3>
<p>#### 1. Cache-Aside (Lazy Loading)</p>
<pre><code class="language-go">func GetUser(id int) (*User, error) {
    // Check cache
    cacheKey := fmt.Sprintf(&quot;user:%d&quot;, id)
    cached, err := redis.Get(cacheKey).Result()
    if err == nil {
        var user User
        json.Unmarshal([]byte(cached), &amp;user)
        return &amp;user, nil
    }
    
    // Cache miss: Query database
    user, err := db.GetUser(id)
    if err != nil {
        return nil, err
    }
    
    // Store in cache
    userData, _ := json.Marshal(user)
    redis.Set(cacheKey, userData, 1*time.Hour)
    
    return user, nil
}</code></pre>
<p>#### 2. Write-Through</p>
<pre><code class="language-go">func UpdateUser(user *User) error {
    // Write to database
    err := db.UpdateUser(user)
    if err != nil {
        return err
    }
    
    // Update cache
    cacheKey := fmt.Sprintf(&quot;user:%d&quot;, user.ID)
    userData, _ := json.Marshal(user)
    redis.Set(cacheKey, userData, 1*time.Hour)
    
    return nil
}</code></pre>
<p>#### 3. Write-Behind (Write-Back)</p>
<pre><code class="language-go">// Write to cache immediately, async write to DB
func UpdateUserAsync(user *User) error {
    // Update cache
    cacheKey := fmt.Sprintf(&quot;user:%d&quot;, user.ID)
    userData, _ := json.Marshal(user)
    redis.Set(cacheKey, userData, 1*time.Hour)
    
    // Queue for async DB write
    queue.Enqueue(DBWriteJob{
        Type: &quot;user_update&quot;,
        Data: user,
    })
    
    return nil
}</code></pre>
<h3>Cache Invalidation</h3>
<pre><code class="language-text">1. TTL (Time To Live):
   Set expiration time (1 hour, 1 day)
<p>2. Event-Based:
   On update/delete ‚Üí invalidate cache</p>
<p>3. Cache Stampede Prevention:
   Multiple requests for expired key ‚Üí single DB query
   Use mutex or probabilistic early expiration</code></pre></p>
<pre><code class="language-go">// Prevent cache stampede
var mu sync.Mutex
<p>func GetUserSafe(id int) (*User, error) {
    cacheKey := fmt.Sprintf(&quot;user:%d&quot;, id)
    
    cached, err := redis.Get(cacheKey).Result()
    if err == nil {
        var user User
        json.Unmarshal([]byte(cached), &amp;user)
        return &amp;user, nil
    }
    
    // Lock to prevent multiple DB queries
    mu.Lock()
    defer mu.Unlock()
    
    // Check again (another goroutine may have filled cache)
    cached, err = redis.Get(cacheKey).Result()
    if err == nil {
        var user User
        json.Unmarshal([]byte(cached), &amp;user)
        return &amp;user, nil
    }
    
    // Query DB
    user, err := db.GetUser(id)
    if err != nil {
        return nil, err
    }
    
    userData, _ := json.Marshal(user)
    redis.Set(cacheKey, userData, 1*time.Hour)
    
    return user, nil
}</code></pre></p>
<p>---</p>
<h2>Message Queues</h2>
<h3>Use Cases</h3>
<pre><code class="language-text">1. Async Processing: Email sending, image processing
2. Decoupling: Producer/consumer independent
3. Load Leveling: Smooth traffic spikes
4. Event Streaming: Real-time data pipelines</code></pre>
<h3>RabbitMQ Example</h3>
<pre><code class="language-go">import &quot;github.com/streadway/amqp&quot;
<p>// Producer
func publishMessage() {
    conn, _ := amqp.Dial(&quot;amqp://guest:guest@localhost:5672/&quot;)
    defer conn.Close()
    
    ch, _ := conn.Channel()
    defer ch.Close()
    
    q, _ := ch.QueueDeclare(&quot;tasks&quot;, false, false, false, false, nil)
    
    body := &quot;Process image&quot;
    ch.Publish(&quot;&quot;, q.Name, false, false, amqp.Publishing{
        ContentType: &quot;text/plain&quot;,
        Body:        []byte(body),
    })
}</p>
<p>// Consumer
func consumeMessages() {
    conn, _ := amqp.Dial(&quot;amqp://guest:guest@localhost:5672/&quot;)
    defer conn.Close()
    
    ch, _ := conn.Channel()
    defer ch.Close()
    
    q, _ := ch.QueueDeclare(&quot;tasks&quot;, false, false, false, false, nil)
    msgs, _ := ch.Consume(q.Name, &quot;&quot;, true, false, false, false, nil)
    
    for msg := range msgs {
        log.Printf(&quot;Received: %s&quot;, msg.Body)
        // Process task
    }
}</code></pre></p>
<p>---</p>
<h2>Case Studies</h2>
<h3>1. URL Shortener (like bit.ly)</h3>
<pre><code class="language-text">Requirements:
<li>Shorten long URLs</li>
<li>Redirect to original URL</li>
<li>100M URLs/month</li>
<li>Low latency (&lt;100ms)</li>
<p>Design:
1. Generate short code (base62 encode ID)
2. Store: { short_code: original_url }
3. Cache popular URLs (Redis)
4. Database sharding by hash(short_code)</p>
<p>Schema:
CREATE TABLE urls (
    id BIGSERIAL PRIMARY KEY,
    short_code VARCHAR(10) UNIQUE,
    original_url TEXT,
    created_at TIMESTAMP,
    expires_at TIMESTAMP
);</p>
<p>API:
POST /shorten ‚Üí { &quot;short_url&quot;: &quot;bit.ly/abc123&quot; }
GET /abc123   ‚Üí 301 Redirect to original URL</p>
<p>Components:
<li>API Gateway (rate limiting)</li>
<li>App Servers (generate short code, write DB)</li>
<li>PostgreSQL (sharded)</li>
<li>Redis (cache popular URLs)</li>
<li>CDN (serve redirects)</code></pre></li></p>
<h3>2. Twitter Timeline</h3>
<pre><code class="language-text">Requirements:
<li>User follows other users</li>
<li>View home timeline (posts from followees)</li>
<li>100M active users</li>
<li>Read-heavy (100:1 read:write)</li>
<p>Design:
1. Fan-out on write (pre-compute timelines)
   When user posts ‚Üí write to followers&#039; timelines
   
2. Fan-out on read (query on demand)
   When user views ‚Üí query posts from followees</p>
<p>Hybrid:
<li>Celebrities: Fan-out on read (millions of followers)</li>
<li>Regular users: Fan-out on write</li></p>
<p>Schema:
users(id, username)
follows(follower_id, followee_id)
tweets(id, user_id, content, created_at)
timelines(user_id, tweet_id, created_at)  # Pre-computed</p>
<p>Cache:
Redis: timeline:{user_id} ‚Üí List of tweet IDs (last 100)</code></pre></p>
<h3>3. Rate Limiter</h3>
<pre><code class="language-text">Requirements:
<li>Limit API calls per user</li>
<li>100 requests/minute per user</li>
<li>Distributed system</li>
<p>Algorithms:
1. Fixed Window:
   Count requests in current minute
   Reset at start of next minute
   Problem: Burst at window boundary</p>
<p>2. Sliding Window Log:
   Store timestamp of each request
   Count requests in last minute
   Memory intensive</p>
<p>3. Token Bucket:
   Bucket holds tokens (capacity = 100)
   Refill tokens at fixed rate (100/min)
   Request consumes token
   Reject if no tokens</p>
<p>Implementation (Redis):</code></pre></p>
<pre><code class="language-go">func isAllowed(userID string) bool {
    key := fmt.Sprintf(&quot;rate_limit:%s&quot;, userID)
    
    // Increment counter
    count, _ := redis.Incr(key).Result()
    
    // Set expiration on first request
    if count == 1 {
        redis.Expire(key, 1*time.Minute)
    }
    
    return count &lt;= 100
}
<p>// Token bucket (Redis Lua script)
script := <code>
local key = KEYS[1]
local capacity = tonumber(ARGV[1])
local rate = tonumber(ARGV[2])
local requested = tonumber(ARGV[3])</p>
<p>local tokens = redis.call(&#039;GET&#039;, key)
if tokens == false then
    tokens = capacity
end
tokens = tonumber(tokens)</p>
<p>local now = redis.call(&#039;TIME&#039;)
local timestamp_key = key .. &#039;:timestamp&#039;
local last_refill = redis.call(&#039;GET&#039;, timestamp_key)</p>
<p>if last_refill then
    local elapsed = now[1] - last_refill
    tokens = math.min(capacity, tokens + elapsed * rate)
end</p>
<p>redis.call(&#039;SET&#039;, timestamp_key, now[1])</p>
<p>if tokens &gt;= requested then
    tokens = tokens - requested
    redis.call(&#039;SET&#039;, key, tokens)
    return 1
else
    redis.call(&#039;SET&#039;, key, tokens)
    return 0
end
</code></code></pre></p>
<p>---</p>
<h2>Interview Questions</h2>
<strong>Q1: How would you design a system to handle 1 million concurrent users?</strong>
<strong>Answer:</strong>
1. <strong>Horizontal scaling</strong>: Load balancer ‚Üí Multiple app servers
2. <strong>Caching</strong>: Redis for hot data (user sessions, frequently accessed)
3. <strong>Database</strong>: Read replicas (master-slave), sharding for writes
4. <strong>Async processing</strong>: Message queue for non-critical tasks
5. <strong>CDN</strong>: Static assets (images, CSS, JS)
6. <strong>Auto-scaling</strong>: Based on CPU/memory metrics
7. <strong>Monitoring</strong>: Track performance, errors, capacity
<strong>Q2: Explain consistency vs availability tradeoff.</strong>
<strong>Answer:</strong> CAP theorem - in distributed system with network partition, choose consistency OR availability:
<li><strong>Consistency</strong>: All nodes return same data. Wait for all replicas to sync. May reject requests during partition.</li>
<li><strong>Availability</strong>: System always responds. May return stale data during partition.</li>
Example: Banking (consistency), social media (availability).
<strong>Q3: How do you handle database migrations with zero downtime?</strong>
<strong>Answer:</strong>
1. <strong>Backward compatible changes</strong>: Add columns (nullable), create tables
2. <strong>Deploy new code</strong> (reads new/old schema)
3. <strong>Run migration</strong> (add column, backfill data)
4. <strong>Deploy again</strong> (remove old code)
5. <strong>Blue-green deployment</strong>: Migrate copy of DB, switch traffic
<strong>Q4: Design a system to detect trending topics (like Twitter).</strong>
<strong>Answer:</strong>
1. <strong>Stream processing</strong>: Kafka consumes tweets in real-time
2. <strong>Windowing</strong>: Count hashtags in sliding windows (1min, 5min, 15min)
3. <strong>Anomaly detection</strong>: Spike in frequency compared to historical baseline
4. <strong>Ranking</strong>: Score = frequency √ó growth rate √ó recency
5. <strong>Cache</strong>: Redis stores top 100 trending topics
6. <strong>Update</strong>: Every 30 seconds, recompute and update cache
<strong>Q5: How would you debug a production outage?</strong>
<strong>Answer:</strong>
1. <strong>Check monitoring</strong>: Dashboards (Grafana), alerts, error rates
2. <strong>Logs</strong>: Centralized logging (ELK), search for errors around incident time
3. <strong>Tracing</strong>: Distributed tracing (Jaeger) to identify slow service
4. <strong>Metrics</strong>: CPU, memory, disk, network - identify bottleneck
5. <strong>Recent changes</strong>: Check deployments, config changes
6. <strong>Reproduce</strong>: Try to reproduce in staging
7. <strong>Rollback</strong>: If recent deploy, rollback immediately
8. <strong>Root cause</strong>: After mitigation, deep dive and postmortem
<p>---</p>
<h2>Hands-On Exercise</h2>
<h3>Task: Design Scalable E-Commerce System</h3>
<pre><code class="language-text">Requirements:
<li>1M products</li>
<li>10M users</li>
<li>1000 orders/minute peak</li>
<li>Product search</li>
<li>Inventory management</li>
<li>Payment processing</li>
<p>Components:
1. User Service (PostgreSQL)
2. Product Service (PostgreSQL + Elasticsearch)
3. Order Service (PostgreSQL + Kafka)
4. Inventory Service (PostgreSQL)
5. Payment Service (external API)
6. Notification Service (email/SMS)</p>
<p>Architecture:</code></pre></p>
<pre><code class="language-text">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   CDN       ‚îÇ  Static assets
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Load Balancer (Nginx)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   API Gateway               ‚îÇ  Auth, rate limiting
‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
   ‚îÇ
   ‚îú‚îÄ‚ñ∫ User Service ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ PostgreSQL
   ‚îÇ                         (user data)
   ‚îÇ
   ‚îú‚îÄ‚ñ∫ Product Service ‚îÄ‚îÄ‚ñ∫ PostgreSQL + Elasticsearch
   ‚îÇ                         (products + search)
   ‚îÇ
   ‚îú‚îÄ‚ñ∫ Order Service ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ PostgreSQL + Kafka
   ‚îÇ                         (orders + events)
   ‚îÇ
   ‚îú‚îÄ‚ñ∫ Inventory Service ‚ñ∫ PostgreSQL + Redis
   ‚îÇ                         (stock + cache)
   ‚îÇ
   ‚îî‚îÄ‚ñ∫ Payment Service ‚îÄ‚îÄ‚ñ∫ External API
                           (Stripe, PayPal)
<p>Kafka Events:
<li>OrderCreated ‚Üí Inventory Service (reserve stock)</li>
<li>OrderCreated ‚Üí Payment Service (charge card)</li>
<li>PaymentSucceeded ‚Üí Inventory Service (confirm)</li>
<li>PaymentFailed ‚Üí Inventory Service (release stock)</li>
<li>OrderShipped ‚Üí Notification Service (email)</code></pre></li></p>
<h3>Implementation Outline</h3>
<pre><code class="language-go">// Order Service
func CreateOrder(order Order) error {
    // 1. Validate
    if err := validateOrder(order); err != nil {
        return err
    }
    
    // 2. Save to database
    tx, _ := db.Begin()
    _, err := tx.Exec(&quot;INSERT INTO orders (...) VALUES (...)&quot;)
    if err != nil {
        tx.Rollback()
        return err
    }
    tx.Commit()
    
    // 3. Publish event (async)
    kafka.Publish(&quot;order-created&quot;, OrderCreatedEvent{
        OrderID:   order.ID,
        UserID:    order.UserID,
        ProductID: order.ProductID,
        Quantity:  order.Quantity,
    })
    
    return nil
}
<p>// Inventory Service (consumer)
func HandleOrderCreated(event OrderCreatedEvent) {
    // Reserve stock
    _, err := db.Exec(<code>
        UPDATE inventory 
        SET reserved = reserved + $1 
        WHERE product_id = $2 AND available &gt;= $1
    </code>, event.Quantity, event.ProductID)
    
    if err != nil {
        // Insufficient stock
        kafka.Publish(&quot;inventory-insufficient&quot;, event)
        return
    }
    
    // Clear cache
    redis.Del(fmt.Sprintf(&quot;inventory:%d&quot;, event.ProductID))
    
    kafka.Publish(&quot;inventory-reserved&quot;, event)
}</code></pre></p>
<p>---</p>
<h2>üìö Additional Resources</h2>
<li>[System Design Primer (GitHub)](https://github.com/donnemartin/system-design-primer)</li>
<li>[Designing Data-Intensive Applications](https://dataintensive.net/)</li>
<li>[High Scalability Blog](http://highscalability.com/)</li>
<li>[AWS Architecture Center](https://aws.amazon.com/architecture/)</li>
<p>---</p>
<h2>‚úÖ Module Checklist</h2>
<li>[ ] Understand CAP theorem and ACID vs BASE</li>
<li>[ ] Design for horizontal scalability</li>
<li>[ ] Implement circuit breaker and retry patterns</li>
<li>[ ] Choose appropriate caching strategy</li>
<li>[ ] Design microservices architecture</li>
<li>[ ] Use message queues for async processing</li>
<li>[ ] Complete system design case studies</li>
<li>[ ] Design scalable e-commerce system</li></ul>
<p>---</p>
<strong>üéâ Infrastructure Section Complete! (5/5 modules)</strong>
<p>Progress: <strong>16/30 modules (53%)</strong></p>
<p>Ready to continue with <strong>Part 4: Microservices Architecture</strong>? üöÄ</p>
<strong>Next Module:</strong> [Module 17: Microservices Architecture](./17_Microservices_Architecture.md) - Build distributed systems! üîÑ

    </div>
    

    <div class="module-content" id="module-17">
        <h1>Module 17: Microservices Architecture üîÑ</h1>
<h2>Build Scalable Distributed Systems with Microservices</h2>
<strong>Duration:</strong> 6-7 hours  
<strong>Prerequisites:</strong> Module 16 (System Design), Go REST APIs, Docker basics  
<strong>Outcome:</strong> Design, build, and deploy production-ready microservices
<p>---</p>
<h2>üìö Table of Contents</h2>
<p>1. [Microservices Overview](#microservices-overview)
2. [Service Design Principles](#service-design-principles)
3. [Service Communication](#service-communication)
4. [API Gateway](#api-gateway)
5. [Service Discovery](#service-discovery)
6. [Circuit Breaker](#circuit-breaker)
7. [Service Mesh](#service-mesh)
8. [Data Management](#data-management)
9. [Best Practices](#best-practices)
10. [Interview Questions](#interview-questions)
11. [Hands-On Exercise](#hands-on-exercise)</p>
<p>---</p>
<h2>Microservices Overview</h2>
<h3>Monolith vs Microservices</h3>
<pre><code class="language-text">MONOLITH:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      Single Application     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ Auth ‚îÇOrders‚îÇUsers ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ          ‚Üì                  ‚îÇ
‚îÇ    Single Database          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
<p>‚úÖ Simple deployment
‚úÖ Easy local development
‚ùå Tight coupling
‚ùå Hard to scale specific features
‚ùå Technology stack locked</p>
<p>MICROSERVICES:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇAuth Svc  ‚îÇ  ‚îÇOrder Svc ‚îÇ  ‚îÇUser Svc  ‚îÇ
‚îÇ   ‚Üì      ‚îÇ  ‚îÇ   ‚Üì      ‚îÇ  ‚îÇ   ‚Üì      ‚îÇ
‚îÇAuth DB   ‚îÇ  ‚îÇOrder DB  ‚îÇ  ‚îÇUser DB   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           API Gateway</p>
<p>‚úÖ Independent deployment
‚úÖ Technology diversity
‚úÖ Scalable per service
‚ùå Complex operations
‚ùå Distributed system challenges</code></pre></p>
<h3>When to Use Microservices</h3>
<pre><code class="language-text">‚úÖ Large team (&gt;50 developers)
‚úÖ Need independent scaling
‚úÖ Different technology requirements
‚úÖ Frequent deployments
‚úÖ Complex domain (bounded contexts)
<p>‚ùå Small team (&lt;10 developers)
‚ùå Simple application
‚ùå Tight coupling between features
‚ùå Limited DevOps expertise</code></pre></p>
<p>---</p>
<h2>Service Design Principles</h2>
<h3>1. Single Responsibility</h3>
<pre><code class="language-text">Each service owns one business capability:
<p>‚úÖ User Service: User management
‚úÖ Order Service: Order processing
‚úÖ Payment Service: Payment handling
‚úÖ Notification Service: Email/SMS</p>
<p>‚ùå UserOrderPayment Service (too much)</code></pre></p>
<h3>2. Bounded Context (DDD)</h3>
<pre><code class="language-text">Define clear boundaries:
<p>User Context:
<ul><li>User registration</li>
<li>User profiles</li>
<li>Authentication</li></p>
<p>Order Context:
<li>Order creation</li>
<li>Order tracking</li>
<li>Order history</li></p>
<p>Each context = separate service</code></pre></p>
<h3>3. Service Structure</h3>
<pre><code class="language-text">user-service/
‚îú‚îÄ‚îÄ cmd/
‚îÇ   ‚îî‚îÄ‚îÄ server/
‚îÇ       ‚îî‚îÄ‚îÄ main.go           # Entry point
‚îú‚îÄ‚îÄ internal/
‚îÇ   ‚îú‚îÄ‚îÄ handlers/             # HTTP handlers
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ user_handler.go
‚îÇ   ‚îú‚îÄ‚îÄ service/              # Business logic
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ user_service.go
‚îÇ   ‚îú‚îÄ‚îÄ repository/           # Data access
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ user_repository.go
‚îÇ   ‚îî‚îÄ‚îÄ models/               # Domain models
‚îÇ       ‚îî‚îÄ‚îÄ user.go
‚îú‚îÄ‚îÄ pkg/                      # Shared packages
‚îÇ   ‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ logger/
‚îÇ   ‚îî‚îÄ‚îÄ middleware/
‚îú‚îÄ‚îÄ api/                      # API definitions
‚îÇ   ‚îî‚îÄ‚îÄ openapi.yaml
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ docker-compose.yml
‚îî‚îÄ‚îÄ go.mod</code></pre>
<p>---</p>
<h2>Service Communication</h2>
<h3>Synchronous (HTTP/gRPC)</h3>
<p>#### REST API</p>
<pre><code class="language-go">// user-service/internal/handlers/user_handler.go
package handlers
<p>import (
    &quot;encoding/json&quot;
    &quot;net/http&quot;
    &quot;github.com/gorilla/mux&quot;
)</p>
<p>type UserHandler struct {
    service UserService
}</p>
<p>func (h *UserHandler) GetUser(w http.ResponseWriter, r *http.Request) {
    vars := mux.Vars(r)
    userID := vars[&quot;id&quot;]
    
    user, err := h.service.GetUser(userID)
    if err != nil {
        http.Error(w, err.Error(), http.StatusNotFound)
        return
    }
    
    json.NewEncoder(w).Encode(user)
}</p>
<p>func (h *UserHandler) CreateUser(w http.ResponseWriter, r *http.Request) {
    var user User
    if err := json.NewDecoder(r.Body).Decode(&amp;user); err != nil {
        http.Error(w, err.Error(), http.StatusBadRequest)
        return
    }
    
    created, err := h.service.CreateUser(&amp;user)
    if err != nil {
        http.Error(w, err.Error(), http.StatusInternalServerError)
        return
    }
    
    w.WriteHeader(http.StatusCreated)
    json.NewEncoder(w).Encode(created)
}</p>
<p>// Register routes
func (h *UserHandler) RegisterRoutes(r *mux.Router) {
    r.HandleFunc(&quot;/users/{id}&quot;, h.GetUser).Methods(&quot;GET&quot;)
    r.HandleFunc(&quot;/users&quot;, h.CreateUser).Methods(&quot;POST&quot;)
}</code></pre></p>
<p>#### gRPC (High Performance)</p>
<pre><code class="language-protobuf">// api/user.proto
syntax = &quot;proto3&quot;;
<p>package user;</p>
<p>service UserService {
  rpc GetUser(GetUserRequest) returns (UserResponse);
  rpc CreateUser(CreateUserRequest) returns (UserResponse);
}</p>
<p>message GetUserRequest {
  string id = 1;
}</p>
<p>message CreateUserRequest {
  string username = 1;
  string email = 2;
}</p>
<p>message UserResponse {
  string id = 1;
  string username = 2;
  string email = 3;
  string created_at = 4;
}</code></pre></p>
<pre><code class="language-go">// Generate code: protoc --go_out=. --go-grpc_out=. api/user.proto
<p>// Server implementation
type server struct {
    pb.UnimplementedUserServiceServer
    userService UserService
}</p>
<p>func (s *server) GetUser(ctx context.Context, req *pb.GetUserRequest) (*pb.UserResponse, error) {
    user, err := s.userService.GetUser(req.Id)
    if err != nil {
        return nil, err
    }
    
    return &amp;pb.UserResponse{
        Id:        user.ID,
        Username:  user.Username,
        Email:     user.Email,
        CreatedAt: user.CreatedAt.String(),
    }, nil
}</p>
<p>// Start gRPC server
func main() {
    lis, _ := net.Listen(&quot;tcp&quot;, &quot;:50051&quot;)
    grpcServer := grpc.NewServer()
    pb.RegisterUserServiceServer(grpcServer, &amp;server{})
    grpcServer.Serve(lis)
}</code></pre></p>
<h3>Asynchronous (Message Queue)</h3>
<pre><code class="language-go">// Order service publishes event
import &quot;github.com/streadway/amqp&quot;
<p>func PublishOrderCreated(orderID string) error {
    conn, _ := amqp.Dial(&quot;amqp://guest:guest@rabbitmq:5672/&quot;)
    defer conn.Close()
    
    ch, _ := conn.Channel()
    defer ch.Close()
    
    event := OrderCreatedEvent{
        OrderID:   orderID,
        UserID:    &quot;user123&quot;,
        Timestamp: time.Now(),
    }
    
    body, _ := json.Marshal(event)
    
    return ch.Publish(
        &quot;orders&quot;,           // exchange
        &quot;order.created&quot;,    // routing key
        false,
        false,
        amqp.Publishing{
            ContentType: &quot;application/json&quot;,
            Body:        body,
        },
    )
}</p>
<p>// Notification service consumes event
func ConsumeOrderEvents() {
    conn, _ := amqp.Dial(&quot;amqp://guest:guest@rabbitmq:5672/&quot;)
    defer conn.Close()
    
    ch, _ := conn.Channel()
    defer ch.Close()
    
    msgs, _ := ch.Consume(
        &quot;order-notifications&quot;, // queue
        &quot;&quot;,                    // consumer
        true,                  // auto-ack
        false,
        false,
        false,
        nil,
    )
    
    for msg := range msgs {
        var event OrderCreatedEvent
        json.Unmarshal(msg.Body, &amp;event)
        
        // Send notification
        sendEmail(event.UserID, &quot;Order created: &quot;+event.OrderID)
    }
}</code></pre></p>
<p>---</p>
<h2>API Gateway</h2>
<h3>What is API Gateway?</h3>
<strong>Single entry point</strong> for all client requests. Routes to appropriate microservices.
<h3>Responsibilities</h3>
<pre><code class="language-text">1. Routing:           Client ‚Üí Gateway ‚Üí Service
2. Authentication:    Verify JWT tokens
3. Rate Limiting:     Prevent abuse
4. Load Balancing:    Distribute requests
5. Request/Response:  Transform data
6. Caching:           Cache responses
7. Logging:           Centralized logging</code></pre>
<h3>Implementation with Gin</h3>
<pre><code class="language-go">// api-gateway/main.go
package main
<p>import (
    &quot;github.com/gin-gonic/gin&quot;
    &quot;net/http&quot;
    &quot;net/http/httputil&quot;
    &quot;net/url&quot;
)</p>
<p>type Gateway struct {
    userServiceURL    *url.URL
    orderServiceURL   *url.URL
    productServiceURL *url.URL
}</p>
<p>func NewGateway() *Gateway {
    userURL, _ := url.Parse(&quot;http://user-service:8080&quot;)
    orderURL, _ := url.Parse(&quot;http://order-service:8080&quot;)
    productURL, _ := url.Parse(&quot;http://product-service:8080&quot;)
    
    return &amp;Gateway{
        userServiceURL:    userURL,
        orderServiceURL:   orderURL,
        productServiceURL: productURL,
    }
}</p>
<p>func (g *Gateway) proxyTo(target *url.URL) gin.HandlerFunc {
    return func(c *gin.Context) {
        proxy := httputil.NewSingleHostReverseProxy(target)
        proxy.Director = func(req *http.Request) {
            req.Header = c.Request.Header
            req.Host = target.Host
            req.URL.Scheme = target.Scheme
            req.URL.Host = target.Host
            req.URL.Path = c.Request.URL.Path
        }
        
        proxy.ServeHTTP(c.Writer, c.Request)
    }
}</p>
<p>// Authentication middleware
func AuthMiddleware() gin.HandlerFunc {
    return func(c *gin.Context) {
        token := c.GetHeader(&quot;Authorization&quot;)
        if token == &quot;&quot; {
            c.JSON(http.StatusUnauthorized, gin.H{&quot;error&quot;: &quot;No token&quot;})
            c.Abort()
            return
        }
        
        // Validate JWT (simplified)
        if !validateToken(token) {
            c.JSON(http.StatusUnauthorized, gin.H{&quot;error&quot;: &quot;Invalid token&quot;})
            c.Abort()
            return
        }
        
        c.Next()
    }
}</p>
<p>// Rate limiting middleware
func RateLimitMiddleware() gin.HandlerFunc {
    return func(c *gin.Context) {
        // Implement rate limiting logic
        c.Next()
    }
}</p>
<p>func main() {
    gateway := NewGateway()
    r := gin.Default()
    
    // Global middlewares
    r.Use(RateLimitMiddleware())
    
    // Public routes
    r.POST(&quot;/auth/login&quot;, gateway.proxyTo(gateway.userServiceURL))
    r.POST(&quot;/auth/register&quot;, gateway.proxyTo(gateway.userServiceURL))
    
    // Protected routes
    protected := r.Group(&quot;/&quot;)
    protected.Use(AuthMiddleware())
    {
        // User service
        protected.GET(&quot;/users/:id&quot;, gateway.proxyTo(gateway.userServiceURL))
        protected.PUT(&quot;/users/:id&quot;, gateway.proxyTo(gateway.userServiceURL))
        
        // Order service
        protected.GET(&quot;/orders&quot;, gateway.proxyTo(gateway.orderServiceURL))
        protected.POST(&quot;/orders&quot;, gateway.proxyTo(gateway.orderServiceURL))
        
        // Product service
        protected.GET(&quot;/products&quot;, gateway.proxyTo(gateway.productServiceURL))
        protected.GET(&quot;/products/:id&quot;, gateway.proxyTo(gateway.productServiceURL))
    }
    
    r.Run(&quot;:8000&quot;)
}</code></pre></p>
<p>---</p>
<h2>Service Discovery</h2>
<h3>What is Service Discovery?</h3>
<strong>Automatic detection</strong> of service instances. Services register themselves, clients discover them.
<h3>Consul Example</h3>
<pre><code class="language-go">// Register service with Consul
import &quot;github.com/hashicorp/consul/api&quot;
<p>func RegisterService() error {
    config := api.DefaultConfig()
    config.Address = &quot;consul:8500&quot;
    
    client, err := api.NewClient(config)
    if err != nil {
        return err
    }
    
    registration := &amp;api.AgentServiceRegistration{
        ID:      &quot;user-service-1&quot;,
        Name:    &quot;user-service&quot;,
        Port:    8080,
        Address: &quot;192.168.1.10&quot;,
        Tags:    []string{&quot;v1&quot;, &quot;production&quot;},
        Check: &amp;api.AgentServiceCheck{
            HTTP:     &quot;http://192.168.1.10:8080/health&quot;,
            Interval: &quot;10s&quot;,
            Timeout:  &quot;2s&quot;,
        },
    }
    
    return client.Agent().ServiceRegister(registration)
}</p>
<p>// Discover service
func DiscoverService(serviceName string) (string, error) {
    config := api.DefaultConfig()
    client, _ := api.NewClient(config)
    
    services, _, err := client.Health().Service(serviceName, &quot;&quot;, true, nil)
    if err != nil {
        return &quot;&quot;, err
    }
    
    if len(services) == 0 {
        return &quot;&quot;, errors.New(&quot;no healthy instances&quot;)
    }
    
    // Simple round-robin (use real LB in production)
    service := services[0]
    address := fmt.Sprintf(&quot;http://%s:%d&quot;, service.Service.Address, service.Service.Port)
    
    return address, nil
}</p>
<p>// Usage
func CallUserService() {
    serviceURL, _ := DiscoverService(&quot;user-service&quot;)
    resp, _ := http.Get(serviceURL + &quot;/users/123&quot;)
    // ...
}</code></pre></p>
<p>---</p>
<h2>Circuit Breaker</h2>
<h3>Why Circuit Breaker?</h3>
<strong>Prevent cascading failures</strong>. If service is down, fail fast instead of waiting for timeout.
<h3>States</h3>
<pre><code class="language-text">CLOSED (Normal):
<li>Requests pass through</li>
<li>Failures counted</li>
<li>If failures &gt; threshold ‚Üí OPEN</li>
<p>OPEN (Failing):
<li>Requests immediately rejected</li>
<li>After timeout ‚Üí HALF_OPEN</li></p>
<p>HALF_OPEN (Testing):
<li>Limited requests allowed</li>
<li>If success ‚Üí CLOSED</li>
<li>If failure ‚Üí OPEN</code></pre></li></p>
<h3>Implementation</h3>
<pre><code class="language-go">package circuitbreaker
<p>import (
    &quot;errors&quot;
    &quot;sync&quot;
    &quot;time&quot;
)</p>
<p>type State int</p>
<p>const (
    StateClosed State = iota
    StateOpen
    StateHalfOpen
)</p>
<p>type CircuitBreaker struct {
    maxFailures  int
    timeout      time.Duration
    state        State
    failures     int
    lastFailTime time.Time
    mu           sync.Mutex
}</p>
<p>func New(maxFailures int, timeout time.Duration) *CircuitBreaker {
    return &amp;CircuitBreaker{
        maxFailures: maxFailures,
        timeout:     timeout,
        state:       StateClosed,
    }
}</p>
<p>func (cb *CircuitBreaker) Call(fn func() error) error {
    cb.mu.Lock()
    
    // Check if we should transition from OPEN to HALF_OPEN
    if cb.state == StateOpen {
        if time.Since(cb.lastFailTime) &gt; cb.timeout {
            cb.state = StateHalfOpen
            cb.failures = 0
        } else {
            cb.mu.Unlock()
            return errors.New(&quot;circuit breaker is open&quot;)
        }
    }
    
    cb.mu.Unlock()
    
    // Try the call
    err := fn()
    
    cb.mu.Lock()
    defer cb.mu.Unlock()
    
    if err != nil {
        cb.failures++
        cb.lastFailTime = time.Now()
        
        if cb.failures &gt;= cb.maxFailures {
            cb.state = StateOpen
        }
        return err
    }
    
    // Success - reset to CLOSED
    cb.state = StateClosed
    cb.failures = 0
    
    return nil
}</p>
<p>// Usage
var userServiceCB = circuitbreaker.New(5, 30*time.Second)</p>
<p>func GetUser(id string) (*User, error) {
    var user *User
    
    err := userServiceCB.Call(func() error {
        resp, err := http.Get(&quot;http://user-service/users/&quot; + id)
        if err != nil {
            return err
        }
        defer resp.Body.Close()
        
        if resp.StatusCode != 200 {
            return errors.New(&quot;user service error&quot;)
        }
        
        return json.NewDecoder(resp.Body).Decode(&amp;user)
    })
    
    return user, err
}</code></pre></p>
<p>---</p>
<h2>Service Mesh</h2>
<h3>What is Service Mesh?</h3>
<strong>Infrastructure layer</strong> for service-to-service communication. Handles networking, security, observability.
<h3>Istio Architecture</h3>
<pre><code class="language-text">Application Pod:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  App Container          ‚îÇ
‚îÇ  (user-service:8080)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Envoy Sidecar Proxy    ‚îÇ  ‚Üê Injected by Istio
‚îÇ  (intercepts traffic)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
<p>Control Plane (Istiod):
<li>Traffic Management</li>
<li>Security (mTLS)</li>
<li>Observability</code></pre></li></p>
<h3>Deploy with Istio</h3>
<pre><code class="language-yaml"># user-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: user-service
spec:
  selector:
    app: user-service
  ports:
    - port: 8080
<p>---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: user-service
spec:
  replicas: 3
  selector:
    matchLabels:
      app: user-service
  template:
    metadata:
      labels:
        app: user-service
    spec:
      containers:
        - name: user-service
          image: user-service:1.0
          ports:
            - containerPort: 8080</code></pre></p>
<h3>Traffic Splitting (Canary)</h3>
<pre><code class="language-yaml"># VirtualService for canary deployment
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: user-service
spec:
  hosts:
    - user-service
  http:
    - match:
        - headers:
            user-agent:
              regex: &quot;.*Mobile.*&quot;
      route:
        - destination:
            host: user-service
            subset: v2
          weight: 100
    - route:
        - destination:
            host: user-service
            subset: v1
          weight: 90
        - destination:
            host: user-service
            subset: v2
          weight: 10  # 10% traffic to v2
<p>---
apiVersion: networking.istio.io/v1beta1
kind: DestinationRule
metadata:
  name: user-service
spec:
  host: user-service
  subsets:
    - name: v1
      labels:
        version: v1
    - name: v2
      labels:
        version: v2</code></pre></p>
<h3>Circuit Breaking (Istio)</h3>
<pre><code class="language-yaml">apiVersion: networking.istio.io/v1beta1
kind: DestinationRule
metadata:
  name: user-service
spec:
  host: user-service
  trafficPolicy:
    connectionPool:
      tcp:
        maxConnections: 100
      http:
        http1MaxPendingRequests: 50
        maxRequestsPerConnection: 2
    outlierDetection:
      consecutiveErrors: 5
      interval: 30s
      baseEjectionTime: 30s
      maxEjectionPercent: 50</code></pre>
<p>---</p>
<h2>Data Management</h2>
<h3>Database Per Service</h3>
<pre><code class="language-text">user-service ‚Üí user_db (PostgreSQL)
order-service ‚Üí order_db (PostgreSQL)
product-service ‚Üí product_db (MongoDB)</code></pre>
<h3>Handling Distributed Transactions</h3>
<p>#### Saga Pattern</p>
<pre><code class="language-go">// Order creation saga
type OrderSaga struct {
    orderService    OrderService
    paymentService  PaymentService
    inventoryService InventoryService
}
<p>func (s *OrderSaga) CreateOrder(order *Order) error {
    // Step 1: Create order
    orderID, err := s.orderService.Create(order)
    if err != nil {
        return err
    }
    
    // Step 2: Process payment
    err = s.paymentService.Charge(order.UserID, order.Total)
    if err != nil {
        // Compensate: Cancel order
        s.orderService.Cancel(orderID)
        return err
    }
    
    // Step 3: Reserve inventory
    err = s.inventoryService.Reserve(order.ProductID, order.Quantity)
    if err != nil {
        // Compensate: Refund payment
        s.paymentService.Refund(order.UserID, order.Total)
        // Compensate: Cancel order
        s.orderService.Cancel(orderID)
        return err
    }
    
    // Success - confirm order
    s.orderService.Confirm(orderID)
    return nil
}</code></pre></p>
<h3>Event Sourcing</h3>
<pre><code class="language-go">// Store events instead of current state
type Event struct {
    AggregateID string
    Type        string
    Data        json.RawMessage
    Timestamp   time.Time
}
<p>type OrderEvents struct {
    OrderCreated  Event
    PaymentCharged Event
    OrderShipped  Event
}</p>
<p>// Rebuild state from events
func ReconstructOrder(orderID string) (*Order, error) {
    events, _ := eventStore.GetEvents(orderID)
    
    order := &amp;Order{ID: orderID}
    
    for _, event := range events {
        switch event.Type {
        case &quot;OrderCreated&quot;:
            var data OrderCreatedData
            json.Unmarshal(event.Data, &amp;data)
            order.UserID = data.UserID
            order.Total = data.Total
            
        case &quot;PaymentCharged&quot;:
            order.Status = &quot;paid&quot;
            
        case &quot;OrderShipped&quot;:
            order.Status = &quot;shipped&quot;
        }
    }
    
    return order, nil
}</code></pre></p>
<p>---</p>
<h2>Best Practices</h2>
<h3>1. Service Independence</h3>
<pre><code class="language-text">‚úÖ Each service has own database
‚úÖ No shared libraries (except contracts)
‚úÖ Independent deployment
‚úÖ Backward compatible APIs
<p>‚ùå Shared database
‚ùå Tight coupling
‚ùå Synchronous dependencies</code></pre></p>
<h3>2. API Versioning</h3>
<pre><code class="language-go">// URL versioning
r.HandleFunc(&quot;/v1/users/{id}&quot;, GetUserV1)
r.HandleFunc(&quot;/v2/users/{id}&quot;, GetUserV2)
<p>// Header versioning
if r.Header.Get(&quot;API-Version&quot;) == &quot;2&quot; {
    GetUserV2(w, r)
} else {
    GetUserV1(w, r)
}</code></pre></p>
<h3>3. Health Checks</h3>
<pre><code class="language-go">func HealthCheck(w http.ResponseWriter, r *http.Request) {
    health := map[string]string{
        &quot;status&quot;: &quot;healthy&quot;,
        &quot;timestamp&quot;: time.Now().String(),
    }
    
    // Check dependencies
    if err := db.Ping(); err != nil {
        health[&quot;status&quot;] = &quot;unhealthy&quot;
        health[&quot;database&quot;] = &quot;unreachable&quot;
        w.WriteHeader(http.StatusServiceUnavailable)
    }
    
    json.NewEncoder(w).Encode(health)
}</code></pre>
<h3>4. Structured Logging</h3>
<pre><code class="language-go">import &quot;github.com/sirupsen/logrus&quot;
<p>log := logrus.WithFields(logrus.Fields{
    &quot;service&quot;: &quot;user-service&quot;,
    &quot;request_id&quot;: requestID,
    &quot;user_id&quot;: userID,
})</p>
<p>log.Info(&quot;User created successfully&quot;)
log.WithError(err).Error(&quot;Failed to create user&quot;)</code></pre></p>
<h3>5. Distributed Tracing</h3>
<pre><code class="language-go">import &quot;go.opentelemetry.io/otel&quot;
<p>func GetUser(ctx context.Context, id string) (*User, error) {
    ctx, span := otel.Tracer(&quot;user-service&quot;).Start(ctx, &quot;GetUser&quot;)
    defer span.End()
    
    span.SetAttributes(attribute.String(&quot;user.id&quot;, id))
    
    // Database call
    user, err := db.GetUser(ctx, id)
    if err != nil {
        span.RecordError(err)
        return nil, err
    }
    
    return user, nil
}</code></pre></p>
<p>---</p>
<h2>Interview Questions</h2>
<strong>Q1: Microservices vs Monolith - when to use each?</strong>
<strong>Answer:</strong>
<li><strong>Monolith</strong>: Small team, simple domain, tight coupling acceptable, startup phase</li>
<li><strong>Microservices</strong>: Large team, complex domain, independent scaling needed, polyglot persistence</li>
<p>Monolith is simpler initially, microservices scale better organizationally.</p>
<strong>Q2: How do you handle transactions across microservices?</strong>
<strong>Answer:</strong> Use Saga pattern:
<li><strong>Choreography</strong>: Services emit events, others react (decentralized)</li>
<li><strong>Orchestration</strong>: Central coordinator (more control, easier debugging)</li>
Implement compensating transactions for rollback. Avoid distributed transactions (2PC) - performance penalty.
<strong>Q3: What is API Gateway and why use it?</strong>
<strong>Answer:</strong> Single entry point for clients. Benefits:
<li>Authentication/authorization in one place</li>
<li>Rate limiting</li>
<li>Request routing to services</li>
<li>Response aggregation (multiple services ‚Üí one response)</li>
<li>Protocol translation (HTTP ‚Üí gRPC)</li>
Examples: Kong, AWS API Gateway, custom (Nginx/Envoy).
<strong>Q4: Explain service mesh.</strong>
<strong>Answer:</strong> Infrastructure layer for service communication. Sidecar proxy (Envoy) intercepts all traffic. Provides:
<li>mTLS encryption</li>
<li>Traffic management (canary, blue-green)</li>
<li>Circuit breaking, retries</li>
<li>Observability (metrics, traces)</li>
Examples: Istio, Linkerd, Consul Connect.
<strong>Q5: How do you test microservices?</strong>
<strong>Answer:</strong>
1. <strong>Unit tests</strong>: Individual functions
2. <strong>Integration tests</strong>: Service + database
3. <strong>Contract tests</strong>: API contracts (Pact)
4. <strong>E2E tests</strong>: Full flow across services
5. <strong>Chaos testing</strong>: Random service failures (Chaos Monkey)
<p>Use test doubles (mocks) for dependencies in integration tests.</p>
<p>---</p>
<h2>Hands-On Exercise</h2>
<h3>Task: Build E-Commerce Microservices</h3>
<pre><code class="language-text">Services:
1. User Service (8081)
2. Product Service (8082)
3. Order Service (8083)
4. API Gateway (8000)</code></pre>
<h3>docker-compose.yml</h3>
<pre><code class="language-yaml">version: &#039;3.8&#039;
<p>services:
  user-service:
    build: ./user-service
    ports:
      - &quot;8081:8080&quot;
    environment:
      DB_URL: postgres://user:pass@user-db:5432/users
    depends_on:
      - user-db</p>
<p>product-service:
    build: ./product-service
    ports:
      - &quot;8082:8080&quot;
    environment:
      DB_URL: postgres://user:pass@product-db:5432/products
    depends_on:
      - product-db</p>
<p>order-service:
    build: ./order-service
    ports:
      - &quot;8083:8080&quot;
    environment:
      DB_URL: postgres://user:pass@order-db:5432/orders
      USER_SERVICE_URL: http://user-service:8080
      PRODUCT_SERVICE_URL: http://product-service:8080
    depends_on:
      - order-db</p>
<p>api-gateway:
    build: ./api-gateway
    ports:
      - &quot;8000:8000&quot;
    environment:
      USER_SERVICE_URL: http://user-service:8080
      PRODUCT_SERVICE_URL: http://product-service:8080
      ORDER_SERVICE_URL: http://order-service:8080</p>
<p>user-db:
    image: postgres:15
    environment:
      POSTGRES_DB: users
      POSTGRES_USER: user
      POSTGRES_PASSWORD: pass</p>
<p>product-db:
    image: postgres:15
    environment:
      POSTGRES_DB: products
      POSTGRES_USER: user
      POSTGRES_PASSWORD: pass</p>
<p>order-db:
    image: postgres:15
    environment:
      POSTGRES_DB: orders
      POSTGRES_USER: user
      POSTGRES_PASSWORD: pass</p>
<p>consul:
    image: consul:latest
    ports:
      - &quot;8500:8500&quot;</code></pre></p>
<h3>Test</h3>
<pre><code class="language-bash"># Start all services
docker-compose up -d
<h1>Create user</h1>
curl -X POST http://localhost:8000/users \
  -H &quot;Content-Type: application/json&quot; \
  -d &#039;{&quot;username&quot;:&quot;john&quot;,&quot;email&quot;:&quot;john@example.com&quot;}&#039;
<h1>Create product</h1>
curl -X POST http://localhost:8000/products \
  -H &quot;Content-Type: application/json&quot; \
  -d &#039;{&quot;name&quot;:&quot;Laptop&quot;,&quot;price&quot;:1299.99,&quot;stock&quot;:10}&#039;
<h1>Create order</h1>
curl -X POST http://localhost:8000/orders \
  -H &quot;Content-Type: application/json&quot; \
  -H &quot;Authorization: Bearer &lt;token&gt;&quot; \
  -d &#039;{&quot;user_id&quot;:&quot;1&quot;,&quot;product_id&quot;:&quot;1&quot;,&quot;quantity&quot;:1}&#039;
<h1>Check order</h1>
curl http://localhost:8000/orders/1 \
  -H &quot;Authorization: Bearer &lt;token&gt;&quot;</code></pre>
<p>---</p>
<h2>üìö Additional Resources</h2>
<li>[Microservices Patterns (Chris Richardson)](https://microservices.io/patterns/)</li>
<li>[Building Microservices (Sam Newman)](https://samnewman.io/books/building_microservices/)</li>
<li>[Istio Documentation](https://istio.io/latest/docs/)</li>
<li>[gRPC Documentation](https://grpc.io/docs/)</li>
<p>---</p>
<h2>‚úÖ Module Checklist</h2>
<li>[ ] Understand microservices principles</li>
<li>[ ] Design bounded contexts</li>
<li>[ ] Implement service-to-service communication (REST, gRPC)</li>
<li>[ ] Build API Gateway</li>
<li>[ ] Configure service discovery (Consul)</li>
<li>[ ] Implement circuit breaker</li>
<li>[ ] Deploy with service mesh (Istio)</li>
<li>[ ] Handle distributed transactions (Saga)</li>
<li>[ ] Complete e-commerce microservices exercise</li></ul>
<p>---</p>
<strong>Next Module:</strong> [Module 18: Authentication & Authorization](./18_Authentication_Authorization.md) - Secure your services! üîê

    </div>
    

    <div class="module-content" id="module-18">
        <h1>Module 18: Authentication & Authorization üîê</h1>
<h2>Secure Your Applications with Modern Auth Patterns</h2>
<strong>Duration:</strong> 6-7 hours  
<strong>Prerequisites:</strong> Module 03 (REST APIs), JWT basics, cryptography basics  
<strong>Outcome:</strong> Implement production-grade authentication and authorization systems
<p>---</p>
<h2>üìö Table of Contents</h2>
<p>1. [Authentication vs Authorization](#authentication-vs-authorization)
2. [Password Security](#password-security)
3. [Session-Based Auth](#session-based-auth)
4. [JWT (JSON Web Tokens)](#jwt-json-web-tokens)
5. [OAuth 2.0](#oauth-20)
6. [OIDC (OpenID Connect)](#oidc-openid-connect)
7. [RBAC (Role-Based Access Control)](#rbac-role-based-access-control)
8. [Best Practices](#best-practices)
9. [Interview Questions](#interview-questions)
10. [Hands-On Exercise](#hands-on-exercise)</p>
<p>---</p>
<h2>Authentication vs Authorization</h2>
<h3>Definitions</h3>
<pre><code class="language-text">Authentication (AuthN):
&quot;Who are you?&quot;
<ul><li>Verify identity</li>
<li>Login with username/password</li>
<li>Prove you are who you claim</li>
<p>Authorization (AuthZ):
&quot;What can you do?&quot;
<li>Verify permissions</li>
<li>Check if user can access resource</li>
<li>After authentication</code></pre></li></p>
<h3>Example</h3>
<pre><code class="language-text">Authentication:
User logs in with email/password ‚Üí Verified as &quot;john@example.com&quot;
<p>Authorization:
Can john@example.com delete this post?
‚Üí Check permissions: Is john the author? Is john an admin?</code></pre></p>
<p>---</p>
<h2>Password Security</h2>
<h3>Hashing (NOT Encryption)</h3>
<pre><code class="language-text">Encryption: Reversible (decrypt with key)
Hashing:    One-way (cannot reverse)
<p>Use hashing for passwords!</code></pre></p>
<h3>bcrypt (Recommended)</h3>
<pre><code class="language-go">import &quot;golang.org/x/crypto/bcrypt&quot;
<p>// Hash password
func HashPassword(password string) (string, error) {
    bytes, err := bcrypt.GenerateFromPassword([]byte(password), 14)
    return string(bytes), err
}</p>
<p>// Verify password
func CheckPassword(password, hash string) bool {
    err := bcrypt.CompareHashAndPassword([]byte(hash), []byte(password))
    return err == nil
}</p>
<p>// Usage
func Register(username, password string) error {
    hash, err := HashPassword(password)
    if err != nil {
        return err
    }
    
    // Store username + hash in database
    _, err = db.Exec(&quot;INSERT INTO users (username, password_hash) VALUES ($1, $2)&quot;, username, hash)
    return err
}</p>
<p>func Login(username, password string) (bool, error) {
    var hash string
    err := db.QueryRow(&quot;SELECT password_hash FROM users WHERE username = $1&quot;, username).Scan(&amp;hash)
    if err != nil {
        return false, err
    }
    
    return CheckPassword(password, hash), nil
}</code></pre></p>
<h3>Password Policies</h3>
<pre><code class="language-go">import &quot;regexp&quot;
<p>func ValidatePassword(password string) error {
    if len(password) &lt; 8 {
        return errors.New(&quot;password must be at least 8 characters&quot;)
    }
    
    hasUpper := regexp.MustCompile(<code>[A-Z]</code>).MatchString(password)
    hasLower := regexp.MustCompile(<code>[a-z]</code>).MatchString(password)
    hasNumber := regexp.MustCompile(<code>[0-9]</code>).MatchString(password)
    hasSpecial := regexp.MustCompile(<code>[!@#$%^&amp;*]</code>).MatchString(password)
    
    if !hasUpper || !hasLower || !hasNumber || !hasSpecial {
        return errors.New(&quot;password must contain uppercase, lowercase, number, and special character&quot;)
    }
    
    return nil
}</code></pre></p>
<p>---</p>
<h2>Session-Based Auth</h2>
<h3>How It Works</h3>
<pre><code class="language-text">1. User logs in with credentials
2. Server creates session, stores in server memory/Redis
3. Server sends session ID to client (cookie)
4. Client sends cookie with each request
5. Server validates session ID</code></pre>
<h3>Implementation</h3>
<pre><code class="language-go">import (
    &quot;github.com/gorilla/sessions&quot;
    &quot;github.com/go-redis/redis/v8&quot;
)
<p>var store = sessions.NewCookieStore([]byte(&quot;secret-key-change-in-production&quot;))</p>
<p>// Login handler
func LoginHandler(w http.ResponseWriter, r *http.Request) {
    username := r.FormValue(&quot;username&quot;)
    password := r.FormValue(&quot;password&quot;)
    
    // Verify credentials
    user, err := authenticateUser(username, password)
    if err != nil {
        http.Error(w, &quot;Invalid credentials&quot;, http.StatusUnauthorized)
        return
    }
    
    // Create session
    session, _ := store.Get(r, &quot;session&quot;)
    session.Values[&quot;user_id&quot;] = user.ID
    session.Values[&quot;username&quot;] = user.Username
    session.Save(r, w)
    
    json.NewEncoder(w).Encode(map[string]string{&quot;message&quot;: &quot;Logged in&quot;})
}</p>
<p>// Protected endpoint
func ProfileHandler(w http.ResponseWriter, r *http.Request) {
    session, _ := store.Get(r, &quot;session&quot;)
    
    userID, ok := session.Values[&quot;user_id&quot;]
    if !ok {
        http.Error(w, &quot;Unauthorized&quot;, http.StatusUnauthorized)
        return
    }
    
    // Fetch user data
    user, _ := getUserByID(userID.(int))
    json.NewEncoder(w).Encode(user)
}</p>
<p>// Logout handler
func LogoutHandler(w http.ResponseWriter, r *http.Request) {
    session, _ := store.Get(r, &quot;session&quot;)
    session.Values[&quot;user_id&quot;] = nil
    session.Options.MaxAge = -1 // Delete cookie
    session.Save(r, w)
    
    json.NewEncoder(w).Encode(map[string]string{&quot;message&quot;: &quot;Logged out&quot;})
}</code></pre></p>
<h3>Redis Session Store</h3>
<pre><code class="language-go">import (
    &quot;github.com/rbcervilla/redisstore/v8&quot;
    &quot;github.com/go-redis/redis/v8&quot;
)
<p>func NewRedisStore() *redisstore.RedisStore {
    client := redis.NewClient(&amp;redis.Options{
        Addr: &quot;localhost:6379&quot;,
    })
    
    store, _ := redisstore.NewRedisStore(context.Background(), client)
    store.KeyPrefix(&quot;session:&quot;)
    store.Options.MaxAge = 86400 * 7 // 7 days
    
    return store
}</p>
<p>// Usage
var store = NewRedisStore()</p>
<p>func LoginHandler(w http.ResponseWriter, r *http.Request) {
    // ... authentication logic ...
    
    session, _ := store.Get(r, &quot;session&quot;)
    session.Values[&quot;user_id&quot;] = user.ID
    session.Save(r, w)
}</code></pre></p>
<p>---</p>
<h2>JWT (JSON Web Tokens)</h2>
<h3>Structure</h3>
<pre><code class="language-text">Header.Payload.Signature
<p>Header (algorithm, type):
{
  &quot;alg&quot;: &quot;HS256&quot;,
  &quot;typ&quot;: &quot;JWT&quot;
}</p>
<p>Payload (claims):
{
  &quot;sub&quot;: &quot;1234567890&quot;,        // Subject (user ID)
  &quot;name&quot;: &quot;John Doe&quot;,
  &quot;iat&quot;: 1516239022,           // Issued at
  &quot;exp&quot;: 1516242622            // Expiration
}</p>
<p>Signature:
HMACSHA256(
  base64UrlEncode(header) + &quot;.&quot; +
  base64UrlEncode(payload),
  secret
)</p>
<p>Example:
eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiaWF0IjoxNTE2MjM5MDIyfQ.SflKxwRJSMeKKF2QT4fwpMeJf36POk6yJV_adQssw5c</code></pre></p>
<h3>Generate JWT</h3>
<pre><code class="language-go">import &quot;github.com/golang-jwt/jwt/v5&quot;
<p>var jwtSecret = []byte(&quot;your-secret-key-change-in-production&quot;)</p>
<p>type Claims struct {
    UserID   int    <code>json:&quot;user_id&quot;</code>
    Username string <code>json:&quot;username&quot;</code>
    Role     string <code>json:&quot;role&quot;</code>
    jwt.RegisteredClaims
}</p>
<p>func GenerateToken(user *User) (string, error) {
    claims := Claims{
        UserID:   user.ID,
        Username: user.Username,
        Role:     user.Role,
        RegisteredClaims: jwt.RegisteredClaims{
            ExpiresAt: jwt.NewNumericDate(time.Now().Add(24 * time.Hour)),
            IssuedAt:  jwt.NewNumericDate(time.Now()),
            Issuer:    &quot;myapp&quot;,
        },
    }
    
    token := jwt.NewWithClaims(jwt.SigningMethodHS256, claims)
    return token.SignedString(jwtSecret)
}</p>
<p>// Login handler
func LoginHandler(w http.ResponseWriter, r *http.Request) {
    var creds struct {
        Username string <code>json:&quot;username&quot;</code>
        Password string <code>json:&quot;password&quot;</code>
    }
    json.NewDecoder(r.Body).Decode(&amp;creds)
    
    // Authenticate user
    user, err := authenticateUser(creds.Username, creds.Password)
    if err != nil {
        http.Error(w, &quot;Invalid credentials&quot;, http.StatusUnauthorized)
        return
    }
    
    // Generate JWT
    token, err := GenerateToken(user)
    if err != nil {
        http.Error(w, &quot;Error generating token&quot;, http.StatusInternalServerError)
        return
    }
    
    json.NewEncoder(w).Encode(map[string]string{
        &quot;token&quot;: token,
    })
}</code></pre></p>
<h3>Verify JWT</h3>
<pre><code class="language-go">func VerifyToken(tokenString string) (*Claims, error) {
    token, err := jwt.ParseWithClaims(tokenString, &amp;Claims{}, func(token *jwt.Token) (interface{}, error) {
        // Verify signing method
        if _, ok := token.Method.(*jwt.SigningMethodHMAC); !ok {
            return nil, fmt.Errorf(&quot;unexpected signing method: %v&quot;, token.Header[&quot;alg&quot;])
        }
        return jwtSecret, nil
    })
    
    if err != nil {
        return nil, err
    }
    
    if claims, ok := token.Claims.(*Claims); ok &amp;&amp; token.Valid {
        return claims, nil
    }
    
    return nil, errors.New(&quot;invalid token&quot;)
}
<p>// Middleware
func AuthMiddleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        // Extract token from header
        authHeader := r.Header.Get(&quot;Authorization&quot;)
        if authHeader == &quot;&quot; {
            http.Error(w, &quot;Missing authorization header&quot;, http.StatusUnauthorized)
            return
        }
        
        // Bearer &lt;token&gt;
        tokenString := strings.TrimPrefix(authHeader, &quot;Bearer &quot;)
        
        // Verify token
        claims, err := VerifyToken(tokenString)
        if err != nil {
            http.Error(w, &quot;Invalid token&quot;, http.StatusUnauthorized)
            return
        }
        
        // Add claims to context
        ctx := context.WithValue(r.Context(), &quot;claims&quot;, claims)
        next.ServeHTTP(w, r.WithContext(ctx))
    })
}</p>
<p>// Protected handler
func ProfileHandler(w http.ResponseWriter, r *http.Request) {
    claims := r.Context().Value(&quot;claims&quot;).(*Claims)
    
    user, _ := getUserByID(claims.UserID)
    json.NewEncoder(w).Encode(user)
}</code></pre></p>
<h3>Refresh Tokens</h3>
<pre><code class="language-go">func GenerateTokenPair(user *User) (accessToken, refreshToken string, err error) {
    // Short-lived access token (15 minutes)
    accessClaims := Claims{
        UserID:   user.ID,
        Username: user.Username,
        RegisteredClaims: jwt.RegisteredClaims{
            ExpiresAt: jwt.NewNumericDate(time.Now().Add(15 * time.Minute)),
        },
    }
    accessTokenObj := jwt.NewWithClaims(jwt.SigningMethodHS256, accessClaims)
    accessToken, _ = accessTokenObj.SignedString(jwtSecret)
    
    // Long-lived refresh token (7 days)
    refreshClaims := jwt.RegisteredClaims{
        Subject:   fmt.Sprintf(&quot;%d&quot;, user.ID),
        ExpiresAt: jwt.NewNumericDate(time.Now().Add(7 * 24 * time.Hour)),
    }
    refreshTokenObj := jwt.NewWithClaims(jwt.SigningMethodHS256, refreshClaims)
    refreshToken, _ = refreshTokenObj.SignedString(jwtSecret)
    
    // Store refresh token in database
    storeRefreshToken(user.ID, refreshToken)
    
    return accessToken, refreshToken, nil
}
<p>func RefreshAccessToken(w http.ResponseWriter, r *http.Request) {
    var req struct {
        RefreshToken string <code>json:&quot;refresh_token&quot;</code>
    }
    json.NewDecoder(r.Body).Decode(&amp;req)
    
    // Verify refresh token
    token, err := jwt.Parse(req.RefreshToken, func(token *jwt.Token) (interface{}, error) {
        return jwtSecret, nil
    })
    
    if err != nil || !token.Valid {
        http.Error(w, &quot;Invalid refresh token&quot;, http.StatusUnauthorized)
        return
    }
    
    claims := token.Claims.(jwt.MapClaims)
    userID := int(claims[&quot;sub&quot;].(float64))
    
    // Verify refresh token exists in database
    if !isValidRefreshToken(userID, req.RefreshToken) {
        http.Error(w, &quot;Refresh token revoked&quot;, http.StatusUnauthorized)
        return
    }
    
    // Generate new access token
    user, _ := getUserByID(userID)
    accessToken, _ := GenerateToken(user)
    
    json.NewEncoder(w).Encode(map[string]string{
        &quot;access_token&quot;: accessToken,
    })
}</code></pre></p>
<p>---</p>
<h2>OAuth 2.0</h2>
<h3>What is OAuth 2.0?</h3>
<strong>Authorization framework</strong> - allows third-party apps to access user data without sharing passwords.
<h3>Use Case</h3>
<pre><code class="language-text">User wants to use &quot;Photo Editor App&quot; 
to edit photos from Google Drive
<p>Without OAuth:
User gives Photo Editor their Google password ‚ùå</p>
<p>With OAuth:
1. Photo Editor redirects to Google
2. User logs in to Google (not Photo Editor)
3. User grants Photo Editor access to Drive
4. Google gives Photo Editor access token
5. Photo Editor uses token to access Drive ‚úÖ</code></pre></p>
<h3>OAuth 2.0 Flows</h3>
<p>#### 1. Authorization Code Flow (Most Common)</p>
<pre><code class="language-text">Client (Web App) ‚Üí Authorization Server (Google) ‚Üí Resource Server (Google Drive)
<p>1. Client redirects user to authorization server:
   https://accounts.google.com/oauth/authorize?
     client_id=123&amp;
     redirect_uri=https://myapp.com/callback&amp;
     response_type=code&amp;
     scope=drive.readonly</p>
<p>2. User logs in and approves</p>
<p>3. Authorization server redirects back with code:
   https://myapp.com/callback?code=AUTH_CODE</p>
<p>4. Client exchanges code for access token:
   POST https://oauth2.googleapis.com/token
   {
     &quot;code&quot;: &quot;AUTH_CODE&quot;,
     &quot;client_id&quot;: &quot;123&quot;,
     &quot;client_secret&quot;: &quot;secret&quot;,
     &quot;redirect_uri&quot;: &quot;https://myapp.com/callback&quot;,
     &quot;grant_type&quot;: &quot;authorization_code&quot;
   }</p>
<p>5. Response:
   {
     &quot;access_token&quot;: &quot;ya29.a0AfH6SMBx...&quot;,
     &quot;refresh_token&quot;: &quot;1//0gLn...&quot;,
     &quot;expires_in&quot;: 3600
   }</p>
<p>6. Client uses access token:
   GET https://www.googleapis.com/drive/v3/files
   Authorization: Bearer ya29.a0AfH6SMBx...</code></pre></p>
<p>#### 2. Client Credentials Flow (Server-to-Server)</p>
<pre><code class="language-go">// Service accessing another service (no user)
func GetAccessToken() (string, error) {
    data := url.Values{}
    data.Set(&quot;grant_type&quot;, &quot;client_credentials&quot;)
    data.Set(&quot;client_id&quot;, &quot;your-client-id&quot;)
    data.Set(&quot;client_secret&quot;, &quot;your-client-secret&quot;)
    
    resp, err := http.PostForm(&quot;https://oauth.provider.com/token&quot;, data)
    if err != nil {
        return &quot;&quot;, err
    }
    defer resp.Body.Close()
    
    var result struct {
        AccessToken string <code>json:&quot;access_token&quot;</code>
        ExpiresIn   int    <code>json:&quot;expires_in&quot;</code>
    }
    json.NewDecoder(resp.Body).Decode(&amp;result)
    
    return result.AccessToken, nil
}</code></pre>
<h3>Implement OAuth 2.0 Server</h3>
<pre><code class="language-go">import &quot;github.com/go-oauth2/oauth2/v4&quot;
<p>// OAuth server setup
func SetupOAuthServer() *server.Server {
    manager := manage.NewDefaultManager()
    
    // Token store (memory, Redis, etc.)
    manager.MustTokenStorage(store.NewMemoryTokenStore())
    
    // Client store
    clientStore := store.NewClientStore()
    clientStore.Set(&quot;client-1&quot;, &amp;models.Client{
        ID:     &quot;client-1&quot;,
        Secret: &quot;client-secret&quot;,
        Domain: &quot;http://localhost:8080&quot;,
    })
    manager.MapClientStorage(clientStore)
    
    srv := server.NewDefaultServer(manager)
    srv.SetAllowGetAccessRequest(true)
    
    return srv
}</p>
<p>// Authorization endpoint
func AuthorizeHandler(w http.ResponseWriter, r *http.Request) {
    // Display login page
    // After login, redirect with authorization code
}</p>
<p>// Token endpoint
func TokenHandler(w http.ResponseWriter, r *http.Request) {
    srv.HandleTokenRequest(w, r)
}</code></pre></p>
<p>---</p>
<h2>OIDC (OpenID Connect)</h2>
<h3>What is OIDC?</h3>
<strong>Identity layer on top of OAuth 2.0</strong>. OAuth = authorization, OIDC = authentication.
<h3>Difference</h3>
<pre><code class="language-text">OAuth 2.0:
<li>&quot;Let app access my photos&quot; (authorization)</li>
<li>Doesn&#039;t verify identity</li>
<p>OIDC:
<li>&quot;Log in with Google&quot; (authentication)</li>
<li>Returns ID token with user info</code></pre></li></p>
<h3>ID Token (JWT)</h3>
<pre><code class="language-json">{
  &quot;iss&quot;: &quot;https://accounts.google.com&quot;,
  &quot;sub&quot;: &quot;1234567890&quot;,
  &quot;aud&quot;: &quot;your-app-client-id&quot;,
  &quot;exp&quot;: 1516242622,
  &quot;iat&quot;: 1516239022,
  &quot;email&quot;: &quot;user@example.com&quot;,
  &quot;email_verified&quot;: true,
  &quot;name&quot;: &quot;John Doe&quot;,
  &quot;picture&quot;: &quot;https://...&quot;
}</code></pre>
<h3>Implement "Login with Google"</h3>
<pre><code class="language-go">import &quot;github.com/coreos/go-oidc/v3/oidc&quot;
<p>var (
    clientID     = &quot;your-google-client-id&quot;
    clientSecret = &quot;your-google-client-secret&quot;
    redirectURL  = &quot;http://localhost:8080/callback&quot;
)</p>
<p>func main() {
    ctx := context.Background()
    
    provider, _ := oidc.NewProvider(ctx, &quot;https://accounts.google.com&quot;)
    
    oauth2Config := oauth2.Config{
        ClientID:     clientID,
        ClientSecret: clientSecret,
        RedirectURL:  redirectURL,
        Endpoint:     provider.Endpoint(),
        Scopes:       []string{oidc.ScopeOpenID, &quot;profile&quot;, &quot;email&quot;},
    }
    
    http.HandleFunc(&quot;/login&quot;, func(w http.ResponseWriter, r *http.Request) {
        // Redirect to Google
        url := oauth2Config.AuthCodeURL(&quot;state-token&quot;)
        http.Redirect(w, r, url, http.StatusFound)
    })
    
    http.HandleFunc(&quot;/callback&quot;, func(w http.ResponseWriter, r *http.Request) {
        // Exchange code for token
        oauth2Token, _ := oauth2Config.Exchange(ctx, r.URL.Query().Get(&quot;code&quot;))
        
        // Extract ID token
        rawIDToken, _ := oauth2Token.Extra(&quot;id_token&quot;).(string)
        
        // Verify ID token
        verifier := provider.Verifier(&amp;oidc.Config{ClientID: clientID})
        idToken, _ := verifier.Verify(ctx, rawIDToken)
        
        // Extract claims
        var claims struct {
            Email         string <code>json:&quot;email&quot;</code>
            EmailVerified bool   <code>json:&quot;email_verified&quot;</code>
            Name          string <code>json:&quot;name&quot;</code>
        }
        idToken.Claims(&amp;claims)
        
        // Create session or JWT for user
        fmt.Fprintf(w, &quot;Hello %s (%s)&quot;, claims.Name, claims.Email)
    })
    
    http.ListenAndServe(&quot;:8080&quot;, nil)
}</code></pre></p>
<p>---</p>
<h2>RBAC (Role-Based Access Control)</h2>
<h3>Concepts</h3>
<pre><code class="language-text">User ‚Üí Role ‚Üí Permissions
<p>Example:
User &quot;john&quot; has Role &quot;Editor&quot;
Role &quot;Editor&quot; has Permissions [&quot;read&quot;, &quot;write&quot;]
‚Üí john can read and write</code></pre></p>
<h3>Database Schema</h3>
<pre><code class="language-sql">CREATE TABLE users (
    id SERIAL PRIMARY KEY,
    username VARCHAR(50) UNIQUE,
    email VARCHAR(100) UNIQUE
);
<p>CREATE TABLE roles (
    id SERIAL PRIMARY KEY,
    name VARCHAR(50) UNIQUE  -- admin, editor, viewer
);</p>
<p>CREATE TABLE permissions (
    id SERIAL PRIMARY KEY,
    name VARCHAR(50) UNIQUE  -- read, write, delete
);</p>
<p>CREATE TABLE user_roles (
    user_id INTEGER REFERENCES users(id),
    role_id INTEGER REFERENCES roles(id),
    PRIMARY KEY (user_id, role_id)
);</p>
<p>CREATE TABLE role_permissions (
    role_id INTEGER REFERENCES roles(id),
    permission_id INTEGER REFERENCES permissions(id),
    PRIMARY KEY (role_id, permission_id)
);</code></pre></p>
<h3>Implementation</h3>
<pre><code class="language-go">type RBAC struct {
    db *sql.DB
}
<p>func (r *RBAC) HasPermission(userID int, permission string) (bool, error) {
    query := <code>
        SELECT COUNT(*) 
        FROM users u
        JOIN user_roles ur ON u.id = ur.user_id
        JOIN role_permissions rp ON ur.role_id = rp.role_id
        JOIN permissions p ON rp.permission_id = p.id
        WHERE u.id = $1 AND p.name = $2
    </code>
    
    var count int
    err := r.db.QueryRow(query, userID, permission).Scan(&amp;count)
    return count &gt; 0, err
}</p>
<p>// Middleware
func RequirePermission(permission string) func(http.Handler) http.Handler {
    return func(next http.Handler) http.Handler {
        return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
            claims := r.Context().Value(&quot;claims&quot;).(*Claims)
            
            rbac := &amp;RBAC{db: db}
            hasPermission, _ := rbac.HasPermission(claims.UserID, permission)
            
            if !hasPermission {
                http.Error(w, &quot;Forbidden&quot;, http.StatusForbidden)
                return
            }
            
            next.ServeHTTP(w, r)
        })
    }
}</p>
<p>// Usage
r.Handle(&quot;/posts&quot;, RequirePermission(&quot;write&quot;)(http.HandlerFunc(CreatePostHandler)))</code></pre></p>
<h3>Resource-Based Access Control</h3>
<pre><code class="language-go">// Check if user owns resource
func CanDeletePost(userID, postID int) (bool, error) {
    var authorID int
    err := db.QueryRow(&quot;SELECT user_id FROM posts WHERE id = $1&quot;, postID).Scan(&amp;authorID)
    if err != nil {
        return false, err
    }
    
    // User can delete if they&#039;re the author
    return authorID == userID, nil
}
<p>func DeletePostHandler(w http.ResponseWriter, r *http.Request) {
    claims := r.Context().Value(&quot;claims&quot;).(*Claims)
    postID := mux.Vars(r)[&quot;id&quot;]
    
    canDelete, _ := CanDeletePost(claims.UserID, postID)
    if !canDelete {
        http.Error(w, &quot;You don&#039;t have permission to delete this post&quot;, http.StatusForbidden)
        return
    }
    
    // Delete post
    db.Exec(&quot;DELETE FROM posts WHERE id = $1&quot;, postID)
    w.WriteHeader(http.StatusNoContent)
}</code></pre></p>
<p>---</p>
<h2>Best Practices</h2>
<h3>1. Never Store Passwords in Plain Text</h3>
<pre><code class="language-text">‚ùå password: &quot;mypassword123&quot;
‚úÖ password_hash: &quot;$2a$14$xyz...&quot;</code></pre>
<h3>2. Use HTTPS</h3>
<pre><code class="language-text">All authentication traffic must be encrypted!</code></pre>
<h3>3. Token Storage</h3>
<pre><code class="language-text">‚úÖ httpOnly cookies (prevents XSS)
‚úÖ Secure flag (HTTPS only)
‚ùå localStorage (vulnerable to XSS)</code></pre>
<h3>4. CSRF Protection</h3>
<pre><code class="language-go">import &quot;github.com/gorilla/csrf&quot;
<p>func main() {
    CSRF := csrf.Protect(
        []byte(&quot;32-byte-long-auth-key&quot;),
        csrf.Secure(false), // Set to true in production with HTTPS
    )
    
    http.Handle(&quot;/&quot;, CSRF(router))
}</code></pre></p>
<h3>5. Rate Limiting</h3>
<pre><code class="language-go">import &quot;golang.org/x/time/rate&quot;
<p>var limiter = rate.NewLimiter(1, 3) // 1 req/sec, burst of 3</p>
<p>func LoginHandler(w http.ResponseWriter, r *http.Request) {
    if !limiter.Allow() {
        http.Error(w, &quot;Too many requests&quot;, http.StatusTooManyRequests)
        return
    }
    
    // Login logic
}</code></pre></p>
<p>---</p>
<h2>Interview Questions</h2>
<strong>Q1: Session-based vs Token-based (JWT) authentication?</strong>
<strong>Answer:</strong>
<li><strong>Session</strong>: Server stores session, client has cookie. Stateful. Good for web apps. Harder to scale (need shared session store).</li>
<li><strong>JWT</strong>: Self-contained token, server validates signature. Stateless. Good for APIs, microservices. Token can't be revoked easily.</li>
<strong>Q2: How do you handle JWT expiration?</strong>
<strong>Answer:</strong> Use refresh tokens:
<li>Short-lived access token (15 min)</li>
<li>Long-lived refresh token (7 days)</li>
<li>When access token expires, client uses refresh token to get new access token</li>
<li>Store refresh tokens in database for revocation</li>
<strong>Q3: What is OAuth 2.0 and when to use it?</strong>
<strong>Answer:</strong> Authorization framework for delegated access. Use when:
<li>Third-party app needs access to user's data (Google Drive, GitHub)</li>
<li>Don't want to share passwords</li>
<li>Examples: "Login with Google", "Connect Spotify"</li>
<strong>Q4: RBAC vs ABAC (Attribute-Based Access Control)?</strong>
<strong>Answer:</strong>
<li><strong>RBAC</strong>: User ‚Üí Role ‚Üí Permissions. Simpler, role-centric. Example: Admin, Editor, Viewer.</li>
<li><strong>ABAC</strong>: Policies based on attributes (user, resource, environment). More flexible. Example: "Allow if user.department == resource.department AND time < 5pm"</li>
<strong>Q5: How do you secure against common attacks?</strong>
<strong>Answer:</strong>
<li><strong>SQL Injection</strong>: Use parameterized queries</li>
<li><strong>XSS</strong>: Sanitize input, use httpOnly cookies</li>
<li><strong>CSRF</strong>: Use CSRF tokens, SameSite cookies</li>
<li><strong>Brute Force</strong>: Rate limiting, account lockout</li>
<li><strong>Session Fixation</strong>: Regenerate session ID after login</li>
<p>---</p>
<h2>Hands-On Exercise</h2>
<h3>Task: Build Complete Auth System</h3>
<pre><code class="language-go">// Complete auth system with JWT + RBAC
package main
<p>import (
    &quot;database/sql&quot;
    &quot;encoding/json&quot;
    &quot;net/http&quot;
    &quot;time&quot;
    
    &quot;github.com/golang-jwt/jwt/v5&quot;
    &quot;github.com/gorilla/mux&quot;
    &quot;golang.org/x/crypto/bcrypt&quot;
)</p>
<p>var jwtSecret = []byte(&quot;secret&quot;)
var db *sql.DB</p>
<p>type User struct {
    ID       int    <code>json:&quot;id&quot;</code>
    Username string <code>json:&quot;username&quot;</code>
    Email    string <code>json:&quot;email&quot;</code>
    Role     string <code>json:&quot;role&quot;</code>
}</p>
<p>type Claims struct {
    UserID int    <code>json:&quot;user_id&quot;</code>
    Role   string <code>json:&quot;role&quot;</code>
    jwt.RegisteredClaims
}</p>
<p>// Register
func RegisterHandler(w http.ResponseWriter, r *http.Request) {
    var req struct {
        Username string <code>json:&quot;username&quot;</code>
        Email    string <code>json:&quot;email&quot;</code>
        Password string <code>json:&quot;password&quot;</code>
    }
    json.NewDecoder(r.Body).Decode(&amp;req)
    
    // Hash password
    hash, _ := bcrypt.GenerateFromPassword([]byte(req.Password), 14)
    
    // Insert user
    var userID int
    err := db.QueryRow(<code>
        INSERT INTO users (username, email, password_hash, role)
        VALUES ($1, $2, $3, &#039;user&#039;)
        RETURNING id
    </code>, req.Username, req.Email, hash).Scan(&amp;userID)
    
    if err != nil {
        http.Error(w, &quot;User already exists&quot;, http.StatusConflict)
        return
    }
    
    w.WriteHeader(http.StatusCreated)
    json.NewEncoder(w).Encode(map[string]int{&quot;user_id&quot;: userID})
}</p>
<p>// Login
func LoginHandler(w http.ResponseWriter, r *http.Request) {
    var req struct {
        Username string <code>json:&quot;username&quot;</code>
        Password string <code>json:&quot;password&quot;</code>
    }
    json.NewDecoder(r.Body).Decode(&amp;req)
    
    // Get user
    var user User
    var hash string
    err := db.QueryRow(<code>
        SELECT id, username, email, role, password_hash
        FROM users WHERE username = $1
    </code>, req.Username).Scan(&amp;user.ID, &amp;user.Username, &amp;user.Email, &amp;user.Role, &amp;hash)
    
    if err != nil {
        http.Error(w, &quot;Invalid credentials&quot;, http.StatusUnauthorized)
        return
    }
    
    // Verify password
    if bcrypt.CompareHashAndPassword([]byte(hash), []byte(req.Password)) != nil {
        http.Error(w, &quot;Invalid credentials&quot;, http.StatusUnauthorized)
        return
    }
    
    // Generate JWT
    claims := Claims{
        UserID: user.ID,
        Role:   user.Role,
        RegisteredClaims: jwt.RegisteredClaims{
            ExpiresAt: jwt.NewNumericDate(time.Now().Add(24 * time.Hour)),
        },
    }
    token := jwt.NewWithClaims(jwt.SigningMethodHS256, claims)
    tokenString, _ := token.SignedString(jwtSecret)
    
    json.NewEncoder(w).Encode(map[string]string{
        &quot;token&quot;: tokenString,
    })
}</p>
<p>// Auth middleware
func AuthMiddleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        tokenString := r.Header.Get(&quot;Authorization&quot;)[7:] // Remove &quot;Bearer &quot;
        
        claims := &amp;Claims{}
        token, err := jwt.ParseWithClaims(tokenString, claims, func(token *jwt.Token) (interface{}, error) {
            return jwtSecret, nil
        })
        
        if err != nil || !token.Valid {
            http.Error(w, &quot;Unauthorized&quot;, http.StatusUnauthorized)
            return
        }
        
        ctx := context.WithValue(r.Context(), &quot;claims&quot;, claims)
        next.ServeHTTP(w, r.WithContext(ctx))
    })
}</p>
<p>// Admin middleware
func AdminOnly(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        claims := r.Context().Value(&quot;claims&quot;).(*Claims)
        
        if claims.Role != &quot;admin&quot; {
            http.Error(w, &quot;Forbidden&quot;, http.StatusForbidden)
            return
        }
        
        next.ServeHTTP(w, r)
    })
}</p>
<p>func main() {
    r := mux.NewRouter()
    
    // Public routes
    r.HandleFunc(&quot;/register&quot;, RegisterHandler).Methods(&quot;POST&quot;)
    r.HandleFunc(&quot;/login&quot;, LoginHandler).Methods(&quot;POST&quot;)
    
    // Protected routes
    api := r.PathPrefix(&quot;/api&quot;).Subrouter()
    api.Use(AuthMiddleware)
    api.HandleFunc(&quot;/profile&quot;, ProfileHandler).Methods(&quot;GET&quot;)
    
    // Admin routes
    admin := r.PathPrefix(&quot;/admin&quot;).Subrouter()
    admin.Use(AuthMiddleware, AdminOnly)
    admin.HandleFunc(&quot;/users&quot;, ListUsersHandler).Methods(&quot;GET&quot;)
    
    http.ListenAndServe(&quot;:8080&quot;, r)
}</code></pre></p>
<p>---</p>
<h2>üìö Additional Resources</h2>
<li>[JWT.io](https://jwt.io/)</li>
<li>[OAuth 2.0 Spec](https://oauth.net/2/)</li>
<li>[OWASP Auth Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/Authentication_Cheat_Sheet.html)</li>
<li>[Go OAuth2 Package](https://pkg.go.dev/golang.org/x/oauth2)</li>
<p>---</p>
<h2>‚úÖ Module Checklist</h2>
<li>[ ] Implement password hashing with bcrypt</li>
<li>[ ] Build session-based authentication</li>
<li>[ ] Generate and verify JWT tokens</li>
<li>[ ] Implement refresh tokens</li>
<li>[ ] Build OAuth 2.0 server</li>
<li>[ ] Integrate "Login with Google" (OIDC)</li>
<li>[ ] Implement RBAC system</li>
<li>[ ] Complete full auth system exercise</li></ul>
<p>---</p>
<strong>Next Module:</strong> [Module 19: Kafka & Event-Driven Architecture](./19_Kafka_Event_Driven.md) - Build scalable event systems! üì®

    </div>
    

    <div class="module-content" id="module-19">
        <h1>Module 19: Kafka & Event-Driven Architecture üì®</h1>
<h2>Build Scalable Event-Driven Systems with Apache Kafka</h2>
<strong>Duration:</strong> 6-7 hours  
<strong>Prerequisites:</strong> Module 17 (Microservices), distributed systems basics  
<strong>Outcome:</strong> Master Kafka for real-time data streaming and event-driven architectures
<p>---</p>
<h2>üìö Table of Contents</h2>
<p>1. [What is Kafka](#what-is-kafka)
2. [Core Concepts](#core-concepts)
3. [Producers](#producers)
4. [Consumers](#consumers)
5. [Topics & Partitions](#topics--partitions)
6. [Consumer Groups](#consumer-groups)
7. [Event-Driven Patterns](#event-driven-patterns)
8. [Best Practices](#best-practices)
9. [Interview Questions](#interview-questions)
10. [Hands-On Exercise](#hands-on-exercise)</p>
<p>---</p>
<h2>What is Kafka</h2>
<h3>Overview</h3>
<strong>Apache Kafka</strong> is a distributed event streaming platform for:
<ul><li><strong>Publish/Subscribe</strong>: Messaging system</li>
<li><strong>Storage</strong>: Durable log storage</li>
<li><strong>Processing</strong>: Stream processing (Kafka Streams)</li>
<h3>Use Cases</h3>
<pre><code class="language-text">1. Messaging:         Service-to-service communication
2. Activity Tracking: User actions, clickstream
3. Log Aggregation:   Centralized logging
4. Stream Processing: Real-time analytics
5. Event Sourcing:    Store all state changes
6. CQRS:              Sync read/write models</code></pre>
<h3>Kafka vs Traditional Message Queues</h3>
<pre><code class="language-text">RabbitMQ/SQS:
<li>Message broker</li>
<li>Messages deleted after consumption</li>
<li>Lower throughput</li>
<p>Kafka:
<li>Distributed commit log</li>
<li>Messages retained (days/weeks)</li>
<li>High throughput (millions/sec)</li>
<li>Replay messages</code></pre></li></p>
<p>---</p>
<h2>Core Concepts</h2>
<h3>Architecture</h3>
<pre><code class="language-text">Producer ‚Üí Kafka Cluster ‚Üí Consumer
<p>Kafka Cluster:
‚îú‚îÄ‚îÄ Broker 1 (server)
‚îú‚îÄ‚îÄ Broker 2
‚îî‚îÄ‚îÄ Broker 3</p>
<p>Topic: Category/feed name (e.g., &quot;orders&quot;, &quot;user-events&quot;)
Partition: Ordered, immutable sequence of messages
Offset: Message position in partition (0, 1, 2, ...)</code></pre></p>
<h3>Message Structure</h3>
<pre><code class="language-text">Record:
<li>Key:       Used for partitioning</li>
<li>Value:     Actual data (JSON, Avro, Protobuf)</li>
<li>Timestamp: When produced</li>
<li>Headers:   Metadata</li>
<p>Example:
{
  &quot;key&quot;: &quot;user-123&quot;,
  &quot;value&quot;: {
    &quot;event&quot;: &quot;order_created&quot;,
    &quot;order_id&quot;: &quot;ord-456&quot;,
    &quot;amount&quot;: 99.99
  },
  &quot;timestamp&quot;: 1699564800
}</code></pre></p>
<p>---</p>
<h2>Installation & Setup</h2>
<h3>Docker Compose</h3>
<pre><code class="language-yaml"># docker-compose.yml
version: &#039;3.8&#039;
<p>services:
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - &quot;2181:2181&quot;</p>
<p>kafka:
    image: confluentinc/cp-kafka:latest
    depends_on:
      - zookeeper
    ports:
      - &quot;9092:9092&quot;
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1</p>
<p>kafka-ui:
    image: provectuslabs/kafka-ui:latest
    ports:
      - &quot;8080:8080&quot;
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092</code></pre></p>
<pre><code class="language-bash"># Start Kafka
docker-compose up -d
<h1>Verify</h1>
docker-compose ps
<h1>Access Kafka UI</h1>
open http://localhost:8080</code></pre>
<p>---</p>
<h2>Producers</h2>
<h3>Simple Producer</h3>
<pre><code class="language-go">package main
<p>import (
    &quot;context&quot;
    &quot;encoding/json&quot;
    &quot;log&quot;
    &quot;time&quot;</p>
<p>&quot;github.com/segmentio/kafka-go&quot;
)</p>
<p>type OrderEvent struct {
    OrderID   string  <code>json:&quot;order_id&quot;</code>
    UserID    string  <code>json:&quot;user_id&quot;</code>
    Amount    float64 <code>json:&quot;amount&quot;</code>
    Timestamp int64   <code>json:&quot;timestamp&quot;</code>
}</p>
<p>func main() {
    // Create writer
    writer := kafka.NewWriter(kafka.WriterConfig{
        Brokers:  []string{&quot;localhost:9092&quot;},
        Topic:    &quot;orders&quot;,
        Balancer: &amp;kafka.LeastBytes{},
    })
    defer writer.Close()</p>
<p>// Create event
    event := OrderEvent{
        OrderID:   &quot;ord-12345&quot;,
        UserID:    &quot;user-67890&quot;,
        Amount:    199.99,
        Timestamp: time.Now().Unix(),
    }</p>
<p>// Serialize to JSON
    value, _ := json.Marshal(event)</p>
<p>// Send message
    err := writer.WriteMessages(context.Background(),
        kafka.Message{
            Key:   []byte(event.OrderID),
            Value: value,
        },
    )</p>
<p>if err != nil {
        log.Fatal(&quot;failed to write message:&quot;, err)
    }</p>
<p>log.Println(&quot;Message sent successfully!&quot;)
}</code></pre></p>
<h3>Batch Producer (High Throughput)</h3>
<pre><code class="language-go">func ProduceBatch() {
    writer := kafka.NewWriter(kafka.WriterConfig{
        Brokers:      []string{&quot;localhost:9092&quot;},
        Topic:        &quot;orders&quot;,
        BatchSize:    100,          // Batch 100 messages
        BatchTimeout: 10 * time.Millisecond,
        Compression:  kafka.Snappy, // Compress messages
    })
    defer writer.Close()
<p>messages := make([]kafka.Message, 0, 1000)</p>
<p>for i := 0; i &lt; 1000; i++ {
        event := OrderEvent{
            OrderID: fmt.Sprintf(&quot;ord-%d&quot;, i),
            UserID:  &quot;user-123&quot;,
            Amount:  99.99,
        }
        value, _ := json.Marshal(event)</p>
<p>messages = append(messages, kafka.Message{
            Key:   []byte(event.OrderID),
            Value: value,
        })
    }</p>
<p>// Send batch
    err := writer.WriteMessages(context.Background(), messages...)
    if err != nil {
        log.Fatal(err)
    }</p>
<p>log.Printf(&quot;Sent %d messages\n&quot;, len(messages))
}</code></pre></p>
<h3>Producer with Partitioning</h3>
<pre><code class="language-go">// Custom partitioner
type UserPartitioner struct{}
<p>func (p *UserPartitioner) Partition(msg kafka.Message, numPartitions int) int {
    // Hash user ID to determine partition
    key := string(msg.Key)
    hash := fnv.New32a()
    hash.Write([]byte(key))
    return int(hash.Sum32()) % numPartitions
}</p>
<p>func main() {
    writer := kafka.NewWriter(kafka.WriterConfig{
        Brokers:  []string{&quot;localhost:9092&quot;},
        Topic:    &quot;orders&quot;,
        Balancer: &amp;UserPartitioner{}, // Custom partitioner
    })
    defer writer.Close()</p>
<p>// All messages with same user ID go to same partition
    // Ensures ordering per user
}</code></pre></p>
<p>---</p>
<h2>Consumers</h2>
<h3>Simple Consumer</h3>
<pre><code class="language-go">func ConsumeOrders() {
    reader := kafka.NewReader(kafka.ReaderConfig{
        Brokers:  []string{&quot;localhost:9092&quot;},
        Topic:    &quot;orders&quot;,
        GroupID:  &quot;order-processor&quot;,
        MinBytes: 10e3, // 10KB
        MaxBytes: 10e6, // 10MB
    })
    defer reader.Close()
<p>log.Println(&quot;Starting consumer...&quot;)</p>
<p>for {
        msg, err := reader.ReadMessage(context.Background())
        if err != nil {
            log.Println(&quot;Error reading message:&quot;, err)
            continue
        }</p>
<p>// Parse message
        var event OrderEvent
        if err := json.Unmarshal(msg.Value, &amp;event); err != nil {
            log.Println(&quot;Error parsing message:&quot;, err)
            continue
        }</p>
<p>// Process event
        log.Printf(&quot;Processing order: %s, Amount: $%.2f\n&quot;, event.OrderID, event.Amount)</p>
<p>// Simulate processing
        processOrder(&amp;event)
    }
}</p>
<p>func processOrder(event *OrderEvent) {
    // Business logic here
    time.Sleep(100 * time.Millisecond)
}</code></pre></p>
<h3>Manual Offset Management</h3>
<pre><code class="language-go">func ConsumeWithManualCommit() {
    reader := kafka.NewReader(kafka.ReaderConfig{
        Brokers: []string{&quot;localhost:9092&quot;},
        Topic:   &quot;orders&quot;,
        GroupID: &quot;order-processor&quot;,
    })
    defer reader.Close()
<p>for {
        msg, err := reader.FetchMessage(context.Background())
        if err != nil {
            log.Println(err)
            continue
        }</p>
<p>// Process message
        var event OrderEvent
        json.Unmarshal(msg.Value, &amp;event)</p>
<p>err = processOrder(&amp;event)
        if err != nil {
            log.Printf(&quot;Failed to process %s: %v\n&quot;, event.OrderID, err)
            // Don&#039;t commit - will retry
            continue
        }</p>
<p>// Commit offset only after successful processing
        if err := reader.CommitMessages(context.Background(), msg); err != nil {
            log.Println(&quot;Failed to commit:&quot;, err)
        }</p>
<p>log.Printf(&quot;Committed offset %d\n&quot;, msg.Offset)
    }
}</code></pre></p>
<p>---</p>
<h2>Topics & Partitions</h2>
<h3>Creating Topics</h3>
<pre><code class="language-bash"># Using kafka-topics.sh
docker exec -it kafka kafka-topics --create \
  --bootstrap-server localhost:9092 \
  --topic orders \
  --partitions 3 \
  --replication-factor 1
<h1>List topics</h1>
docker exec -it kafka kafka-topics --list \
  --bootstrap-server localhost:9092
<h1>Describe topic</h1>
docker exec -it kafka kafka-topics --describe \
  --bootstrap-server localhost:9092 \
  --topic orders</code></pre>
<h3>Partitioning Strategy</h3>
<pre><code class="language-text">Why Partitions?
1. Parallelism: Multiple consumers
2. Ordering:    Guaranteed within partition
3. Scalability: Distribute load
<p>Partition Assignment:
<li>Key-based:   hash(key) % num_partitions</li>
<li>Round-robin: If no key</li>
<li>Custom:      Custom partitioner</li></p>
<p>Example (3 partitions):
user-1 ‚Üí Partition 0
user-2 ‚Üí Partition 1
user-3 ‚Üí Partition 2
user-1 ‚Üí Partition 0 (same user, same partition)</code></pre></p>
<h3>Partition Selection</h3>
<pre><code class="language-go">// Choosing number of partitions
/*
Factors:
1. Consumer parallelism: Max consumers = num partitions
2. Broker capacity
3. Producer throughput
<p>Formula:
Partitions &gt;= (Target Throughput) / (Consumer Throughput)</p>
<p>Example:
<li>Target: 1M msgs/sec</li>
<li>Each consumer: 100K msgs/sec</li>
<li>Partitions = 1M / 100K = 10 partitions</li>
*/</p>
<p>// Create topic with Go
func CreateTopic() {
    conn, _ := kafka.Dial(&quot;tcp&quot;, &quot;localhost:9092&quot;)
    defer conn.Close()</p>
<p>topicConfig := kafka.TopicConfig{
        Topic:             &quot;orders&quot;,
        NumPartitions:     10,
        ReplicationFactor: 3,
    }</p>
<p>err := conn.CreateTopics(topicConfig)
    if err != nil {
        log.Fatal(err)
    }
}</code></pre></p>
<p>---</p>
<h2>Consumer Groups</h2>
<h3>How Consumer Groups Work</h3>
<pre><code class="language-text">Topic: orders (3 partitions)
<p>Consumer Group: order-processors
‚îú‚îÄ‚îÄ Consumer 1 ‚Üí Partition 0
‚îú‚îÄ‚îÄ Consumer 2 ‚Üí Partition 1
‚îî‚îÄ‚îÄ Consumer 3 ‚Üí Partition 2</p>
<p>Rules:
1. Each partition consumed by ONE consumer in group
2. If consumer dies, partitions rebalanced
3. Can&#039;t have more consumers than partitions</code></pre></p>
<h3>Multiple Consumer Groups</h3>
<pre><code class="language-text">orders topic
<p>Group 1 (order-processor):
<li>Consumer A ‚Üí All partitions</li>
<li>Processes orders</li></p>
<p>Group 2 (analytics):
<li>Consumer B ‚Üí All partitions</li>
<li>Generates reports</li></p>
<p>Group 3 (email-sender):
<li>Consumer C ‚Üí All partitions</li>
<li>Sends confirmation emails</li></p>
<p>Each group gets ALL messages independently!</code></pre></p>
<h3>Implementation</h3>
<pre><code class="language-go">// Consumer Group 1: Order Processing
func OrderProcessor() {
    reader := kafka.NewReader(kafka.ReaderConfig{
        Brokers: []string{&quot;localhost:9092&quot;},
        Topic:   &quot;orders&quot;,
        GroupID: &quot;order-processor&quot;,  // Same group ID
    })
    defer reader.Close()
<p>for {
        msg, _ := reader.ReadMessage(context.Background())
        // Process order
        log.Printf(&quot;[ORDER-PROCESSOR] Processing: %s\n&quot;, msg.Value)
    }
}</p>
<p>// Consumer Group 2: Analytics
func Analytics() {
    reader := kafka.NewReader(kafka.ReaderConfig{
        Brokers: []string{&quot;localhost:9092&quot;},
        Topic:   &quot;orders&quot;,
        GroupID: &quot;analytics&quot;,  // Different group ID
    })
    defer reader.Close()</p>
<p>for {
        msg, _ := reader.ReadMessage(context.Background())
        // Generate analytics
        log.Printf(&quot;[ANALYTICS] Analyzing: %s\n&quot;, msg.Value)
    }
}</p>
<p>func main() {
    go OrderProcessor()
    go Analytics()
    
    select {} // Keep running
}</code></pre></p>
<p>---</p>
<h2>Event-Driven Patterns</h2>
<h3>1. Event Sourcing</h3>
<pre><code class="language-go">// Store all events, rebuild state
type Event struct {
    Type      string          <code>json:&quot;type&quot;</code>
    AggregateID string        <code>json:&quot;aggregate_id&quot;</code>
    Data      json.RawMessage <code>json:&quot;data&quot;</code>
    Timestamp time.Time       <code>json:&quot;timestamp&quot;</code>
}
<p>// Events for an order
var events = []Event{
    {Type: &quot;OrderCreated&quot;, AggregateID: &quot;ord-1&quot;, Data: []byte(<code>{&quot;user_id&quot;:&quot;user-1&quot;,&quot;total&quot;:99.99}</code>)},
    {Type: &quot;PaymentReceived&quot;, AggregateID: &quot;ord-1&quot;, Data: []byte(<code>{&quot;amount&quot;:99.99}</code>)},
    {Type: &quot;OrderShipped&quot;, AggregateID: &quot;ord-1&quot;, Data: []byte(<code>{&quot;tracking&quot;:&quot;TRACK123&quot;}</code>)},
}</p>
<p>// Publish events to Kafka
func PublishEvent(event Event) error {
    writer := kafka.NewWriter(kafka.WriterConfig{
        Brokers: []string{&quot;localhost:9092&quot;},
        Topic:   &quot;order-events&quot;,
    })
    defer writer.Close()</p>
<p>value, _ := json.Marshal(event)
    return writer.WriteMessages(context.Background(), kafka.Message{
        Key:   []byte(event.AggregateID),
        Value: value,
    })
}</p>
<p>// Rebuild order state from events
func RebuildOrderState(orderID string) *Order {
    reader := kafka.NewReader(kafka.ReaderConfig{
        Brokers: []string{&quot;localhost:9092&quot;},
        Topic:   &quot;order-events&quot;,
    })
    defer reader.Close()</p>
<p>order := &amp;Order{ID: orderID}</p>
<p>for {
        msg, err := reader.ReadMessage(context.Background())
        if err != nil {
            break
        }</p>
<p>var event Event
        json.Unmarshal(msg.Value, &amp;event)</p>
<p>if event.AggregateID != orderID {
            continue
        }</p>
<p>// Apply event
        switch event.Type {
        case &quot;OrderCreated&quot;:
            order.Status = &quot;created&quot;
        case &quot;PaymentReceived&quot;:
            order.Status = &quot;paid&quot;
        case &quot;OrderShipped&quot;:
            order.Status = &quot;shipped&quot;
        }
    }</p>
<p>return order
}</code></pre></p>
<h3>2. CQRS (Command Query Responsibility Segregation)</h3>
<pre><code class="language-go">// Write Model (commands)
type OrderCommandHandler struct {
    kafkaWriter *kafka.Writer
}
<p>func (h *OrderCommandHandler) CreateOrder(cmd CreateOrderCommand) error {
    // Validate command
    
    // Publish event
    event := OrderCreatedEvent{
        OrderID: uuid.New().String(),
        UserID:  cmd.UserID,
        Items:   cmd.Items,
        Total:   cmd.Total,
    }
    
    value, _ := json.Marshal(event)
    return h.kafkaWriter.WriteMessages(context.Background(), kafka.Message{
        Key:   []byte(event.OrderID),
        Value: value,
    })
}</p>
<p>// Read Model (queries)
type OrderQueryHandler struct {
    db *sql.DB
}</p>
<p>func (h *OrderQueryHandler) GetOrder(orderID string) (*Order, error) {
    // Read from optimized read database
    var order Order
    err := h.db.QueryRow(&quot;SELECT * FROM orders WHERE id = $1&quot;, orderID).Scan(&amp;order)
    return &amp;order, err
}</p>
<p>// Event Processor (updates read model)
func EventProcessor() {
    reader := kafka.NewReader(kafka.ReaderConfig{
        Brokers: []string{&quot;localhost:9092&quot;},
        Topic:   &quot;order-events&quot;,
        GroupID: &quot;read-model-updater&quot;,
    })
    defer reader.Close()</p>
<p>for {
        msg, _ := reader.ReadMessage(context.Background())
        
        var event OrderCreatedEvent
        json.Unmarshal(msg.Value, &amp;event)
        
        // Update read database
        db.Exec(<code>
            INSERT INTO orders (id, user_id, total, status)
            VALUES ($1, $2, $3, &#039;created&#039;)
        </code>, event.OrderID, event.UserID, event.Total)
    }
}</code></pre></p>
<h3>3. Saga Pattern (Distributed Transactions)</h3>
<pre><code class="language-go">// Order Saga - coordinated via Kafka
func OrderSaga() {
    reader := kafka.NewReader(kafka.ReaderConfig{
        Brokers: []string{&quot;localhost:9092&quot;},
        Topic:   &quot;order-commands&quot;,
        GroupID: &quot;order-saga&quot;,
    })
    defer reader.Close()
<p>writer := kafka.NewWriter(kafka.WriterConfig{
        Brokers: []string{&quot;localhost:9092&quot;},
        Topic:   &quot;saga-events&quot;,
    })
    defer writer.Close()</p>
<p>for {
        msg, _ := reader.ReadMessage(context.Background())
        
        var cmd CreateOrderCommand
        json.Unmarshal(msg.Value, &amp;cmd)
        
        // Step 1: Reserve inventory
        inventoryEvent := ReserveInventoryEvent{OrderID: cmd.OrderID}
        publishEvent(writer, &quot;inventory-commands&quot;, inventoryEvent)
        
        // Wait for confirmation
        confirmed := waitForEvent(&quot;inventory-confirmed&quot;, cmd.OrderID)
        if !confirmed {
            // Compensate - cancel order
            cancelEvent := CancelOrderEvent{OrderID: cmd.OrderID}
            publishEvent(writer, &quot;order-commands&quot;, cancelEvent)
            continue
        }
        
        // Step 2: Process payment
        paymentEvent := ProcessPaymentEvent{OrderID: cmd.OrderID, Amount: cmd.Total}
        publishEvent(writer, &quot;payment-commands&quot;, paymentEvent)
        
        // Wait for confirmation
        confirmed = waitForEvent(&quot;payment-confirmed&quot;, cmd.OrderID)
        if !confirmed {
            // Compensate - release inventory
            releaseEvent := ReleaseInventoryEvent{OrderID: cmd.OrderID}
            publishEvent(writer, &quot;inventory-commands&quot;, releaseEvent)
            continue
        }
        
        // Success - confirm order
        confirmEvent := ConfirmOrderEvent{OrderID: cmd.OrderID}
        publishEvent(writer, &quot;order-events&quot;, confirmEvent)
    }
}</code></pre></p>
<h3>4. Change Data Capture (CDC)</h3>
<pre><code class="language-go">// Capture database changes and publish to Kafka
func DatabaseCDC() {
    // Listen to PostgreSQL WAL (Write-Ahead Log)
    // Or use Debezium connector
    
    // When user is created in database:
    user := User{ID: 1, Name: &quot;John&quot;, Email: &quot;john@example.com&quot;}
    
    // Publish to Kafka
    event := UserCreatedEvent{
        UserID: user.ID,
        Name:   user.Name,
        Email:  user.Email,
    }
    
    publishToKafka(&quot;user-events&quot;, event)
    
    // Other services consume this event
    // - Send welcome email
    // - Update analytics
    // - Sync to Elasticsearch
}</code></pre>
<p>---</p>
<h2>Best Practices</h2>
<h3>1. Message Serialization</h3>
<pre><code class="language-go">// JSON (simple, human-readable)
type OrderEvent struct {
    OrderID string  <code>json:&quot;order_id&quot;</code>
    Amount  float64 <code>json:&quot;amount&quot;</code>
}
<p>// Avro (schema evolution, compact)
import &quot;github.com/linkedin/goavro/v2&quot;</p>
<p>schema := <code>{
  &quot;type&quot;: &quot;record&quot;,
  &quot;name&quot;: &quot;OrderEvent&quot;,
  &quot;fields&quot;: [
    {&quot;name&quot;: &quot;order_id&quot;, &quot;type&quot;: &quot;string&quot;},
    {&quot;name&quot;: &quot;amount&quot;, &quot;type&quot;: &quot;double&quot;}
  ]
}</code></p>
<p>codec, _ := goavro.NewCodec(schema)
binary, _ := codec.BinaryFromNative(nil, map[string]interface{}{
    &quot;order_id&quot;: &quot;ord-123&quot;,
    &quot;amount&quot;:   99.99,
})</code></pre></p>
<h3>2. Error Handling</h3>
<pre><code class="language-go">func ConsumeWithRetry() {
    reader := kafka.NewReader(kafka.ReaderConfig{
        Brokers: []string{&quot;localhost:9092&quot;},
        Topic:   &quot;orders&quot;,
        GroupID: &quot;order-processor&quot;,
    })
    defer reader.Close()
<p>deadLetterWriter := kafka.NewWriter(kafka.WriterConfig{
        Brokers: []string{&quot;localhost:9092&quot;},
        Topic:   &quot;orders-dlq&quot;, // Dead Letter Queue
    })
    defer deadLetterWriter.Close()</p>
<p>for {
        msg, _ := reader.FetchMessage(context.Background())
        
        // Retry logic
        var err error
        for attempt := 0; attempt &lt; 3; attempt++ {
            err = processMessage(msg)
            if err == nil {
                break
            }
            time.Sleep(time.Second * time.Duration(attempt+1))
        }
        
        if err != nil {
            // Send to DLQ after max retries
            deadLetterWriter.WriteMessages(context.Background(), kafka.Message{
                Key:   msg.Key,
                Value: msg.Value,
                Headers: []kafka.Header{
                    {Key: &quot;error&quot;, Value: []byte(err.Error())},
                },
            })
        }
        
        // Commit regardless
        reader.CommitMessages(context.Background(), msg)
    }
}</code></pre></p>
<h3>3. Exactly-Once Semantics</h3>
<pre><code class="language-go">// Enable idempotence
writer := kafka.NewWriter(kafka.WriterConfig{
    Brokers:  []string{&quot;localhost:9092&quot;},
    Topic:    &quot;orders&quot;,
    Idempotent: true, // Prevents duplicate messages
})
<p>// Transactional writes
writer := kafka.NewWriter(kafka.WriterConfig{
    Brokers:  []string{&quot;localhost:9092&quot;},
    Topic:    &quot;orders&quot;,
    Transactions: true,
    TransactionalID: &quot;order-producer-1&quot;,
})</p>
<p>// Begin transaction
writer.BeginTxn()</p>
<p>// Write messages
writer.WriteMessages(ctx, messages...)</p>
<p>// Commit transaction
writer.CommitTxn()
// or writer.AbortTxn()</code></pre></p>
<h3>4. Monitoring</h3>
<pre><code class="language-go">import &quot;github.com/prometheus/client_golang/prometheus&quot;
<p>var (
    messagesProduced = prometheus.NewCounter(prometheus.CounterOpts{
        Name: &quot;kafka_messages_produced_total&quot;,
    })
    
    messagesConsumed = prometheus.NewCounter(prometheus.CounterOpts{
        Name: &quot;kafka_messages_consumed_total&quot;,
    })
    
    consumerLag = prometheus.NewGauge(prometheus.GaugeOpts{
        Name: &quot;kafka_consumer_lag&quot;,
    })
)</p>
<p>func init() {
    prometheus.MustRegister(messagesProduced, messagesConsumed, consumerLag)
}</code></pre></p>
<p>---</p>
<h2>Interview Questions</h2>
<strong>Q1: Kafka vs RabbitMQ - when to use each?</strong>
<strong>Answer:</strong>
<li><strong>Kafka</strong>: High throughput, message retention, replay capability, stream processing. Use for event streaming, log aggregation, CDC.</li>
<li><strong>RabbitMQ</strong>: Complex routing, traditional queuing, lower throughput. Use for task queues, RPC, priority queues.</li>
<strong>Q2: How does Kafka guarantee message ordering?</strong>
<strong>Answer:</strong> Ordering guaranteed <strong>within a partition only</strong>. Messages with same key go to same partition (hash-based). To ensure global ordering, use single partition (limits throughput). For per-entity ordering (e.g., per user), use entity ID as key.
<strong>Q3: What is consumer lag and how to handle it?</strong>
<strong>Answer:</strong> Lag = difference between latest offset and consumer's current offset. Indicates consumer can't keep up. Solutions:
<li>Scale consumers (add more to group)</li>
<li>Optimize processing (faster code, batching)</li>
<li>Increase partitions (more parallelism)</li>
<li>Tune consumer config (fetch sizes, poll intervals)</li>
<strong>Q4: Explain Kafka replication.</strong>
<strong>Answer:</strong> Each partition has N replicas across brokers. One leader (handles reads/writes), others followers (sync data). If leader fails, follower promoted. Replication factor 3 = 1 leader + 2 followers. ISR (In-Sync Replicas) = replicas caught up with leader.
<strong>Q5: How do you handle poison messages?</strong>
<strong>Answer:</strong> Poison message = message that causes processing to fail repeatedly. Solutions:
1. Retry with exponential backoff
2. Dead Letter Queue (DLQ) after max retries
3. Manual review/fix in DLQ
4. Skip message (log and continue)
5. Circuit breaker pattern
<p>---</p>
<h2>Hands-On Exercise</h2>
<h3>Task: Build Event-Driven Order System</h3>
<pre><code class="language-go">// Complete event-driven order processing
package main
<p>import (
    &quot;context&quot;
    &quot;encoding/json&quot;
    &quot;log&quot;
    &quot;time&quot;
    
    &quot;github.com/segmentio/kafka-go&quot;
)</p>
<p>// Events
type OrderCreatedEvent struct {
    OrderID   string    <code>json:&quot;order_id&quot;</code>
    UserID    string    <code>json:&quot;user_id&quot;</code>
    Total     float64   <code>json:&quot;total&quot;</code>
    Timestamp time.Time <code>json:&quot;timestamp&quot;</code>
}</p>
<p>type PaymentProcessedEvent struct {
    OrderID string  <code>json:&quot;order_id&quot;</code>
    Amount  float64 <code>json:&quot;amount&quot;</code>
}</p>
<p>type OrderShippedEvent struct {
    OrderID  string <code>json:&quot;order_id&quot;</code>
    Tracking string <code>json:&quot;tracking&quot;</code>
}</p>
<p>// Order Service - publishes OrderCreated
func OrderService() {
    writer := kafka.NewWriter(kafka.WriterConfig{
        Brokers: []string{&quot;localhost:9092&quot;},
        Topic:   &quot;order-events&quot;,
    })
    defer writer.Close()</p>
<p>event := OrderCreatedEvent{
        OrderID:   &quot;ord-12345&quot;,
        UserID:    &quot;user-67890&quot;,
        Total:     199.99,
        Timestamp: time.Now(),
    }</p>
<p>value, _ := json.Marshal(event)
    writer.WriteMessages(context.Background(), kafka.Message{
        Key:   []byte(event.OrderID),
        Value: value,
    })</p>
<p>log.Println(&quot;Order created:&quot;, event.OrderID)
}</p>
<p>// Payment Service - consumes OrderCreated, publishes PaymentProcessed
func PaymentService() {
    reader := kafka.NewReader(kafka.ReaderConfig{
        Brokers: []string{&quot;localhost:9092&quot;},
        Topic:   &quot;order-events&quot;,
        GroupID: &quot;payment-service&quot;,
    })
    defer reader.Close()</p>
<p>writer := kafka.NewWriter(kafka.WriterConfig{
        Brokers: []string{&quot;localhost:9092&quot;},
        Topic:   &quot;payment-events&quot;,
    })
    defer writer.Close()</p>
<p>for {
        msg, _ := reader.ReadMessage(context.Background())
        
        var orderEvent OrderCreatedEvent
        json.Unmarshal(msg.Value, &amp;orderEvent)</p>
<p>// Process payment
        log.Printf(&quot;Processing payment for order: %s\n&quot;, orderEvent.OrderID)
        time.Sleep(2 * time.Second) // Simulate payment processing</p>
<p>// Publish payment event
        paymentEvent := PaymentProcessedEvent{
            OrderID: orderEvent.OrderID,
            Amount:  orderEvent.Total,
        }
        value, _ := json.Marshal(paymentEvent)
        writer.WriteMessages(context.Background(), kafka.Message{
            Key:   []byte(paymentEvent.OrderID),
            Value: value,
        })</p>
<p>log.Printf(&quot;Payment processed for order: %s\n&quot;, orderEvent.OrderID)
    }
}</p>
<p>// Shipping Service - consumes PaymentProcessed, publishes OrderShipped
func ShippingService() {
    reader := kafka.NewReader(kafka.ReaderConfig{
        Brokers: []string{&quot;localhost:9092&quot;},
        Topic:   &quot;payment-events&quot;,
        GroupID: &quot;shipping-service&quot;,
    })
    defer reader.Close()</p>
<p>writer := kafka.NewWriter(kafka.WriterConfig{
        Brokers: []string{&quot;localhost:9092&quot;},
        Topic:   &quot;shipping-events&quot;,
    })
    defer writer.Close()</p>
<p>for {
        msg, _ := reader.ReadMessage(context.Background())
        
        var paymentEvent PaymentProcessedEvent
        json.Unmarshal(msg.Value, &amp;paymentEvent)</p>
<p>// Ship order
        log.Printf(&quot;Shipping order: %s\n&quot;, paymentEvent.OrderID)
        time.Sleep(1 * time.Second)</p>
<p>// Publish shipping event
        shippingEvent := OrderShippedEvent{
            OrderID:  paymentEvent.OrderID,
            Tracking: &quot;TRACK-&quot; + paymentEvent.OrderID,
        }
        value, _ := json.Marshal(shippingEvent)
        writer.WriteMessages(context.Background(), kafka.Message{
            Key:   []byte(shippingEvent.OrderID),
            Value: value,
        })</p>
<p>log.Printf(&quot;Order shipped: %s, Tracking: %s\n&quot;, shippingEvent.OrderID, shippingEvent.Tracking)
    }
}</p>
<p>// Notification Service - consumes all events
func NotificationService() {
    reader := kafka.NewReader(kafka.ReaderConfig{
        Brokers: []string{&quot;localhost:9092&quot;},
        Topic:   &quot;order-events&quot;,
        GroupID: &quot;notification-service&quot;,
    })
    defer reader.Close()</p>
<p>for {
        msg, _ := reader.ReadMessage(context.Background())
        log.Printf(&quot;Sending notification for: %s\n&quot;, msg.Value)
    }
}</p>
<p>func main() {
    // Start services
    go PaymentService()
    go ShippingService()
    go NotificationService()</p>
<p>time.Sleep(2 * time.Second)</p>
<p>// Create order
    OrderService()</p>
<p>select {} // Keep running
}</code></pre></p>
<p>---</p>
<h2>üìö Additional Resources</h2>
<li>[Kafka Documentation](https://kafka.apache.org/documentation/)</li>
<li>[Designing Event-Driven Systems (Ben Stopford)](https://www.confluent.io/designing-event-driven-systems/)</li>
<li>[Kafka: The Definitive Guide](https://www.confluent.io/resources/kafka-the-definitive-guide/)</li>
<li>[Segmentio Kafka-Go](https://github.com/segmentio/kafka-go)</li>
<p>---</p>
<h2>‚úÖ Module Checklist</h2>
<li>[ ] Install and configure Kafka</li>
<li>[ ] Implement producer with partitioning</li>
<li>[ ] Build consumer with offset management</li>
<li>[ ] Create consumer groups for parallel processing</li>
<li>[ ] Implement event sourcing pattern</li>
<li>[ ] Build CQRS with Kafka</li>
<li>[ ] Implement saga pattern for distributed transactions</li>
<li>[ ] Complete event-driven order system exercise</li></ul>
<p>---</p>
<strong>Next Module:</strong> [Module 20: Frontend-Backend Integration](./20_Frontend_Backend_Integration.md) - Connect UIs to your APIs! üåê

    </div>
    

    <div class="module-content" id="module-20">
        <h1>Module 20: Frontend-Backend Integration üåê</h1>
<h2>Connect Your Backend APIs to Modern UIs</h2>
<strong>Duration:</strong> 5-6 hours  
<strong>Prerequisites:</strong> Module 03 (REST APIs), Module 17 (Microservices)  
<strong>Outcome:</strong> Master communication patterns between frontend and backend
<p>---</p>
<h2>üìö Table of Contents</h2>
<p>1. [Communication Patterns](#communication-patterns)
2. [RESTful API Best Practices](#restful-api-best-practices)
3. [GraphQL](#graphql)
4. [WebSockets](#websockets)
5. [CORS](#cors)
6. [API Documentation](#api-documentation)
7. [Best Practices](#best-practices)
8. [Interview Questions](#interview-questions)
9. [Hands-On Exercise](#hands-on-exercise)</p>
<p>---</p>
<h2>Communication Patterns</h2>
<h3>Overview</h3>
<pre><code class="language-text">Frontend ‚Üê‚Üí Backend Communication
<p>1. REST (Representational State Transfer)
   - Request/response model
   - Stateless
   - HTTP methods (GET, POST, PUT, DELETE)</p>
<p>2. GraphQL
   - Query language
   - Request exactly what you need
   - Single endpoint</p>
<p>3. WebSockets
   - Bidirectional communication
   - Real-time updates
   - Persistent connection</p>
<p>4. Server-Sent Events (SSE)
   - One-way server ‚Üí client
   - HTTP-based
   - Simpler than WebSockets</code></pre></p>
<p>---</p>
<h2>RESTful API Best Practices</h2>
<h3>1. Resource Naming</h3>
<pre><code class="language-text">Good API Design:
<p>GET    /api/v1/users           # List all users
GET    /api/v1/users/123       # Get specific user
POST   /api/v1/users           # Create user
PUT    /api/v1/users/123       # Update user (full)
PATCH  /api/v1/users/123       # Update user (partial)
DELETE /api/v1/users/123       # Delete user</p>
<p>GET    /api/v1/users/123/orders  # User&#039;s orders (nested resource)</p>
<p>Bad Examples:
GET /api/v1/getAllUsers        ‚ùå Verb in URL
POST /api/v1/user/create       ‚ùå Use POST /users
GET /api/v1/users/delete/123   ‚ùå Use DELETE method</code></pre></p>
<h3>2. HTTP Status Codes</h3>
<pre><code class="language-go">// Proper status code usage
func CreateUser(w http.ResponseWriter, r *http.Request) {
    var user User
    if err := json.NewDecoder(r.Body).Decode(&amp;user); err != nil {
        // 400 Bad Request - client error
        http.Error(w, &quot;Invalid request body&quot;, http.StatusBadRequest)
        return
    }
<p>if err := validateUser(&amp;user); err != nil {
        // 422 Unprocessable Entity - validation failed
        w.WriteHeader(http.StatusUnprocessableEntity)
        json.NewEncoder(w).Encode(map[string]string{&quot;error&quot;: err.Error()})
        return
    }</p>
<p>if err := db.Create(&amp;user).Error; err != nil {
        // 500 Internal Server Error
        http.Error(w, &quot;Database error&quot;, http.StatusInternalServerError)
        return
    }</p>
<p>// 201 Created - resource created successfully
    w.WriteHeader(http.StatusCreated)
    w.Header().Set(&quot;Location&quot;, fmt.Sprintf(&quot;/api/v1/users/%d&quot;, user.ID))
    json.NewEncoder(w).Encode(user)
}</code></pre></p>
<h3>3. Pagination</h3>
<pre><code class="language-go">type PaginatedResponse struct {
    Data       []User <code>json:&quot;data&quot;</code>
    Page       int    <code>json:&quot;page&quot;</code>
    PerPage    int    <code>json:&quot;per_page&quot;</code>
    Total      int64  <code>json:&quot;total&quot;</code>
    TotalPages int    <code>json:&quot;total_pages&quot;</code>
}
<p>func ListUsers(w http.ResponseWriter, r *http.Request) {
    // Parse query params
    page, _ := strconv.Atoi(r.URL.Query().Get(&quot;page&quot;))
    if page &lt; 1 {
        page = 1
    }
    perPage, _ := strconv.Atoi(r.URL.Query().Get(&quot;per_page&quot;))
    if perPage &lt; 1 || perPage &gt; 100 {
        perPage = 20
    }</p>
<p>offset := (page - 1) * perPage</p>
<p>var users []User
    var total int64</p>
<p>db.Model(&amp;User{}).Count(&amp;total)
    db.Offset(offset).Limit(perPage).Find(&amp;users)</p>
<p>totalPages := int(math.Ceil(float64(total) / float64(perPage)))</p>
<p>response := PaginatedResponse{
        Data:       users,
        Page:       page,
        PerPage:    perPage,
        Total:      total,
        TotalPages: totalPages,
    }</p>
<p>json.NewEncoder(w).Encode(response)
}</p>
<p>/*
Request:
GET /api/v1/users?page=2&amp;per_page=20</p>
<p>Response:
{
  &quot;data&quot;: [...],
  &quot;page&quot;: 2,
  &quot;per_page&quot;: 20,
  &quot;total&quot;: 150,
  &quot;total_pages&quot;: 8
}
*/</code></pre></p>
<h3>4. Filtering & Sorting</h3>
<pre><code class="language-go">func ListProducts(w http.ResponseWriter, r *http.Request) {
    query := db.Model(&amp;Product{})
<p>// Filtering
    if category := r.URL.Query().Get(&quot;category&quot;); category != &quot;&quot; {
        query = query.Where(&quot;category = ?&quot;, category)
    }
    if minPrice := r.URL.Query().Get(&quot;min_price&quot;); minPrice != &quot;&quot; {
        query = query.Where(&quot;price &gt;= ?&quot;, minPrice)
    }
    if maxPrice := r.URL.Query().Get(&quot;max_price&quot;); maxPrice != &quot;&quot; {
        query = query.Where(&quot;price &lt;= ?&quot;, maxPrice)
    }</p>
<p>// Sorting
    sortBy := r.URL.Query().Get(&quot;sort_by&quot;)
    if sortBy == &quot;&quot; {
        sortBy = &quot;created_at&quot;
    }
    order := r.URL.Query().Get(&quot;order&quot;)
    if order != &quot;asc&quot; &amp;&amp; order != &quot;desc&quot; {
        order = &quot;desc&quot;
    }
    query = query.Order(fmt.Sprintf(&quot;%s %s&quot;, sortBy, order))</p>
<p>// Execute query
    var products []Product
    query.Find(&amp;products)</p>
<p>json.NewEncoder(w).Encode(products)
}</p>
<p>/*
Examples:
GET /api/v1/products?category=electronics&amp;min_price=100&amp;sort_by=price&amp;order=asc
GET /api/v1/products?category=books&amp;max_price=50&amp;sort_by=rating&amp;order=desc
*/</code></pre></p>
<h3>5. API Versioning</h3>
<pre><code class="language-go">// Method 1: URL versioning (recommended)
r := mux.NewRouter()
v1 := r.PathPrefix(&quot;/api/v1&quot;).Subrouter()
v1.HandleFunc(&quot;/users&quot;, ListUsersV1).Methods(&quot;GET&quot;)
<p>v2 := r.PathPrefix(&quot;/api/v2&quot;).Subrouter()
v2.HandleFunc(&quot;/users&quot;, ListUsersV2).Methods(&quot;GET&quot;) // Different response format</p>
<p>// Method 2: Header versioning
func VersionMiddleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        version := r.Header.Get(&quot;API-Version&quot;)
        if version == &quot;&quot; {
            version = &quot;1&quot;
        }
        ctx := context.WithValue(r.Context(), &quot;api_version&quot;, version)
        next.ServeHTTP(w, r.WithContext(ctx))
    })
}</p>
<p>// Method 3: Content negotiation
// Accept: application/vnd.myapi.v1+json
// Accept: application/vnd.myapi.v2+json</code></pre></p>
<h3>6. HATEOAS (Hypermedia)</h3>
<pre><code class="language-go">type UserResponse struct {
    ID    int    <code>json:&quot;id&quot;</code>
    Name  string <code>json:&quot;name&quot;</code>
    Email string <code>json:&quot;email&quot;</code>
    Links struct {
        Self    string <code>json:&quot;self&quot;</code>
        Orders  string <code>json:&quot;orders&quot;</code>
        Profile string <code>json:&quot;profile&quot;</code>
    } <code>json:&quot;_links&quot;</code>
}
<p>func GetUser(w http.ResponseWriter, r *http.Request) {
    vars := mux.Vars(r)
    id := vars[&quot;id&quot;]</p>
<p>var user User
    db.First(&amp;user, id)</p>
<p>response := UserResponse{
        ID:    user.ID,
        Name:  user.Name,
        Email: user.Email,
    }
    response.Links.Self = fmt.Sprintf(&quot;/api/v1/users/%d&quot;, user.ID)
    response.Links.Orders = fmt.Sprintf(&quot;/api/v1/users/%d/orders&quot;, user.ID)
    response.Links.Profile = fmt.Sprintf(&quot;/api/v1/users/%d/profile&quot;, user.ID)</p>
<p>json.NewEncoder(w).Encode(response)
}</p>
<p>/*
Response:
{
  &quot;id&quot;: 123,
  &quot;name&quot;: &quot;John Doe&quot;,
  &quot;email&quot;: &quot;john@example.com&quot;,
  &quot;_links&quot;: {
    &quot;self&quot;: &quot;/api/v1/users/123&quot;,
    &quot;orders&quot;: &quot;/api/v1/users/123/orders&quot;,
    &quot;profile&quot;: &quot;/api/v1/users/123/profile&quot;
  }
}
*/</code></pre></p>
<p>---</p>
<h2>GraphQL</h2>
<h3>What is GraphQL?</h3>
<pre><code class="language-text">REST:
GET /users/123           ‚Üí Full user object
GET /users/123/posts     ‚Üí All posts
GET /posts/456/comments  ‚Üí All comments
(Multiple requests, over-fetching/under-fetching)
<p>GraphQL:
Single request, exact data needed:
{
  user(id: 123) {
    name
    email
    posts(limit: 5) {
      title
      comments(limit: 3) {
        text
        author { name }
      }
    }
  }
}</code></pre></p>
<h3>GraphQL Server in Go</h3>
<pre><code class="language-go">// Install: go get github.com/graphql-go/graphql
package main
<p>import (
    &quot;encoding/json&quot;
    &quot;log&quot;
    &quot;net/http&quot;</p>
<p>&quot;github.com/graphql-go/graphql&quot;
)</p>
<p>// Define schema
var userType = graphql.NewObject(graphql.ObjectConfig{
    Name: &quot;User&quot;,
    Fields: graphql.Fields{
        &quot;id&quot;:    &amp;graphql.Field{Type: graphql.Int},
        &quot;name&quot;:  &amp;graphql.Field{Type: graphql.String},
        &quot;email&quot;: &amp;graphql.Field{Type: graphql.String},
    },
})</p>
<p>var queryType = graphql.NewObject(graphql.ObjectConfig{
    Name: &quot;Query&quot;,
    Fields: graphql.Fields{
        &quot;user&quot;: &amp;graphql.Field{
            Type: userType,
            Args: graphql.FieldConfigArgument{
                &quot;id&quot;: &amp;graphql.ArgumentConfig{
                    Type: graphql.Int,
                },
            },
            Resolve: func(p graphql.ResolveParams) (interface{}, error) {
                id, _ := p.Args[&quot;id&quot;].(int)
                // Fetch from database
                return User{ID: id, Name: &quot;John&quot;, Email: &quot;john@example.com&quot;}, nil
            },
        },
    },
})</p>
<p>var schema, _ = graphql.NewSchema(graphql.SchemaConfig{
    Query: queryType,
})</p>
<p>func graphqlHandler(w http.ResponseWriter, r *http.Request) {
    var params struct {
        Query string <code>json:&quot;query&quot;</code>
    }
    json.NewDecoder(r.Body).Decode(&amp;params)</p>
<p>result := graphql.Do(graphql.Params{
        Schema:        schema,
        RequestString: params.Query,
    })</p>
<p>json.NewEncoder(w).Encode(result)
}</p>
<p>func main() {
    http.HandleFunc(&quot;/graphql&quot;, graphqlHandler)
    log.Fatal(http.ListenAndServe(&quot;:8080&quot;, nil))
}</code></pre></p>
<h3>GraphQL Mutations</h3>
<pre><code class="language-go">var mutationType = graphql.NewObject(graphql.ObjectConfig{
    Name: &quot;Mutation&quot;,
    Fields: graphql.Fields{
        &quot;createUser&quot;: &amp;graphql.Field{
            Type: userType,
            Args: graphql.FieldConfigArgument{
                &quot;name&quot;: &amp;graphql.ArgumentConfig{
                    Type: graphql.NewNonNull(graphql.String),
                },
                &quot;email&quot;: &amp;graphql.ArgumentConfig{
                    Type: graphql.NewNonNull(graphql.String),
                },
            },
            Resolve: func(p graphql.ResolveParams) (interface{}, error) {
                name, _ := p.Args[&quot;name&quot;].(string)
                email, _ := p.Args[&quot;email&quot;].(string)
<p>user := User{Name: name, Email: email}
                db.Create(&amp;user)</p>
<p>return user, nil
            },
        },
    },
})</p>
<p>// Client request:
/*
mutation {
  createUser(name: &quot;Jane Doe&quot;, email: &quot;jane@example.com&quot;) {
    id
    name
    email
  }
}
*/</code></pre></p>
<h3>GraphQL Subscriptions (Real-time)</h3>
<pre><code class="language-go">var subscriptionType = graphql.NewObject(graphql.ObjectConfig{
    Name: &quot;Subscription&quot;,
    Fields: graphql.Fields{
        &quot;messageAdded&quot;: &amp;graphql.Field{
            Type: messageType,
            Resolve: func(p graphql.ResolveParams) (interface{}, error) {
                // Subscribe to message channel
                msgChan := make(chan Message)
                // Return channel
                return msgChan, nil
            },
        },
    },
})
<p>// Client subscription:
/*
subscription {
  messageAdded {
    id
    text
    user { name }
  }
}
*/</code></pre></p>
<p>---</p>
<h2>WebSockets</h2>
<h3>WebSocket Server</h3>
<pre><code class="language-go">import (
    &quot;log&quot;
    &quot;net/http&quot;
<p>&quot;github.com/gorilla/websocket&quot;
)</p>
<p>var upgrader = websocket.Upgrader{
    CheckOrigin: func(r *http.Request) bool {
        return true // Allow all origins (configure properly in production)
    },
}</p>
<p>type Client struct {
    conn *websocket.Conn
    send chan []byte
}</p>
<p>type Hub struct {
    clients    map[*Client]bool
    broadcast  chan []byte
    register   chan *Client
    unregister chan *Client
}</p>
<p>func newHub() *Hub {
    return &amp;Hub{
        clients:    make(map[*Client]bool),
        broadcast:  make(chan []byte),
        register:   make(chan *Client),
        unregister: make(chan *Client),
    }
}</p>
<p>func (h *Hub) run() {
    for {
        select {
        case client := &lt;-h.register:
            h.clients[client] = true
        case client := &lt;-h.unregister:
            if _, ok := h.clients[client]; ok {
                delete(h.clients, client)
                close(client.send)
            }
        case message := &lt;-h.broadcast:
            for client := range h.clients {
                select {
                case client.send &lt;- message:
                default:
                    close(client.send)
                    delete(h.clients, client)
                }
            }
        }
    }
}</p>
<p>func (c *Client) readPump(hub *Hub) {
    defer func() {
        hub.unregister &lt;- c
        c.conn.Close()
    }()</p>
<p>for {
        _, message, err := c.conn.ReadMessage()
        if err != nil {
            break
        }
        hub.broadcast &lt;- message
    }
}</p>
<p>func (c *Client) writePump() {
    defer c.conn.Close()</p>
<p>for message := range c.send {
        if err := c.conn.WriteMessage(websocket.TextMessage, message); err != nil {
            break
        }
    }
}</p>
<p>func serveWs(hub *Hub, w http.ResponseWriter, r *http.Request) {
    conn, err := upgrader.Upgrade(w, r, nil)
    if err != nil {
        log.Println(err)
        return
    }</p>
<p>client := &amp;Client{conn: conn, send: make(chan []byte, 256)}
    hub.register &lt;- client</p>
<p>go client.writePump()
    go client.readPump(hub)
}</p>
<p>func main() {
    hub := newHub()
    go hub.run()</p>
<p>http.HandleFunc(&quot;/ws&quot;, func(w http.ResponseWriter, r *http.Request) {
        serveWs(hub, w, r)
    })</p>
<p>log.Fatal(http.ListenAndServe(&quot;:8080&quot;, nil))
}</code></pre></p>
<h3>JavaScript Client</h3>
<pre><code class="language-javascript">// Frontend WebSocket client
const socket = new WebSocket(&#039;ws://localhost:8080/ws&#039;);
<p>socket.onopen = () =&gt; {
    console.log(&#039;Connected to WebSocket&#039;);
    socket.send(JSON.stringify({ type: &#039;join&#039;, user: &#039;John&#039; }));
};</p>
<p>socket.onmessage = (event) =&gt; {
    const message = JSON.parse(event.data);
    console.log(&#039;Received:&#039;, message);
    // Update UI
    displayMessage(message);
};</p>
<p>socket.onclose = () =&gt; {
    console.log(&#039;Disconnected&#039;);
    // Reconnect logic
    setTimeout(() =&gt; {
        socket = new WebSocket(&#039;ws://localhost:8080/ws&#039;);
    }, 3000);
};</p>
<p>socket.onerror = (error) =&gt; {
    console.error(&#039;WebSocket error:&#039;, error);
};</p>
<p>// Send message
function sendMessage(text) {
    socket.send(JSON.stringify({
        type: &#039;message&#039;,
        text: text,
        timestamp: Date.now()
    }));
}</code></pre></p>
<h3>Chat Application Example</h3>
<pre><code class="language-go">type Message struct {
    Type      string    <code>json:&quot;type&quot;</code>
    User      string    <code>json:&quot;user&quot;</code>
    Text      string    <code>json:&quot;text&quot;</code>
    Timestamp time.Time <code>json:&quot;timestamp&quot;</code>
}
<p>func (c *Client) readPump(hub *Hub) {
    defer func() {
        hub.unregister &lt;- c
        c.conn.Close()
    }()</p>
<p>for {
        var msg Message
        err := c.conn.ReadJSON(&amp;msg)
        if err != nil {
            break
        }</p>
<p>msg.Timestamp = time.Now()</p>
<p>// Broadcast to all clients
        data, _ := json.Marshal(msg)
        hub.broadcast &lt;- data</p>
<p>// Save to database
        db.Create(&amp;msg)
    }
}</code></pre></p>
<p>---</p>
<h2>CORS</h2>
<h3>What is CORS?</h3>
<pre><code class="language-text">Cross-Origin Resource Sharing
<p>Browser security: prevents websites from making requests to different domains</p>
<p>Example:
Frontend: http://localhost:3000 (React app)
Backend:  http://localhost:8080 (Go API)</p>
<p>Without CORS: ‚ùå Blocked by browser
With CORS:    ‚úÖ Allowed</code></pre></p>
<h3>CORS Middleware</h3>
<pre><code class="language-go">import &quot;github.com/rs/cors&quot;
<p>func main() {
    r := mux.NewRouter()
    r.HandleFunc(&quot;/api/users&quot;, GetUsers).Methods(&quot;GET&quot;)</p>
<p>// CORS middleware
    c := cors.New(cors.Options{
        AllowedOrigins:   []string{&quot;http://localhost:3000&quot;, &quot;https://myapp.com&quot;},
        AllowedMethods:   []string{&quot;GET&quot;, &quot;POST&quot;, &quot;PUT&quot;, &quot;DELETE&quot;, &quot;OPTIONS&quot;},
        AllowedHeaders:   []string{&quot;Content-Type&quot;, &quot;Authorization&quot;},
        AllowCredentials: true,
        MaxAge:           300, // Cache preflight for 5 minutes
    })</p>
<p>handler := c.Handler(r)
    http.ListenAndServe(&quot;:8080&quot;, handler)
}</code></pre></p>
<h3>Manual CORS Headers</h3>
<pre><code class="language-go">func CORSMiddleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        w.Header().Set(&quot;Access-Control-Allow-Origin&quot;, &quot;*&quot;)
        w.Header().Set(&quot;Access-Control-Allow-Methods&quot;, &quot;GET, POST, PUT, DELETE, OPTIONS&quot;)
        w.Header().Set(&quot;Access-Control-Allow-Headers&quot;, &quot;Content-Type, Authorization&quot;)
<p>// Handle preflight
        if r.Method == &quot;OPTIONS&quot; {
            w.WriteHeader(http.StatusOK)
            return
        }</p>
<p>next.ServeHTTP(w, r)
    })
}</code></pre></p>
<h3>Preflight Requests</h3>
<pre><code class="language-text">Browser sends OPTIONS request first:
<p>OPTIONS /api/users
Origin: http://localhost:3000
Access-Control-Request-Method: POST
Access-Control-Request-Headers: Content-Type</p>
<p>Server responds:
200 OK
Access-Control-Allow-Origin: http://localhost:3000
Access-Control-Allow-Methods: GET, POST, PUT, DELETE
Access-Control-Allow-Headers: Content-Type</p>
<p>Then browser sends actual request:
POST /api/users</code></pre></p>
<p>---</p>
<h2>API Documentation</h2>
<h3>Swagger/OpenAPI</h3>
<pre><code class="language-go">// Install: go get -u github.com/swaggo/swag/cmd/swag
// Install: go get -u github.com/swaggo/http-swagger
<p>// @title User API
// @version 1.0
// @description This is a sample API server
// @host localhost:8080
// @BasePath /api/v1</p>
<p>// @Summary Get all users
// @Description Get list of all users with pagination
// @Tags users
// @Accept json
// @Produce json
// @Param page query int false &quot;Page number&quot;
// @Param per_page query int false &quot;Items per page&quot;
// @Success 200 {array} User
// @Router /users [get]
func GetUsers(w http.ResponseWriter, r *http.Request) {
    // Implementation
}</p>
<p>// @Summary Create user
// @Description Create a new user
// @Tags users
// @Accept json
// @Produce json
// @Param user body User true &quot;User object&quot;
// @Success 201 {object} User
// @Failure 400 {object} ErrorResponse
// @Router /users [post]
func CreateUser(w http.ResponseWriter, r *http.Request) {
    // Implementation
}</p>
<p>// Generate docs: swag init
// Serve: http://localhost:8080/swagger/index.html</code></pre></p>
<h3>API Blueprint</h3>
<pre><code class="language-markdown"># User API
<h2>Users Collection [/api/v1/users]</h2>
<h3>List Users [GET]</h3>
<p>+ Parameters
    + page: 1 (number, optional) - Page number
    + per_page: 20 (number, optional) - Items per page</p>
<p>+ Response 200 (application/json)
    
    + Body
    
            {
                &quot;data&quot;: [
                    {
                        &quot;id&quot;: 1,
                        &quot;name&quot;: &quot;John Doe&quot;,
                        &quot;email&quot;: &quot;john@example.com&quot;
                    }
                ],
                &quot;page&quot;: 1,
                &quot;total&quot;: 100
            }</p>
<h3>Create User [POST]</h3>
<p>+ Request (application/json)</p>
<p>{
            &quot;name&quot;: &quot;Jane Doe&quot;,
            &quot;email&quot;: &quot;jane@example.com&quot;
        }</p>
<p>+ Response 201 (application/json)</p>
<p>{
            &quot;id&quot;: 2,
            &quot;name&quot;: &quot;Jane Doe&quot;,
            &quot;email&quot;: &quot;jane@example.com&quot;
        }</code></pre></p>
<p>---</p>
<h2>Best Practices</h2>
<h3>1. Request/Response Wrapper</h3>
<pre><code class="language-go">type APIResponse struct {
    Success bool        <code>json:&quot;success&quot;</code>
    Data    interface{} <code>json:&quot;data,omitempty&quot;</code>
    Error   string      <code>json:&quot;error,omitempty&quot;</code>
    Meta    *Meta       <code>json:&quot;meta,omitempty&quot;</code>
}
<p>type Meta struct {
    Page       int   <code>json:&quot;page,omitempty&quot;</code>
    PerPage    int   <code>json:&quot;per_page,omitempty&quot;</code>
    Total      int64 <code>json:&quot;total,omitempty&quot;</code>
    TotalPages int   <code>json:&quot;total_pages,omitempty&quot;</code>
}</p>
<p>func SuccessResponse(w http.ResponseWriter, data interface{}, meta *Meta) {
    w.Header().Set(&quot;Content-Type&quot;, &quot;application/json&quot;)
    json.NewEncoder(w).Encode(APIResponse{
        Success: true,
        Data:    data,
        Meta:    meta,
    })
}</p>
<p>func ErrorResponse(w http.ResponseWriter, message string, statusCode int) {
    w.Header().Set(&quot;Content-Type&quot;, &quot;application/json&quot;)
    w.WriteHeader(statusCode)
    json.NewEncoder(w).Encode(APIResponse{
        Success: false,
        Error:   message,
    })
}</code></pre></p>
<h3>2. Rate Limiting</h3>
<pre><code class="language-go">import &quot;golang.org/x/time/rate&quot;
<p>var limiter = rate.NewLimiter(10, 100) // 10 req/sec, burst 100</p>
<p>func RateLimitMiddleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        if !limiter.Allow() {
            http.Error(w, &quot;Too many requests&quot;, http.StatusTooManyRequests)
            return
        }
        next.ServeHTTP(w, r)
    })
}</code></pre></p>
<h3>3. Caching</h3>
<pre><code class="language-go">func CacheMiddleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        // Cache GET requests for 5 minutes
        if r.Method == &quot;GET&quot; {
            w.Header().Set(&quot;Cache-Control&quot;, &quot;public, max-age=300&quot;)
        } else {
            w.Header().Set(&quot;Cache-Control&quot;, &quot;no-cache&quot;)
        }
        next.ServeHTTP(w, r)
    })
}</code></pre>
<h3>4. Request ID Tracking</h3>
<pre><code class="language-go">func RequestIDMiddleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        requestID := r.Header.Get(&quot;X-Request-ID&quot;)
        if requestID == &quot;&quot; {
            requestID = uuid.New().String()
        }
        w.Header().Set(&quot;X-Request-ID&quot;, requestID)
        
        ctx := context.WithValue(r.Context(), &quot;request_id&quot;, requestID)
        next.ServeHTTP(w, r.WithContext(ctx))
    })
}</code></pre>
<p>---</p>
<h2>Interview Questions</h2>
<strong>Q1: REST vs GraphQL - when to use each?</strong>
<strong>Answer:</strong>
<ul><li><strong>REST</strong>: Simple CRUD, caching important, public APIs, mobile apps (predictable data)</li>
<li><strong>GraphQL</strong>: Complex data relationships, multiple client types (web/mobile), over-fetching/under-fetching problems, rapid frontend development</li>
<strong>Q2: How do WebSockets differ from HTTP polling?</strong>
<strong>Answer:</strong>
<li><strong>HTTP Polling</strong>: Client repeatedly requests server (every N seconds). Inefficient, latency, server load.</li>
<li><strong>WebSockets</strong>: Persistent bidirectional connection. Real-time, efficient, lower latency. Use for chat, live updates, gaming.</li>
<strong>Q3: Explain CORS preflight requests.</strong>
<strong>Answer:</strong> Browser sends OPTIONS request before actual request to check if cross-origin request allowed. Server responds with allowed methods/headers. Then browser sends real request. Only for "complex" requests (POST with JSON, custom headers).
<strong>Q4: How do you handle API versioning?</strong>
<strong>Answer:</strong> 
1. <strong>URL versioning</strong>: <code>/api/v1/users</code> (most common, clear)
2. <strong>Header versioning</strong>: <code>Accept: application/vnd.api.v2+json</code> (cleaner URLs)
3. <strong>Query param</strong>: <code>/api/users?version=2</code> (not recommended)
<p>Choose based on: breaking changes frequency, client flexibility, documentation needs.</p>
<strong>Q5: Best practices for pagination?</strong>
<strong>Answer:</strong>
<li><strong>Offset-based</strong>: <code>?page=2&per_page=20</code> (simple, can skip pages)</li>
<li><strong>Cursor-based</strong>: <code>?cursor=abc123&limit=20</code> (better for real-time data, no skipped records)</li>
<li>Include metadata: total count, total pages, next/prev cursors</li>
<li>Limit max per_page (prevent abuse)</li>
<li>Use indexes on sort columns</li>
<p>---</p>
<h2>Hands-On Exercise</h2>
<h3>Task: Build Full-Stack API with Multiple Communication Patterns</h3>
<pre><code class="language-go">package main
<p>import (
    &quot;encoding/json&quot;
    &quot;log&quot;
    &quot;net/http&quot;
    &quot;strconv&quot;
    &quot;sync&quot;</p>
<p>&quot;github.com/gorilla/mux&quot;
    &quot;github.com/gorilla/websocket&quot;
    &quot;github.com/rs/cors&quot;
)</p>
<p>// Models
type Product struct {
    ID          int     <code>json:&quot;id&quot;</code>
    Name        string  <code>json:&quot;name&quot;</code>
    Description string  <code>json:&quot;description&quot;</code>
    Price       float64 <code>json:&quot;price&quot;</code>
    Category    string  <code>json:&quot;category&quot;</code>
}</p>
<p>var (
    products   = make(map[int]Product)
    productsMu sync.RWMutex
    nextID     = 1
)</p>
<p>// REST: List products with pagination and filtering
func ListProducts(w http.ResponseWriter, r *http.Request) {
    productsMu.RLock()
    defer productsMu.RUnlock()</p>
<p>// Filter by category
    category := r.URL.Query().Get(&quot;category&quot;)
    
    var filtered []Product
    for _, p := range products {
        if category == &quot;&quot; || p.Category == category {
            filtered = append(filtered, p)
        }
    }</p>
<p>// Pagination
    page, _ := strconv.Atoi(r.URL.Query().Get(&quot;page&quot;))
    if page &lt; 1 {
        page = 1
    }
    perPage := 10
    start := (page - 1) * perPage
    end := start + perPage</p>
<p>if start &gt; len(filtered) {
        filtered = []Product{}
    } else if end &gt; len(filtered) {
        filtered = filtered[start:]
    } else {
        filtered = filtered[start:end]
    }</p>
<p>w.Header().Set(&quot;Content-Type&quot;, &quot;application/json&quot;)
    json.NewEncoder(w).Encode(map[string]interface{}{
        &quot;data&quot;:  filtered,
        &quot;page&quot;:  page,
        &quot;total&quot;: len(products),
    })
}</p>
<p>// REST: Create product
func CreateProduct(w http.ResponseWriter, r *http.Request) {
    var product Product
    if err := json.NewDecoder(r.Body).Decode(&amp;product); err != nil {
        http.Error(w, err.Error(), http.StatusBadRequest)
        return
    }</p>
<p>productsMu.Lock()
    product.ID = nextID
    nextID++
    products[product.ID] = product
    productsMu.Unlock()</p>
<p>// Notify WebSocket clients
    hub.broadcast &lt;- []byte(fmt.Sprintf(&quot;New product: %s&quot;, product.Name))</p>
<p>w.WriteHeader(http.StatusCreated)
    json.NewEncoder(w).Encode(product)
}</p>
<p>// WebSocket Hub
type Hub struct {
    clients    map[*Client]bool
    broadcast  chan []byte
    register   chan *Client
    unregister chan *Client
}</p>
<p>var hub = &amp;Hub{
    clients:    make(map[*Client]bool),
    broadcast:  make(chan []byte),
    register:   make(chan *Client),
    unregister: make(chan *Client),
}</p>
<p>func (h *Hub) run() {
    for {
        select {
        case client := &lt;-h.register:
            h.clients[client] = true
        case client := &lt;-h.unregister:
            if _, ok := h.clients[client]; ok {
                delete(h.clients, client)
                close(client.send)
            }
        case message := &lt;-h.broadcast:
            for client := range h.clients {
                select {
                case client.send &lt;- message:
                default:
                    close(client.send)
                    delete(h.clients, client)
                }
            }
        }
    }
}</p>
<p>type Client struct {
    conn *websocket.Conn
    send chan []byte
}</p>
<p>var upgrader = websocket.Upgrader{
    CheckOrigin: func(r *http.Request) bool { return true },
}</p>
<p>func ServeWs(w http.ResponseWriter, r *http.Request) {
    conn, err := upgrader.Upgrade(w, r, nil)
    if err != nil {
        log.Println(err)
        return
    }</p>
<p>client := &amp;Client{conn: conn, send: make(chan []byte, 256)}
    hub.register &lt;- client</p>
<p>go client.writePump()
    go client.readPump()
}</p>
<p>func (c *Client) readPump() {
    defer func() {
        hub.unregister &lt;- c
        c.conn.Close()
    }()
    for {
        _, _, err := c.conn.ReadMessage()
        if err != nil {
            break
        }
    }
}</p>
<p>func (c *Client) writePump() {
    defer c.conn.Close()
    for message := range c.send {
        c.conn.WriteMessage(websocket.TextMessage, message)
    }
}</p>
<p>func main() {
    // Initialize with sample data
    products[1] = Product{ID: 1, Name: &quot;Laptop&quot;, Price: 999.99, Category: &quot;electronics&quot;}
    products[2] = Product{ID: 2, Name: &quot;Book&quot;, Price: 19.99, Category: &quot;books&quot;}
    nextID = 3</p>
<p>// Start WebSocket hub
    go hub.run()</p>
<p>// Router
    r := mux.NewRouter()</p>
<p>// REST endpoints
    r.HandleFunc(&quot;/api/v1/products&quot;, ListProducts).Methods(&quot;GET&quot;)
    r.HandleFunc(&quot;/api/v1/products&quot;, CreateProduct).Methods(&quot;POST&quot;)</p>
<p>// WebSocket endpoint
    r.HandleFunc(&quot;/ws&quot;, ServeWs)</p>
<p>// CORS
    c := cors.New(cors.Options{
        AllowedOrigins:   []string{&quot;http://localhost:3000&quot;},
        AllowedMethods:   []string{&quot;GET&quot;, &quot;POST&quot;, &quot;PUT&quot;, &quot;DELETE&quot;, &quot;OPTIONS&quot;},
        AllowedHeaders:   []string{&quot;Content-Type&quot;},
        AllowCredentials: true,
    })</p>
<p>handler := c.Handler(r)
    log.Println(&quot;Server starting on :8080&quot;)
    log.Fatal(http.ListenAndServe(&quot;:8080&quot;, handler))
}</code></pre></p>
<h3>Frontend (React Example)</h3>
<pre><code class="language-jsx">// App.js
import React, { useState, useEffect } from &#039;react&#039;;
<p>function App() {
  const [products, setProducts] = useState([]);
  const [ws, setWs] = useState(null);
  const [notifications, setNotifications] = useState([]);</p>
<p>// Fetch products (REST)
  useEffect(() =&gt; {
    fetch(&#039;http://localhost:8080/api/v1/products&#039;)
      .then(res =&gt; res.json())
      .then(data =&gt; setProducts(data.data));
  }, []);</p>
<p>// WebSocket connection
  useEffect(() =&gt; {
    const socket = new WebSocket(&#039;ws://localhost:8080/ws&#039;);
    
    socket.onmessage = (event) =&gt; {
      setNotifications(prev =&gt; [...prev, event.data]);
    };</p>
<p>setWs(socket);</p>
<p>return () =&gt; socket.close();
  }, []);</p>
<p>// Create product
  const createProduct = async () =&gt; {
    const newProduct = {
      name: &#039;New Item&#039;,
      description: &#039;Test product&#039;,
      price: 49.99,
      category: &#039;electronics&#039;
    };</p>
<p>const response = await fetch(&#039;http://localhost:8080/api/v1/products&#039;, {
      method: &#039;POST&#039;,
      headers: { &#039;Content-Type&#039;: &#039;application/json&#039; },
      body: JSON.stringify(newProduct)
    });</p>
<p>const product = await response.json();
    setProducts([...products, product]);
  };</p>
<p>return (
    &lt;div&gt;
      &lt;h1&gt;Products&lt;/h1&gt;
      &lt;button onClick={createProduct}&gt;Add Product&lt;/button&gt;
      
      &lt;ul&gt;
        {products.map(p =&gt; (
          &lt;li key={p.id}&gt;{p.name} - ${p.price}&lt;/li&gt;
        ))}
      &lt;/ul&gt;</p>
<p>&lt;h2&gt;Live Notifications&lt;/h2&gt;
      &lt;ul&gt;
        {notifications.map((n, i) =&gt; (
          &lt;li key={i}&gt;{n}&lt;/li&gt;
        ))}
      &lt;/ul&gt;
    &lt;/div&gt;
  );
}</p>
<p>export default App;</code></pre></p>
<p>---</p>
<h2>üìö Additional Resources</h2>
<li>[REST API Design Best Practices](https://restfulapi.net/)</li>
<li>[GraphQL Official Documentation](https://graphql.org/learn/)</li>
<li>[WebSocket Protocol RFC 6455](https://datatracker.ietf.org/doc/html/rfc6455)</li>
<li>[CORS MDN Guide](https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS)</li>
<p>---</p>
<h2>‚úÖ Module Checklist</h2>
<li>[ ] Implement RESTful API with pagination and filtering</li>
<li>[ ] Add API versioning (URL-based)</li>
<li>[ ] Create GraphQL server with queries and mutations</li>
<li>[ ] Build WebSocket chat application</li>
<li>[ ] Configure CORS properly for production</li>
<li>[ ] Add Swagger/OpenAPI documentation</li>
<li>[ ] Implement rate limiting and caching</li>
<li>[ ] Complete full-stack exercise with React frontend</li></ul>
<p>---</p>
<strong>üéâ Congratulations!</strong> You've completed Part 4: Microservices Architecture!
<strong>Next Section:</strong> [Module 21: AWS IAM & VPC](./21_AWS_IAM_VPC.md) - Deploy to the cloud! ‚òÅÔ∏è

    </div>
    

    <div class="module-content" id="module-21">
        <h1>Module 21: AWS IAM & VPC ‚òÅÔ∏è</h1>
<h2>Secure Your Cloud Infrastructure with IAM and Networking</h2>
<strong>Duration:</strong> 5-6 hours  
<strong>Prerequisites:</strong> Basic cloud concepts, networking fundamentals  
<strong>Outcome:</strong> Master AWS security and networking foundations
<p>---</p>
<h2>üìö Table of Contents</h2>
<p>1. [AWS Overview](#aws-overview)
2. [IAM (Identity and Access Management)](#iam)
3. [VPC (Virtual Private Cloud)](#vpc)
4. [Security Best Practices](#security-best-practices)
5. [Terraform for AWS](#terraform-for-aws)
6. [Interview Questions](#interview-questions)
7. [Hands-On Exercise](#hands-on-exercise)</p>
<p>---</p>
<h2>AWS Overview</h2>
<h3>AWS Services Hierarchy</h3>
<pre><code class="language-text">AWS Account (Root)
‚îú‚îÄ‚îÄ IAM (Who can access)
‚îú‚îÄ‚îÄ VPC (Network isolation)
‚îú‚îÄ‚îÄ Compute (EC2, Lambda, EKS)
‚îú‚îÄ‚îÄ Storage (S3, EBS, EFS)
‚îú‚îÄ‚îÄ Database (RDS, DynamoDB)
‚îú‚îÄ‚îÄ Monitoring (CloudWatch, X-Ray)
‚îî‚îÄ‚îÄ DevOps (CodePipeline, CodeBuild)
<p>Foundation:
1. IAM - Authentication &amp; Authorization
2. VPC - Network &amp; Security</code></pre></p>
<h3>AWS CLI Setup</h3>
<pre><code class="language-bash"># Install AWS CLI
curl &quot;https://awscli.amazonaws.com/AWSCLIV2.pkg&quot; -o &quot;AWSCLIV2.pkg&quot;
sudo installer -pkg AWSCLIV2.pkg -target /
<h1>Configure credentials</h1>
aws configure
<h1>AWS Access Key ID: YOUR_ACCESS_KEY</h1>
<h1>AWS Secret Access Key: YOUR_SECRET_KEY</h1>
<h1>Default region: us-east-1</h1>
<h1>Default output format: json</h1>
<h1>Verify</h1>
aws sts get-caller-identity</code></pre>
<p>---</p>
<h2>IAM (Identity and Access Management)</h2>
<h3>Core Concepts</h3>
<pre><code class="language-text">IAM Components:
<p>1. Users:   Individual people (john@company.com)
2. Groups:  Collection of users (developers, admins)
3. Roles:   AWS services or applications
4. Policies: JSON documents defining permissions</p>
<p>Authentication: Who are you? (username/password, access keys)
Authorization:  What can you do? (policies)</code></pre></p>
<h3>IAM Users</h3>
<pre><code class="language-bash"># Create user
aws iam create-user --user-name john-developer
<h1>Create access keys</h1>
aws iam create-access-key --user-name john-developer
<h1>List users</h1>
aws iam list-users
<h1>Delete user</h1>
aws iam delete-user --user-name john-developer</code></pre>
<h3>IAM Groups</h3>
<pre><code class="language-bash"># Create group
aws iam create-group --group-name developers
<h1>Add user to group</h1>
aws iam add-user-to-group \
  --user-name john-developer \
  --group-name developers
<h1>Attach policy to group</h1>
aws iam attach-group-policy \
  --group-name developers \
  --policy-arn arn:aws:iam::aws:policy/AmazonEC2FullAccess
<h1>List groups</h1>
aws iam list-groups</code></pre>
<h3>IAM Policies</h3>
<p>#### AWS Managed Policies (Pre-built)</p>
<pre><code class="language-bash"># Common managed policies
AdministratorAccess           # Full access to everything
PowerUserAccess               # Everything except IAM
ReadOnlyAccess                # Read-only to all services
AmazonEC2FullAccess          # Full EC2 access
AmazonS3ReadOnlyAccess       # Read S3 only
<h1>Attach managed policy</h1>
aws iam attach-user-policy \
  --user-name john-developer \
  --policy-arn arn:aws:iam::aws:policy/AmazonEC2FullAccess</code></pre>
<p>#### Custom Policies (JSON)</p>
<pre><code class="language-json">{
  &quot;Version&quot;: &quot;2012-10-17&quot;,
  &quot;Statement&quot;: [
    {
      &quot;Effect&quot;: &quot;Allow&quot;,
      &quot;Action&quot;: [
        &quot;ec2:DescribeInstances&quot;,
        &quot;ec2:StartInstances&quot;,
        &quot;ec2:StopInstances&quot;
      ],
      &quot;Resource&quot;: &quot;*&quot;
    },
    {
      &quot;Effect&quot;: &quot;Allow&quot;,
      &quot;Action&quot;: &quot;s3:*&quot;,
      &quot;Resource&quot;: [
        &quot;arn:aws:s3:::my-bucket&quot;,
        &quot;arn:aws:s3:::my-bucket/*&quot;
      ]
    },
    {
      &quot;Effect&quot;: &quot;Deny&quot;,
      &quot;Action&quot;: &quot;ec2:TerminateInstances&quot;,
      &quot;Resource&quot;: &quot;*&quot;
    }
  ]
}</code></pre>
<pre><code class="language-bash"># Create custom policy
aws iam create-policy \
  --policy-name EC2-Start-Stop \
  --policy-document file://policy.json
<h1>Attach custom policy</h1>
aws iam attach-user-policy \
  --user-name john-developer \
  --policy-arn arn:aws:iam::123456789012:policy/EC2-Start-Stop</code></pre>
<h3>IAM Roles</h3>
<pre><code class="language-text">Roles vs Users:
<p>Users:  Humans with permanent credentials
Roles:  Applications/services with temporary credentials</p>
<p>Use cases:
<ul><li>EC2 instance needs S3 access ‚Üí EC2 Role</li>
<li>Lambda function needs DynamoDB access ‚Üí Lambda Role</li>
<li>Cross-account access ‚Üí Assume Role</code></pre></li></p>
<pre><code class="language-bash"># Create role trust policy (who can assume this role)
cat &gt; trust-policy.json &lt;&lt;EOF
{
  &quot;Version&quot;: &quot;2012-10-17&quot;,
  &quot;Statement&quot;: [
    {
      &quot;Effect&quot;: &quot;Allow&quot;,
      &quot;Principal&quot;: {
        &quot;Service&quot;: &quot;ec2.amazonaws.com&quot;
      },
      &quot;Action&quot;: &quot;sts:AssumeRole&quot;
    }
  ]
}
EOF
<h1>Create role</h1>
aws iam create-role \
  --role-name EC2-S3-Access \
  --assume-role-policy-document file://trust-policy.json
<h1>Attach policy to role</h1>
aws iam attach-role-policy \
  --role-name EC2-S3-Access \
  --policy-arn arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess
<h1>Create instance profile (wrapper for EC2)</h1>
aws iam create-instance-profile \
  --instance-profile-name EC2-S3-Access-Profile
<h1>Add role to instance profile</h1>
aws iam add-role-to-instance-profile \
  --instance-profile-name EC2-S3-Access-Profile \
  --role-name EC2-S3-Access</code></pre>
<h3>Go SDK - IAM Operations</h3>
<pre><code class="language-go">package main
<p>import (
    &quot;context&quot;
    &quot;fmt&quot;
    &quot;log&quot;</p>
<p>&quot;github.com/aws/aws-sdk-go-v2/config&quot;
    &quot;github.com/aws/aws-sdk-go-v2/service/iam&quot;
)</p>
<p>func main() {
    // Load AWS configuration
    cfg, err := config.LoadDefaultConfig(context.TODO())
    if err != nil {
        log.Fatal(err)
    }</p>
<p>client := iam.NewFromConfig(cfg)</p>
<p>// List users
    users, err := client.ListUsers(context.TODO(), &amp;iam.ListUsersInput{})
    if err != nil {
        log.Fatal(err)
    }</p>
<p>for _, user := range users.Users {
        fmt.Printf(&quot;User: %s, Created: %v\n&quot;, *user.UserName, *user.CreateDate)
    }
}</code></pre></p>
<h3>MFA (Multi-Factor Authentication)</h3>
<pre><code class="language-bash"># Enable MFA for user (virtual MFA device)
aws iam create-virtual-mfa-device \
  --virtual-mfa-device-name john-mfa \
  --outfile QRCode.png \
  --bootstrap-method QRCodePNG
<h1>Enable MFA device</h1>
aws iam enable-mfa-device \
  --user-name john-developer \
  --serial-number arn:aws:iam::123456789012:mfa/john-mfa \
  --authentication-code-1 123456 \
  --authentication-code-2 789012
<h1>Policy requiring MFA</h1>
{
  &quot;Version&quot;: &quot;2012-10-17&quot;,
  &quot;Statement&quot;: [
    {
      &quot;Effect&quot;: &quot;Deny&quot;,
      &quot;Action&quot;: &quot;*&quot;,
      &quot;Resource&quot;: &quot;*&quot;,
      &quot;Condition&quot;: {
        &quot;BoolIfExists&quot;: {
          &quot;aws:MultiFactorAuthPresent&quot;: &quot;false&quot;
        }
      }
    }
  ]
}</code></pre>
<p>---</p>
<h2>VPC (Virtual Private Cloud)</h2>
<h3>VPC Architecture</h3>
<pre><code class="language-text">VPC (10.0.0.0/16)
‚îú‚îÄ‚îÄ Public Subnet (10.0.1.0/24)
‚îÇ   ‚îú‚îÄ‚îÄ Internet Gateway
‚îÇ   ‚îú‚îÄ‚îÄ NAT Gateway
‚îÇ   ‚îî‚îÄ‚îÄ Web Servers
‚îú‚îÄ‚îÄ Private Subnet (10.0.2.0/24)
‚îÇ   ‚îú‚îÄ‚îÄ Application Servers
‚îÇ   ‚îî‚îÄ‚îÄ No direct internet access
‚îî‚îÄ‚îÄ Database Subnet (10.0.3.0/24)
    ‚îî‚îÄ‚îÄ RDS instances
<p>Components:
1. VPC:             Isolated network
2. Subnets:         Network segments
3. Route Tables:    Traffic routing
4. Internet Gateway: Connect to internet
5. NAT Gateway:     Outbound internet for private subnets
6. Security Groups: Instance-level firewall
7. NACLs:           Subnet-level firewall</code></pre></p>
<h3>Create VPC</h3>
<pre><code class="language-bash"># Create VPC
aws ec2 create-vpc \
  --cidr-block 10.0.0.0/16 \
  --tag-specifications &#039;ResourceType=vpc,Tags=[{Key=Name,Value=my-vpc}]&#039;
<h1>Enable DNS hostnames</h1>
aws ec2 modify-vpc-attribute \
  --vpc-id vpc-12345678 \
  --enable-dns-hostnames</code></pre>
<h3>Subnets</h3>
<pre><code class="language-bash"># Create public subnet
aws ec2 create-subnet \
  --vpc-id vpc-12345678 \
  --cidr-block 10.0.1.0/24 \
  --availability-zone us-east-1a \
  --tag-specifications &#039;ResourceType=subnet,Tags=[{Key=Name,Value=public-subnet}]&#039;
<h1>Create private subnet</h1>
aws ec2 create-subnet \
  --vpc-id vpc-12345678 \
  --cidr-block 10.0.2.0/24 \
  --availability-zone us-east-1a \
  --tag-specifications &#039;ResourceType=subnet,Tags=[{Key=Name,Value=private-subnet}]&#039;
<h1>Auto-assign public IP in public subnet</h1>
aws ec2 modify-subnet-attribute \
  --subnet-id subnet-11111111 \
  --map-public-ip-on-launch</code></pre>
<h3>Internet Gateway</h3>
<pre><code class="language-bash"># Create internet gateway
aws ec2 create-internet-gateway \
  --tag-specifications &#039;ResourceType=internet-gateway,Tags=[{Key=Name,Value=my-igw}]&#039;
<h1>Attach to VPC</h1>
aws ec2 attach-internet-gateway \
  --internet-gateway-id igw-12345678 \
  --vpc-id vpc-12345678</code></pre>
<h3>Route Tables</h3>
<pre><code class="language-bash"># Create route table for public subnet
aws ec2 create-route-table \
  --vpc-id vpc-12345678 \
  --tag-specifications &#039;ResourceType=route-table,Tags=[{Key=Name,Value=public-rt}]&#039;
<h1>Add route to internet gateway</h1>
aws ec2 create-route \
  --route-table-id rtb-12345678 \
  --destination-cidr-block 0.0.0.0/0 \
  --gateway-id igw-12345678
<h1>Associate route table with subnet</h1>
aws ec2 associate-route-table \
  --route-table-id rtb-12345678 \
  --subnet-id subnet-11111111</code></pre>
<h3>NAT Gateway</h3>
<pre><code class="language-bash"># Allocate Elastic IP
aws ec2 allocate-address --domain vpc
<h1>Create NAT gateway in public subnet</h1>
aws ec2 create-nat-gateway \
  --subnet-id subnet-11111111 \
  --allocation-id eipalloc-12345678
<h1>Add route in private subnet route table</h1>
aws ec2 create-route \
  --route-table-id rtb-private \
  --destination-cidr-block 0.0.0.0/0 \
  --nat-gateway-id nat-12345678</code></pre>
<h3>Security Groups</h3>
<pre><code class="language-text">Security Groups: Stateful firewall at instance level
<p>Stateful: If you allow inbound, response is automatically allowed
Default: All outbound allowed, no inbound allowed</code></pre></p>
<pre><code class="language-bash"># Create security group
aws ec2 create-security-group \
  --group-name web-sg \
  --description &quot;Web server security group&quot; \
  --vpc-id vpc-12345678
<h1>Allow HTTP (port 80)</h1>
aws ec2 authorize-security-group-ingress \
  --group-id sg-12345678 \
  --protocol tcp \
  --port 80 \
  --cidr 0.0.0.0/0
<h1>Allow HTTPS (port 443)</h1>
aws ec2 authorize-security-group-ingress \
  --group-id sg-12345678 \
  --protocol tcp \
  --port 443 \
  --cidr 0.0.0.0/0
<h1>Allow SSH from specific IP</h1>
aws ec2 authorize-security-group-ingress \
  --group-id sg-12345678 \
  --protocol tcp \
  --port 22 \
  --cidr 203.0.113.0/24
<h1>Allow from another security group (e.g., app servers)</h1>
aws ec2 authorize-security-group-ingress \
  --group-id sg-db \
  --protocol tcp \
  --port 3306 \
  --source-group sg-app</code></pre>
<h3>Network ACLs (NACLs)</h3>
<pre><code class="language-text">NACLs: Stateless firewall at subnet level
<p>Stateless: Must explicitly allow both inbound and outbound
Default:    Allow all inbound and outbound</code></pre></p>
<pre><code class="language-bash"># Create NACL
aws ec2 create-network-acl \
  --vpc-id vpc-12345678
<h1>Add inbound rule (allow HTTP)</h1>
aws ec2 create-network-acl-entry \
  --network-acl-id acl-12345678 \
  --ingress \
  --rule-number 100 \
  --protocol tcp \
  --port-range From=80,To=80 \
  --cidr-block 0.0.0.0/0 \
  --rule-action allow
<h1>Add outbound rule (allow HTTP response)</h1>
aws ec2 create-network-acl-entry \
  --network-acl-id acl-12345678 \
  --egress \
  --rule-number 100 \
  --protocol tcp \
  --port-range From=1024,To=65535 \
  --cidr-block 0.0.0.0/0 \
  --rule-action allow</code></pre>
<h3>VPC Peering</h3>
<pre><code class="language-text">VPC Peering: Connect two VPCs (same/different accounts)
<p>VPC A (10.0.0.0/16) ‚Üê‚Üí VPC B (10.1.0.0/16)</p>
<p>Requirements:
<li>Non-overlapping CIDR blocks</li>
<li>Update route tables in both VPCs</code></pre></li></p>
<pre><code class="language-bash"># Create peering connection
aws ec2 create-vpc-peering-connection \
  --vpc-id vpc-aaaa \
  --peer-vpc-id vpc-bbbb
<h1>Accept peering connection (in peer account)</h1>
aws ec2 accept-vpc-peering-connection \
  --vpc-peering-connection-id pcx-12345678
<h1>Add route in VPC A to VPC B</h1>
aws ec2 create-route \
  --route-table-id rtb-aaaa \
  --destination-cidr-block 10.1.0.0/16 \
  --vpc-peering-connection-id pcx-12345678</code></pre>
<p>---</p>
<h2>Security Best Practices</h2>
<h3>IAM Best Practices</h3>
<pre><code class="language-text">1. Root Account
   ‚úÖ Enable MFA
   ‚úÖ Don&#039;t use for daily tasks
   ‚úÖ Delete access keys
   
2. Users
   ‚úÖ Create individual users (no sharing)
   ‚úÖ Enable MFA for privileged users
   ‚úÖ Rotate access keys regularly
   ‚úÖ Use strong password policy
   
3. Permissions
   ‚úÖ Principle of least privilege
   ‚úÖ Use groups, not individual policies
   ‚úÖ Use roles for applications
   ‚úÖ Regularly review permissions
   
4. Monitoring
   ‚úÖ Enable CloudTrail
   ‚úÖ Monitor with CloudWatch
   ‚úÖ Set up billing alerts</code></pre>
<h3>VPC Best Practices</h3>
<pre><code class="language-text">1. Network Design
   ‚úÖ Use multiple subnets across AZs
   ‚úÖ Separate public/private/database tiers
   ‚úÖ Plan CIDR blocks carefully
   
2. Security
   ‚úÖ Minimal security group rules
   ‚úÖ Use security group chaining
   ‚úÖ Enable VPC Flow Logs
   ‚úÖ Use NACLs for additional defense
   
3. High Availability
   ‚úÖ Multi-AZ deployment
   ‚úÖ NAT Gateway in each AZ
   ‚úÖ Load balancers across AZs</code></pre>
<p>---</p>
<h2>Terraform for AWS</h2>
<h3>Complete VPC with Terraform</h3>
<pre><code class="language-hcl"># main.tf
terraform {
  required_providers {
    aws = {
      source  = &quot;hashicorp/aws&quot;
      version = &quot;~&gt; 5.0&quot;
    }
  }
}
<p>provider &quot;aws&quot; {
  region = &quot;us-east-1&quot;
}</p>
<h1>VPC</h1>
resource &quot;aws_vpc&quot; &quot;main&quot; {
  cidr_block           = &quot;10.0.0.0/16&quot;
  enable_dns_hostnames = true
  enable_dns_support   = true
<p>tags = {
    Name = &quot;main-vpc&quot;
  }
}</p>
<h1>Public Subnet</h1>
resource &quot;aws_subnet&quot; &quot;public&quot; {
  count             = 2
  vpc_id            = aws_vpc.main.id
  cidr_block        = &quot;10.0.${count.index + 1}.0/24&quot;
  availability_zone = data.aws_availability_zones.available.names[count.index]
<p>map_public_ip_on_launch = true</p>
<p>tags = {
    Name = &quot;public-subnet-${count.index + 1}&quot;
  }
}</p>
<h1>Private Subnet</h1>
resource &quot;aws_subnet&quot; &quot;private&quot; {
  count             = 2
  vpc_id            = aws_vpc.main.id
  cidr_block        = &quot;10.0.${count.index + 10}.0/24&quot;
  availability_zone = data.aws_availability_zones.available.names[count.index]
<p>tags = {
    Name = &quot;private-subnet-${count.index + 1}&quot;
  }
}</p>
<h1>Internet Gateway</h1>
resource &quot;aws_internet_gateway&quot; &quot;main&quot; {
  vpc_id = aws_vpc.main.id
<p>tags = {
    Name = &quot;main-igw&quot;
  }
}</p>
<h1>Elastic IP for NAT Gateway</h1>
resource &quot;aws_eip&quot; &quot;nat&quot; {
  count  = 2
  domain = &quot;vpc&quot;
<p>tags = {
    Name = &quot;nat-eip-${count.index + 1}&quot;
  }
}</p>
<h1>NAT Gateway</h1>
resource &quot;aws_nat_gateway&quot; &quot;main&quot; {
  count         = 2
  allocation_id = aws_eip.nat[count.index].id
  subnet_id     = aws_subnet.public[count.index].id
<p>tags = {
    Name = &quot;nat-gateway-${count.index + 1}&quot;
  }</p>
<p>depends_on = [aws_internet_gateway.main]
}</p>
<h1>Route Table for Public Subnets</h1>
resource &quot;aws_route_table&quot; &quot;public&quot; {
  vpc_id = aws_vpc.main.id
<p>route {
    cidr_block = &quot;0.0.0.0/0&quot;
    gateway_id = aws_internet_gateway.main.id
  }</p>
<p>tags = {
    Name = &quot;public-rt&quot;
  }
}</p>
<h1>Route Table for Private Subnets</h1>
resource &quot;aws_route_table&quot; &quot;private&quot; {
  count  = 2
  vpc_id = aws_vpc.main.id
<p>route {
    cidr_block     = &quot;0.0.0.0/0&quot;
    nat_gateway_id = aws_nat_gateway.main[count.index].id
  }</p>
<p>tags = {
    Name = &quot;private-rt-${count.index + 1}&quot;
  }
}</p>
<h1>Route Table Associations</h1>
resource &quot;aws_route_table_association&quot; &quot;public&quot; {
  count          = 2
  subnet_id      = aws_subnet.public[count.index].id
  route_table_id = aws_route_table.public.id
}
<p>resource &quot;aws_route_table_association&quot; &quot;private&quot; {
  count          = 2
  subnet_id      = aws_subnet.private[count.index].id
  route_table_id = aws_route_table.private[count.index].id
}</p>
<h1>Security Group</h1>
resource &quot;aws_security_group&quot; &quot;web&quot; {
  name        = &quot;web-sg&quot;
  description = &quot;Security group for web servers&quot;
  vpc_id      = aws_vpc.main.id
<p>ingress {
    from_port   = 80
    to_port     = 80
    protocol    = &quot;tcp&quot;
    cidr_blocks = [&quot;0.0.0.0/0&quot;]
  }</p>
<p>ingress {
    from_port   = 443
    to_port     = 443
    protocol    = &quot;tcp&quot;
    cidr_blocks = [&quot;0.0.0.0/0&quot;]
  }</p>
<p>egress {
    from_port   = 0
    to_port     = 0
    protocol    = &quot;-1&quot;
    cidr_blocks = [&quot;0.0.0.0/0&quot;]
  }</p>
<p>tags = {
    Name = &quot;web-sg&quot;
  }
}</p>
<h1>Data source for AZs</h1>
data &quot;aws_availability_zones&quot; &quot;available&quot; {
  state = &quot;available&quot;
}
<h1>Outputs</h1>
output &quot;vpc_id&quot; {
  value = aws_vpc.main.id
}
<p>output &quot;public_subnet_ids&quot; {
  value = aws_subnet.public[*].id
}</p>
<p>output &quot;private_subnet_ids&quot; {
  value = aws_subnet.private[*].id
}</code></pre></p>
<pre><code class="language-bash"># Deploy
terraform init
terraform plan
terraform apply</code></pre>
<p>---</p>
<h2>Interview Questions</h2>
<strong>Q1: Explain IAM users vs roles.</strong>
<strong>Answer:</strong>
<li><strong>Users</strong>: For people. Permanent credentials (username/password, access keys). Example: john@company.com</li>
<li><strong>Roles</strong>: For applications/services. Temporary credentials via STS. Example: EC2 instance accessing S3, Lambda accessing DynamoDB</li>
<strong>Q2: What's the difference between security groups and NACLs?</strong>
<strong>Answer:</strong>
<li><strong>Security Groups</strong>: Instance-level, stateful (return traffic auto-allowed), allow rules only, default deny all</li>
<li><strong>NACLs</strong>: Subnet-level, stateless (must allow both directions), allow & deny rules, default allow all, processed in order</li>
<strong>Q3: Explain VPC public vs private subnet.</strong>
<strong>Answer:</strong>
<li><strong>Public</strong>: Has route to Internet Gateway (0.0.0.0/0 ‚Üí IGW), instances get public IPs</li>
<li><strong>Private</strong>: No direct internet access, uses NAT Gateway for outbound, instances only have private IPs</li>
<strong>Q4: How do you secure access between tiers (web/app/db)?</strong>
<strong>Answer:</strong>
1. Separate subnets (public/private/database)
2. Security group chaining (web SG ‚Üí app SG ‚Üí db SG)
3. No direct internet to app/db
4. Minimal ports (web: 80/443, app: custom, db: 3306/5432)
5. NACLs for additional layer
<strong>Q5: What is the principle of least privilege?</strong>
<strong>Answer:</strong> Grant minimum permissions needed. Start with no access, add only what's required. Review regularly. Use groups and roles, not individual policies. Example: Developer needs EC2 read-only, not full access.
<p>---</p>
<h2>Hands-On Exercise</h2>
<h3>Task: Create Multi-Tier VPC with Terraform</h3>
<strong>Architecture:</strong>
<pre><code class="language-text">VPC (10.0.0.0/16)
‚îú‚îÄ‚îÄ Public Subnet (10.0.1.0/24) - Web tier
‚îÇ   ‚îî‚îÄ‚îÄ Security Group: Allow 80, 443
‚îú‚îÄ‚îÄ Private Subnet (10.0.2.0/24) - App tier
‚îÇ   ‚îî‚îÄ‚îÄ Security Group: Allow from web SG
‚îî‚îÄ‚îÄ Database Subnet (10.0.3.0/24) - DB tier
    ‚îî‚îÄ‚îÄ Security Group: Allow 3306 from app SG</code></pre>
<strong>Solution:</strong>
<pre><code class="language-hcl"># variables.tf
variable &quot;project_name&quot; {
  default = &quot;myapp&quot;
}
<p>variable &quot;vpc_cidr&quot; {
  default = &quot;10.0.0.0/16&quot;
}</p>
<h1>vpc.tf</h1>
resource &quot;aws_vpc&quot; &quot;main&quot; {
  cidr_block           = var.vpc_cidr
  enable_dns_hostnames = true
<p>tags = {
    Name = &quot;${var.project_name}-vpc&quot;
  }
}</p>
<h1>subnets.tf</h1>
resource &quot;aws_subnet&quot; &quot;web&quot; {
  vpc_id                  = aws_vpc.main.id
  cidr_block              = &quot;10.0.1.0/24&quot;
  map_public_ip_on_launch = true
  availability_zone       = &quot;us-east-1a&quot;
<p>tags = {
    Name = &quot;${var.project_name}-web-subnet&quot;
    Tier = &quot;public&quot;
  }
}</p>
<p>resource &quot;aws_subnet&quot; &quot;app&quot; {
  vpc_id            = aws_vpc.main.id
  cidr_block        = &quot;10.0.2.0/24&quot;
  availability_zone = &quot;us-east-1a&quot;</p>
<p>tags = {
    Name = &quot;${var.project_name}-app-subnet&quot;
    Tier = &quot;private&quot;
  }
}</p>
<p>resource &quot;aws_subnet&quot; &quot;db&quot; {
  vpc_id            = aws_vpc.main.id
  cidr_block        = &quot;10.0.3.0/24&quot;
  availability_zone = &quot;us-east-1a&quot;</p>
<p>tags = {
    Name = &quot;${var.project_name}-db-subnet&quot;
    Tier = &quot;database&quot;
  }
}</p>
<h1>security-groups.tf</h1>
resource &quot;aws_security_group&quot; &quot;web&quot; {
  name        = &quot;${var.project_name}-web-sg&quot;
  description = &quot;Web tier security group&quot;
  vpc_id      = aws_vpc.main.id
<p>ingress {
    description = &quot;HTTP&quot;
    from_port   = 80
    to_port     = 80
    protocol    = &quot;tcp&quot;
    cidr_blocks = [&quot;0.0.0.0/0&quot;]
  }</p>
<p>ingress {
    description = &quot;HTTPS&quot;
    from_port   = 443
    to_port     = 443
    protocol    = &quot;tcp&quot;
    cidr_blocks = [&quot;0.0.0.0/0&quot;]
  }</p>
<p>egress {
    from_port   = 0
    to_port     = 0
    protocol    = &quot;-1&quot;
    cidr_blocks = [&quot;0.0.0.0/0&quot;]
  }</p>
<p>tags = {
    Name = &quot;${var.project_name}-web-sg&quot;
  }
}</p>
<p>resource &quot;aws_security_group&quot; &quot;app&quot; {
  name        = &quot;${var.project_name}-app-sg&quot;
  description = &quot;App tier security group&quot;
  vpc_id      = aws_vpc.main.id</p>
<p>ingress {
    description     = &quot;From web tier&quot;
    from_port       = 8080
    to_port         = 8080
    protocol        = &quot;tcp&quot;
    security_groups = [aws_security_group.web.id]
  }</p>
<p>egress {
    from_port   = 0
    to_port     = 0
    protocol    = &quot;-1&quot;
    cidr_blocks = [&quot;0.0.0.0/0&quot;]
  }</p>
<p>tags = {
    Name = &quot;${var.project_name}-app-sg&quot;
  }
}</p>
<p>resource &quot;aws_security_group&quot; &quot;db&quot; {
  name        = &quot;${var.project_name}-db-sg&quot;
  description = &quot;Database tier security group&quot;
  vpc_id      = aws_vpc.main.id</p>
<p>ingress {
    description     = &quot;MySQL from app tier&quot;
    from_port       = 3306
    to_port         = 3306
    protocol        = &quot;tcp&quot;
    security_groups = [aws_security_group.app.id]
  }</p>
<p>egress {
    from_port   = 0
    to_port     = 0
    protocol    = &quot;-1&quot;
    cidr_blocks = [&quot;0.0.0.0/0&quot;]
  }</p>
<p>tags = {
    Name = &quot;${var.project_name}-db-sg&quot;
  }
}</p>
<h1>outputs.tf</h1>
output &quot;vpc_id&quot; {
  value = aws_vpc.main.id
}
<p>output &quot;web_subnet_id&quot; {
  value = aws_subnet.web.id
}</p>
<p>output &quot;web_sg_id&quot; {
  value = aws_security_group.web.id
}</code></pre></p>
<pre><code class="language-bash"># Deploy
terraform init
terraform apply -auto-approve
<h1>Verify</h1>
aws ec2 describe-vpcs --filters &quot;Name=tag:Name,Values=myapp-vpc&quot;
aws ec2 describe-subnets --filters &quot;Name=vpc-id,Values=&lt;vpc-id&gt;&quot;
aws ec2 describe-security-groups --filters &quot;Name=vpc-id,Values=&lt;vpc-id&gt;&quot;</code></pre>
<p>---</p>
<h2>üìö Additional Resources</h2>
<li>[AWS IAM Best Practices](https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html)</li>
<li>[VPC User Guide](https://docs.aws.amazon.com/vpc/latest/userguide/)</li>
<li>[AWS CLI Reference](https://docs.aws.amazon.com/cli/latest/)</li>
<li>[Terraform AWS Provider](https://registry.terraform.io/providers/hashicorp/aws/latest/docs)</li>
<p>---</p>
<h2>‚úÖ Module Checklist</h2>
<li>[ ] Set up AWS CLI and credentials</li>
<li>[ ] Create IAM users, groups, and policies</li>
<li>[ ] Configure IAM roles for EC2</li>
<li>[ ] Enable MFA for root and users</li>
<li>[ ] Create VPC with public and private subnets</li>
<li>[ ] Configure Internet Gateway and NAT Gateway</li>
<li>[ ] Set up security groups with proper rules</li>
<li>[ ] Deploy multi-tier VPC with Terraform</li>
<li>[ ] Test security group chaining</li></ul>
<p>---</p>
<strong>Next Module:</strong> [Module 22: AWS Compute](./22_AWS_Compute.md) - EC2, Lambda, EKS! üöÄ

    </div>
    

    <div class="module-content" id="module-22">
        <h1>Module 22: AWS Compute - EC2, Lambda, EKS üöÄ</h1>
<h2>Master AWS Compute Services: VMs, Serverless, and Kubernetes</h2>
<strong>Duration:</strong> 6-7 hours  
<strong>Prerequisites:</strong> Module 21 (IAM & VPC), Kubernetes basics  
<strong>Outcome:</strong> Deploy and manage applications on EC2, Lambda, and EKS
<p>---</p>
<h2>üìö Table of Contents</h2>
<p>1. [Compute Services Overview](#compute-services-overview)
2. [EC2 (Elastic Compute Cloud)](#ec2)
3. [Lambda (Serverless Functions)](#lambda)
4. [EKS (Elastic Kubernetes Service)](#eks)
5. [ECS & Fargate](#ecs--fargate)
6. [Auto Scaling](#auto-scaling)
7. [Best Practices](#best-practices)
8. [Interview Questions](#interview-questions)
9. [Hands-On Exercise](#hands-on-exercise)</p>
<p>---</p>
<h2>Compute Services Overview</h2>
<h3>Choosing the Right Compute Service</h3>
<pre><code class="language-text">EC2 (Virtual Machines)
‚úÖ Full control over OS
‚úÖ Custom software/configurations
‚úÖ Long-running applications
‚úÖ Legacy applications
‚ùå Manage servers yourself
<p>Lambda (Serverless Functions)
‚úÖ Event-driven workloads
‚úÖ No server management
‚úÖ Pay per invocation
‚úÖ Auto-scaling built-in
‚ùå 15-minute execution limit
‚ùå Cold starts</p>
<p>EKS (Managed Kubernetes)
‚úÖ Containerized microservices
‚úÖ Multi-cloud portability
‚úÖ Advanced orchestration
‚úÖ Hybrid cloud
‚ùå Kubernetes complexity</p>
<p>ECS + Fargate (AWS Container Service)
‚úÖ AWS-native containers
‚úÖ Serverless containers
‚úÖ Simpler than Kubernetes
‚ùå AWS lock-in</code></pre></p>
<p>---</p>
<h2>EC2 (Elastic Compute Cloud)</h2>
<h3>Instance Types</h3>
<pre><code class="language-text">Instance Families:
<p>T3/T4g:  Burstable (web servers, dev environments)
M5/M6i:  General purpose (balanced CPU/memory)
C5/C6i:  Compute optimized (HPC, batch processing)
R5/R6i:  Memory optimized (databases, caches)
P3/P4:   GPU (ML training, graphics)
I3/I4i:  Storage optimized (NoSQL, data warehousing)</p>
<p>Naming: m5.xlarge
        ‚îÇ‚îÇ  ‚îÇ
        ‚îÇ‚îÇ  ‚îî‚îÄ Size (nano, small, medium, large, xlarge, 2xlarge...)
        ‚îÇ‚îî‚îÄ‚îÄ‚îÄ‚îÄ Generation
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Family</code></pre></p>
<h3>Launch EC2 Instance</h3>
<pre><code class="language-bash"># Create key pair
aws ec2 create-key-pair \
  --key-name my-key \
  --query &#039;KeyMaterial&#039; \
  --output text &gt; my-key.pem
<p>chmod 400 my-key.pem</p>
<h1>Launch instance</h1>
aws ec2 run-instances \
  --image-id ami-0c55b159cbfafe1f0 \  # Amazon Linux 2
  --instance-type t3.micro \
  --key-name my-key \
  --security-group-ids sg-12345678 \
  --subnet-id subnet-12345678 \
  --tag-specifications &#039;ResourceType=instance,Tags=[{Key=Name,Value=web-server}]&#039; \
  --user-data file://user-data.sh
<h1>List instances</h1>
aws ec2 describe-instances \
  --filters &quot;Name=tag:Name,Values=web-server&quot; \
  --query &#039;Reservations[*].Instances[*].[InstanceId,State.Name,PublicIpAddress]&#039; \
  --output table
<h1>Connect via SSH</h1>
ssh -i my-key.pem ec2-user@&lt;public-ip&gt;</code></pre>
<h3>User Data (Bootstrap Script)</h3>
<pre><code class="language-bash">#!/bin/bash
<h1>user-data.sh - runs on first boot</h1>
<h1>Update system</h1>
yum update -y
<h1>Install Docker</h1>
amazon-linux-extras install docker -y
systemctl start docker
systemctl enable docker
usermod -aG docker ec2-user
<h1>Install Go</h1>
wget https://go.dev/dl/go1.21.0.linux-amd64.tar.gz
tar -C /usr/local -xzf go1.21.0.linux-amd64.tar.gz
echo &#039;export PATH=$PATH:/usr/local/go/bin&#039; &gt;&gt; /etc/profile
<h1>Deploy application</h1>
mkdir -p /opt/app
cat &gt; /opt/app/server.go &lt;&lt;&#039;EOF&#039;
package main
import (
    &quot;fmt&quot;
    &quot;net/http&quot;
)
func main() {
    http.HandleFunc(&quot;/&quot;, func(w http.ResponseWriter, r *http.Request) {
        fmt.Fprintf(w, &quot;Hello from EC2!&quot;)
    })
    http.ListenAndServe(&quot;:8080&quot;, nil)
}
EOF
<p>cd /opt/app
/usr/local/go/bin/go run server.go &amp;</code></pre></p>
<h3>AMI (Amazon Machine Image)</h3>
<pre><code class="language-bash"># Create custom AMI from running instance
aws ec2 create-image \
  --instance-id i-1234567890abcdef0 \
  --name &quot;my-web-server-v1.0&quot; \
  --description &quot;Web server with all dependencies&quot;
<h1>Launch instance from custom AMI</h1>
aws ec2 run-instances \
  --image-id ami-0abcdef1234567890 \
  --instance-type t3.micro \
  --count 3  # Launch 3 identical instances</code></pre>
<h3>Terraform - EC2 with Auto Scaling</h3>
<pre><code class="language-hcl"># ec2.tf
data &quot;aws_ami&quot; &quot;amazon_linux_2&quot; {
  most_recent = true
  owners      = [&quot;amazon&quot;]
<p>filter {
    name   = &quot;name&quot;
    values = [&quot;amzn2-ami-hvm-*-x86_64-gp2&quot;]
  }
}</p>
<p>resource &quot;aws_launch_template&quot; &quot;web&quot; {
  name_prefix   = &quot;web-&quot;
  image_id      = data.aws_ami.amazon_linux_2.id
  instance_type = &quot;t3.micro&quot;</p>
<p>network_interfaces {
    associate_public_ip_address = true
    security_groups             = [aws_security_group.web.id]
  }</p>
<p>user_data = base64encode(&lt;&lt;-EOF
              #!/bin/bash
              yum update -y
              yum install -y httpd
              systemctl start httpd
              systemctl enable httpd
              echo &quot;&lt;h1&gt;Hello from $(hostname)&lt;/h1&gt;&quot; &gt; /var/www/html/index.html
              EOF
  )</p>
<p>tag_specifications {
    resource_type = &quot;instance&quot;
    tags = {
      Name = &quot;web-server&quot;
    }
  }
}</p>
<p>resource &quot;aws_autoscaling_group&quot; &quot;web&quot; {
  desired_capacity    = 2
  max_size            = 5
  min_size            = 1
  target_group_arns   = [aws_lb_target_group.web.arn]
  vpc_zone_identifier = aws_subnet.public[*].id</p>
<p>launch_template {
    id      = aws_launch_template.web.id
    version = &quot;$Latest&quot;
  }</p>
<p>tag {
    key                 = &quot;Name&quot;
    value               = &quot;web-asg&quot;
    propagate_at_launch = true
  }
}</code></pre></p>
<p>---</p>
<h2>Lambda (Serverless Functions)</h2>
<h3>Lambda Function Structure</h3>
<pre><code class="language-go">// main.go - Lambda function in Go
package main
<p>import (
    &quot;context&quot;
    &quot;fmt&quot;</p>
<p>&quot;github.com/aws/aws-lambda-go/lambda&quot;
)</p>
<p>type Event struct {
    Name string <code>json:&quot;name&quot;</code>
}</p>
<p>type Response struct {
    Message string <code>json:&quot;message&quot;</code>
}</p>
<p>func HandleRequest(ctx context.Context, event Event) (Response, error) {
    message := fmt.Sprintf(&quot;Hello, %s!&quot;, event.Name)
    return Response{Message: message}, nil
}</p>
<p>func main() {
    lambda.Start(HandleRequest)
}</code></pre></p>
<pre><code class="language-bash"># Build for Lambda
GOOS=linux GOARCH=amd64 go build -o bootstrap main.go
zip function.zip bootstrap
<h1>Create Lambda function</h1>
aws lambda create-function \
  --function-name hello-lambda \
  --runtime provided.al2 \
  --role arn:aws:iam::123456789012:role/lambda-role \
  --handler bootstrap \
  --zip-file fileb://function.zip
<h1>Invoke function</h1>
aws lambda invoke \
  --function-name hello-lambda \
  --payload &#039;{&quot;name&quot;: &quot;World&quot;}&#039; \
  response.json
<p>cat response.json
<h1>{&quot;message&quot;:&quot;Hello, World!&quot;}</code></pre></h1></p>
<h3>Lambda with API Gateway</h3>
<pre><code class="language-go">package main
<p>import (
    &quot;context&quot;
    &quot;encoding/json&quot;</p>
<p>&quot;github.com/aws/aws-lambda-go/events&quot;
    &quot;github.com/aws/aws-lambda-go/lambda&quot;
)</p>
<p>type User struct {
    ID    string <code>json:&quot;id&quot;</code>
    Name  string <code>json:&quot;name&quot;</code>
    Email string <code>json:&quot;email&quot;</code>
}</p>
<p>func HandleRequest(ctx context.Context, request events.APIGatewayProxyRequest) (events.APIGatewayProxyResponse, error) {
    // Parse request body
    var user User
    json.Unmarshal([]byte(request.Body), &amp;user)</p>
<p>// Business logic
    user.ID = &quot;generated-id-123&quot;</p>
<p>// Response
    responseBody, _ := json.Marshal(user)</p>
<p>return events.APIGatewayProxyResponse{
        StatusCode: 200,
        Headers: map[string]string{
            &quot;Content-Type&quot;: &quot;application/json&quot;,
        },
        Body: string(responseBody),
    }, nil
}</p>
<p>func main() {
    lambda.Start(HandleRequest)
}</code></pre></p>
<h3>Lambda Triggers</h3>
<pre><code class="language-text">Event Sources:
<p>1. API Gateway     - HTTP requests
2. S3              - Object uploads
3. DynamoDB        - Stream changes
4. SNS/SQS         - Messages
5. CloudWatch      - Scheduled (cron)
6. EventBridge     - Custom events</code></pre></p>
<pre><code class="language-bash"># S3 trigger - process uploaded images
aws lambda add-permission \
  --function-name process-image \
  --statement-id s3-trigger \
  --action lambda:InvokeFunction \
  --principal s3.amazonaws.com \
  --source-arn arn:aws:s3:::my-bucket
<p>aws s3api put-bucket-notification-configuration \
  --bucket my-bucket \
  --notification-configuration file://notification.json</code></pre></p>
<pre><code class="language-json">// notification.json
{
  &quot;LambdaFunctionConfigurations&quot;: [
    {
      &quot;LambdaFunctionArn&quot;: &quot;arn:aws:lambda:us-east-1:123456789012:function:process-image&quot;,
      &quot;Events&quot;: [&quot;s3:ObjectCreated:*&quot;],
      &quot;Filter&quot;: {
        &quot;Key&quot;: {
          &quot;FilterRules&quot;: [
            {
              &quot;Name&quot;: &quot;suffix&quot;,
              &quot;Value&quot;: &quot;.jpg&quot;
            }
          ]
        }
      }
    }
  ]
}</code></pre>
<h3>Lambda Layers</h3>
<pre><code class="language-text">Layers: Share code across functions
<p>Use cases:
<ul><li>Common libraries (AWS SDK, database drivers)</li>
<li>Utilities/helpers</li>
<li>Configuration files</li></p>
<p>Benefits:
<li>Reduce deployment package size</li>
<li>Share code without duplication</li>
<li>Update dependencies independently</code></pre></li></p>
<pre><code class="language-bash"># Create layer
mkdir -p layer/nodejs/node_modules
cd layer/nodejs
npm install axios
cd ../..
zip -r layer.zip layer/
<h1>Publish layer</h1>
aws lambda publish-layer-version \
  --layer-name common-libs \
  --zip-file fileb://layer.zip \
  --compatible-runtimes nodejs18.x
<h1>Use layer in function</h1>
aws lambda update-function-configuration \
  --function-name my-function \
  --layers arn:aws:lambda:us-east-1:123456789012:layer:common-libs:1</code></pre>
<h3>Terraform - Lambda with API Gateway</h3>
<pre><code class="language-hcl"># lambda.tf
resource &quot;aws_iam_role&quot; &quot;lambda&quot; {
  name = &quot;lambda-role&quot;
<p>assume_role_policy = jsonencode({
    Version = &quot;2012-10-17&quot;
    Statement = [{
      Action = &quot;sts:AssumeRole&quot;
      Effect = &quot;Allow&quot;
      Principal = {
        Service = &quot;lambda.amazonaws.com&quot;
      }
    }]
  })
}</p>
<p>resource &quot;aws_iam_role_policy_attachment&quot; &quot;lambda_basic&quot; {
  role       = aws_iam_role.lambda.name
  policy_arn = &quot;arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole&quot;
}</p>
<p>resource &quot;aws_lambda_function&quot; &quot;api&quot; {
  filename      = &quot;function.zip&quot;
  function_name = &quot;hello-api&quot;
  role          = aws_iam_role.lambda.arn
  handler       = &quot;bootstrap&quot;
  runtime       = &quot;provided.al2&quot;</p>
<p>environment {
    variables = {
      ENVIRONMENT = &quot;production&quot;
    }
  }
}</p>
<p>resource &quot;aws_apigatewayv2_api&quot; &quot;lambda&quot; {
  name          = &quot;hello-api&quot;
  protocol_type = &quot;HTTP&quot;
}</p>
<p>resource &quot;aws_apigatewayv2_integration&quot; &quot;lambda&quot; {
  api_id           = aws_apigatewayv2_api.lambda.id
  integration_type = &quot;AWS_PROXY&quot;
  integration_uri  = aws_lambda_function.api.invoke_arn
}</p>
<p>resource &quot;aws_apigatewayv2_route&quot; &quot;lambda&quot; {
  api_id    = aws_apigatewayv2_api.lambda.id
  route_key = &quot;POST /users&quot;
  target    = &quot;integrations/${aws_apigatewayv2_integration.lambda.id}&quot;
}</p>
<p>resource &quot;aws_apigatewayv2_stage&quot; &quot;lambda&quot; {
  api_id      = aws_apigatewayv2_api.lambda.id
  name        = &quot;$default&quot;
  auto_deploy = true
}</p>
<p>output &quot;api_endpoint&quot; {
  value = aws_apigatewayv2_stage.lambda.invoke_url
}</code></pre></p>
<p>---</p>
<h2>EKS (Elastic Kubernetes Service)</h2>
<h3>EKS Architecture</h3>
<pre><code class="language-text">EKS Cluster
‚îú‚îÄ‚îÄ Control Plane (Managed by AWS)
‚îÇ   ‚îú‚îÄ‚îÄ API Server
‚îÇ   ‚îú‚îÄ‚îÄ etcd
‚îÇ   ‚îî‚îÄ‚îÄ Scheduler
‚îî‚îÄ‚îÄ Worker Nodes (EC2 or Fargate)
    ‚îú‚îÄ‚îÄ Node Group 1 (EC2 Auto Scaling Group)
    ‚îú‚îÄ‚îÄ Node Group 2 (Spot instances)
    ‚îî‚îÄ‚îÄ Fargate Profiles (Serverless pods)</code></pre>
<h3>Create EKS Cluster with eksctl</h3>
<pre><code class="language-bash"># Install eksctl
brew install eksctl  # macOS
<h1>or download from https://eksctl.io</h1>
<h1>Create cluster (simple)</h1>
eksctl create cluster \
  --name my-cluster \
  --region us-east-1 \
  --nodegroup-name standard-workers \
  --node-type t3.medium \
  --nodes 3 \
  --nodes-min 1 \
  --nodes-max 4
<h1>With custom config</h1>
cat &gt; cluster.yaml &lt;&lt;EOF
apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig
<p>metadata:
  name: my-cluster
  region: us-east-1
  version: &quot;1.28&quot;</p>
<p>vpc:
  cidr: 10.0.0.0/16</p>
<p>managedNodeGroups:
  - name: standard-workers
    instanceType: t3.medium
    minSize: 2
    maxSize: 5
    desiredCapacity: 3
    volumeSize: 20
    ssh:
      allow: true
      publicKeyName: my-key
    labels:
      role: standard
    tags:
      nodegroup-role: standard</p>
<p>- name: spot-workers
    instanceTypes: [&quot;t3.medium&quot;, &quot;t3a.medium&quot;]
    minSize: 0
    maxSize: 10
    desiredCapacity: 3
    spot: true
    labels:
      role: spot
    tags:
      nodegroup-role: spot
EOF</p>
<p>eksctl create cluster -f cluster.yaml</p>
<h1>Update kubeconfig</h1>
aws eks update-kubeconfig --name my-cluster --region us-east-1
<h1>Verify</h1>
kubectl get nodes</code></pre>
<h3>Deploy Application to EKS</h3>
<pre><code class="language-yaml"># deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: go-api
spec:
  replicas: 3
  selector:
    matchLabels:
      app: go-api
  template:
    metadata:
      labels:
        app: go-api
    spec:
      containers:
      - name: api
        image: &lt;your-ecr-repo&gt;/go-api:latest
        ports:
        - containerPort: 8080
        env:
        - name: DB_HOST
          valueFrom:
            secretKeyRef:
              name: db-secret
              key: host
        resources:
          requests:
            memory: &quot;128Mi&quot;
            cpu: &quot;100m&quot;
          limits:
            memory: &quot;256Mi&quot;
            cpu: &quot;200m&quot;
---
apiVersion: v1
kind: Service
metadata:
  name: go-api
spec:
  type: LoadBalancer
  selector:
    app: go-api
  ports:
  - port: 80
    targetPort: 8080</code></pre>
<pre><code class="language-bash">kubectl apply -f deployment.yaml
<h1>Get LoadBalancer URL</h1>
kubectl get svc go-api</code></pre>
<h3>EKS with Fargate</h3>
<pre><code class="language-bash"># Create Fargate profile
eksctl create fargateprofile \
  --cluster my-cluster \
  --name backend \
  --namespace backend
<h1>Pods in &#039;backend&#039; namespace run on Fargate (serverless)</h1>
kubectl create namespace backend
kubectl apply -f deployment.yaml -n backend</code></pre>
<h3>Terraform - Complete EKS Cluster</h3>
<pre><code class="language-hcl"># eks.tf
module &quot;eks&quot; {
  source  = &quot;terraform-aws-modules/eks/aws&quot;
  version = &quot;~&gt; 19.0&quot;
<p>cluster_name    = &quot;my-cluster&quot;
  cluster_version = &quot;1.28&quot;</p>
<p>vpc_id     = aws_vpc.main.id
  subnet_ids = aws_subnet.private[*].id</p>
<p>cluster_endpoint_public_access = true</p>
<p>eks_managed_node_groups = {
    standard = {
      min_size     = 2
      max_size     = 5
      desired_size = 3</p>
<p>instance_types = [&quot;t3.medium&quot;]
      capacity_type  = &quot;ON_DEMAND&quot;</p>
<p>labels = {
        role = &quot;standard&quot;
      }</p>
<p>tags = {
        Environment = &quot;production&quot;
      }
    }</p>
<p>spot = {
      min_size     = 0
      max_size     = 10
      desired_size = 3</p>
<p>instance_types = [&quot;t3.medium&quot;, &quot;t3a.medium&quot;]
      capacity_type  = &quot;SPOT&quot;</p>
<p>labels = {
        role = &quot;spot&quot;
      }
    }
  }</p>
<p>tags = {
    Environment = &quot;production&quot;
  }
}</p>
<h1>Configure kubectl</h1>
data &quot;aws_eks_cluster_auth&quot; &quot;cluster&quot; {
  name = module.eks.cluster_name
}
<p>provider &quot;kubernetes&quot; {
  host                   = module.eks.cluster_endpoint
  cluster_ca_certificate = base64decode(module.eks.cluster_certificate_authority_data)
  token                  = data.aws_eks_cluster_auth.cluster.token
}</code></pre></p>
<p>---</p>
<h2>ECS & Fargate</h2>
<h3>ECS Task Definition</h3>
<pre><code class="language-json">{
  &quot;family&quot;: &quot;go-api&quot;,
  &quot;networkMode&quot;: &quot;awsvpc&quot;,
  &quot;requiresCompatibilities&quot;: [&quot;FARGATE&quot;],
  &quot;cpu&quot;: &quot;256&quot;,
  &quot;memory&quot;: &quot;512&quot;,
  &quot;containerDefinitions&quot;: [
    {
      &quot;name&quot;: &quot;api&quot;,
      &quot;image&quot;: &quot;123456789012.dkr.ecr.us-east-1.amazonaws.com/go-api:latest&quot;,
      &quot;portMappings&quot;: [
        {
          &quot;containerPort&quot;: 8080,
          &quot;protocol&quot;: &quot;tcp&quot;
        }
      ],
      &quot;environment&quot;: [
        {
          &quot;name&quot;: &quot;ENVIRONMENT&quot;,
          &quot;value&quot;: &quot;production&quot;
        }
      ],
      &quot;secrets&quot;: [
        {
          &quot;name&quot;: &quot;DB_PASSWORD&quot;,
          &quot;valueFrom&quot;: &quot;arn:aws:secretsmanager:us-east-1:123456789012:secret:db-password&quot;
        }
      ],
      &quot;logConfiguration&quot;: {
        &quot;logDriver&quot;: &quot;awslogs&quot;,
        &quot;options&quot;: {
          &quot;awslogs-group&quot;: &quot;/ecs/go-api&quot;,
          &quot;awslogs-region&quot;: &quot;us-east-1&quot;,
          &quot;awslogs-stream-prefix&quot;: &quot;ecs&quot;
        }
      }
    }
  ]
}</code></pre>
<pre><code class="language-bash"># Register task definition
aws ecs register-task-definition --cli-input-json file://task-def.json
<h1>Create ECS cluster</h1>
aws ecs create-cluster --cluster-name my-cluster
<h1>Create Fargate service</h1>
aws ecs create-service \
  --cluster my-cluster \
  --service-name go-api \
  --task-definition go-api:1 \
  --desired-count 2 \
  --launch-type FARGATE \
  --network-configuration &quot;awsvpcConfiguration={subnets=[subnet-12345,subnet-67890],securityGroups=[sg-12345678],assignPublicIp=ENABLED}&quot;</code></pre>
<p>---</p>
<h2>Auto Scaling</h2>
<h3>EC2 Auto Scaling Policies</h3>
<pre><code class="language-bash"># Target tracking - maintain CPU at 70%
aws autoscaling put-scaling-policy \
  --auto-scaling-group-name web-asg \
  --policy-name cpu-target-tracking \
  --policy-type TargetTrackingScaling \
  --target-tracking-configuration file://config.json</code></pre>
<pre><code class="language-json">{
  &quot;PredefinedMetricSpecification&quot;: {
    &quot;PredefinedMetricType&quot;: &quot;ASGAverageCPUUtilization&quot;
  },
  &quot;TargetValue&quot;: 70.0
}</code></pre>
<h3>Lambda Auto Scaling</h3>
<pre><code class="language-text">Lambda auto-scales automatically!
<p>Concurrent executions:
<li>Default: 1000 per region</li>
<li>Reserved: Guarantee capacity</li>
<li>Provisioned: Pre-warmed instances (reduce cold starts)</code></pre></li></p>
<pre><code class="language-bash"># Set provisioned concurrency
aws lambda put-provisioned-concurrency-config \
  --function-name my-function \
  --provisioned-concurrent-executions 5 \
  --qualifier prod</code></pre>
<p>---</p>
<h2>Best Practices</h2>
<h3>EC2 Best Practices</h3>
<pre><code class="language-text">1. Use Auto Scaling Groups
2. Enable detailed monitoring
3. Use latest generation instance types
4. Right-size instances (cost optimization)
5. Use Spot instances for fault-tolerant workloads
6. Store secrets in Secrets Manager
7. Regular AMI updates
8. Enable termination protection for critical instances</code></pre>
<h3>Lambda Best Practices</h3>
<pre><code class="language-text">1. Keep functions small and focused
2. Use environment variables for configuration
3. Minimize deployment package size
4. Use layers for dependencies
5. Set appropriate timeout (don&#039;t use max)
6. Configure dead letter queues
7. Use provisioned concurrency for critical APIs
8. Monitor with CloudWatch Logs Insights</code></pre>
<h3>EKS Best Practices</h3>
<pre><code class="language-text">1. Use managed node groups
2. Mix on-demand and spot instances
3. Enable cluster autoscaler
4. Use IRSA (IAM Roles for Service Accounts)
5. Enable control plane logging
6. Use AWS Load Balancer Controller
7. Implement pod security policies
8. Regular cluster upgrades</code></pre>
<p>---</p>
<h2>Interview Questions</h2>
<strong>Q1: EC2 vs Lambda - when to use each?</strong>
<strong>Answer:</strong>
<li><strong>EC2</strong>: Long-running apps, full OS control, consistent workloads, stateful apps, legacy software</li>
<li><strong>Lambda</strong>: Event-driven, short tasks (<15 min), variable load, no server management, pay-per-use</li>
<strong>Q2: What are EKS node groups?</strong>
<strong>Answer:</strong> Managed EC2 Auto Scaling Groups for worker nodes. Types:
<li><strong>Managed</strong>: AWS handles provisioning, updates, draining</li>
<li><strong>Self-managed</strong>: You manage lifecycle</li>
<li><strong>Fargate</strong>: Serverless nodes, no EC2 management</li>
<strong>Q3: Explain Lambda cold starts and how to mitigate.</strong>
<strong>Answer:</strong> Cold start = time to initialize new function instance (container, runtime, code).
Mitigations:
1. Provisioned concurrency (pre-warmed instances)
2. Keep deployment package small
3. Minimize dependencies
4. Use compiled languages (Go faster than Python)
5. VPC: Use Hyperplane ENIs (faster)
<strong>Q4: How do you handle secrets in containers?</strong>
<strong>Answer:</strong>
<li><strong>AWS Secrets Manager</strong>: Rotate automatically, fine-grained IAM</li>
<li><strong>Parameter Store</strong>: Free tier, simpler</li>
<li><strong>EKS</strong>: External Secrets Operator, Secrets Store CSI Driver</li>
<li><strong>Never</strong>: Hardcode or use environment variables in task definition</li>
<strong>Q5: Spot instances vs On-Demand?</strong>
<strong>Answer:</strong>
<li><strong>Spot</strong>: Up to 90% cheaper, can be interrupted (2-min warning), fault-tolerant workloads</li>
<li><strong>On-Demand</strong>: Pay full price, guaranteed availability, stateful/critical apps</li>
<li><strong>Best</strong>: Mix both with node affinity for different workloads</li>
<p>---</p>
<h2>Hands-On Exercise</h2>
<h3>Task: Deploy Go API to EKS with Auto Scaling</h3>
<pre><code class="language-bash"># 1. Create EKS cluster
eksctl create cluster \
  --name demo-cluster \
  --region us-east-1 \
  --node-type t3.medium \
  --nodes 2 \
  --nodes-min 1 \
  --nodes-max 4
<h1>2. Install metrics server (for HPA)</h1>
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
<h1>3. Deploy application</h1>
cat &gt; deployment.yaml &lt;&lt;EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: go-api
spec:
  replicas: 2
  selector:
    matchLabels:
      app: go-api
  template:
    metadata:
      labels:
        app: go-api
    spec:
      containers:
      - name: api
        image: hashicorp/http-echo
        args:
        - &quot;-text=Hello from EKS!&quot;
        ports:
        - containerPort: 5678
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 200m
            memory: 256Mi
---
apiVersion: v1
kind: Service
metadata:
  name: go-api
spec:
  type: LoadBalancer
  selector:
    app: go-api
  ports:
  - port: 80
    targetPort: 5678
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: go-api-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: go-api
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
EOF
<p>kubectl apply -f deployment.yaml</p>
<h1>4. Test</h1>
kubectl get pods
kubectl get svc go-api  # Get LoadBalancer URL
curl &lt;lb-url&gt;
<h1>5. Load test (trigger auto-scaling)</h1>
kubectl run -it --rm load-generator --image=busybox /bin/sh
while true; do wget -q -O- http://go-api; done
<h1>Watch scaling</h1>
kubectl get hpa -w
<h1>6. Cleanup</h1>
eksctl delete cluster --name demo-cluster</code></pre>
<p>---</p>
<h2>üìö Additional Resources</h2>
<li>[EC2 User Guide](https://docs.aws.amazon.com/ec2/)</li>
<li>[AWS Lambda Developer Guide](https://docs.aws.amazon.com/lambda/)</li>
<li>[EKS Best Practices Guide](https://aws.github.io/aws-eks-best-practices/)</li>
<li>[eksctl Documentation](https://eksctl.io/)</li>
<p>---</p>
<h2>‚úÖ Module Checklist</h2>
<li>[ ] Launch and connect to EC2 instance</li>
<li>[ ] Create custom AMI</li>
<li>[ ] Deploy Lambda function with Go</li>
<li>[ ] Set up Lambda with API Gateway trigger</li>
<li>[ ] Create EKS cluster with eksctl</li>
<li>[ ] Deploy application to EKS with HPA</li>
<li>[ ] Set up ECS Fargate service</li>
<li>[ ] Configure Auto Scaling for EC2</li>
<li>[ ] Test spot instances</li></ul>
<p>---</p>
<strong>Next Module:</strong> [Module 23: AWS Storage](./23_AWS_Storage.md) - S3, EBS, EFS, CloudFront! üíæ

    </div>
    

    <div class="module-content" id="module-23">
        <h1>Module 23: AWS Storage - S3, EBS, EFS üíæ</h1>
<h2>Master AWS Storage Services for Scalable Data Management</h2>
<strong>Duration:</strong> 5-6 hours  
<strong>Prerequisites:</strong> Module 21 (IAM & VPC)  
<strong>Outcome:</strong> Understand and implement AWS storage solutions
<p>---</p>
<h2>üìö Table of Contents</h2>
<p>1. [Storage Services Overview](#storage-services-overview)
2. [S3 (Simple Storage Service)](#s3)
3. [EBS (Elastic Block Store)](#ebs)
4. [EFS (Elastic File System)](#efs)
5. [CloudFront (CDN)](#cloudfront)
6. [Storage Gateway](#storage-gateway)
7. [Best Practices](#best-practices)
8. [Interview Questions](#interview-questions)
9. [Hands-On Exercise](#hands-on-exercise)</p>
<p>---</p>
<h2>Storage Services Overview</h2>
<h3>Storage Types</h3>
<pre><code class="language-text">Block Storage (EBS):
<ul><li>Attached to single EC2 instance</li>
<li>Low latency, high IOPS</li>
<li>Use: Databases, boot volumes</li>
<p>File Storage (EFS):
<li>Shared across multiple instances</li>
<li>POSIX-compliant</li>
<li>Use: Shared application data, content management</li></p>
<p>Object Storage (S3):
<li>Unlimited scalability</li>
<li>HTTP/S access</li>
<li>Use: Static assets, backups, data lakes</li></p>
<p>Comparison:
EBS:  1 instance,  low latency,    expensive
EFS:  N instances, medium latency, moderate
S3:   HTTP access, high latency,   cheap</code></pre></p>
<p>---</p>
<h2>S3 (Simple Storage Service)</h2>
<h3>S3 Basics</h3>
<pre><code class="language-text">S3 Structure:
Bucket (globally unique name)
‚îî‚îÄ‚îÄ Objects (files)
    ‚îú‚îÄ‚îÄ Key (path/filename)
    ‚îú‚îÄ‚îÄ Value (data)
    ‚îú‚îÄ‚îÄ Metadata
    ‚îî‚îÄ‚îÄ Version ID
<p>Example:
s3://my-app-bucket/images/logo.png
       ‚îÇ            ‚îÇ
       Bucket       Key</code></pre></p>
<h3>Create Bucket</h3>
<pre><code class="language-bash"># Create bucket
aws s3 mb s3://my-unique-bucket-12345
<h1>List buckets</h1>
aws s3 ls
<h1>Upload file</h1>
aws s3 cp file.txt s3://my-unique-bucket-12345/
<h1>Upload directory</h1>
aws s3 cp ./images s3://my-unique-bucket-12345/images/ --recursive
<h1>Download file</h1>
aws s3 cp s3://my-unique-bucket-12345/file.txt ./
<h1>List objects</h1>
aws s3 ls s3://my-unique-bucket-12345/
<h1>Delete object</h1>
aws s3 rm s3://my-unique-bucket-12345/file.txt
<h1>Delete bucket (must be empty)</h1>
aws s3 rb s3://my-unique-bucket-12345 --force</code></pre>
<h3>Go SDK - S3 Operations</h3>
<pre><code class="language-go">package main
<p>import (
    &quot;bytes&quot;
    &quot;context&quot;
    &quot;fmt&quot;
    &quot;io&quot;
    &quot;log&quot;</p>
<p>&quot;github.com/aws/aws-sdk-go-v2/config&quot;
    &quot;github.com/aws/aws-sdk-go-v2/service/s3&quot;
)</p>
<p>func main() {
    cfg, _ := config.LoadDefaultConfig(context.TODO())
    client := s3.NewFromConfig(cfg)</p>
<p>// Upload file
    uploadFile(client, &quot;my-bucket&quot;, &quot;test.txt&quot;, []byte(&quot;Hello S3!&quot;))</p>
<p>// Download file
    data := downloadFile(client, &quot;my-bucket&quot;, &quot;test.txt&quot;)
    fmt.Println(string(data))</p>
<p>// List objects
    listObjects(client, &quot;my-bucket&quot;)</p>
<p>// Delete object
    deleteObject(client, &quot;my-bucket&quot;, &quot;test.txt&quot;)
}</p>
<p>func uploadFile(client *s3.Client, bucket, key string, data []byte) {
    _, err := client.PutObject(context.TODO(), &amp;s3.PutObjectInput{
        Bucket: &amp;bucket,
        Key:    &amp;key,
        Body:   bytes.NewReader(data),
    })
    if err != nil {
        log.Fatal(err)
    }
    fmt.Printf(&quot;Uploaded: %s\n&quot;, key)
}</p>
<p>func downloadFile(client *s3.Client, bucket, key string) []byte {
    result, err := client.GetObject(context.TODO(), &amp;s3.GetObjectInput{
        Bucket: &amp;bucket,
        Key:    &amp;key,
    })
    if err != nil {
        log.Fatal(err)
    }
    defer result.Body.Close()</p>
<p>data, _ := io.ReadAll(result.Body)
    return data
}</p>
<p>func listObjects(client *s3.Client, bucket string) {
    result, _ := client.ListObjectsV2(context.TODO(), &amp;s3.ListObjectsV2Input{
        Bucket: &amp;bucket,
    })</p>
<p>for _, obj := range result.Contents {
        fmt.Printf(&quot;%s (Size: %d bytes)\n&quot;, *obj.Key, obj.Size)
    }
}</p>
<p>func deleteObject(client *s3.Client, bucket, key string) {
    _, err := client.DeleteObject(context.TODO(), &amp;s3.DeleteObjectInput{
        Bucket: &amp;bucket,
        Key:    &amp;key,
    })
    if err != nil {
        log.Fatal(err)
    }
    fmt.Printf(&quot;Deleted: %s\n&quot;, key)
}</code></pre></p>
<h3>S3 Storage Classes</h3>
<pre><code class="language-text">S3 Standard:
<li>Frequently accessed</li>
<li>Low latency</li>
<li>$0.023/GB/month</li>
<p>S3 Intelligent-Tiering:
<li>Auto-moves between tiers</li>
<li>Unknown access patterns</li></p>
<p>S3 Standard-IA (Infrequent Access):
<li>Less frequent access</li>
<li>$0.0125/GB/month</li>
<li>Retrieval fee</li></p>
<p>S3 One Zone-IA:
<li>Single AZ</li>
<li>Cheaper than Standard-IA</li>
<li>Less durability</li></p>
<p>S3 Glacier Instant Retrieval:
<li>Archive storage</li>
<li>Millisecond retrieval</li>
<li>$0.004/GB/month</li></p>
<p>S3 Glacier Flexible Retrieval:
<li>Minutes to hours retrieval</li>
<li>$0.0036/GB/month</li></p>
<p>S3 Glacier Deep Archive:
<li>Lowest cost</li>
<li>12-hour retrieval</li>
<li>$0.00099/GB/month</code></pre></li></p>
<pre><code class="language-bash"># Set storage class
aws s3 cp file.txt s3://my-bucket/ --storage-class GLACIER
<h1>Lifecycle policy</h1>
aws s3api put-bucket-lifecycle-configuration \
  --bucket my-bucket \
  --lifecycle-configuration file://lifecycle.json</code></pre>
<pre><code class="language-json">{
  &quot;Rules&quot;: [
    {
      &quot;Id&quot;: &quot;MoveToGlacier&quot;,
      &quot;Status&quot;: &quot;Enabled&quot;,
      &quot;Transitions&quot;: [
        {
          &quot;Days&quot;: 30,
          &quot;StorageClass&quot;: &quot;STANDARD_IA&quot;
        },
        {
          &quot;Days&quot;: 90,
          &quot;StorageClass&quot;: &quot;GLACIER&quot;
        }
      ],
      &quot;Expiration&quot;: {
        &quot;Days&quot;: 365
      }
    }
  ]
}</code></pre>
<h3>S3 Versioning</h3>
<pre><code class="language-bash"># Enable versioning
aws s3api put-bucket-versioning \
  --bucket my-bucket \
  --versioning-configuration Status=Enabled
<h1>List versions</h1>
aws s3api list-object-versions --bucket my-bucket
<h1>Get specific version</h1>
aws s3api get-object \
  --bucket my-bucket \
  --key file.txt \
  --version-id abc123 \
  output.txt
<h1>Delete specific version (permanent)</h1>
aws s3api delete-object \
  --bucket my-bucket \
  --key file.txt \
  --version-id abc123</code></pre>
<h3>S3 Presigned URLs</h3>
<pre><code class="language-go">// Generate presigned URL (temporary access)
import (
    &quot;github.com/aws/aws-sdk-go-v2/service/s3&quot;
    &quot;github.com/aws/aws-sdk-go-v2/aws&quot;
)
<p>func generatePresignedURL(client *s3.Client, bucket, key string) string {
    presignClient := s3.NewPresignClient(client)
    
    request, err := presignClient.PresignGetObject(context.TODO(), &amp;s3.GetObjectInput{
        Bucket: aws.String(bucket),
        Key:    aws.String(key),
    }, s3.WithPresignExpires(15*time.Minute))
    
    if err != nil {
        log.Fatal(err)
    }
    
    return request.URL  // Valid for 15 minutes
}</p>
<p>// Anyone with this URL can download (no auth needed)
// Use for: User file downloads, temporary sharing</code></pre></p>
<h3>S3 Static Website Hosting</h3>
<pre><code class="language-bash"># Enable website hosting
aws s3 website s3://my-bucket/ \
  --index-document index.html \
  --error-document error.html
<h1>Upload files</h1>
aws s3 cp index.html s3://my-bucket/
aws s3 cp error.html s3://my-bucket/
<h1>Make public</h1>
aws s3api put-bucket-policy \
  --bucket my-bucket \
  --policy file://policy.json</code></pre>
<pre><code class="language-json">{
  &quot;Version&quot;: &quot;2012-10-17&quot;,
  &quot;Statement&quot;: [
    {
      &quot;Sid&quot;: &quot;PublicReadGetObject&quot;,
      &quot;Effect&quot;: &quot;Allow&quot;,
      &quot;Principal&quot;: &quot;*&quot;,
      &quot;Action&quot;: &quot;s3:GetObject&quot;,
      &quot;Resource&quot;: &quot;arn:aws:s3:::my-bucket/*&quot;
    }
  ]
}</code></pre>
<h3>S3 Encryption</h3>
<pre><code class="language-text">Server-Side Encryption (SSE):
<p>SSE-S3:   AWS manages keys (AES-256)
SSE-KMS:  AWS KMS (audit trail, rotation)
SSE-C:    Customer-provided keys</p>
<p>Client-Side Encryption:
Encrypt before upload, decrypt after download</code></pre></p>
<pre><code class="language-bash"># Enable default encryption
aws s3api put-bucket-encryption \
  --bucket my-bucket \
  --server-side-encryption-configuration &#039;{
    &quot;Rules&quot;: [{
      &quot;ApplyServerSideEncryptionByDefault&quot;: {
        &quot;SSEAlgorithm&quot;: &quot;AES256&quot;
      }
    }]
  }&#039;</code></pre>
<p>---</p>
<h2>EBS (Elastic Block Store)</h2>
<h3>EBS Volume Types</h3>
<pre><code class="language-text">General Purpose SSD (gp3, gp2):
<li>Balanced price/performance</li>
<li>3,000-16,000 IOPS</li>
<li>Use: Boot volumes, dev/test</li>
<p>Provisioned IOPS SSD (io2, io1):
<li>Highest performance</li>
<li>Up to 64,000 IOPS</li>
<li>Use: Databases, critical apps</li></p>
<p>Throughput Optimized HDD (st1):
<li>Low-cost HDD</li>
<li>Big data, data warehouses</li>
<li>Cannot be boot volume</li></p>
<p>Cold HDD (sc1):
<li>Lowest cost</li>
<li>Infrequent access</li>
<li>Cannot be boot volume</code></pre></li></p>
<h3>Create and Attach EBS Volume</h3>
<pre><code class="language-bash"># Create volume
aws ec2 create-volume \
  --availability-zone us-east-1a \
  --size 100 \
  --volume-type gp3 \
  --iops 3000 \
  --tag-specifications &#039;ResourceType=volume,Tags=[{Key=Name,Value=my-volume}]&#039;
<h1>List volumes</h1>
aws ec2 describe-volumes
<h1>Attach to instance</h1>
aws ec2 attach-volume \
  --volume-id vol-1234567890abcdef0 \
  --instance-id i-1234567890abcdef0 \
  --device /dev/sdf
<h1>Format and mount (on EC2 instance)</h1>
sudo mkfs -t ext4 /dev/sdf
sudo mkdir /data
sudo mount /dev/sdf /data
<h1>Auto-mount on reboot (add to /etc/fstab)</h1>
echo &#039;/dev/sdf /data ext4 defaults,nofail 0 2&#039; | sudo tee -a /etc/fstab</code></pre>
<h3>EBS Snapshots</h3>
<pre><code class="language-bash"># Create snapshot
aws ec2 create-snapshot \
  --volume-id vol-1234567890abcdef0 \
  --description &quot;Backup before update&quot;
<h1>List snapshots</h1>
aws ec2 describe-snapshots --owner-ids self
<h1>Create volume from snapshot</h1>
aws ec2 create-volume \
  --snapshot-id snap-1234567890abcdef0 \
  --availability-zone us-east-1a
<h1>Copy snapshot to another region</h1>
aws ec2 copy-snapshot \
  --source-region us-east-1 \
  --source-snapshot-id snap-1234567890abcdef0 \
  --destination-region us-west-2
<h1>Delete snapshot</h1>
aws ec2 delete-snapshot --snapshot-id snap-1234567890abcdef0</code></pre>
<h3>Terraform - EBS with Snapshots</h3>
<pre><code class="language-hcl">resource &quot;aws_ebs_volume&quot; &quot;data&quot; {
  availability_zone = &quot;us-east-1a&quot;
  size              = 100
  type              = &quot;gp3&quot;
  iops              = 3000
  throughput        = 125
<p>tags = {
    Name = &quot;data-volume&quot;
  }
}</p>
<p>resource &quot;aws_volume_attachment&quot; &quot;data&quot; {
  device_name = &quot;/dev/sdf&quot;
  volume_id   = aws_ebs_volume.data.id
  instance_id = aws_instance.web.id
}</p>
<h1>Automated snapshots</h1>
resource &quot;aws_dlm_lifecycle_policy&quot; &quot;snapshots&quot; {
  description        = &quot;Daily snapshots&quot;
  execution_role_arn = aws_iam_role.dlm.arn
  state              = &quot;ENABLED&quot;
<p>policy_details {
    resource_types = [&quot;VOLUME&quot;]</p>
<p>schedule {
      name = &quot;Daily snapshots&quot;</p>
<p>create_rule {
        interval      = 24
        interval_unit = &quot;HOURS&quot;
        times         = [&quot;23:00&quot;]
      }</p>
<p>retain_rule {
        count = 7  # Keep 7 days
      }
    }</p>
<p>target_tags = {
      Snapshot = &quot;true&quot;
    }
  }
}</code></pre></p>
<p>---</p>
<h2>EFS (Elastic File System)</h2>
<h3>EFS Features</h3>
<pre><code class="language-text">Shared File System:
<li>NFSv4 protocol</li>
<li>Multi-AZ, multi-instance access</li>
<li>Auto-scaling (no capacity planning)</li>
<li>Pay for what you use</li>
<p>Use Cases:
<li>Web serving</li>
<li>Content management</li>
<li>Development environments</li>
<li>Container storage</code></pre></li></p>
<h3>Create EFS</h3>
<pre><code class="language-bash"># Create EFS file system
aws efs create-file-system \
  --performance-mode generalPurpose \
  --throughput-mode bursting \
  --encrypted \
  --tags Key=Name,Value=my-efs
<h1>Create mount targets (one per AZ)</h1>
aws efs create-mount-target \
  --file-system-id fs-12345678 \
  --subnet-id subnet-aaaaa \
  --security-groups sg-12345678
<h1>Mount on EC2 (install nfs-utils first)</h1>
sudo yum install -y amazon-efs-utils
sudo mkdir /mnt/efs
sudo mount -t efs fs-12345678:/ /mnt/efs
<h1>Auto-mount on boot</h1>
echo &#039;fs-12345678:/ /mnt/efs efs defaults,_netdev 0 0&#039; | sudo tee -a /etc/fstab</code></pre>
<h3>EFS Performance Modes</h3>
<pre><code class="language-text">General Purpose:
<li>Low latency</li>
<li>Web serving, CMS</li>
<li>Max 7,000 IOPS</li>
<p>Max I/O:
<li>Higher latency</li>
<li>Big data, media processing</li>
<li>500,000+ IOPS</li></p>
<p>Throughput Modes:
Bursting:     Scales with size
Provisioned:  Fixed throughput
Elastic:      Auto-scales (recommended)</code></pre></p>
<h3>Terraform - EFS with Mount Targets</h3>
<pre><code class="language-hcl">resource &quot;aws_efs_file_system&quot; &quot;shared&quot; {
  creation_token = &quot;my-efs&quot;
  encrypted      = true
<p>performance_mode = &quot;generalPurpose&quot;
  throughput_mode  = &quot;elastic&quot;</p>
<p>lifecycle_policy {
    transition_to_ia = &quot;AFTER_30_DAYS&quot;
  }</p>
<p>tags = {
    Name = &quot;shared-efs&quot;
  }
}</p>
<p>resource &quot;aws_efs_mount_target&quot; &quot;az&quot; {
  count = length(var.private_subnets)</p>
<p>file_system_id  = aws_efs_file_system.shared.id
  subnet_id       = var.private_subnets[count.index]
  security_groups = [aws_security_group.efs.id]
}</p>
<p>resource &quot;aws_security_group&quot; &quot;efs&quot; {
  name        = &quot;efs-sg&quot;
  description = &quot;EFS mount target security group&quot;
  vpc_id      = var.vpc_id</p>
<p>ingress {
    from_port   = 2049
    to_port     = 2049
    protocol    = &quot;tcp&quot;
    cidr_blocks = [var.vpc_cidr]
  }
}</p>
<p>output &quot;efs_id&quot; {
  value = aws_efs_file_system.shared.id
}</code></pre></p>
<p>---</p>
<h2>CloudFront (CDN)</h2>
<h3>CloudFront Basics</h3>
<pre><code class="language-text">Content Delivery Network (CDN):
<li>Cache content at edge locations (400+ worldwide)</li>
<li>Reduce latency for global users</li>
<li>DDoS protection</li>
<li>SSL/TLS</li>
<p>Origin:
<li>S3 bucket</li>
<li>EC2/ALB</li>
<li>Custom HTTP server</code></pre></li></p>
<h3>Create CloudFront Distribution</h3>
<pre><code class="language-bash"># Create distribution
aws cloudfront create-distribution \
  --origin-domain-name my-bucket.s3.amazonaws.com \
  --default-root-object index.html</code></pre>
<h3>Terraform - CloudFront with S3</h3>
<pre><code class="language-hcl"># S3 bucket for website
resource &quot;aws_s3_bucket&quot; &quot;website&quot; {
  bucket = &quot;my-website-bucket&quot;
}
<p>resource &quot;aws_s3_bucket_website_configuration&quot; &quot;website&quot; {
  bucket = aws_s3_bucket.website.id</p>
<p>index_document {
    suffix = &quot;index.html&quot;
  }
}</p>
<h1>CloudFront distribution</h1>
resource &quot;aws_cloudfront_distribution&quot; &quot;cdn&quot; {
  origin {
    domain_name = aws_s3_bucket.website.bucket_regional_domain_name
    origin_id   = &quot;S3-my-website&quot;
<p>s3_origin_config {
      origin_access_identity = aws_cloudfront_origin_access_identity.oai.cloudfront_access_identity_path
    }
  }</p>
<p>enabled             = true
  default_root_object = &quot;index.html&quot;</p>
<p>default_cache_behavior {
    target_origin_id       = &quot;S3-my-website&quot;
    viewer_protocol_policy = &quot;redirect-to-https&quot;</p>
<p>allowed_methods = [&quot;GET&quot;, &quot;HEAD&quot;]
    cached_methods  = [&quot;GET&quot;, &quot;HEAD&quot;]</p>
<p>forwarded_values {
      query_string = false
      cookies {
        forward = &quot;none&quot;
      }
    }</p>
<p>min_ttl     = 0
    default_ttl = 3600
    max_ttl     = 86400
  }</p>
<p>restrictions {
    geo_restriction {
      restriction_type = &quot;none&quot;
    }
  }</p>
<p>viewer_certificate {
    cloudfront_default_certificate = true
  }
}</p>
<p>resource &quot;aws_cloudfront_origin_access_identity&quot; &quot;oai&quot; {
  comment = &quot;OAI for my website&quot;
}</p>
<p>output &quot;cloudfront_url&quot; {
  value = aws_cloudfront_distribution.cdn.domain_name
}</code></pre></p>
<p>---</p>
<h2>Best Practices</h2>
<h3>S3 Best Practices</h3>
<pre><code class="language-text">1. Security
   ‚úÖ Block public access by default
   ‚úÖ Use bucket policies with least privilege
   ‚úÖ Enable versioning for critical data
   ‚úÖ Enable encryption (SSE-S3 or SSE-KMS)
   ‚úÖ Use presigned URLs for temporary access
<p>2. Cost Optimization
   ‚úÖ Use lifecycle policies
   ‚úÖ Intelligent-Tiering for unknown patterns
   ‚úÖ Delete incomplete multipart uploads
   ‚úÖ Enable S3 Analytics</p>
<p>3. Performance
   ‚úÖ Use CloudFront for static content
   ‚úÖ Parallelize uploads (multipart)
   ‚úÖ Use Transfer Acceleration for global uploads</code></pre></p>
<h3>EBS Best Practices</h3>
<pre><code class="language-text">1. Backups
   ‚úÖ Automated snapshots (DLM)
   ‚úÖ Copy snapshots to another region
   ‚úÖ Test restores regularly
<p>2. Performance
   ‚úÖ Use gp3 (cheaper than gp2)
   ‚úÖ Provision IOPS for databases
   ‚úÖ Monitor with CloudWatch</p>
<p>3. Availability
   ‚úÖ Use RAID for redundancy
   ‚úÖ Snapshots before major changes</code></pre></p>
<h3>EFS Best Practices</h3>
<pre><code class="language-text">1. Performance
   ‚úÖ Use elastic throughput mode
   ‚úÖ Enable lifecycle management (move to IA)
   ‚úÖ Use Max I/O for big data
<p>2. Security
   ‚úÖ Use VPC and security groups
   ‚úÖ Enable encryption
   ‚úÖ Use IAM policies</p>
<p>3. Cost
   ‚úÖ Enable IA storage class
   ‚úÖ Monitor usage with CloudWatch</code></pre></p>
<p>---</p>
<h2>Interview Questions</h2>
<strong>Q1: S3 vs EBS vs EFS - when to use each?</strong>
<strong>Answer:</strong>
<li><strong>S3</strong>: Object storage, unlimited scale, HTTP access. Use: Static assets, backups, data lakes</li>
<li><strong>EBS</strong>: Block storage, single instance, low latency. Use: Databases, boot volumes</li>
<li><strong>EFS</strong>: File storage, shared across instances, NFS. Use: Shared app data, content management</li>
<strong>Q2: How do you ensure S3 data durability and availability?</strong>
<strong>Answer:</strong>
<li>Durability: 99.999999999% (11 9's) - data replicated across 3+ AZs</li>
<li>Availability: 99.99% (Standard), 99.9% (IA)</li>
<li>Enable versioning (protect from deletes)</li>
<li>Cross-region replication (disaster recovery)</li>
<li>MFA delete for critical buckets</li>
<strong>Q3: Explain S3 lifecycle policies.</strong>
<strong>Answer:</strong> Automate transitions between storage classes and deletions.
Example: Standard ‚Üí Standard-IA (30 days) ‚Üí Glacier (90 days) ‚Üí Delete (365 days).
Saves costs by moving to cheaper tiers automatically.
<strong>Q4: What's the difference between EBS snapshots and AMIs?</strong>
<strong>Answer:</strong>
<li><strong>EBS Snapshot</strong>: Point-in-time backup of single volume. Use: Data backup, disaster recovery</li>
<li><strong>AMI</strong>: Complete machine image (root volume + config). Use: Launch identical instances, scaling</li>
<strong>Q5: How does CloudFront improve performance?</strong>
<strong>Answer:</strong>
<li>Caches content at 400+ edge locations worldwide</li>
<li>Users download from nearest edge (lower latency)</li>
<li>Reduces load on origin server</li>
<li>Free data transfer from S3 to CloudFront</li>
<li>DDoS protection (AWS Shield)</li>
<p>---</p>
<h2>Hands-On Exercise</h2>
<h3>Task: Build Scalable File Upload System</h3>
<strong>Architecture:</strong>
<pre><code class="language-text">User ‚Üí API Gateway ‚Üí Lambda ‚Üí S3
                       ‚Üì
                   CloudFront (for downloads)</code></pre>
<pre><code class="language-go">// Lambda function - upload handler
package main
<p>import (
    &quot;context&quot;
    &quot;encoding/base64&quot;
    &quot;fmt&quot;
    &quot;github.com/aws/aws-lambda-go/events&quot;
    &quot;github.com/aws/aws-lambda-go/lambda&quot;
    &quot;github.com/aws/aws-sdk-go-v2/config&quot;
    &quot;github.com/aws/aws-sdk-go-v2/service/s3&quot;
    &quot;strings&quot;
)</p>
<p>type UploadResponse struct {
    URL string <code>json:&quot;url&quot;</code>
}</p>
<p>func handler(ctx context.Context, request events.APIGatewayProxyRequest) (events.APIGatewayProxyResponse, error) {
    // Parse file from base64
    fileData, _ := base64.StdEncoding.DecodeString(request.Body)
    fileName := request.Headers[&quot;x-filename&quot;]
    
    // Upload to S3
    cfg, _ := config.LoadDefaultConfig(ctx)
    client := s3.NewFromConfig(cfg)
    
    bucket := &quot;my-uploads-bucket&quot;
    key := fmt.Sprintf(&quot;uploads/%s&quot;, fileName)
    
    _, err := client.PutObject(ctx, &amp;s3.PutObjectInput{
        Bucket: &amp;bucket,
        Key:    &amp;key,
        Body:   strings.NewReader(string(fileData)),
    })
    
    if err != nil {
        return events.APIGatewayProxyResponse{
            StatusCode: 500,
            Body:       err.Error(),
        }, nil
    }
    
    // Generate presigned URL for download
    presignClient := s3.NewPresignClient(client)
    presignedURL, _ := presignClient.PresignGetObject(ctx, &amp;s3.GetObjectInput{
        Bucket: &amp;bucket,
        Key:    &amp;key,
    })
    
    return events.APIGatewayProxyResponse{
        StatusCode: 200,
        Body:       fmt.Sprintf(<code>{&quot;url&quot;: &quot;%s&quot;}</code>, presignedURL.URL),
    }, nil
}</p>
<p>func main() {
    lambda.Start(handler)
}</code></pre></p>
<pre><code class="language-hcl"># Terraform - complete setup
resource &quot;aws_s3_bucket&quot; &quot;uploads&quot; {
  bucket = &quot;my-uploads-bucket-12345&quot;
}
<p>resource &quot;aws_s3_bucket_versioning&quot; &quot;uploads&quot; {
  bucket = aws_s3_bucket.uploads.id
  versioning_configuration {
    status = &quot;Enabled&quot;
  }
}</p>
<p>resource &quot;aws_s3_bucket_lifecycle_configuration&quot; &quot;uploads&quot; {
  bucket = aws_s3_bucket.uploads.id</p>
<p>rule {
    id     = &quot;archive-old-uploads&quot;
    status = &quot;Enabled&quot;</p>
<p>transition {
      days          = 30
      storage_class = &quot;STANDARD_IA&quot;
    }</p>
<p>transition {
      days          = 90
      storage_class = &quot;GLACIER&quot;
    }
  }
}</p>
<p>resource &quot;aws_cloudfront_distribution&quot; &quot;cdn&quot; {
  origin {
    domain_name = aws_s3_bucket.uploads.bucket_regional_domain_name
    origin_id   = &quot;S3-uploads&quot;
  }</p>
<p>enabled = true</p>
<p>default_cache_behavior {
    target_origin_id       = &quot;S3-uploads&quot;
    viewer_protocol_policy = &quot;https-only&quot;
    allowed_methods        = [&quot;GET&quot;, &quot;HEAD&quot;]
    cached_methods         = [&quot;GET&quot;, &quot;HEAD&quot;]</p>
<p>forwarded_values {
      query_string = false
      cookies { forward = &quot;none&quot; }
    }
  }</p>
<p>restrictions {
    geo_restriction {
      restriction_type = &quot;none&quot;
    }
  }</p>
<p>viewer_certificate {
    cloudfront_default_certificate = true
  }
}</code></pre></p>
<p>---</p>
<h2>üìö Additional Resources</h2>
<li>[S3 Developer Guide](https://docs.aws.amazon.com/s3/)</li>
<li>[EBS User Guide](https://docs.aws.amazon.com/ebs/)</li>
<li>[EFS User Guide](https://docs.aws.amazon.com/efs/)</li>
<li>[CloudFront Developer Guide](https://docs.aws.amazon.com/cloudfront/)</li>
<p>---</p>
<h2>‚úÖ Module Checklist</h2>
<li>[ ] Create S3 bucket and upload files</li>
<li>[ ] Configure S3 lifecycle policies</li>
<li>[ ] Generate presigned URLs</li>
<li>[ ] Set up S3 static website hosting</li>
<li>[ ] Create and attach EBS volume</li>
<li>[ ] Create and test EBS snapshots</li>
<li>[ ] Set up EFS and mount on multiple instances</li>
<li>[ ] Create CloudFront distribution for S3</li>
<li>[ ] Implement file upload system with Lambda + S3</li></ul>
<p>---</p>
<strong>Next Module:</strong> [Module 24: AWS Databases](./24_AWS_Databases.md) - RDS, DynamoDB, Aurora! üóÑÔ∏è

    </div>
    

    <div class="module-content" id="module-24">
        <h1>Module 24: AWS Databases - RDS, DynamoDB, Aurora üóÑÔ∏è</h1>
<h2>Master AWS Database Services for Scalable Data Storage</h2>
<strong>Duration:</strong> 5-6 hours  
<strong>Prerequisites:</strong> Module 04 (Database Integration), SQL basics  
<strong>Outcome:</strong> Deploy and manage AWS databases effectively
<p>---</p>
<h2>üìö Table of Contents</h2>
<p>1. [Database Services Overview](#database-services-overview)
2. [RDS (Relational Database Service)](#rds)
3. [DynamoDB (NoSQL)](#dynamodb)
4. [Aurora (MySQL/PostgreSQL Compatible)](#aurora)
5. [ElastiCache (Redis/Memcached)](#elasticache)
6. [Database Migration](#database-migration)
7. [Best Practices](#best-practices)
8. [Interview Questions](#interview-questions)
9. [Hands-On Exercise](#hands-on-exercise)</p>
<p>---</p>
<h2>Database Services Overview</h2>
<h3>Choosing the Right Database</h3>
<pre><code class="language-text">RDS (Relational):
‚úÖ Structured data
‚úÖ ACID transactions
‚úÖ Complex queries (JOINs)
‚úÖ Traditional apps
‚ùå Horizontal scaling limited
<p>DynamoDB (NoSQL):
‚úÖ Key-value/document
‚úÖ Unlimited scaling
‚úÖ Single-digit millisecond latency
‚úÖ Serverless option
‚ùå No complex queries</p>
<p>Aurora (High-Performance Relational):
‚úÖ MySQL/PostgreSQL compatible
‚úÖ 5x MySQL, 3x PostgreSQL performance
‚úÖ Auto-scaling storage
‚úÖ Global databases
‚ùå More expensive than RDS</p>
<p>ElastiCache (In-Memory):
‚úÖ Microsecond latency
‚úÖ Session store, caching
‚úÖ Redis or Memcached
‚ùå Not persistent (use with backup DB)</code></pre></p>
<p>---</p>
<h2>RDS (Relational Database Service)</h2>
<h3>Supported Engines</h3>
<pre><code class="language-text">- PostgreSQL
<ul><li>MySQL</li>
<li>MariaDB</li>
<li>Oracle</li>
<li>SQL Server</li>
<li>Aurora (AWS proprietary)</code></pre></li>
<h3>Create RDS Instance</h3>
<pre><code class="language-bash"># Create PostgreSQL database
aws rds create-db-instance \
  --db-instance-identifier mydb \
  --db-instance-class db.t3.micro \
  --engine postgres \
  --engine-version 15.3 \
  --master-username admin \
  --master-user-password MyPassword123! \
  --allocated-storage 20 \
  --storage-type gp3 \
  --vpc-security-group-ids sg-12345678 \
  --db-subnet-group-name my-db-subnet-group \
  --backup-retention-period 7 \
  --preferred-backup-window &quot;03:00-04:00&quot; \
  --multi-az \
  --publicly-accessible false
<h1>Get endpoint</h1>
aws rds describe-db-instances \
  --db-instance-identifier mydb \
  --query &#039;DBInstances[0].Endpoint.Address&#039;</code></pre>
<h3>Connect from Go</h3>
<pre><code class="language-go">package main
<p>import (
    &quot;database/sql&quot;
    &quot;fmt&quot;
    &quot;log&quot;</p>
<p>_ &quot;github.com/lib/pq&quot;
)</p>
<p>func main() {
    // RDS endpoint
    host := &quot;mydb.abc123.us-east-1.rds.amazonaws.com&quot;
    port := 5432
    user := &quot;admin&quot;
    password := &quot;MyPassword123!&quot;
    dbname := &quot;postgres&quot;</p>
<p>connStr := fmt.Sprintf(&quot;host=%s port=%d user=%s password=%s dbname=%s sslmode=require&quot;,
        host, port, user, password, dbname)</p>
<p>db, err := sql.Open(&quot;postgres&quot;, connStr)
    if err != nil {
        log.Fatal(err)
    }
    defer db.Close()</p>
<p>// Test connection
    err = db.Ping()
    if err != nil {
        log.Fatal(err)
    }</p>
<p>fmt.Println(&quot;Connected to RDS!&quot;)</p>
<p>// Query
    rows, _ := db.Query(&quot;SELECT version()&quot;)
    defer rows.Close()</p>
<p>var version string
    rows.Next()
    rows.Scan(&amp;version)
    fmt.Println(&quot;PostgreSQL version:&quot;, version)
}</code></pre></p>
<h3>RDS Multi-AZ</h3>
<pre><code class="language-text">Multi-AZ Deployment:
<li>Primary instance in AZ-A</li>
<li>Standby instance in AZ-B</li>
<li>Synchronous replication</li>
<li>Automatic failover (30-60 seconds)</li>
<li>No downtime for maintenance</li>
<p>Use: Production databases requiring high availability</code></pre></p>
<h3>Read Replicas</h3>
<pre><code class="language-text">Read Replicas:
<li>Asynchronous replication</li>
<li>Scale read traffic</li>
<li>Up to 5 replicas</li>
<li>Can promote to standalone DB</li>
<li>Cross-region replicas</li>
<p>Use: Read-heavy workloads, reporting, analytics</code></pre></p>
<pre><code class="language-bash"># Create read replica
aws rds create-db-instance-read-replica \
  --db-instance-identifier mydb-replica \
  --source-db-instance-identifier mydb \
  --db-instance-class db.t3.micro
<h1>Promote replica to standalone</h1>
aws rds promote-read-replica \
  --db-instance-identifier mydb-replica</code></pre>
<h3>Terraform - RDS with Multi-AZ</h3>
<pre><code class="language-hcl"># rds.tf
resource &quot;aws_db_subnet_group&quot; &quot;main&quot; {
  name       = &quot;my-db-subnet-group&quot;
  subnet_ids = var.private_subnet_ids
<p>tags = {
    Name = &quot;My DB subnet group&quot;
  }
}</p>
<p>resource &quot;aws_security_group&quot; &quot;db&quot; {
  name        = &quot;rds-sg&quot;
  description = &quot;Security group for RDS&quot;
  vpc_id      = var.vpc_id</p>
<p>ingress {
    from_port   = 5432
    to_port     = 5432
    protocol    = &quot;tcp&quot;
    cidr_blocks = [var.vpc_cidr]
  }
}</p>
<p>resource &quot;aws_db_instance&quot; &quot;postgres&quot; {
  identifier = &quot;mydb&quot;</p>
<p>engine         = &quot;postgres&quot;
  engine_version = &quot;15.3&quot;
  instance_class = &quot;db.t3.micro&quot;</p>
<p>allocated_storage     = 20
  max_allocated_storage = 100  # Auto-scaling
  storage_type          = &quot;gp3&quot;
  storage_encrypted     = true</p>
<p>db_name  = &quot;myapp&quot;
  username = &quot;admin&quot;
  password = var.db_password  # Use Secrets Manager in production</p>
<p>db_subnet_group_name   = aws_db_subnet_group.main.name
  vpc_security_group_ids = [aws_security_group.db.id]</p>
<p>multi_az               = true
  publicly_accessible    = false
  backup_retention_period = 7
  backup_window          = &quot;03:00-04:00&quot;
  maintenance_window     = &quot;sun:04:00-sun:05:00&quot;</p>
<p>skip_final_snapshot       = false
  final_snapshot_identifier = &quot;mydb-final-snapshot&quot;</p>
<p>enabled_cloudwatch_logs_exports = [&quot;postgresql&quot;, &quot;upgrade&quot;]</p>
<p>tags = {
    Name = &quot;Production Database&quot;
  }
}</p>
<h1>Read replica</h1>
resource &quot;aws_db_instance&quot; &quot;replica&quot; {
  identifier             = &quot;mydb-replica&quot;
  replicate_source_db    = aws_db_instance.postgres.identifier
  instance_class         = &quot;db.t3.micro&quot;
  publicly_accessible    = false
  skip_final_snapshot    = true
<p>tags = {
    Name = &quot;Read Replica&quot;
  }
}</p>
<p>output &quot;db_endpoint&quot; {
  value = aws_db_instance.postgres.endpoint
}</p>
<p>output &quot;replica_endpoint&quot; {
  value = aws_db_instance.replica.endpoint
}</code></pre></p>
<p>---</p>
<h2>DynamoDB (NoSQL)</h2>
<h3>DynamoDB Basics</h3>
<pre><code class="language-text">Table Structure:
<li>Partition Key (required)</li>
<li>Sort Key (optional)</li>
<li>Attributes (schema-less)</li>
<p>Example Table: Users
Partition Key: user_id
Sort Key:      timestamp
Attributes:    name, email, status (any JSON)</code></pre></p>
<h3>Create Table</h3>
<pre><code class="language-bash"># Create table
aws dynamodb create-table \
  --table-name Users \
  --attribute-definitions \
    AttributeName=user_id,AttributeType=S \
    AttributeName=timestamp,AttributeType=N \
  --key-schema \
    AttributeName=user_id,KeyType=HASH \
    AttributeName=timestamp,KeyType=RANGE \
  --billing-mode PAY_PER_REQUEST
<h1>List tables</h1>
aws dynamodb list-tables
<h1>Describe table</h1>
aws dynamodb describe-table --table-name Users</code></pre>
<h3>Go SDK - DynamoDB Operations</h3>
<pre><code class="language-go">package main
<p>import (
    &quot;context&quot;
    &quot;fmt&quot;
    &quot;log&quot;</p>
<p>&quot;github.com/aws/aws-sdk-go-v2/config&quot;
    &quot;github.com/aws/aws-sdk-go-v2/feature/dynamodb/attributevalue&quot;
    &quot;github.com/aws/aws-sdk-go-v2/service/dynamodb&quot;
    &quot;github.com/aws/aws-sdk-go-v2/service/dynamodb/types&quot;
    &quot;github.com/aws/aws-sdk-go/aws&quot;
)</p>
<p>type User struct {
    UserID    string <code>dynamodbav:&quot;user_id&quot;</code>
    Name      string <code>dynamodbav:&quot;name&quot;</code>
    Email     string <code>dynamodbav:&quot;email&quot;</code>
    Timestamp int64  <code>dynamodbav:&quot;timestamp&quot;</code>
}</p>
<p>func main() {
    cfg, _ := config.LoadDefaultConfig(context.TODO())
    client := dynamodb.NewFromConfig(cfg)</p>
<p>// Put item
    putItem(client, User{
        UserID:    &quot;user-123&quot;,
        Name:      &quot;John Doe&quot;,
        Email:     &quot;john@example.com&quot;,
        Timestamp: 1699564800,
    })</p>
<p>// Get item
    user := getItem(client, &quot;user-123&quot;, 1699564800)
    fmt.Printf(&quot;Retrieved: %+v\n&quot;, user)</p>
<p>// Query items
    users := queryByUserID(client, &quot;user-123&quot;)
    fmt.Printf(&quot;Found %d items\n&quot;, len(users))</p>
<p>// Scan table
    allUsers := scanTable(client)
    fmt.Printf(&quot;Total users: %d\n&quot;, len(allUsers))</p>
<p>// Update item
    updateItem(client, &quot;user-123&quot;, 1699564800, &quot;jane@example.com&quot;)</p>
<p>// Delete item
    deleteItem(client, &quot;user-123&quot;, 1699564800)
}</p>
<p>func putItem(client *dynamodb.Client, user User) {
    item, _ := attributevalue.MarshalMap(user)</p>
<p>_, err := client.PutItem(context.TODO(), &amp;dynamodb.PutItemInput{
        TableName: aws.String(&quot;Users&quot;),
        Item:      item,
    })</p>
<p>if err != nil {
        log.Fatal(err)
    }
    fmt.Println(&quot;Item added&quot;)
}</p>
<p>func getItem(client *dynamodb.Client, userID string, timestamp int64) User {
    result, _ := client.GetItem(context.TODO(), &amp;dynamodb.GetItemInput{
        TableName: aws.String(&quot;Users&quot;),
        Key: map[string]types.AttributeValue{
            &quot;user_id&quot;:   &amp;types.AttributeValueMemberS{Value: userID},
            &quot;timestamp&quot;: &amp;types.AttributeValueMemberN{Value: fmt.Sprintf(&quot;%d&quot;, timestamp)},
        },
    })</p>
<p>var user User
    attributevalue.UnmarshalMap(result.Item, &amp;user)
    return user
}</p>
<p>func queryByUserID(client *dynamodb.Client, userID string) []User {
    result, _ := client.Query(context.TODO(), &amp;dynamodb.QueryInput{
        TableName:              aws.String(&quot;Users&quot;),
        KeyConditionExpression: aws.String(&quot;user_id = :uid&quot;),
        ExpressionAttributeValues: map[string]types.AttributeValue{
            &quot;:uid&quot;: &amp;types.AttributeValueMemberS{Value: userID},
        },
    })</p>
<p>var users []User
    attributevalue.UnmarshalListOfMaps(result.Items, &amp;users)
    return users
}</p>
<p>func scanTable(client *dynamodb.Client) []User {
    result, _ := client.Scan(context.TODO(), &amp;dynamodb.ScanInput{
        TableName: aws.String(&quot;Users&quot;),
    })</p>
<p>var users []User
    attributevalue.UnmarshalListOfMaps(result.Items, &amp;users)
    return users
}</p>
<p>func updateItem(client *dynamodb.Client, userID string, timestamp int64, newEmail string) {
    _, err := client.UpdateItem(context.TODO(), &amp;dynamodb.UpdateItemInput{
        TableName: aws.String(&quot;Users&quot;),
        Key: map[string]types.AttributeValue{
            &quot;user_id&quot;:   &amp;types.AttributeValueMemberS{Value: userID},
            &quot;timestamp&quot;: &amp;types.AttributeValueMemberN{Value: fmt.Sprintf(&quot;%d&quot;, timestamp)},
        },
        UpdateExpression: aws.String(&quot;SET email = :email&quot;),
        ExpressionAttributeValues: map[string]types.AttributeValue{
            &quot;:email&quot;: &amp;types.AttributeValueMemberS{Value: newEmail},
        },
    })</p>
<p>if err != nil {
        log.Fatal(err)
    }
    fmt.Println(&quot;Item updated&quot;)
}</p>
<p>func deleteItem(client *dynamodb.Client, userID string, timestamp int64) {
    _, err := client.DeleteItem(context.TODO(), &amp;dynamodb.DeleteItemInput{
        TableName: aws.String(&quot;Users&quot;),
        Key: map[string]types.AttributeValue{
            &quot;user_id&quot;:   &amp;types.AttributeValueMemberS{Value: userID},
            &quot;timestamp&quot;: &amp;types.AttributeValueMemberN{Value: fmt.Sprintf(&quot;%d&quot;, timestamp)},
        },
    })</p>
<p>if err != nil {
        log.Fatal(err)
    }
    fmt.Println(&quot;Item deleted&quot;)
}</code></pre></p>
<h3>Global Secondary Index (GSI)</h3>
<pre><code class="language-text">GSI: Query by non-key attributes
<p>Example:
Primary Index: user_id (partition), timestamp (sort)
GSI: email (partition)</p>
<p>Now you can query by email!</code></pre></p>
<pre><code class="language-bash"># Add GSI
aws dynamodb update-table \
  --table-name Users \
  --attribute-definitions AttributeName=email,AttributeType=S \
  --global-secondary-index-updates &#039;[
    {
      &quot;Create&quot;: {
        &quot;IndexName&quot;: &quot;EmailIndex&quot;,
        &quot;KeySchema&quot;: [{&quot;AttributeName&quot;: &quot;email&quot;, &quot;KeyType&quot;: &quot;HASH&quot;}],
        &quot;Projection&quot;: {&quot;ProjectionType&quot;: &quot;ALL&quot;},
        &quot;ProvisionedThroughput&quot;: {&quot;ReadCapacityUnits&quot;: 5, &quot;WriteCapacityUnits&quot;: 5}
      }
    }
  ]&#039;</code></pre>
<h3>DynamoDB Streams</h3>
<pre><code class="language-text">Streams: Capture changes (insert, update, delete)
<p>Use cases:
<li>Trigger Lambda on changes</li>
<li>Replicate to another table</li>
<li>Analytics pipeline</code></pre></li></p>
<pre><code class="language-go">// Enable streams in Terraform
resource &quot;aws_dynamodb_table&quot; &quot;users&quot; {
  name           = &quot;Users&quot;
  billing_mode   = &quot;PAY_PER_REQUEST&quot;
  hash_key       = &quot;user_id&quot;
  range_key      = &quot;timestamp&quot;
<p>attribute {
    name = &quot;user_id&quot;
    type = &quot;S&quot;
  }</p>
<p>attribute {
    name = &quot;timestamp&quot;
    type = &quot;N&quot;
  }</p>
<p>stream_enabled   = true
  stream_view_type = &quot;NEW_AND_OLD_IMAGES&quot;</p>
<p>tags = {
    Name = &quot;Users table&quot;
  }
}</code></pre></p>
<p>---</p>
<h2>Aurora (MySQL/PostgreSQL Compatible)</h2>
<h3>Aurora Features</h3>
<pre><code class="language-text">Performance:
<li>5x faster than MySQL</li>
<li>3x faster than PostgreSQL</li>
<li>Up to 128 TB storage (auto-scaling)</li>
<li>Up to 15 read replicas</li>
<p>Availability:
<li>6 copies across 3 AZs</li>
<li>Self-healing storage</li>
<li>Automatic failover (&lt;30 seconds)</li></p>
<p>Serverless:
<li>Auto-scaling compute</li>
<li>Pay per second</li>
<li>Good for intermittent workloads</code></pre></li></p>
<h3>Create Aurora Cluster</h3>
<pre><code class="language-bash"># Create Aurora cluster
aws rds create-db-cluster \
  --db-cluster-identifier my-aurora-cluster \
  --engine aurora-postgresql \
  --engine-version 15.3 \
  --master-username admin \
  --master-user-password MyPassword123! \
  --db-subnet-group-name my-db-subnet-group \
  --vpc-security-group-ids sg-12345678
<h1>Create instances</h1>
aws rds create-db-instance \
  --db-instance-identifier my-aurora-instance-1 \
  --db-instance-class db.r6g.large \
  --engine aurora-postgresql \
  --db-cluster-identifier my-aurora-cluster</code></pre>
<h3>Aurora Serverless</h3>
<pre><code class="language-hcl">resource &quot;aws_rds_cluster&quot; &quot;aurora_serverless&quot; {
  cluster_identifier      = &quot;aurora-cluster&quot;
  engine                  = &quot;aurora-postgresql&quot;
  engine_mode             = &quot;serverless&quot;
  database_name           = &quot;mydb&quot;
  master_username         = &quot;admin&quot;
  master_password         = var.db_password
  db_subnet_group_name    = aws_db_subnet_group.main.name
  vpc_security_group_ids  = [aws_security_group.db.id]
<p>scaling_configuration {
    auto_pause               = true
    min_capacity             = 2
    max_capacity             = 16
    seconds_until_auto_pause = 300
  }</p>
<p>skip_final_snapshot = true
}</code></pre></p>
<p>---</p>
<h2>ElastiCache (Redis/Memcached)</h2>
<h3>Redis vs Memcached</h3>
<pre><code class="language-text">Redis:
‚úÖ Persistence
‚úÖ Data structures (lists, sets, sorted sets)
‚úÖ Pub/Sub
‚úÖ Replication
‚úÖ Transactions
Use: Session store, leaderboards, real-time analytics
<p>Memcached:
‚úÖ Simple key-value
‚úÖ Multi-threaded
‚úÖ Slightly faster for simple ops
‚ùå No persistence
Use: Simple caching</code></pre></p>
<h3>Create Redis Cluster</h3>
<pre><code class="language-bash"># Create subnet group
aws elasticache create-cache-subnet-group \
  --cache-subnet-group-name my-cache-subnet \
  --cache-subnet-group-description &quot;Subnet group for cache&quot; \
  --subnet-ids subnet-12345 subnet-67890
<h1>Create Redis cluster</h1>
aws elasticache create-cache-cluster \
  --cache-cluster-id my-redis \
  --cache-node-type cache.t3.micro \
  --engine redis \
  --num-cache-nodes 1 \
  --cache-subnet-group-name my-cache-subnet \
  --security-group-ids sg-12345678</code></pre>
<h3>Go - Connect to Redis</h3>
<pre><code class="language-go">package main
<p>import (
    &quot;context&quot;
    &quot;fmt&quot;
    &quot;time&quot;</p>
<p>&quot;github.com/go-redis/redis/v8&quot;
)</p>
<p>func main() {
    // ElastiCache Redis endpoint
    rdb := redis.NewClient(&amp;redis.Options{
        Addr:     &quot;my-redis.abc123.0001.use1.cache.amazonaws.com:6379&quot;,
        Password: &quot;&quot;, // No password for ElastiCache by default
        DB:       0,
    })</p>
<p>ctx := context.Background()</p>
<p>// Set value with expiration
    err := rdb.Set(ctx, &quot;session:user123&quot;, &quot;session-data&quot;, 1*time.Hour).Err()
    if err != nil {
        panic(err)
    }</p>
<p>// Get value
    val, err := rdb.Get(ctx, &quot;session:user123&quot;).Result()
    if err != nil {
        panic(err)
    }
    fmt.Println(&quot;Value:&quot;, val)</p>
<p>// Increment counter
    rdb.Incr(ctx, &quot;page_views&quot;)</p>
<p>// List operations
    rdb.LPush(ctx, &quot;queue&quot;, &quot;task1&quot;, &quot;task2&quot;, &quot;task3&quot;)
    task, _ := rdb.RPop(ctx, &quot;queue&quot;).Result()
    fmt.Println(&quot;Popped task:&quot;, task)</p>
<p>// Hash operations
    rdb.HSet(ctx, &quot;user:123&quot;, &quot;name&quot;, &quot;John&quot;, &quot;email&quot;, &quot;john@example.com&quot;)
    name, _ := rdb.HGet(ctx, &quot;user:123&quot;, &quot;name&quot;).Result()
    fmt.Println(&quot;User name:&quot;, name)</p>
<p>// Set operations
    rdb.SAdd(ctx, &quot;online_users&quot;, &quot;user1&quot;, &quot;user2&quot;, &quot;user3&quot;)
    count, _ := rdb.SCard(ctx, &quot;online_users&quot;).Result()
    fmt.Println(&quot;Online users:&quot;, count)
}</code></pre></p>
<h3>Terraform - ElastiCache Redis</h3>
<pre><code class="language-hcl">resource &quot;aws_elasticache_subnet_group&quot; &quot;redis&quot; {
  name       = &quot;redis-subnet-group&quot;
  subnet_ids = var.private_subnet_ids
}
<p>resource &quot;aws_security_group&quot; &quot;redis&quot; {
  name   = &quot;redis-sg&quot;
  vpc_id = var.vpc_id</p>
<p>ingress {
    from_port   = 6379
    to_port     = 6379
    protocol    = &quot;tcp&quot;
    cidr_blocks = [var.vpc_cidr]
  }
}</p>
<p>resource &quot;aws_elasticache_replication_group&quot; &quot;redis&quot; {
  replication_group_id       = &quot;my-redis-cluster&quot;
  replication_group_description = &quot;Redis cluster for caching&quot;</p>
<p>engine               = &quot;redis&quot;
  engine_version       = &quot;7.0&quot;
  node_type            = &quot;cache.t3.micro&quot;
  num_cache_clusters   = 2</p>
<p>automatic_failover_enabled = true
  multi_az_enabled          = true</p>
<p>subnet_group_name  = aws_elasticache_subnet_group.redis.name
  security_group_ids = [aws_security_group.redis.id]</p>
<p>at_rest_encryption_enabled = true
  transit_encryption_enabled = true</p>
<p>snapshot_retention_limit = 5
  snapshot_window          = &quot;03:00-05:00&quot;</p>
<p>tags = {
    Name = &quot;Production Redis&quot;
  }
}</p>
<p>output &quot;redis_endpoint&quot; {
  value = aws_elasticache_replication_group.redis.configuration_endpoint_address
}</code></pre></p>
<p>---</p>
<h2>Best Practices</h2>
<h3>RDS Best Practices</h3>
<pre><code class="language-text">1. High Availability
   ‚úÖ Use Multi-AZ for production
   ‚úÖ Enable automated backups
   ‚úÖ Test failover procedures
<p>2. Performance
   ‚úÖ Use read replicas for read-heavy workloads
   ‚úÖ Enable Performance Insights
   ‚úÖ Right-size instance type</p>
<p>3. Security
   ‚úÖ Encrypt at rest and in transit
   ‚úÖ Use IAM database authentication
   ‚úÖ Store credentials in Secrets Manager
   ‚úÖ Private subnets only</p>
<p>4. Maintenance
   ‚úÖ Enable auto minor version upgrades
   ‚úÖ Schedule maintenance windows
   ‚úÖ Monitor with CloudWatch</code></pre></p>
<h3>DynamoDB Best Practices</h3>
<pre><code class="language-text">1. Schema Design
   ‚úÖ Design for access patterns
   ‚úÖ Use composite keys
   ‚úÖ Avoid hot partitions
<p>2. Performance
   ‚úÖ Use on-demand billing for unpredictable workloads
   ‚úÖ Enable auto-scaling for provisioned mode
   ‚úÖ Use DAX for microsecond latency</p>
<p>3. Cost Optimization
   ‚úÖ Use sparse indexes
   ‚úÖ Set TTL for automatic deletions
   ‚úÖ Archive old data to S3</p>
<p>4. Availability
   ‚úÖ Use global tables for multi-region
   ‚úÖ Enable point-in-time recovery
   ‚úÖ Enable streams for change capture</code></pre></p>
<p>---</p>
<h2>Interview Questions</h2>
<strong>Q1: RDS Multi-AZ vs Read Replicas?</strong>
<strong>Answer:</strong>
<li><strong>Multi-AZ</strong>: High availability, synchronous replication, automatic failover, same region, cannot read from standby</li>
<li><strong>Read Replicas</strong>: Scale reads, asynchronous replication, can be cross-region, can read from replica, manual promotion</li>
<strong>Q2: When to use DynamoDB vs RDS?</strong>
<strong>Answer:</strong>
<li><strong>DynamoDB</strong>: Key-value access, unlimited scale, simple queries, serverless, variable traffic</li>
<li><strong>RDS</strong>: Complex queries (JOINs), ACID transactions, existing SQL apps, structured data with relationships</li>
<strong>Q3: Explain DynamoDB partition key design.</strong>
<strong>Answer:</strong> Partition key determines data distribution. Bad: Sequential IDs (hot partition). Good: Random/hashed values (even distribution). Use composite key (partition + sort) for related items. Example: <code>user_id</code> (partition) + <code>timestamp</code> (sort) for user events.
<strong>Q4: What is Aurora Global Database?</strong>
<strong>Answer:</strong> Multi-region Aurora deployment. One primary region (writes), up to 5 secondary regions (reads). Sub-second replication lag. Disaster recovery: promote secondary in <1 minute. Use: Global applications, disaster recovery.
<strong>Q5: How does ElastiCache improve performance?</strong>
<strong>Answer:</strong> In-memory cache (microsecond latency) sits in front of database. Cache frequently accessed data. Reduces database load. Patterns: cache-aside (lazy load), write-through (update cache on write). Use: Session store, API responses, database query results.
<p>---</p>
<h2>Hands-On Exercise</h2>
<h3>Task: Multi-Tier Application with RDS + ElastiCache</h3>
<pre><code class="language-go">// Complete application with caching layer
package main
<p>import (
    &quot;context&quot;
    &quot;database/sql&quot;
    &quot;encoding/json&quot;
    &quot;fmt&quot;
    &quot;log&quot;
    &quot;net/http&quot;
    &quot;time&quot;</p>
<p>&quot;github.com/gin-gonic/gin&quot;
    &quot;github.com/go-redis/redis/v8&quot;
    _ &quot;github.com/lib/pq&quot;
)</p>
<p>var (
    db    *sql.DB
    cache *redis.Client
    ctx   = context.Background()
)</p>
<p>type User struct {
    ID    int    <code>json:&quot;id&quot;</code>
    Name  string <code>json:&quot;name&quot;</code>
    Email string <code>json:&quot;email&quot;</code>
}</p>
<p>func init() {
    // Connect to RDS
    var err error
    db, err = sql.Open(&quot;postgres&quot;, &quot;postgres://admin:password@mydb.rds.amazonaws.com:5432/myapp?sslmode=require&quot;)
    if err != nil {
        log.Fatal(err)
    }</p>
<p>// Connect to ElastiCache
    cache = redis.NewClient(&amp;redis.Options{
        Addr: &quot;my-redis.cache.amazonaws.com:6379&quot;,
    })
}</p>
<p>func getUser(c *gin.Context) {
    userID := c.Param(&quot;id&quot;)
    cacheKey := fmt.Sprintf(&quot;user:%s&quot;, userID)</p>
<p>// Try cache first
    cached, err := cache.Get(ctx, cacheKey).Result()
    if err == nil {
        var user User
        json.Unmarshal([]byte(cached), &amp;user)
        c.JSON(http.StatusOK, gin.H{
            &quot;user&quot;:   user,
            &quot;source&quot;: &quot;cache&quot;,
        })
        return
    }</p>
<p>// Cache miss - query database
    var user User
    err = db.QueryRow(&quot;SELECT id, name, email FROM users WHERE id = $1&quot;, userID).
        Scan(&amp;user.ID, &amp;user.Name, &amp;user.Email)</p>
<p>if err != nil {
        c.JSON(http.StatusNotFound, gin.H{&quot;error&quot;: &quot;User not found&quot;})
        return
    }</p>
<p>// Store in cache (15 minutes)
    userData, _ := json.Marshal(user)
    cache.Set(ctx, cacheKey, userData, 15*time.Minute)</p>
<p>c.JSON(http.StatusOK, gin.H{
        &quot;user&quot;:   user,
        &quot;source&quot;: &quot;database&quot;,
    })
}</p>
<p>func createUser(c *gin.Context) {
    var user User
    if err := c.ShouldBindJSON(&amp;user); err != nil {
        c.JSON(http.StatusBadRequest, gin.H{&quot;error&quot;: err.Error()})
        return
    }</p>
<p>// Insert into database
    err := db.QueryRow(&quot;INSERT INTO users (name, email) VALUES ($1, $2) RETURNING id&quot;,
        user.Name, user.Email).Scan(&amp;user.ID)</p>
<p>if err != nil {
        c.JSON(http.StatusInternalServerError, gin.H{&quot;error&quot;: err.Error()})
        return
    }</p>
<p>// Invalidate cache
    cache.Del(ctx, fmt.Sprintf(&quot;user:%d&quot;, user.ID))</p>
<p>c.JSON(http.StatusCreated, user)
}</p>
<p>func main() {
    r := gin.Default()</p>
<p>r.GET(&quot;/users/:id&quot;, getUser)
    r.POST(&quot;/users&quot;, createUser)</p>
<p>r.Run(&quot;:8080&quot;)
}</code></pre></p>
<p>---</p>
<h2>üìö Additional Resources</h2>
<li>[RDS User Guide](https://docs.aws.amazon.com/rds/)</li>
<li>[DynamoDB Developer Guide](https://docs.aws.amazon.com/dynamodb/)</li>
<li>[Aurora User Guide](https://docs.aws.amazon.com/aurora/)</li>
<li>[ElastiCache User Guide](https://docs.aws.amazon.com/elasticache/)</li>
<p>---</p>
<h2>‚úÖ Module Checklist</h2>
<li>[ ] Create RDS PostgreSQL instance with Multi-AZ</li>
<li>[ ] Set up read replicas</li>
<li>[ ] Create DynamoDB table with GSI</li>
<li>[ ] Implement CRUD operations with DynamoDB</li>
<li>[ ] Deploy Aurora Serverless cluster</li>
<li>[ ] Set up ElastiCache Redis cluster</li>
<li>[ ] Build caching layer with Redis</li>
<li>[ ] Complete multi-tier app with RDS + ElastiCache</li></ul>
<p>---</p>
<strong>Next Module:</strong> [Module 25: AWS DevOps & CI/CD](./25_AWS_DevOps_CICD.md) - CodePipeline, CloudWatch, X-Ray! üöÄ

    </div>
    

    <div class="module-content" id="module-25">
        <h1>Module 25: AWS DevOps & CI/CD üöÄ</h1>
<h2>Automate Deployment with CodePipeline, CloudWatch, X-Ray</h2>
<strong>Duration:</strong> 6-7 hours  
<strong>Prerequisites:</strong> Module 22 (Compute), Module 21 (IAM), Git basics  
<strong>Outcome:</strong> Build complete CI/CD pipelines and monitoring for production
<p>---</p>
<h2>üìö Table of Contents</h2>
<p>1. [DevOps on AWS Overview](#devops-on-aws-overview)
2. [CodePipeline (CI/CD Orchestration)](#codepipeline)
3. [CodeBuild (Build Service)](#codebuild)
4. [CodeDeploy (Deployment)](#codedeploy)
5. [CloudWatch (Monitoring & Logging)](#cloudwatch)
6. [X-Ray (Distributed Tracing)](#x-ray)
7. [Complete CI/CD Pipeline](#complete-cicd-pipeline)
8. [Best Practices](#best-practices)
9. [Interview Questions](#interview-questions)
10. [Hands-On Exercise](#hands-on-exercise)</p>
<p>---</p>
<h2>DevOps on AWS Overview</h2>
<h3>AWS DevOps Services</h3>
<pre><code class="language-text">Source ‚Üí Build ‚Üí Test ‚Üí Deploy ‚Üí Monitor
<p>CodeCommit:   Git repository (like GitHub)
CodeBuild:    Compile, test, package
CodeDeploy:   Deploy to EC2, ECS, Lambda
CodePipeline: Orchestrate entire workflow</p>
<p>CloudWatch:   Logs, metrics, alarms
X-Ray:        Distributed tracing
CloudTrail:   API audit logs</code></pre></p>
<p>---</p>
<h2>CodePipeline (CI/CD Orchestration)</h2>
<h3>Pipeline Structure</h3>
<pre><code class="language-text">Pipeline:
‚îú‚îÄ‚îÄ Source Stage (GitHub, CodeCommit, S3)
‚îú‚îÄ‚îÄ Build Stage (CodeBuild)
‚îú‚îÄ‚îÄ Test Stage (CodeBuild, 3rd party)
‚îî‚îÄ‚îÄ Deploy Stage (CodeDeploy, ECS, CloudFormation)
<p>Triggers:
<ul><li>Push to repository</li>
<li>Scheduled (cron)</li>
<li>Manual approval</code></pre></li></p>
<h3>Create Simple Pipeline</h3>
<pre><code class="language-bash"># Create pipeline (JSON config)
aws codepipeline create-pipeline --cli-input-json file://pipeline.json</code></pre>
<pre><code class="language-json">{
  &quot;pipeline&quot;: {
    &quot;name&quot;: &quot;MyPipeline&quot;,
    &quot;roleArn&quot;: &quot;arn:aws:iam::123456789012:role/CodePipelineServiceRole&quot;,
    &quot;artifactStore&quot;: {
      &quot;type&quot;: &quot;S3&quot;,
      &quot;location&quot;: &quot;my-pipeline-artifacts&quot;
    },
    &quot;stages&quot;: [
      {
        &quot;name&quot;: &quot;Source&quot;,
        &quot;actions&quot;: [
          {
            &quot;name&quot;: &quot;SourceAction&quot;,
            &quot;actionTypeId&quot;: {
              &quot;category&quot;: &quot;Source&quot;,
              &quot;owner&quot;: &quot;ThirdParty&quot;,
              &quot;provider&quot;: &quot;GitHub&quot;,
              &quot;version&quot;: &quot;1&quot;
            },
            &quot;configuration&quot;: {
              &quot;Owner&quot;: &quot;myusername&quot;,
              &quot;Repo&quot;: &quot;my-app&quot;,
              &quot;Branch&quot;: &quot;main&quot;,
              &quot;OAuthToken&quot;: &quot;<strong></strong>&quot;
            },
            &quot;outputArtifacts&quot;: [{&quot;name&quot;: &quot;SourceOutput&quot;}]
          }
        ]
      },
      {
        &quot;name&quot;: &quot;Build&quot;,
        &quot;actions&quot;: [
          {
            &quot;name&quot;: &quot;BuildAction&quot;,
            &quot;actionTypeId&quot;: {
              &quot;category&quot;: &quot;Build&quot;,
              &quot;owner&quot;: &quot;AWS&quot;,
              &quot;provider&quot;: &quot;CodeBuild&quot;,
              &quot;version&quot;: &quot;1&quot;
            },
            &quot;configuration&quot;: {
              &quot;ProjectName&quot;: &quot;MyBuildProject&quot;
            },
            &quot;inputArtifacts&quot;: [{&quot;name&quot;: &quot;SourceOutput&quot;}],
            &quot;outputArtifacts&quot;: [{&quot;name&quot;: &quot;BuildOutput&quot;}]
          }
        ]
      },
      {
        &quot;name&quot;: &quot;Deploy&quot;,
        &quot;actions&quot;: [
          {
            &quot;name&quot;: &quot;DeployAction&quot;,
            &quot;actionTypeId&quot;: {
              &quot;category&quot;: &quot;Deploy&quot;,
              &quot;owner&quot;: &quot;AWS&quot;,
              &quot;provider&quot;: &quot;CodeDeploy&quot;,
              &quot;version&quot;: &quot;1&quot;
            },
            &quot;configuration&quot;: {
              &quot;ApplicationName&quot;: &quot;MyApp&quot;,
              &quot;DeploymentGroupName&quot;: &quot;Production&quot;
            },
            &quot;inputArtifacts&quot;: [{&quot;name&quot;: &quot;BuildOutput&quot;}]
          }
        ]
      }
    ]
  }
}</code></pre>
<h3>Terraform - CodePipeline</h3>
<pre><code class="language-hcl">resource &quot;aws_codepipeline&quot; &quot;pipeline&quot; {
  name     = &quot;my-pipeline&quot;
  role_arn = aws_iam_role.codepipeline.arn
<p>artifact_store {
    location = aws_s3_bucket.artifacts.bucket
    type     = &quot;S3&quot;
  }</p>
<p>stage {
    name = &quot;Source&quot;</p>
<p>action {
      name             = &quot;Source&quot;
      category         = &quot;Source&quot;
      owner            = &quot;ThirdParty&quot;
      provider         = &quot;GitHub&quot;
      version          = &quot;1&quot;
      output_artifacts = [&quot;source_output&quot;]</p>
<p>configuration = {
        Owner      = &quot;myusername&quot;
        Repo       = &quot;my-app&quot;
        Branch     = &quot;main&quot;
        OAuthToken = var.github_token
      }
    }
  }</p>
<p>stage {
    name = &quot;Build&quot;</p>
<p>action {
      name             = &quot;Build&quot;
      category         = &quot;Build&quot;
      owner            = &quot;AWS&quot;
      provider         = &quot;CodeBuild&quot;
      version          = &quot;1&quot;
      input_artifacts  = [&quot;source_output&quot;]
      output_artifacts = [&quot;build_output&quot;]</p>
<p>configuration = {
        ProjectName = aws_codebuild_project.build.name
      }
    }
  }</p>
<p>stage {
    name = &quot;Deploy&quot;</p>
<p>action {
      name            = &quot;Deploy&quot;
      category        = &quot;Deploy&quot;
      owner           = &quot;AWS&quot;
      provider        = &quot;CodeDeploy&quot;
      version         = &quot;1&quot;
      input_artifacts = [&quot;build_output&quot;]</p>
<p>configuration = {
        ApplicationName     = aws_codedeploy_app.app.name
        DeploymentGroupName = aws_codedeploy_deployment_group.group.deployment_group_name
      }
    }
  }
}</code></pre></p>
<p>---</p>
<h2>CodeBuild (Build Service)</h2>
<h3>BuildSpec File</h3>
<pre><code class="language-yaml"># buildspec.yml (in repository root)
version: 0.2
<p>env:
  variables:
    GO_VERSION: &quot;1.21&quot;
  parameter-store:
    DB_PASSWORD: /myapp/db/password</p>
<p>phases:
  install:
    runtime-versions:
      golang: 1.21
    commands:
      - echo &quot;Installing dependencies...&quot;
      - go version</p>
<p>pre_build:
    commands:
      - echo &quot;Running tests...&quot;
      - go test -v ./...
      - go vet ./...</p>
<p>build:
    commands:
      - echo &quot;Building application...&quot;
      - GOOS=linux GOARCH=amd64 go build -o myapp main.go
      - echo &quot;Build completed on $(date)&quot;</p>
<p>post_build:
    commands:
      - echo &quot;Creating deployment package...&quot;
      - zip deployment.zip myapp appspec.yml scripts/*</p>
<p>artifacts:
  files:
    - deployment.zip
  name: BuildArtifact</p>
<p>cache:
  paths:
    - &#039;/go/pkg/mod/**/*&#039;</code></pre></p>
<h3>Create Build Project</h3>
<pre><code class="language-bash">aws codebuild create-project \
  --name MyBuildProject \
  --source type=GITHUB,location=https://github.com/user/repo \
  --artifacts type=S3,location=my-artifacts-bucket \
  --environment type=LINUX_CONTAINER,image=aws/codebuild/standard:5.0,computeType=BUILD_GENERAL1_SMALL \
  --service-role arn:aws:iam::123456789012:role/CodeBuildServiceRole</code></pre>
<h3>Terraform - CodeBuild</h3>
<pre><code class="language-hcl">resource &quot;aws_codebuild_project&quot; &quot;build&quot; {
  name          = &quot;my-build-project&quot;
  service_role  = aws_iam_role.codebuild.arn
  build_timeout = 60
<p>artifacts {
    type = &quot;CODEPIPELINE&quot;
  }</p>
<p>environment {
    compute_type                = &quot;BUILD_GENERAL1_SMALL&quot;
    image                       = &quot;aws/codebuild/standard:5.0&quot;
    type                        = &quot;LINUX_CONTAINER&quot;
    image_pull_credentials_type = &quot;CODEBUILD&quot;</p>
<p>environment_variable {
      name  = &quot;ENVIRONMENT&quot;
      value = &quot;production&quot;
    }</p>
<p>environment_variable {
      name  = &quot;DB_PASSWORD&quot;
      value = &quot;/myapp/db/password&quot;
      type  = &quot;PARAMETER_STORE&quot;
    }
  }</p>
<p>source {
    type      = &quot;CODEPIPELINE&quot;
    buildspec = file(&quot;buildspec.yml&quot;)
  }</p>
<p>logs_config {
    cloudwatch_logs {
      group_name  = &quot;/aws/codebuild/my-project&quot;
      stream_name = &quot;build&quot;
    }
  }</p>
<p>cache {
    type     = &quot;S3&quot;
    location = &quot;${aws_s3_bucket.cache.bucket}/build-cache&quot;
  }
}</code></pre></p>
<h3>Docker Build in CodeBuild</h3>
<pre><code class="language-yaml"># buildspec.yml for Docker
version: 0.2
<p>phases:
  pre_build:
    commands:
      - echo Logging in to Amazon ECR...
      - aws ecr get-login-password --region $AWS_DEFAULT_REGION | docker login --username AWS --password-stdin $ECR_REPO
  
  build:
    commands:
      - echo Building Docker image...
      - docker build -t $IMAGE_REPO_NAME:$IMAGE_TAG .
      - docker tag $IMAGE_REPO_NAME:$IMAGE_TAG $ECR_REPO/$IMAGE_REPO_NAME:$IMAGE_TAG
  
  post_build:
    commands:
      - echo Pushing to ECR...
      - docker push $ECR_REPO/$IMAGE_REPO_NAME:$IMAGE_TAG
      - echo Writing image definitions file...
      - printf &#039;[{&quot;name&quot;:&quot;app&quot;,&quot;imageUri&quot;:&quot;%s&quot;}]&#039; $ECR_REPO/$IMAGE_REPO_NAME:$IMAGE_TAG &gt; imagedefinitions.json</p>
<p>artifacts:
  files: imagedefinitions.json</code></pre></p>
<p>---</p>
<h2>CodeDeploy (Deployment)</h2>
<h3>Deployment Types</h3>
<pre><code class="language-text">In-Place Deployment (EC2/On-Premises):
<li>Stop app on existing instances</li>
<li>Deploy new version</li>
<li>Start app</li>
<li>Downtime during deployment</li>
<p>Blue/Green Deployment (EC2, ECS, Lambda):
<li>New instances (green) created</li>
<li>Traffic shifted from old (blue) to new</li>
<li>Old instances terminated after success</li>
<li>Zero downtime</code></pre></li></p>
<h3>AppSpec File (EC2)</h3>
<pre><code class="language-yaml"># appspec.yml
version: 0.0
os: linux
<p>files:
  - source: /
    destination: /opt/myapp</p>
<p>hooks:
  BeforeInstall:
    - location: scripts/install_dependencies.sh
      timeout: 300
      runas: root
  
  AfterInstall:
    - location: scripts/configure_app.sh
      timeout: 300
      runas: root
  
  ApplicationStart:
    - location: scripts/start_app.sh
      timeout: 300
      runas: root
  
  ValidateService:
    - location: scripts/validate.sh
      timeout: 300
      runas: root</code></pre></p>
<pre><code class="language-bash">#!/bin/bash
<h1>scripts/start_app.sh</h1>
cd /opt/myapp
nohup ./myapp &gt; /var/log/myapp.log 2&gt;&amp;1 &amp;</code></pre>
<h3>Terraform - CodeDeploy</h3>
<pre><code class="language-hcl">resource &quot;aws_codedeploy_app&quot; &quot;app&quot; {
  name = &quot;my-app&quot;
}
<p>resource &quot;aws_codedeploy_deployment_group&quot; &quot;group&quot; {
  app_name              = aws_codedeploy_app.app.name
  deployment_group_name = &quot;production&quot;
  service_role_arn      = aws_iam_role.codedeploy.arn</p>
<p>deployment_config_name = &quot;CodeDeployDefault.OneAtATime&quot;</p>
<p>ec2_tag_set {
    ec2_tag_filter {
      key   = &quot;Environment&quot;
      type  = &quot;KEY_AND_VALUE&quot;
      value = &quot;production&quot;
    }
  }</p>
<p>auto_rollback_configuration {
    enabled = true
    events  = [&quot;DEPLOYMENT_FAILURE&quot;]
  }</p>
<p>load_balancer_info {
    target_group_info {
      name = aws_lb_target_group.app.name
    }
  }</p>
<p>blue_green_deployment_config {
    terminate_blue_instances_on_deployment_success {
      action                           = &quot;TERMINATE&quot;
      termination_wait_time_in_minutes = 5
    }</p>
<p>deployment_ready_option {
      action_on_timeout = &quot;CONTINUE_DEPLOYMENT&quot;
    }</p>
<p>green_fleet_provisioning_option {
      action = &quot;COPY_AUTO_SCALING_GROUP&quot;
    }
  }
}</code></pre></p>
<p>---</p>
<h2>CloudWatch (Monitoring & Logging)</h2>
<h3>CloudWatch Logs</h3>
<pre><code class="language-go">// Send logs to CloudWatch
package main
<p>import (
    &quot;context&quot;
    &quot;log&quot;
    &quot;time&quot;</p>
<p>&quot;github.com/aws/aws-sdk-go-v2/config&quot;
    &quot;github.com/aws/aws-sdk-go-v2/service/cloudwatchlogs&quot;
    &quot;github.com/aws/aws-sdk-go-v2/aws&quot;
)</p>
<p>func main() {
    cfg, _ := config.LoadDefaultConfig(context.TODO())
    client := cloudwatchlogs.NewFromConfig(cfg)</p>
<p>logGroup := &quot;/aws/myapp&quot;
    logStream := &quot;app-server-1&quot;</p>
<p>// Create log stream
    client.CreateLogStream(context.TODO(), &amp;cloudwatchlogs.CreateLogStreamInput{
        LogGroupName:  aws.String(logGroup),
        LogStreamName: aws.String(logStream),
    })</p>
<p>// Send log events
    events := []types.InputLogEvent{
        {
            Message:   aws.String(&quot;Application started&quot;),
            Timestamp: aws.Int64(time.Now().UnixMilli()),
        },
        {
            Message:   aws.String(&quot;Processing request from user 123&quot;),
            Timestamp: aws.Int64(time.Now().UnixMilli()),
        },
    }</p>
<p>client.PutLogEvents(context.TODO(), &amp;cloudwatchlogs.PutLogEventsInput{
        LogGroupName:  aws.String(logGroup),
        LogStreamName: aws.String(logStream),
        LogEvents:     events,
    })</p>
<p>log.Println(&quot;Logs sent to CloudWatch&quot;)
}</code></pre></p>
<h3>CloudWatch Metrics</h3>
<pre><code class="language-go">// Publish custom metrics
import (
    &quot;github.com/aws/aws-sdk-go-v2/service/cloudwatch&quot;
    &quot;github.com/aws/aws-sdk-go-v2/service/cloudwatch/types&quot;
)
<p>func publishMetric(client *cloudwatch.Client, value float64) {
    client.PutMetricData(context.TODO(), &amp;cloudwatch.PutMetricDataInput{
        Namespace: aws.String(&quot;MyApp&quot;),
        MetricData: []types.MetricDatum{
            {
                MetricName: aws.String(&quot;RequestCount&quot;),
                Value:      aws.Float64(value),
                Unit:       types.StandardUnitCount,
                Timestamp:  aws.Time(time.Now()),
                Dimensions: []types.Dimension{
                    {
                        Name:  aws.String(&quot;Environment&quot;),
                        Value: aws.String(&quot;production&quot;),
                    },
                },
            },
        },
    })
}</code></pre></p>
<h3>CloudWatch Alarms</h3>
<pre><code class="language-hcl">resource &quot;aws_cloudwatch_metric_alarm&quot; &quot;high_cpu&quot; {
  alarm_name          = &quot;high-cpu-utilization&quot;
  comparison_operator = &quot;GreaterThanThreshold&quot;
  evaluation_periods  = 2
  metric_name         = &quot;CPUUtilization&quot;
  namespace           = &quot;AWS/EC2&quot;
  period              = 300
  statistic           = &quot;Average&quot;
  threshold           = 80
  alarm_description   = &quot;Alert when CPU exceeds 80%&quot;
  alarm_actions       = [aws_sns_topic.alerts.arn]
<p>dimensions = {
    InstanceId = aws_instance.web.id
  }
}</p>
<p>resource &quot;aws_cloudwatch_metric_alarm&quot; &quot;api_errors&quot; {
  alarm_name          = &quot;api-error-rate&quot;
  comparison_operator = &quot;GreaterThanThreshold&quot;
  evaluation_periods  = 1
  metric_name         = &quot;5XXError&quot;
  namespace           = &quot;AWS/ApiGateway&quot;
  period              = 60
  statistic           = &quot;Sum&quot;
  threshold           = 10
  alarm_description   = &quot;Alert on API errors&quot;
  alarm_actions       = [aws_sns_topic.alerts.arn]</p>
<p>dimensions = {
    ApiName = &quot;my-api&quot;
  }
}</code></pre></p>
<h3>CloudWatch Logs Insights</h3>
<pre><code class="language-sql">-- Query logs
fields @timestamp, @message
| filter @message like /ERROR/
| sort @timestamp desc
| limit 20
<p>-- Count errors by type
fields @timestamp, @message
| parse @message /ERROR: (?&lt;error_type&gt;.*)/
| stats count() by error_type</p>
<p>-- API latency percentiles
fields @timestamp, duration
| filter ispresent(duration)
| stats avg(duration), pct(duration, 50), pct(duration, 95), pct(duration, 99)</code></pre></p>
<p>---</p>
<h2>X-Ray (Distributed Tracing)</h2>
<h3>X-Ray Concepts</h3>
<pre><code class="language-text">Trace:    End-to-end request journey
Segment:  Work done by single service
Subsegment: Details within segment (DB call, HTTP request)
<p>Trace Map:
API Gateway ‚Üí Lambda ‚Üí DynamoDB
    |
    ‚îî‚Üí S3</code></pre></p>
<h3>Instrument Go App</h3>
<pre><code class="language-go">package main
<p>import (
    &quot;context&quot;
    &quot;database/sql&quot;
    &quot;net/http&quot;</p>
<p>&quot;github.com/aws/aws-xray-sdk-go/xray&quot;
    _ &quot;github.com/lib/pq&quot;
)</p>
<p>func main() {
    // Wrap HTTP handler
    http.Handle(&quot;/&quot;, xray.Handler(xray.NewFixedSegmentNamer(&quot;myapp&quot;), http.HandlerFunc(handler)))
    http.ListenAndServe(&quot;:8080&quot;, nil)
}</p>
<p>func handler(w http.ResponseWriter, r *http.Request) {
    ctx := r.Context()</p>
<p>// Add annotations (indexed)
    xray.AddAnnotation(ctx, &quot;user_id&quot;, &quot;123&quot;)
    xray.AddAnnotation(ctx, &quot;environment&quot;, &quot;production&quot;)</p>
<p>// Add metadata (not indexed, for details)
    xray.AddMetadata(ctx, &quot;request&quot;, map[string]interface{}{
        &quot;method&quot;: r.Method,
        &quot;path&quot;:   r.URL.Path,
    })</p>
<p>// Trace database call
    err := queryDatabase(ctx)
    if err != nil {
        xray.AddError(ctx, err)
    }</p>
<p>// Trace HTTP call
    makeHTTPRequest(ctx)</p>
<p>w.Write([]byte(&quot;Hello World&quot;))
}</p>
<p>func queryDatabase(ctx context.Context) error {
    // Wrap database connection
    db, _ := xray.SQL(&quot;postgres&quot;, &quot;postgres://user:pass@db:5432/mydb&quot;)
    defer db.Close()</p>
<p>// This query will be traced
    _, err := db.QueryContext(ctx, &quot;SELECT * FROM users WHERE id = $1&quot;, 123)
    return err
}</p>
<p>func makeHTTPRequest(ctx context.Context) {
    // Wrap HTTP client
    client := xray.Client(&amp;http.Client{})
    
    req, _ := http.NewRequestWithContext(ctx, &quot;GET&quot;, &quot;https://api.example.com/data&quot;, nil)
    resp, _ := client.Do(req)
    defer resp.Body.Close()
}</code></pre></p>
<h3>X-Ray Daemon</h3>
<pre><code class="language-yaml"># docker-compose.yml
version: &#039;3&#039;
<p>services:
  xray-daemon:
    image: amazon/aws-xray-daemon
    ports:
      - &quot;2000:2000/udp&quot;
    environment:
      - AWS_REGION=us-east-1</p>
<p>app:
    build: .
    ports:
      - &quot;8080:8080&quot;
    environment:
      - AWS_XRAY_DAEMON_ADDRESS=xray-daemon:2000
    depends_on:
      - xray-daemon</code></pre></p>
<h3>Terraform - X-Ray</h3>
<pre><code class="language-hcl"># Enable X-Ray on Lambda
resource &quot;aws_lambda_function&quot; &quot;api&quot; {
  filename      = &quot;function.zip&quot;
  function_name = &quot;my-function&quot;
  role          = aws_iam_role.lambda.arn
  handler       = &quot;main&quot;
  runtime       = &quot;go1.x&quot;
<p>tracing_config {
    mode = &quot;Active&quot;  # Enable X-Ray
  }</p>
<p>environment {
    variables = {
      AWS_XRAY_TRACING_NAME = &quot;my-api&quot;
    }
  }
}</p>
<h1>IAM permission for X-Ray</h1>
resource &quot;aws_iam_role_policy_attachment&quot; &quot;xray&quot; {
  role       = aws_iam_role.lambda.name
  policy_arn = &quot;arn:aws:iam::aws:policy/AWSXRayDaemonWriteAccess&quot;
}</code></pre>
<p>---</p>
<h2>Complete CI/CD Pipeline</h2>
<h3>Full Example with All Services</h3>
<pre><code class="language-hcl"># main.tf - Complete CI/CD pipeline
<h1>S3 bucket for artifacts</h1>
resource &quot;aws_s3_bucket&quot; &quot;artifacts&quot; {
  bucket = &quot;my-pipeline-artifacts&quot;
}
<h1>CodeBuild project</h1>
resource &quot;aws_codebuild_project&quot; &quot;build&quot; {
  name          = &quot;my-app-build&quot;
  service_role  = aws_iam_role.codebuild.arn
<p>artifacts {
    type = &quot;CODEPIPELINE&quot;
  }</p>
<p>environment {
    compute_type = &quot;BUILD_GENERAL1_SMALL&quot;
    image        = &quot;aws/codebuild/standard:5.0&quot;
    type         = &quot;LINUX_CONTAINER&quot;
  }</p>
<p>source {
    type = &quot;CODEPIPELINE&quot;
  }
}</p>
<h1>CodeDeploy application</h1>
resource &quot;aws_codedeploy_app&quot; &quot;app&quot; {
  name = &quot;my-app&quot;
}
<p>resource &quot;aws_codedeploy_deployment_group&quot; &quot;prod&quot; {
  app_name              = aws_codedeploy_app.app.name
  deployment_group_name = &quot;production&quot;
  service_role_arn      = aws_iam_role.codedeploy.arn</p>
<p>ec2_tag_set {
    ec2_tag_filter {
      key   = &quot;Environment&quot;
      value = &quot;production&quot;
      type  = &quot;KEY_AND_VALUE&quot;
    }
  }</p>
<p>auto_rollback_configuration {
    enabled = true
    events  = [&quot;DEPLOYMENT_FAILURE&quot;, &quot;DEPLOYMENT_STOP_ON_ALARM&quot;]
  }</p>
<p>alarm_configuration {
    enabled = true
    alarms  = [aws_cloudwatch_metric_alarm.deployment_error.alarm_name]
  }
}</p>
<h1>CodePipeline</h1>
resource &quot;aws_codepipeline&quot; &quot;pipeline&quot; {
  name     = &quot;my-app-pipeline&quot;
  role_arn = aws_iam_role.codepipeline.arn
<p>artifact_store {
    location = aws_s3_bucket.artifacts.bucket
    type     = &quot;S3&quot;
  }</p>
<p>stage {
    name = &quot;Source&quot;
    action {
      name             = &quot;Source&quot;
      category         = &quot;Source&quot;
      owner            = &quot;ThirdParty&quot;
      provider         = &quot;GitHub&quot;
      version          = &quot;1&quot;
      output_artifacts = [&quot;source&quot;]</p>
<p>configuration = {
        Owner  = var.github_owner
        Repo   = var.github_repo
        Branch = &quot;main&quot;
        OAuthToken = var.github_token
      }
    }
  }</p>
<p>stage {
    name = &quot;Build&quot;
    action {
      name             = &quot;Build&quot;
      category         = &quot;Build&quot;
      owner            = &quot;AWS&quot;
      provider         = &quot;CodeBuild&quot;
      version          = &quot;1&quot;
      input_artifacts  = [&quot;source&quot;]
      output_artifacts = [&quot;build&quot;]</p>
<p>configuration = {
        ProjectName = aws_codebuild_project.build.name
      }
    }
  }</p>
<p>stage {
    name = &quot;Deploy&quot;
    action {
      name            = &quot;Deploy&quot;
      category        = &quot;Deploy&quot;
      owner           = &quot;AWS&quot;
      provider        = &quot;CodeDeploy&quot;
      version         = &quot;1&quot;
      input_artifacts = [&quot;build&quot;]</p>
<p>configuration = {
        ApplicationName     = aws_codedeploy_app.app.name
        DeploymentGroupName = aws_codedeploy_deployment_group.prod.deployment_group_name
      }
    }
  }
}</p>
<h1>CloudWatch alarm for deployment</h1>
resource &quot;aws_cloudwatch_metric_alarm&quot; &quot;deployment_error&quot; {
  alarm_name          = &quot;deployment-errors&quot;
  comparison_operator = &quot;GreaterThanThreshold&quot;
  evaluation_periods  = 1
  metric_name         = &quot;5XXError&quot;
  namespace           = &quot;AWS/ApplicationELB&quot;
  period              = 60
  statistic           = &quot;Sum&quot;
  threshold           = 5
}
<h1>SNS topic for notifications</h1>
resource &quot;aws_sns_topic&quot; &quot;pipeline_notifications&quot; {
  name = &quot;pipeline-notifications&quot;
}
<p>resource &quot;aws_sns_topic_subscription&quot; &quot;email&quot; {
  topic_arn = aws_sns_topic.pipeline_notifications.arn
  protocol  = &quot;email&quot;
  endpoint  = &quot;team@example.com&quot;
}</code></pre></p>
<p>---</p>
<h2>Best Practices</h2>
<h3>CI/CD Best Practices</h3>
<pre><code class="language-text">1. Pipeline Design
   ‚úÖ Automate everything
   ‚úÖ Fail fast (run tests early)
   ‚úÖ Parallel stages when possible
   ‚úÖ Manual approval for production
<p>2. Security
   ‚úÖ Use IAM roles, not access keys
   ‚úÖ Secrets in Parameter Store/Secrets Manager
   ‚úÖ Scan for vulnerabilities
   ‚úÖ Sign artifacts</p>
<p>3. Deployment
   ‚úÖ Blue/green for zero downtime
   ‚úÖ Canary deployments (gradual rollout)
   ‚úÖ Automatic rollback on failure
   ‚úÖ Deployment windows for maintenance</p>
<p>4. Monitoring
   ‚úÖ CloudWatch alarms on key metrics
   ‚úÖ Log aggregation
   ‚úÖ X-Ray for distributed tracing
   ‚úÖ Alerts to SNS/Slack</code></pre></p>
<h3>CloudWatch Best Practices</h3>
<pre><code class="language-text">1. Logging
   ‚úÖ Structured logs (JSON)
   ‚úÖ Consistent log format
   ‚úÖ Include request IDs
   ‚úÖ Set retention periods
<p>2. Metrics
   ‚úÖ Custom metrics for business KPIs
   ‚úÖ High-resolution metrics (1-second) for critical
   ‚úÖ Use dimensions for filtering
   ‚úÖ Dashboard for visibility</p>
<p>3. Alarms
   ‚úÖ Alert on trends, not spikes
   ‚úÖ Multiple evaluation periods
   ‚úÖ Actionable alerts only
   ‚úÖ Different severity levels</code></pre></p>
<p>---</p>
<h2>Interview Questions</h2>
<strong>Q1: Blue/Green vs Canary deployment?</strong>
<strong>Answer:</strong>
<li><strong>Blue/Green</strong>: Two identical environments. Deploy to green, test, switch traffic 100% at once. Quick rollback.</li>
<li><strong>Canary</strong>: Gradual rollout. Route 10% traffic to new version, monitor, gradually increase to 100%. Safer for critical systems.</li>
<strong>Q2: How do you ensure zero-downtime deployments?</strong>
<strong>Answer:</strong>
1. Use blue/green or rolling deployments
2. Health checks before routing traffic
3. Graceful shutdown (finish in-flight requests)
4. Database migrations backward-compatible
5. Feature flags for gradual rollout
<strong>Q3: Explain X-Ray service map.</strong>
<strong>Answer:</strong> Visual representation of request flow through distributed system. Shows services as nodes, calls as edges. Displays latency, error rates, throttling. Helps identify bottlenecks and failures. Example: API Gateway ‚Üí Lambda ‚Üí DynamoDB, with latency at each hop.
<strong>Q4: CloudWatch Logs vs Metrics?</strong>
<strong>Answer:</strong>
<li><strong>Logs</strong>: Text data, events, debugging. Query with Logs Insights. Example: application logs, error stack traces</li>
<li><strong>Metrics</strong>: Numeric data over time. Graph, alert. Example: CPU%, request count, latency</li>
<li>Use both: Logs for debugging, metrics for monitoring/alerting</li>
<strong>Q5: How do you handle secrets in CI/CD?</strong>
<strong>Answer:</strong>
<li><strong>AWS Secrets Manager</strong>: Auto-rotation, fine-grained IAM, versioning</li>
<li><strong>Parameter Store</strong>: Free tier, simpler, no auto-rotation</li>
<li><strong>Never</strong>: Hardcode, commit to Git, use environment variables in pipeline definition</li>
<li>Inject at runtime via IAM roles</li>
<p>---</p>
<h2>Hands-On Exercise</h2>
<h3>Task: Complete CI/CD Pipeline for Go API</h3>
<strong>Project Structure:</strong>
<pre><code class="language-text">my-app/
‚îú‚îÄ‚îÄ main.go
‚îú‚îÄ‚îÄ buildspec.yml
‚îú‚îÄ‚îÄ appspec.yml
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ install_dependencies.sh
‚îÇ   ‚îú‚îÄ‚îÄ start_app.sh
‚îÇ   ‚îî‚îÄ‚îÄ validate.sh
‚îî‚îÄ‚îÄ terraform/
    ‚îî‚îÄ‚îÄ pipeline.tf</code></pre>
<p>See complete Terraform configuration in "Complete CI/CD Pipeline" section above.</p>
<p>---</p>
<h2>üìö Additional Resources</h2>
<li>[AWS CodePipeline User Guide](https://docs.aws.amazon.com/codepipeline/)</li>
<li>[AWS CodeBuild User Guide](https://docs.aws.amazon.com/codebuild/)</li>
<li>[AWS X-Ray Developer Guide](https://docs.aws.amazon.com/xray/)</li>
<li>[CloudWatch User Guide](https://docs.aws.amazon.com/cloudwatch/)</li>
<p>---</p>
<h2>‚úÖ Module Checklist</h2>
<li>[ ] Create CodePipeline with GitHub source</li>
<li>[ ] Set up CodeBuild project with buildspec.yml</li>
<li>[ ] Configure CodeDeploy for EC2</li>
<li>[ ] Implement blue/green deployment</li>
<li>[ ] Set up CloudWatch Logs and Metrics</li>
<li>[ ] Create CloudWatch alarms</li>
<li>[ ] Instrument application with X-Ray</li>
<li>[ ] Build complete CI/CD pipeline with Terraform</li>
<li>[ ] Test automatic rollback on failure</li></ul>
<p>---</p>
<strong>üéâ Congratulations!</strong> You've completed Part 5: AWS!
<strong>Next Section:</strong> [Module 26: Prometheus & Grafana](./26_Prometheus_Grafana.md) - Observability! üìä

    </div>
    

    <div class="module-content" id="module-26">
        <h1>Module 26: Prometheus Monitoring</h1>
<h2>Table of Contents</h2>
<ul><li>[Introduction to Prometheus](#introduction)</li>
<li>[Prometheus Architecture](#architecture)</li>
<li>[Metrics and Data Model](#metrics)</li>
<li>[PromQL Query Language](#promql)</li>
<li>[Exporters and Instrumentation](#exporters)</li>
<li>[Service Discovery](#service-discovery)</li>
<li>[Alerting Rules](#alerting)</li>
<li>[Go Application Instrumentation](#go-instrumentation)</li>
<li>[Kubernetes Monitoring](#kubernetes)</li>
<li>[Best Practices](#best-practices)</li>
<li>[Interview Questions](#interview-questions)</li>
<li>[Hands-On Exercise](#exercise)</li>
<p>---</p>
<h2>Introduction to Prometheus {#introduction}</h2>
<p>Prometheus is an open-source monitoring and alerting toolkit designed for reliability and scalability.</p>
<h3>Key Features</h3>
<p>1. <strong>Multi-dimensional data model</strong> with time series data
2. <strong>PromQL</strong> - powerful query language
3. <strong>Pull-based</strong> metric collection
4. <strong>Service discovery</strong> for dynamic environments
5. <strong>Built-in alerting</strong> with Alertmanager integration</p>
<h3>Architecture Components</h3>
<pre><code class="language-text">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Targets   ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ  Prometheus  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ Alertmanager‚îÇ
‚îÇ (Exporters) ‚îÇ      ‚îÇ    Server    ‚îÇ      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                            ‚ñº
                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                     ‚îÇ   Grafana   ‚îÇ
                     ‚îÇ (Visualization)
                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</code></pre>
<h3>When to Use Prometheus</h3>
<p>‚úÖ <strong>Good For:</strong>
<li>Microservices monitoring</li>
<li>Kubernetes/container environments</li>
<li>Time-series metrics (CPU, memory, request rates)</li>
<li>Dynamic service discovery</li>
<li>Alerting on metric thresholds</li></p>
<p>‚ùå <strong>Not Ideal For:</strong>
<li>Long-term data storage (>2 weeks)</li>
<li>Event logging (use EFK/ELK instead)</li>
<li>Distributed tracing (use Jaeger/Zipkin)</li>
<li>High-cardinality data</li></p>
<p>---</p>
<h2>Prometheus Architecture {#architecture}</h2>
<h3>Core Components</h3>
<pre><code class="language-yaml"># Prometheus ecosystem
prometheus-server:
  - Scrapes and stores metrics
  - Evaluates alerting rules
  - Provides PromQL query interface
  
exporters:
  - node_exporter: System metrics (CPU, disk, network)
  - blackbox_exporter: Probe endpoints (HTTP, TCP, ICMP)
  - custom_exporters: Application-specific metrics
  
pushgateway:
  - For short-lived jobs that can&#039;t be scraped
  
alertmanager:
  - Handles alerts from Prometheus
  - Deduplication, grouping, routing
  - Sends notifications (email, Slack, PagerDuty)</code></pre>
<h3>Scraping Model</h3>
<p>Prometheus pulls metrics from targets (HTTP endpoints):</p>
<pre><code class="language-text">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Application ‚îÇ :9090/metrics
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ≤‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ HTTP GET (scrape)
       ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Prometheus  ‚îÇ
‚îÇ   Server    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</code></pre>
<h3>Installation (Docker)</h3>
<pre><code class="language-bash"># docker-compose.yml
version: &#039;3&#039;
services:
  prometheus:
    image: prom/prometheus:latest
    ports:
      - &quot;9090:9090&quot;
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    command:
      - &#039;--config.file=/etc/prometheus/prometheus.yml&#039;
      - &#039;--storage.tsdb.path=/prometheus&#039;
      - &#039;--storage.tsdb.retention.time=15d&#039;
    
  node-exporter:
    image: prom/node-exporter:latest
    ports:
      - &quot;9100:9100&quot;
    
  alertmanager:
    image: prom/alertmanager:latest
    ports:
      - &quot;9093:9093&quot;
    volumes:
      - ./alertmanager.yml:/etc/alertmanager/alertmanager.yml
<p>volumes:
  prometheus-data:</code></pre></p>
<h3>Basic Configuration</h3>
<pre><code class="language-yaml"># prometheus.yml
global:
  scrape_interval: 15s      # How often to scrape targets
  evaluation_interval: 15s  # How often to evaluate rules
<h1>Alertmanager configuration</h1>
alerting:
  alertmanagers:
    - static_configs:
        - targets: [&#039;alertmanager:9093&#039;]
<h1>Load rules once and periodically evaluate them</h1>
rule_files:
  - &quot;alerts/*.yml&quot;
<h1>Scrape configurations</h1>
scrape_configs:
  # Prometheus self-monitoring
  - job_name: &#039;prometheus&#039;
    static_configs:
      - targets: [&#039;localhost:9090&#039;]
  
  # Node exporter
  - job_name: &#039;node&#039;
    static_configs:
      - targets: [&#039;node-exporter:9100&#039;]
  
  # Go application
  - job_name: &#039;myapp&#039;
    static_configs:
      - targets: [&#039;myapp:8080&#039;]</code></pre>
<p>---</p>
<h2>Metrics and Data Model {#metrics}</h2>
<h3>Metric Types</h3>
<p>1. <strong>Counter</strong>: Monotonically increasing value (requests, errors)
2. <strong>Gauge</strong>: Can go up and down (temperature, memory usage)
3. <strong>Histogram</strong>: Samples observations (request durations, response sizes)
4. <strong>Summary</strong>: Similar to histogram with quantiles</p>
<h3>Time Series Structure</h3>
<pre><code class="language-text">metric_name{label1=&quot;value1&quot;, label2=&quot;value2&quot;} value timestamp</code></pre>
<p>Example:
<pre><code class="language-text">http_requests_total{method=&quot;GET&quot;, endpoint=&quot;/api/users&quot;, status=&quot;200&quot;} 1234 1638360000</code></pre></p>
<h3>Metric Naming Conventions</h3>
<pre><code class="language-text"># Format: &lt;namespace&gt;_&lt;subsystem&gt;_&lt;name&gt;_&lt;unit&gt;
<h1>Counters (always end with _total)</h1>
http_requests_total
api_errors_total
db_queries_total
<h1>Gauges</h1>
memory_usage_bytes
cpu_usage_percent
active_connections
<h1>Histograms (with _bucket, _sum, _count)</h1>
http_request_duration_seconds
response_size_bytes</code></pre>
<h3>Labels Best Practices</h3>
<pre><code class="language-yaml"># Good labels (low cardinality)
http_requests_total{
  method: &quot;GET&quot;,           # Limited values: GET, POST, PUT, DELETE
  endpoint: &quot;/api/users&quot;,  # Group by route pattern, not individual IDs
  status: &quot;200&quot;            # HTTP status codes
}
<h1>Bad labels (high cardinality - AVOID)</h1>
http_requests_total{
  user_id: &quot;12345&quot;,        # Millions of unique values
  request_id: &quot;abc-123&quot;,   # Every request is unique
  timestamp: &quot;1638360000&quot;  # Already tracked by Prometheus
}</code></pre>
<p>---</p>
<h2>PromQL Query Language {#promql}</h2>
<h3>Basic Queries</h3>
<pre><code class="language-promql"># Instant vector - current values
http_requests_total
<h1>Filter by labels</h1>
http_requests_total{method=&quot;GET&quot;}
<h1>Multiple label filters</h1>
http_requests_total{method=&quot;GET&quot;, status=&quot;200&quot;}
<h1>Regex matching</h1>
http_requests_total{endpoint=~&quot;/api/.*&quot;}
<h1>Negative matching</h1>
http_requests_total{status!=&quot;200&quot;}</code></pre>
<h3>Range Vectors</h3>
<pre><code class="language-promql"># Last 5 minutes of data
http_requests_total[5m]
<h1>Time ranges</h1>
http_requests_total[1h]
http_requests_total[1d]</code></pre>
<h3>Aggregation Operators</h3>
<pre><code class="language-promql"># Sum across all instances
sum(http_requests_total)
<h1>Average</h1>
avg(cpu_usage_percent)
<h1>Min/Max</h1>
min(memory_usage_bytes)
max(response_time_seconds)
<h1>Count</h1>
count(up == 0)  # Count down instances
<h1>Group by labels</h1>
sum(http_requests_total) by (method)
sum(http_requests_total) by (method, status)
<h1>Without specific labels</h1>
sum(http_requests_total) without (instance)</code></pre>
<h3>Rate and Increase</h3>
<pre><code class="language-promql"># Requests per second (for counters)
rate(http_requests_total[5m])
<h1>Total increase over time range</h1>
increase(http_requests_total[1h])
<h1>Per-second rate for gauges</h1>
irate(cpu_usage_percent[5m])  # Instant rate</code></pre>
<h3>Arithmetic Operations</h3>
<pre><code class="language-promql"># Calculate error rate percentage
(
  sum(rate(http_requests_total{status=~&quot;5..&quot;}[5m]))
  /
  sum(rate(http_requests_total[5m]))
) * 100
<h1>Memory usage percentage</h1>
(node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) 
/ node_memory_MemTotal_bytes * 100
<h1>Request duration 95th percentile</h1>
histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))</code></pre>
<h3>Useful Query Examples</h3>
<pre><code class="language-promql"># Top 5 endpoints by request count
topk(5, sum(rate(http_requests_total[5m])) by (endpoint))
<h1>Services down for more than 5 minutes</h1>
up == 0
<h1>High CPU usage</h1>
cpu_usage_percent &gt; 80
<h1>Predict disk full time (linear regression)</h1>
predict_linear(node_filesystem_free_bytes[1h], 4 * 3600) &lt; 0
<h1>Request rate increase</h1>
delta(http_requests_total[5m]) &gt; 1000</code></pre>
<p>---</p>
<h2>Exporters and Instrumentation {#exporters}</h2>
<h3>Node Exporter (System Metrics)</h3>
<pre><code class="language-bash"># Install node_exporter
docker run -d \
  --name=node-exporter \
  --net=&quot;host&quot; \
  --pid=&quot;host&quot; \
  -v &quot;/:/host:ro,rslave&quot; \
  prom/node-exporter \
  --path.rootfs=/host
<h1>Metrics exposed at :9100/metrics</h1>
curl localhost:9100/metrics</code></pre>
<strong>Key Metrics:</strong>
<li><code>node_cpu_seconds_total</code> - CPU usage</li>
<li><code>node_memory_MemAvailable_bytes</code> - Available memory</li>
<li><code>node_disk_io_time_seconds_total</code> - Disk I/O</li>
<li><code>node_network_receive_bytes_total</code> - Network traffic</li>
<li><code>node_filesystem_avail_bytes</code> - Disk space</li>
<h3>Blackbox Exporter (Endpoint Probing)</h3>
<pre><code class="language-yaml"># blackbox.yml
modules:
  http_2xx:
    prober: http
    timeout: 5s
    http:
      valid_http_versions: [&quot;HTTP/1.1&quot;, &quot;HTTP/2.0&quot;]
      valid_status_codes: [200]
      method: GET
  
  tcp_connect:
    prober: tcp
    timeout: 5s
  
  icmp:
    prober: icmp
    timeout: 5s</code></pre>
<pre><code class="language-yaml"># prometheus.yml - scrape config
scrape_configs:
  - job_name: &#039;blackbox&#039;
    metrics_path: /probe
    params:
      module: [http_2xx]
    static_configs:
      - targets:
          - https://example.com
          - https://api.example.com/health
    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: blackbox-exporter:9115</code></pre>
<p>---</p>
<h2>Go Application Instrumentation {#go-instrumentation}</h2>
<h3>Setup Prometheus Client</h3>
<pre><code class="language-go">// go.mod
module myapp
<p>require github.com/prometheus/client_golang v1.17.0</code></pre></p>
<h3>Basic HTTP Server with Metrics</h3>
<pre><code class="language-go">package main
<p>import (
    &quot;log&quot;
    &quot;net/http&quot;
    &quot;time&quot;
    
    &quot;github.com/prometheus/client_golang/prometheus&quot;
    &quot;github.com/prometheus/client_golang/prometheus/promhttp&quot;
)</p>
<p>var (
    // Counter: Total HTTP requests
    httpRequestsTotal = prometheus.NewCounterVec(
        prometheus.CounterOpts{
            Name: &quot;http_requests_total&quot;,
            Help: &quot;Total number of HTTP requests&quot;,
        },
        []string{&quot;method&quot;, &quot;endpoint&quot;, &quot;status&quot;},
    )
    
    // Histogram: Request duration
    httpRequestDuration = prometheus.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    &quot;http_request_duration_seconds&quot;,
            Help:    &quot;HTTP request duration in seconds&quot;,
            Buckets: prometheus.DefBuckets, // Default: 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1, 2.5, 5, 10
        },
        []string{&quot;method&quot;, &quot;endpoint&quot;},
    )
    
    // Gauge: Active connections
    activeConnections = prometheus.NewGauge(
        prometheus.GaugeOpts{
            Name: &quot;active_connections&quot;,
            Help: &quot;Number of active connections&quot;,
        },
    )
)</p>
<p>func init() {
    // Register metrics with Prometheus
    prometheus.MustRegister(httpRequestsTotal)
    prometheus.MustRegister(httpRequestDuration)
    prometheus.MustRegister(activeConnections)
}</p>
<p>func main() {
    // Metrics endpoint
    http.Handle(&quot;/metrics&quot;, promhttp.Handler())
    
    // Application endpoints with instrumentation
    http.HandleFunc(&quot;/api/users&quot;, instrumentHandler(usersHandler))
    http.HandleFunc(&quot;/api/products&quot;, instrumentHandler(productsHandler))
    
    log.Println(&quot;Server starting on :8080&quot;)
    log.Fatal(http.ListenAndServe(&quot;:8080&quot;, nil))
}</p>
<p>// Middleware to instrument HTTP handlers
func instrumentHandler(next http.HandlerFunc) http.HandlerFunc {
    return func(w http.ResponseWriter, r *http.Request) {
        start := time.Now()
        
        // Increment active connections
        activeConnections.Inc()
        defer activeConnections.Dec()
        
        // Wrap response writer to capture status code
        wrappedWriter := &amp;responseWriter{ResponseWriter: w, statusCode: http.StatusOK}
        
        // Call the actual handler
        next(wrappedWriter, r)
        
        // Record metrics
        duration := time.Since(start).Seconds()
        httpRequestDuration.WithLabelValues(r.Method, r.URL.Path).Observe(duration)
        httpRequestsTotal.WithLabelValues(r.Method, r.URL.Path, 
            http.StatusText(wrappedWriter.statusCode)).Inc()
    }
}</p>
<p>// Response writer wrapper to capture status code
type responseWriter struct {
    http.ResponseWriter
    statusCode int
}</p>
<p>func (rw *responseWriter) WriteHeader(code int) {
    rw.statusCode = code
    rw.ResponseWriter.WriteHeader(code)
}</p>
<p>func usersHandler(w http.ResponseWriter, r *http.Request) {
    // Simulate work
    time.Sleep(50 * time.Millisecond)
    w.Write([]byte(<code>{&quot;users&quot;: []}</code>))
}</p>
<p>func productsHandler(w http.ResponseWriter, r *http.Request) {
    time.Sleep(30 * time.Millisecond)
    w.Write([]byte(<code>{&quot;products&quot;: []}</code>))
}</code></pre></p>
<h3>Custom Business Metrics</h3>
<pre><code class="language-go">package metrics
<p>import &quot;github.com/prometheus/client_golang/prometheus&quot;</p>
<p>var (
    // Database connection pool
    dbConnectionsActive = prometheus.NewGauge(
        prometheus.GaugeOpts{
            Name: &quot;db_connections_active&quot;,
            Help: &quot;Number of active database connections&quot;,
        },
    )
    
    dbConnectionsIdle = prometheus.NewGauge(
        prometheus.GaugeOpts{
            Name: &quot;db_connections_idle&quot;,
            Help: &quot;Number of idle database connections&quot;,
        },
    )
    
    // Database queries
    dbQueriesTotal = prometheus.NewCounterVec(
        prometheus.CounterOpts{
            Name: &quot;db_queries_total&quot;,
            Help: &quot;Total number of database queries&quot;,
        },
        []string{&quot;operation&quot;, &quot;table&quot;},
    )
    
    dbQueryDuration = prometheus.NewHistogramVec(
        prometheus.HistogramOpts{
            Name: &quot;db_query_duration_seconds&quot;,
            Help: &quot;Database query duration&quot;,
            Buckets: []float64{0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1},
        },
        []string{&quot;operation&quot;, &quot;table&quot;},
    )
    
    // Cache
    cacheHitsTotal = prometheus.NewCounter(
        prometheus.CounterOpts{
            Name: &quot;cache_hits_total&quot;,
            Help: &quot;Total cache hits&quot;,
        },
    )
    
    cacheMissesTotal = prometheus.NewCounter(
        prometheus.CounterOpts{
            Name: &quot;cache_misses_total&quot;,
            Help: &quot;Total cache misses&quot;,
        },
    )
    
    // Business metrics
    ordersCreatedTotal = prometheus.NewCounterVec(
        prometheus.CounterOpts{
            Name: &quot;orders_created_total&quot;,
            Help: &quot;Total orders created&quot;,
        },
        []string{&quot;status&quot;},
    )
    
    orderValue = prometheus.NewHistogram(
        prometheus.HistogramOpts{
            Name: &quot;order_value_dollars&quot;,
            Help: &quot;Order value in dollars&quot;,
            Buckets: []float64{10, 50, 100, 250, 500, 1000, 2500, 5000},
        },
    )
)</p>
<p>func init() {
    prometheus.MustRegister(dbConnectionsActive, dbConnectionsIdle)
    prometheus.MustRegister(dbQueriesTotal, dbQueryDuration)
    prometheus.MustRegister(cacheHitsTotal, cacheMissesTotal)
    prometheus.MustRegister(ordersCreatedTotal, orderValue)
}</p>
<p>// Usage examples
func RecordDBQuery(operation, table string, duration float64) {
    dbQueriesTotal.WithLabelValues(operation, table).Inc()
    dbQueryDuration.WithLabelValues(operation, table).Observe(duration)
}</p>
<p>func RecordCacheHit() {
    cacheHitsTotal.Inc()
}</p>
<p>func RecordCacheMiss() {
    cacheMissesTotal.Inc()
}</p>
<p>func RecordOrder(status string, value float64) {
    ordersCreatedTotal.WithLabelValues(status).Inc()
    orderValue.Observe(value)
}</code></pre></p>
<h3>Database Instrumentation Example</h3>
<pre><code class="language-go">package database
<p>import (
    &quot;database/sql&quot;
    &quot;time&quot;
    
    &quot;myapp/metrics&quot;
)</p>
<p>type DB struct {
    *sql.DB
}</p>
<p>func (db *DB) QueryUsers() ([]User, error) {
    start := time.Now()
    defer func() {
        metrics.RecordDBQuery(&quot;select&quot;, &quot;users&quot;, time.Since(start).Seconds())
    }()
    
    rows, err := db.Query(&quot;SELECT id, name, email FROM users&quot;)
    if err != nil {
        return nil, err
    }
    defer rows.Close()
    
    var users []User
    for rows.Next() {
        var u User
        if err := rows.Scan(&amp;u.ID, &amp;u.Name, &amp;u.Email); err != nil {
            return nil, err
        }
        users = append(users, u)
    }
    
    return users, rows.Err()
}</p>
<p>func (db *DB) CreateUser(u User) error {
    start := time.Now()
    defer func() {
        metrics.RecordDBQuery(&quot;insert&quot;, &quot;users&quot;, time.Since(start).Seconds())
    }()
    
    _, err := db.Exec(&quot;INSERT INTO users (name, email) VALUES (?, ?)&quot;, u.Name, u.Email)
    return err
}</code></pre></p>
<p>---</p>
<h2>Service Discovery {#service-discovery}</h2>
<h3>Kubernetes Service Discovery</h3>
<pre><code class="language-yaml"># prometheus.yml for Kubernetes
scrape_configs:
  # Kubernetes pods
  - job_name: &#039;kubernetes-pods&#039;
    kubernetes_sd_configs:
      - role: pod
    relabel_configs:
      # Only scrape pods with annotation prometheus.io/scrape: &quot;true&quot;
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      
      # Use custom port if specified
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        target_label: __address__
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
      
      # Use custom path if specified
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      
      # Add namespace label
      - source_labels: [__meta_kubernetes_namespace]
        target_label: kubernetes_namespace
      
      # Add pod name label
      - source_labels: [__meta_kubernetes_pod_name]
        target_label: kubernetes_pod_name</code></pre>
<h3>Deployment with Prometheus Annotations</h3>
<pre><code class="language-yaml"># deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
      annotations:
        prometheus.io/scrape: &quot;true&quot;
        prometheus.io/port: &quot;8080&quot;
        prometheus.io/path: &quot;/metrics&quot;
    spec:
      containers:
      - name: myapp
        image: myapp:latest
        ports:
        - containerPort: 8080
          name: metrics</code></pre>
<h3>Consul Service Discovery</h3>
<pre><code class="language-yaml"># prometheus.yml
scrape_configs:
  - job_name: &#039;consul-services&#039;
    consul_sd_configs:
      - server: &#039;consul:8500&#039;
        services: []  # Empty list = all services
    relabel_configs:
      - source_labels: [__meta_consul_service]
        target_label: service
      - source_labels: [__meta_consul_tags]
        target_label: tags</code></pre>
<p>---</p>
<h2>Alerting Rules {#alerting}</h2>
<h3>Alert Rule Structure</h3>
<pre><code class="language-yaml"># alerts/api_alerts.yml
groups:
  - name: api_alerts
    interval: 30s
    rules:
      # High error rate
      - alert: HighErrorRate
        expr: |
          (
            sum(rate(http_requests_total{status=~&quot;5..&quot;}[5m]))
            /
            sum(rate(http_requests_total[5m]))
          ) * 100 &gt; 5
        for: 5m
        labels:
          severity: critical
          team: backend
        annotations:
          summary: &quot;High error rate on {{ $labels.instance }}&quot;
          description: &quot;Error rate is {{ $value }}% (threshold: 5%)&quot;
      
      # Slow response time
      - alert: SlowResponseTime
        expr: |
          histogram_quantile(0.95, 
            rate(http_request_duration_seconds_bucket[5m])
          ) &gt; 1
        for: 10m
        labels:
          severity: warning
          team: backend
        annotations:
          summary: &quot;Slow API responses on {{ $labels.instance }}&quot;
          description: &quot;95th percentile response time is {{ $value }}s&quot;
      
      # Service down
      - alert: ServiceDown
        expr: up == 0
        for: 2m
        labels:
          severity: critical
          team: sre
        annotations:
          summary: &quot;Service {{ $labels.job }} is down&quot;
          description: &quot;Instance {{ $labels.instance }} has been down for 2 minutes&quot;</code></pre>
<h3>Infrastructure Alerts</h3>
<pre><code class="language-yaml"># alerts/infrastructure.yml
groups:
  - name: infrastructure
    interval: 30s
    rules:
      # High CPU usage
      - alert: HighCPUUsage
        expr: |
          100 - (avg by (instance) (rate(node_cpu_seconds_total{mode=&quot;idle&quot;}[5m])) * 100) &gt; 80
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: &quot;High CPU usage on {{ $labels.instance }}&quot;
          description: &quot;CPU usage is {{ $value }}%&quot;
      
      # High memory usage
      - alert: HighMemoryUsage
        expr: |
          (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 &gt; 85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: &quot;High memory usage on {{ $labels.instance }}&quot;
          description: &quot;Memory usage is {{ $value }}%&quot;
      
      # Disk space low
      - alert: DiskSpaceLow
        expr: |
          (1 - (node_filesystem_avail_bytes / node_filesystem_size_bytes)) * 100 &gt; 90
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: &quot;Disk space low on {{ $labels.instance }}&quot;
          description: &quot;Disk {{ $labels.mountpoint }} is {{ $value }}% full&quot;
      
      # Disk will fill in 4 hours
      - alert: DiskWillFillSoon
        expr: |
          predict_linear(node_filesystem_avail_bytes[1h], 4 * 3600) &lt; 0
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: &quot;Disk will fill soon on {{ $labels.instance }}&quot;
          description: &quot;Disk {{ $labels.mountpoint }} will fill in &lt;4 hours&quot;</code></pre>
<h3>Alertmanager Configuration</h3>
<pre><code class="language-yaml"># alertmanager.yml
global:
  smtp_smarthost: &#039;smtp.gmail.com:587&#039;
  smtp_from: &#039;alerts@example.com&#039;
  smtp_auth_username: &#039;alerts@example.com&#039;
  smtp_auth_password: &#039;password&#039;
<p>route:
  # Default receiver
  receiver: &#039;team-email&#039;
  group_by: [&#039;alertname&#039;, &#039;cluster&#039;]
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 12h
  
  # Route based on labels
  routes:
    # Critical alerts to PagerDuty
    - match:
        severity: critical
      receiver: &#039;pagerduty&#039;
      continue: true  # Also send to other receivers
    
    # Team-specific routing
    - match:
        team: backend
      receiver: &#039;backend-slack&#039;
    
    - match:
        team: sre
      receiver: &#039;sre-slack&#039;</p>
<p>receivers:
  - name: &#039;team-email&#039;
    email_configs:
      - to: &#039;team@example.com&#039;
  
  - name: &#039;pagerduty&#039;
    pagerduty_configs:
      - service_key: &#039;&lt;pagerduty-key&gt;&#039;
  
  - name: &#039;backend-slack&#039;
    slack_configs:
      - api_url: &#039;https://hooks.slack.com/services/XXX&#039;
        channel: &#039;#backend-alerts&#039;
        title: &#039;Alert: {{ .GroupLabels.alertname }}&#039;
        text: &#039;{{ range .Alerts }}{{ .Annotations.description }}{{ end }}&#039;
  
  - name: &#039;sre-slack&#039;
    slack_configs:
      - api_url: &#039;https://hooks.slack.com/services/YYY&#039;
        channel: &#039;#sre-alerts&#039;</p>
<p>inhibit_rules:
  # Inhibit warning if critical is firing
  - source_match:
      severity: &#039;critical&#039;
    target_match:
      severity: &#039;warning&#039;
    equal: [&#039;alertname&#039;, &#039;instance&#039;]</code></pre></p>
<p>---</p>
<h2>Kubernetes Monitoring {#kubernetes}</h2>
<h3>Prometheus Operator</h3>
<pre><code class="language-bash"># Install Prometheus Operator with Helm
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update
helm install prometheus prometheus-community/kube-prometheus-stack \
  --namespace monitoring --create-namespace</code></pre>
<h3>ServiceMonitor for Custom App</h3>
<pre><code class="language-yaml"># servicemonitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: myapp
  namespace: monitoring
spec:
  selector:
    matchLabels:
      app: myapp
  endpoints:
    - port: metrics
      interval: 30s
      path: /metrics</code></pre>
<h3>Key Kubernetes Metrics</h3>
<pre><code class="language-promql"># Pod CPU usage
sum(rate(container_cpu_usage_seconds_total{pod=~&quot;myapp-.*&quot;}[5m])) by (pod)
<h1>Pod memory usage</h1>
sum(container_memory_usage_bytes{pod=~&quot;myapp-.*&quot;}) by (pod)
<h1>Pod restart count</h1>
kube_pod_container_status_restarts_total{pod=~&quot;myapp-.*&quot;}
<h1>Deployment replica status</h1>
kube_deployment_status_replicas_available{deployment=&quot;myapp&quot;}
<h1>Node status</h1>
kube_node_status_condition{condition=&quot;Ready&quot;, status=&quot;true&quot;}
<h1>Persistent volume usage</h1>
kubelet_volume_stats_used_bytes / kubelet_volume_stats_capacity_bytes * 100</code></pre>
<p>---</p>
<h2>Best Practices {#best-practices}</h2>
<h3>1. Metric Design</h3>
<pre><code class="language-go">// ‚úÖ Good: Low cardinality labels
httpRequestsTotal.WithLabelValues(&quot;GET&quot;, &quot;/api/users&quot;, &quot;200&quot;).Inc()
<p>// ‚ùå Bad: High cardinality (user IDs change frequently)
httpRequestsTotal.WithLabelValues(&quot;GET&quot;, &quot;/api/users&quot;, userID, &quot;200&quot;).Inc()</p>
<p>// ‚úÖ Good: Use histograms for latency
httpDuration.Observe(duration)</p>
<p>// ‚ùå Bad: Don&#039;t create gauges for every percentile
p50Gauge.Set(calculateP50())
p95Gauge.Set(calculateP95())
p99Gauge.Set(calculateP99())</code></pre></p>
<h3>2. Query Optimization</h3>
<pre><code class="language-promql"># ‚úÖ Good: Use recording rules for expensive queries
<h1>recording_rules.yml</h1>
groups:
  - name: aggregations
    interval: 30s
    rules:
      - record: job:http_requests:rate5m
        expr: sum(rate(http_requests_total[5m])) by (job)
<h1>‚ùå Bad: Complex query in dashboard (slow)</h1>
sum(rate(http_requests_total[5m])) by (job, instance, method, status)</code></pre>
<h3>3. Retention and Storage</h3>
<pre><code class="language-bash"># Configure retention
--storage.tsdb.retention.time=15d   # Keep 15 days
--storage.tsdb.retention.size=50GB  # Or max 50GB
<h1>For long-term storage, use remote write</h1>
<h1>prometheus.yml</h1>
remote_write:
  - url: &quot;http://thanos:9090/api/v1/receive&quot;</code></pre>
<h3>4. Security</h3>
<pre><code class="language-yaml"># Enable basic auth
basic_auth_users:
  admin: $2y$10$... # bcrypt hash
<h1>Use TLS</h1>
tls_server_config:
  cert_file: /path/to/cert.pem
  key_file: /path/to/key.pem</code></pre>
<p>---</p>
<h2>Interview Questions {#interview-questions}</h2>
<h3>Basic Questions</h3>
<strong>Q1: What is Prometheus and how does it differ from other monitoring tools?</strong>
<strong>A:</strong> Prometheus is a pull-based monitoring system with a multi-dimensional data model. Unlike push-based systems (Graphite, InfluxDB), Prometheus scrapes metrics from targets. It's designed for dynamic environments with built-in service discovery.
<strong>Q2: Explain the four metric types in Prometheus.</strong>
<strong>A:</strong>
<li><strong>Counter</strong>: Cumulative value that only increases (e.g., total requests)</li>
<li><strong>Gauge</strong>: Value that can go up/down (e.g., memory usage, temperature)</li>
<li><strong>Histogram</strong>: Samples observations in configurable buckets (e.g., request duration)</li>
<li><strong>Summary</strong>: Like histogram but calculates quantiles on client side</li>
<strong>Q3: What is the difference between rate() and irate()?</strong>
<strong>A:</strong>
<li><code>rate()</code>: Average rate over time range, smooths spikes</li>
<li><code>irate()</code>: Instant rate using last two samples, more sensitive to changes</li>
<li>Use <code>rate()</code> for alerts and long-term trends, <code>irate()</code> for graphs showing rapid changes</li>
<h3>Advanced Questions</h3>
<strong>Q4: How do you calculate 95th percentile request latency?</strong>
<pre><code class="language-promql">histogram_quantile(0.95, 
  rate(http_request_duration_seconds_bucket[5m])
)</code></pre>
<strong>Q5: Design an alerting strategy for a microservices architecture.</strong>
<strong>A:</strong>
1. <strong>Multi-level alerts</strong>: Critical (PagerDuty), Warning (Slack), Info (Email)
2. <strong>Symptom-based</strong>: Alert on user-facing issues (high error rate, slow responses)
3. <strong>Cause-based</strong>: Secondary alerts for root causes (high CPU, memory)
4. <strong>Inhibition rules</strong>: Suppress noise (don't alert on warnings if critical fires)
5. <strong>Runbooks</strong>: Include links to resolution steps in annotations
<strong>Q6: How do you handle high-cardinality metrics?</strong>
<strong>A:</strong>
<li>Avoid user IDs, request IDs, timestamps as labels</li>
<li>Use aggregation and drop unnecessary labels</li>
<li>Use recording rules to pre-aggregate</li>
<li>Consider using logs/traces for high-cardinality data</li>
<li>Set limits: <code>--query.max-samples</code> to prevent OOM</li>
<p>---</p>
<h2>Hands-On Exercise {#exercise}</h2>
<h3>Build a Monitored Microservice</h3>
<strong>Goal</strong>: Create a Go service with comprehensive Prometheus monitoring.
<p>#### Requirements</p>
<p>1. HTTP API with multiple endpoints
2. Database connection pool monitoring
3. Cache hit/miss metrics
4. Business metrics (orders, revenue)
5. Custom histograms for latency
6. Kubernetes deployment with ServiceMonitor
7. Alert rules for errors and latency</p>
<p>#### Solution</p>
<pre><code class="language-go">// main.go
package main
<p>import (
    &quot;database/sql&quot;
    &quot;encoding/json&quot;
    &quot;log&quot;
    &quot;math/rand&quot;
    &quot;net/http&quot;
    &quot;time&quot;
    
    &quot;github.com/prometheus/client_golang/prometheus&quot;
    &quot;github.com/prometheus/client_golang/prometheus/promhttp&quot;
    _ &quot;github.com/lib/pq&quot;
)</p>
<p>var (
    // HTTP metrics
    httpRequests = prometheus.NewCounterVec(
        prometheus.CounterOpts{
            Name: &quot;shop_http_requests_total&quot;,
            Help: &quot;Total HTTP requests&quot;,
        },
        []string{&quot;method&quot;, &quot;endpoint&quot;, &quot;status&quot;},
    )
    
    httpDuration = prometheus.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    &quot;shop_http_duration_seconds&quot;,
            Help:    &quot;HTTP request duration&quot;,
            Buckets: []float64{0.01, 0.05, 0.1, 0.25, 0.5, 1, 2.5, 5},
        },
        []string{&quot;method&quot;, &quot;endpoint&quot;},
    )
    
    // Database metrics
    dbConnections = prometheus.NewGaugeVec(
        prometheus.GaugeOpts{
            Name: &quot;shop_db_connections&quot;,
            Help: &quot;Database connections&quot;,
        },
        []string{&quot;state&quot;}, // active, idle
    )
    
    dbQueries = prometheus.NewCounterVec(
        prometheus.CounterOpts{
            Name: &quot;shop_db_queries_total&quot;,
            Help: &quot;Total database queries&quot;,
        },
        []string{&quot;operation&quot;},
    )
    
    // Cache metrics
    cacheOperations = prometheus.NewCounterVec(
        prometheus.CounterOpts{
            Name: &quot;shop_cache_operations_total&quot;,
            Help: &quot;Cache operations&quot;,
        },
        []string{&quot;operation&quot;, &quot;result&quot;}, // get/set, hit/miss
    )
    
    // Business metrics
    ordersCreated = prometheus.NewCounter(
        prometheus.CounterOpts{
            Name: &quot;shop_orders_created_total&quot;,
            Help: &quot;Total orders created&quot;,
        },
    )
    
    revenue = prometheus.NewCounter(
        prometheus.CounterOpts{
            Name: &quot;shop_revenue_total&quot;,
            Help: &quot;Total revenue&quot;,
        },
    )
)</p>
<p>func init() {
    prometheus.MustRegister(httpRequests, httpDuration)
    prometheus.MustRegister(dbConnections, dbQueries)
    prometheus.MustRegister(cacheOperations)
    prometheus.MustRegister(ordersCreated, revenue)
}</p>
<p>func main() {
    // Simulate database connection pool
    go monitorDBConnections()
    
    http.Handle(&quot;/metrics&quot;, promhttp.Handler())
    http.HandleFunc(&quot;/health&quot;, healthHandler)
    http.HandleFunc(&quot;/api/products&quot;, instrument(productsHandler))
    http.HandleFunc(&quot;/api/orders&quot;, instrument(ordersHandler))
    
    log.Println(&quot;Server starting on :8080&quot;)
    log.Fatal(http.ListenAndServe(&quot;:8080&quot;, nil))
}</p>
<p>func instrument(next http.HandlerFunc) http.HandlerFunc {
    return func(w http.ResponseWriter, r *http.Request) {
        start := time.Now()
        rw := &amp;responseWriter{ResponseWriter: w, statusCode: 200}
        
        next(rw, r)
        
        duration := time.Since(start).Seconds()
        httpDuration.WithLabelValues(r.Method, r.URL.Path).Observe(duration)
        httpRequests.WithLabelValues(r.Method, r.URL.Path, 
            http.StatusText(rw.statusCode)).Inc()
    }
}</p>
<p>type responseWriter struct {
    http.ResponseWriter
    statusCode int
}</p>
<p>func (rw *responseWriter) WriteHeader(code int) {
    rw.statusCode = code
    rw.ResponseWriter.WriteHeader(code)
}</p>
<p>func healthHandler(w http.ResponseWriter, r *http.Request) {
    w.WriteHeader(http.StatusOK)
    w.Write([]byte(&quot;OK&quot;))
}</p>
<p>func productsHandler(w http.ResponseWriter, r *http.Request) {
    // Simulate cache check
    if rand.Float32() &lt; 0.8 { // 80% cache hit rate
        cacheOperations.WithLabelValues(&quot;get&quot;, &quot;hit&quot;).Inc()
        time.Sleep(5 * time.Millisecond)
    } else {
        cacheOperations.WithLabelValues(&quot;get&quot;, &quot;miss&quot;).Inc()
        dbQueries.WithLabelValues(&quot;select&quot;).Inc()
        time.Sleep(50 * time.Millisecond)
    }
    
    products := []map[string]interface{}{
        {&quot;id&quot;: 1, &quot;name&quot;: &quot;Product 1&quot;, &quot;price&quot;: 29.99},
        {&quot;id&quot;: 2, &quot;name&quot;: &quot;Product 2&quot;, &quot;price&quot;: 49.99},
    }
    
    json.NewEncoder(w).Encode(products)
}</p>
<p>func ordersHandler(w http.ResponseWriter, r *http.Request) {
    if r.Method != http.MethodPost {
        w.WriteHeader(http.StatusMethodNotAllowed)
        return
    }
    
    // Simulate order creation
    dbQueries.WithLabelValues(&quot;insert&quot;).Inc()
    time.Sleep(100 * time.Millisecond)
    
    orderValue := 50.0 + rand.Float64()*100.0
    ordersCreated.Inc()
    revenue.Add(orderValue)
    
    response := map[string]interface{}{
        &quot;order_id&quot;: rand.Intn(10000),
        &quot;total&quot;:    orderValue,
        &quot;status&quot;:   &quot;created&quot;,
    }
    
    json.NewEncoder(w).Encode(response)
}</p>
<p>func monitorDBConnections() {
    ticker := time.NewTicker(10 * time.Second)
    for range ticker.C {
        // Simulate varying connection pool
        active := float64(5 + rand.Intn(10))
        idle := float64(15 - int(active))
        
        dbConnections.WithLabelValues(&quot;active&quot;).Set(active)
        dbConnections.WithLabelValues(&quot;idle&quot;).Set(idle)
    }
}</code></pre></p>
<p>#### Kubernetes Deployment</p>
<pre><code class="language-yaml"># deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: shop-api
  namespace: default
spec:
  replicas: 3
  selector:
    matchLabels:
      app: shop-api
  template:
    metadata:
      labels:
        app: shop-api
      annotations:
        prometheus.io/scrape: &quot;true&quot;
        prometheus.io/port: &quot;8080&quot;
        prometheus.io/path: &quot;/metrics&quot;
    spec:
      containers:
      - name: shop-api
        image: shop-api:latest
        ports:
        - containerPort: 8080
          name: http
        resources:
          requests:
            memory: &quot;128Mi&quot;
            cpu: &quot;100m&quot;
          limits:
            memory: &quot;256Mi&quot;
            cpu: &quot;500m&quot;
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: shop-api
  labels:
    app: shop-api
spec:
  selector:
    app: shop-api
  ports:
  - port: 80
    targetPort: 8080
    name: http</code></pre>
<p>#### Alert Rules</p>
<pre><code class="language-yaml"># alerts.yml
groups:
  - name: shop_api
    interval: 30s
    rules:
      - alert: HighErrorRate
        expr: |
          (
            sum(rate(shop_http_requests_total{status=~&quot;5..&quot;}[5m]))
            / sum(rate(shop_http_requests_total[5m]))
          ) &gt; 0.05
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: &quot;High error rate in shop API&quot;
          description: &quot;Error rate: {{ $value | humanizePercentage }}&quot;
      
      - alert: SlowResponseTime
        expr: |
          histogram_quantile(0.95,
            rate(shop_http_duration_seconds_bucket[5m])
          ) &gt; 1
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: &quot;Slow response time in shop API&quot;
          description: &quot;P95 latency: {{ $value }}s&quot;
      
      - alert: LowCacheHitRate
        expr: |
          (
            sum(rate(shop_cache_operations_total{result=&quot;hit&quot;}[5m]))
            / sum(rate(shop_cache_operations_total{operation=&quot;get&quot;}[5m]))
          ) &lt; 0.6
        for: 15m
        labels:
          severity: warning
        annotations:
          summary: &quot;Low cache hit rate&quot;
          description: &quot;Cache hit rate: {{ $value | humanizePercentage }}&quot;</code></pre>
<p>#### Testing</p>
<pre><code class="language-bash"># Generate traffic
while true; do
  curl http://localhost:8080/api/products
  curl -X POST http://localhost:8080/api/orders
  sleep 0.1
done
<h1>View metrics</h1>
curl http://localhost:8080/metrics | grep shop_
<h1>Query Prometheus</h1>
<h1>Error rate</h1>
(sum(rate(shop_http_requests_total{status=~&quot;5..&quot;}[5m])) / sum(rate(shop_http_requests_total[5m]))) * 100
<h1>P95 latency</h1>
histogram_quantile(0.95, rate(shop_http_duration_seconds_bucket[5m]))
<h1>Cache hit rate</h1>
(sum(rate(shop_cache_operations_total{result=&quot;hit&quot;}[5m])) / sum(rate(shop_cache_operations_total{operation=&quot;get&quot;}[5m]))) * 100</code></pre>
<p>---</p>
<h2>Summary</h2>
<p>You've learned:
<li>‚úÖ Prometheus architecture and scraping model</li>
<li>‚úÖ Four metric types and data model</li>
<li>‚úÖ PromQL for powerful queries and aggregations</li>
<li>‚úÖ Exporters (node, blackbox) for infrastructure monitoring</li>
<li>‚úÖ Go instrumentation with client library</li>
<li>‚úÖ Service discovery for dynamic environments</li>
<li>‚úÖ Alert rules and Alertmanager configuration</li>
<li>‚úÖ Kubernetes monitoring with ServiceMonitor</li></ul></p>
<strong>Next Module</strong>: [Module 27: Grafana Dashboards](27_Grafana_Dashboards.md) - Learn visualization and dashboard creation.

    </div>
    

    <div class="module-content" id="module-27">
        <h1>Module 27: Grafana Dashboards & Visualization</h1>
<h2>Table of Contents</h2>
<ul><li>[Introduction to Grafana](#introduction)</li>
<li>[Installation and Setup](#installation)</li>
<li>[Data Sources](#data-sources)</li>
<li>[Dashboard Basics](#dashboards)</li>
<li>[Panel Types and Visualizations](#panels)</li>
<li>[Variables and Templating](#variables)</li>
<li>[Alerting in Grafana](#alerting)</li>
<li>[Best Practices](#best-practices)</li>
<li>[Advanced Features](#advanced)</li>
<li>[Interview Questions](#interview-questions)</li>
<li>[Hands-On Exercise](#exercise)</li>
<p>---</p>
<h2>Introduction to Grafana {#introduction}</h2>
<p>Grafana is an open-source analytics and monitoring platform that visualizes time-series data from multiple sources.</p>
<h3>Key Features</h3>
<li><strong>Multi-source support</strong>: Prometheus, InfluxDB, Elasticsearch, MySQL, PostgreSQL, CloudWatch</li>
<li><strong>Rich visualizations</strong>: Graphs, heatmaps, gauges, tables, alerts</li>
<li><strong>Templating</strong>: Dynamic dashboards with variables</li>
<li><strong>Alerting</strong>: Built-in alerting with multiple notification channels</li>
<li><strong>Plugins</strong>: Extensible with community panels and data sources</li>
<h3>Use Cases</h3>
<p>‚úÖ <strong>Infrastructure monitoring</strong> - CPU, memory, disk, network
‚úÖ <strong>Application performance</strong> - Request rates, latency, errors
‚úÖ <strong>Business metrics</strong> - Orders, revenue, user signups
‚úÖ <strong>Log analysis</strong> - Error trends, log volumes
‚úÖ <strong>IoT dashboards</strong> - Sensor data, device status</p>
<p>---</p>
<h2>Installation and Setup {#installation}</h2>
<h3>Docker Installation</h3>
<pre><code class="language-bash"># docker-compose.yml
version: &#039;3&#039;
services:
  grafana:
    image: grafana/grafana:latest
    ports:
      - &quot;3000:3000&quot;
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning
    depends_on:
      - prometheus
<p>prometheus:
    image: prom/prometheus:latest
    ports:
      - &quot;9090:9090&quot;
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus</p>
<p>volumes:
  grafana-data:
  prometheus-data:</code></pre></p>
<pre><code class="language-bash">docker-compose up -d
<h1>Access Grafana</h1>
<h1>http://localhost:3000</h1>
<h1>Default credentials: admin/admin</code></pre></h1>
<h3>Kubernetes Installation (Helm)</h3>
<pre><code class="language-bash"># Add Grafana Helm repo
helm repo add grafana https://grafana.github.io/helm-charts
helm repo update
<h1>Install with Prometheus Operator stack</h1>
helm install grafana prometheus-community/kube-prometheus-stack \
  --namespace monitoring --create-namespace
<h1>Get admin password</h1>
kubectl get secret -n monitoring grafana -o jsonpath=&quot;{.data.admin-password}&quot; | base64 --decode
<h1>Port forward</h1>
kubectl port-forward -n monitoring svc/grafana 3000:80</code></pre>
<h3>Configuration Provisioning</h3>
<pre><code class="language-yaml"># grafana/provisioning/datasources/prometheus.yml
apiVersion: 1
<p>datasources:
  - name: Prometheus
    type: prometheus
    access: proxy
    url: http://prometheus:9090
    isDefault: true
    editable: false</code></pre></p>
<pre><code class="language-yaml"># grafana/provisioning/dashboards/default.yml
apiVersion: 1
<p>providers:
  - name: &#039;Default&#039;
    orgId: 1
    folder: &#039;&#039;
    type: file
    disableDeletion: false
    updateIntervalSeconds: 10
    allowUiUpdates: true
    options:
      path: /var/lib/grafana/dashboards</code></pre></p>
<p>---</p>
<h2>Data Sources {#data-sources}</h2>
<h3>Adding Prometheus Data Source</h3>
<strong>UI Method:</strong>
1. Go to Configuration ‚Üí Data Sources
2. Click "Add data source"
3. Select "Prometheus"
4. Set URL: <code>http://prometheus:9090</code>
5. Click "Save & Test"
<strong>Provisioning Method:</strong>
<pre><code class="language-yaml"># datasources.yml
apiVersion: 1
<p>datasources:
  - name: Prometheus
    type: prometheus
    access: proxy
    url: http://prometheus:9090
    jsonData:
      timeInterval: &quot;15s&quot;
      httpMethod: POST
    editable: false
  
  - name: Loki
    type: loki
    access: proxy
    url: http://loki:3100
    jsonData:
      maxLines: 1000
  
  - name: Elasticsearch
    type: elasticsearch
    access: proxy
    url: http://elasticsearch:9200
    database: &quot;logstash-*&quot;
    jsonData:
      interval: Daily
      timeField: &quot;@timestamp&quot;</code></pre></p>
<h3>Data Source Query Examples</h3>
<strong>Prometheus:</strong>
<pre><code class="language-promql">rate(http_requests_total[5m])</code></pre>
<strong>Elasticsearch:</strong>
<pre><code class="language-json">{
  &quot;query&quot;: {
    &quot;bool&quot;: {
      &quot;filter&quot;: [
        {&quot;range&quot;: {&quot;@timestamp&quot;: {&quot;gte&quot;: &quot;now-1h&quot;}}}
      ]
    }
  }
}</code></pre>
<strong>MySQL:</strong>
<pre><code class="language-sql">SELECT
  UNIX_TIMESTAMP(timestamp) as time_sec,
  value
FROM metrics
WHERE $__timeFilter(timestamp)
ORDER BY timestamp</code></pre>
<p>---</p>
<h2>Dashboard Basics {#dashboards}</h2>
<h3>Creating a Dashboard</h3>
<pre><code class="language-json">// dashboard.json
{
  &quot;dashboard&quot;: {
    &quot;id&quot;: null,
    &quot;uid&quot;: &quot;shop-api&quot;,
    &quot;title&quot;: &quot;Shop API Monitoring&quot;,
    &quot;tags&quot;: [&quot;api&quot;, &quot;microservice&quot;],
    &quot;timezone&quot;: &quot;browser&quot;,
    &quot;schemaVersion&quot;: 27,
    &quot;version&quot;: 0,
    &quot;refresh&quot;: &quot;10s&quot;,
    &quot;time&quot;: {
      &quot;from&quot;: &quot;now-1h&quot;,
      &quot;to&quot;: &quot;now&quot;
    },
    &quot;panels&quot;: []
  }
}</code></pre>
<h3>Dashboard Structure</h3>
<pre><code class="language-text">Dashboard
‚îú‚îÄ‚îÄ Rows (organize panels)
‚îÇ   ‚îú‚îÄ‚îÄ Panel 1 (Graph)
‚îÇ   ‚îú‚îÄ‚îÄ Panel 2 (Stat)
‚îÇ   ‚îî‚îÄ‚îÄ Panel 3 (Table)
‚îú‚îÄ‚îÄ Variables (dynamic filtering)
‚îî‚îÄ‚îÄ Annotations (events)</code></pre>
<h3>Row Organization</h3>
<pre><code class="language-json">{
  &quot;panels&quot;: [
    {
      &quot;type&quot;: &quot;row&quot;,
      &quot;title&quot;: &quot;HTTP Metrics&quot;,
      &quot;collapsed&quot;: false,
      &quot;panels&quot;: []
    },
    {
      &quot;type&quot;: &quot;graph&quot;,
      &quot;title&quot;: &quot;Request Rate&quot;,
      &quot;gridPos&quot;: {&quot;h&quot;: 8, &quot;w&quot;: 12, &quot;x&quot;: 0, &quot;y&quot;: 1},
      &quot;targets&quot;: [
        {
          &quot;expr&quot;: &quot;sum(rate(http_requests_total[5m])) by (method)&quot;,
          &quot;legendFormat&quot;: &quot;{{method}}&quot;
        }
      ]
    }
  ]
}</code></pre>
<p>---</p>
<h2>Panel Types and Visualizations {#panels}</h2>
<h3>1. Time Series (Graph)</h3>
<p>Perfect for trends over time.</p>
<pre><code class="language-json">{
  &quot;type&quot;: &quot;timeseries&quot;,
  &quot;title&quot;: &quot;Request Rate by Method&quot;,
  &quot;targets&quot;: [
    {
      &quot;expr&quot;: &quot;sum(rate(http_requests_total[5m])) by (method)&quot;,
      &quot;legendFormat&quot;: &quot;{{method}}&quot;
    }
  ],
  &quot;fieldConfig&quot;: {
    &quot;defaults&quot;: {
      &quot;unit&quot;: &quot;reqps&quot;,
      &quot;custom&quot;: {
        &quot;lineInterpolation&quot;: &quot;smooth&quot;,
        &quot;fillOpacity&quot;: 10
      }
    }
  }
}</code></pre>
<strong>Common PromQL Queries:</strong>
<pre><code class="language-promql"># Request rate
rate(http_requests_total[5m])
<h1>Error rate percentage</h1>
(sum(rate(http_requests_total{status=~&quot;5..&quot;}[5m])) / sum(rate(http_requests_total[5m]))) * 100
<h1>P95 latency</h1>
histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))</code></pre>
<h3>2. Stat Panel (Single Value)</h3>
<p>Show current value with thresholds.</p>
<pre><code class="language-json">{
  &quot;type&quot;: &quot;stat&quot;,
  &quot;title&quot;: &quot;Current Error Rate&quot;,
  &quot;targets&quot;: [
    {
      &quot;expr&quot;: &quot;(sum(rate(http_requests_total{status=~&#039;5..&#039;}[5m])) / sum(rate(http_requests_total[5m]))) * 100&quot;
    }
  ],
  &quot;fieldConfig&quot;: {
    &quot;defaults&quot;: {
      &quot;unit&quot;: &quot;percent&quot;,
      &quot;thresholds&quot;: {
        &quot;mode&quot;: &quot;absolute&quot;,
        &quot;steps&quot;: [
          {&quot;value&quot;: 0, &quot;color&quot;: &quot;green&quot;},
          {&quot;value&quot;: 1, &quot;color&quot;: &quot;yellow&quot;},
          {&quot;value&quot;: 5, &quot;color&quot;: &quot;red&quot;}
        ]
      }
    }
  },
  &quot;options&quot;: {
    &quot;graphMode&quot;: &quot;area&quot;,
    &quot;colorMode&quot;: &quot;background&quot;
  }
}</code></pre>
<h3>3. Gauge</h3>
<p>Visual representation of a metric with min/max.</p>
<pre><code class="language-json">{
  &quot;type&quot;: &quot;gauge&quot;,
  &quot;title&quot;: &quot;CPU Usage&quot;,
  &quot;targets&quot;: [
    {
      &quot;expr&quot;: &quot;100 - (avg(rate(node_cpu_seconds_total{mode=&#039;idle&#039;}[5m])) * 100)&quot;
    }
  ],
  &quot;fieldConfig&quot;: {
    &quot;defaults&quot;: {
      &quot;min&quot;: 0,
      &quot;max&quot;: 100,
      &quot;unit&quot;: &quot;percent&quot;,
      &quot;thresholds&quot;: {
        &quot;steps&quot;: [
          {&quot;value&quot;: 0, &quot;color&quot;: &quot;green&quot;},
          {&quot;value&quot;: 60, &quot;color&quot;: &quot;yellow&quot;},
          {&quot;value&quot;: 80, &quot;color&quot;: &quot;red&quot;}
        ]
      }
    }
  }
}</code></pre>
<h3>4. Heatmap</h3>
<p>Show distribution of values over time.</p>
<pre><code class="language-json">{
  &quot;type&quot;: &quot;heatmap&quot;,
  &quot;title&quot;: &quot;Request Duration Distribution&quot;,
  &quot;targets&quot;: [
    {
      &quot;expr&quot;: &quot;sum(increase(http_request_duration_seconds_bucket[1m])) by (le)&quot;,
      &quot;format&quot;: &quot;heatmap&quot;,
      &quot;legendFormat&quot;: &quot;{{le}}&quot;
    }
  ],
  &quot;options&quot;: {
    &quot;calculate&quot;: false,
    &quot;yAxis&quot;: {
      &quot;format&quot;: &quot;s&quot;,
      &quot;logBase&quot;: 1
    }
  }
}</code></pre>
<h3>5. Table</h3>
<p>Display metrics in tabular format.</p>
<pre><code class="language-json">{
  &quot;type&quot;: &quot;table&quot;,
  &quot;title&quot;: &quot;Top Endpoints by Request Count&quot;,
  &quot;targets&quot;: [
    {
      &quot;expr&quot;: &quot;topk(10, sum(rate(http_requests_total[5m])) by (endpoint))&quot;,
      &quot;format&quot;: &quot;table&quot;,
      &quot;instant&quot;: true
    }
  ],
  &quot;options&quot;: {
    &quot;sortBy&quot;: [
      {&quot;displayName&quot;: &quot;Value&quot;, &quot;desc&quot;: true}
    ]
  }
}</code></pre>
<h3>6. Bar Gauge</h3>
<p>Horizontal bars for comparison.</p>
<pre><code class="language-json">{
  &quot;type&quot;: &quot;bargauge&quot;,
  &quot;title&quot;: &quot;Requests by Status Code&quot;,
  &quot;targets&quot;: [
    {
      &quot;expr&quot;: &quot;sum(rate(http_requests_total[5m])) by (status)&quot;
    }
  ],
  &quot;options&quot;: {
    &quot;orientation&quot;: &quot;horizontal&quot;,
    &quot;displayMode&quot;: &quot;gradient&quot;
  }
}</code></pre>
<p>---</p>
<h2>Variables and Templating {#variables}</h2>
<h3>Query Variable (Prometheus)</h3>
<pre><code class="language-json">{
  &quot;templating&quot;: {
    &quot;list&quot;: [
      {
        &quot;name&quot;: &quot;instance&quot;,
        &quot;type&quot;: &quot;query&quot;,
        &quot;datasource&quot;: &quot;Prometheus&quot;,
        &quot;query&quot;: &quot;label_values(up, instance)&quot;,
        &quot;refresh&quot;: 1,
        &quot;multi&quot;: true,
        &quot;includeAll&quot;: true
      },
      {
        &quot;name&quot;: &quot;job&quot;,
        &quot;type&quot;: &quot;query&quot;,
        &quot;datasource&quot;: &quot;Prometheus&quot;,
        &quot;query&quot;: &quot;label_values(up, job)&quot;,
        &quot;refresh&quot;: 1
      },
      {
        &quot;name&quot;: &quot;interval&quot;,
        &quot;type&quot;: &quot;interval&quot;,
        &quot;query&quot;: &quot;1m,5m,10m,30m,1h&quot;,
        &quot;auto&quot;: true,
        &quot;auto_count&quot;: 30,
        &quot;auto_min&quot;: &quot;10s&quot;
      }
    ]
  }
}</code></pre>
<h3>Using Variables in Queries</h3>
<pre><code class="language-promql"># Use $instance variable
rate(http_requests_total{instance=~&quot;$instance&quot;}[$interval])
<h1>Use $job variable</h1>
up{job=&quot;$job&quot;}
<h1>Multiple selection with regex</h1>
node_cpu_seconds_total{instance=~&quot;$instance&quot;}</code></pre>
<h3>Advanced Variable Queries</h3>
<pre><code class="language-promql"># Chained variables (job depends on namespace)
label_values(kube_pod_info{namespace=&quot;$namespace&quot;}, job)
<h1>Label values from specific metric</h1>
label_values(http_requests_total, endpoint)
<h1>Custom query</h1>
query_result(sum(rate(http_requests_total[5m])) by (service))</code></pre>
<h3>Variable in Panel Title</h3>
<pre><code class="language-json">{
  &quot;title&quot;: &quot;Request Rate - $instance&quot;,
  &quot;targets&quot;: [
    {
      &quot;expr&quot;: &quot;rate(http_requests_total{instance=~\&quot;$instance\&quot;}[5m])&quot;
    }
  ]
}</code></pre>
<p>---</p>
<h2>Alerting in Grafana {#alerting}</h2>
<h3>Alert Rule Configuration</h3>
<pre><code class="language-json">{
  &quot;type&quot;: &quot;graph&quot;,
  &quot;title&quot;: &quot;High Error Rate&quot;,
  &quot;alert&quot;: {
    &quot;name&quot;: &quot;High Error Rate Alert&quot;,
    &quot;message&quot;: &quot;Error rate is above 5%&quot;,
    &quot;conditions&quot;: [
      {
        &quot;type&quot;: &quot;query&quot;,
        &quot;query&quot;: {
          &quot;params&quot;: [&quot;A&quot;, &quot;5m&quot;, &quot;now&quot;]
        },
        &quot;reducer&quot;: {
          &quot;type&quot;: &quot;avg&quot;
        },
        &quot;evaluator&quot;: {
          &quot;type&quot;: &quot;gt&quot;,
          &quot;params&quot;: [5]
        }
      }
    ],
    &quot;frequency&quot;: &quot;1m&quot;,
    &quot;for&quot;: &quot;5m&quot;,
    &quot;noDataState&quot;: &quot;no_data&quot;,
    &quot;executionErrorState&quot;: &quot;alerting&quot;
  },
  &quot;targets&quot;: [
    {
      &quot;refId&quot;: &quot;A&quot;,
      &quot;expr&quot;: &quot;(sum(rate(http_requests_total{status=~&#039;5..&#039;}[5m])) / sum(rate(http_requests_total[5m]))) * 100&quot;
    }
  ]
}</code></pre>
<h3>Notification Channels</h3>
<strong>Slack:</strong>
<pre><code class="language-json">{
  &quot;name&quot;: &quot;Slack Alerts&quot;,
  &quot;type&quot;: &quot;slack&quot;,
  &quot;settings&quot;: {
    &quot;url&quot;: &quot;https://hooks.slack.com/services/XXX/YYY/ZZZ&quot;,
    &quot;recipient&quot;: &quot;#alerts&quot;,
    &quot;username&quot;: &quot;Grafana&quot;,
    &quot;mentionChannel&quot;: &quot;here&quot;
  }
}</code></pre>
<strong>Email:</strong>
<pre><code class="language-json">{
  &quot;name&quot;: &quot;Email Alerts&quot;,
  &quot;type&quot;: &quot;email&quot;,
  &quot;settings&quot;: {
    &quot;addresses&quot;: &quot;team@example.com;ops@example.com&quot;,
    &quot;singleEmail&quot;: true
  }
}</code></pre>
<strong>PagerDuty:</strong>
<pre><code class="language-json">{
  &quot;name&quot;: &quot;PagerDuty&quot;,
  &quot;type&quot;: &quot;pagerduty&quot;,
  &quot;settings&quot;: {
    &quot;integrationKey&quot;: &quot;xxx&quot;,
    &quot;severity&quot;: &quot;critical&quot;,
    &quot;autoResolve&quot;: true
  }
}</code></pre>
<h3>Alert Testing</h3>
<pre><code class="language-bash"># Test notification channel
POST /api/alert-notifications/test
{
  &quot;name&quot;: &quot;Slack Alerts&quot;,
  &quot;type&quot;: &quot;slack&quot;,
  &quot;settings&quot;: {...}
}</code></pre>
<p>---</p>
<h2>Best Practices {#best-practices}</h2>
<h3>1. Dashboard Organization</h3>
<pre><code class="language-text">üìÅ Dashboards
‚îú‚îÄ‚îÄ üìä Overview (high-level metrics)
‚îú‚îÄ‚îÄ üìÇ Services
‚îÇ   ‚îú‚îÄ‚îÄ API Gateway
‚îÇ   ‚îú‚îÄ‚îÄ User Service
‚îÇ   ‚îî‚îÄ‚îÄ Order Service
‚îú‚îÄ‚îÄ üìÇ Infrastructure
‚îÇ   ‚îú‚îÄ‚îÄ Kubernetes Cluster
‚îÇ   ‚îú‚îÄ‚îÄ Database Servers
‚îÇ   ‚îî‚îÄ‚îÄ Load Balancers
‚îî‚îÄ‚îÄ üìÇ Business Metrics
    ‚îú‚îÄ‚îÄ Revenue
    ‚îî‚îÄ‚îÄ User Analytics</code></pre>
<h3>2. Panel Naming</h3>
<pre><code class="language-text">‚úÖ Good:
<li>&quot;Request Rate (last 5m)&quot;</li>
<li>&quot;P95 Latency by Endpoint&quot;</li>
<li>&quot;Error Rate %&quot;</li>
<p>‚ùå Bad:
<li>&quot;Graph 1&quot;</li>
<li>&quot;Panel&quot;</li>
<li>&quot;Metric&quot;</code></pre></li></p>
<h3>3. Color Schemes</h3>
<pre><code class="language-json">{
  &quot;fieldConfig&quot;: {
    &quot;overrides&quot;: [
      {
        &quot;matcher&quot;: {&quot;id&quot;: &quot;byName&quot;, &quot;options&quot;: &quot;GET&quot;},
        &quot;properties&quot;: [{&quot;id&quot;: &quot;color&quot;, &quot;value&quot;: {&quot;mode&quot;: &quot;fixed&quot;, &quot;fixedColor&quot;: &quot;green&quot;}}]
      },
      {
        &quot;matcher&quot;: {&quot;id&quot;: &quot;byName&quot;, &quot;options&quot;: &quot;POST&quot;},
        &quot;properties&quot;: [{&quot;id&quot;: &quot;color&quot;, &quot;value&quot;: {&quot;mode&quot;: &quot;fixed&quot;, &quot;fixedColor&quot;: &quot;blue&quot;}}]
      },
      {
        &quot;matcher&quot;: {&quot;id&quot;: &quot;byName&quot;, &quot;options&quot;: &quot;DELETE&quot;},
        &quot;properties&quot;: [{&quot;id&quot;: &quot;color&quot;, &quot;value&quot;: {&quot;mode&quot;: &quot;fixed&quot;, &quot;fixedColor&quot;: &quot;red&quot;}}]
      }
    ]
  }
}</code></pre>
<h3>4. Performance Optimization</h3>
<pre><code class="language-promql"># ‚úÖ Good: Use recording rules for expensive queries
job:http_requests:rate5m
<h1>‚ùå Bad: Complex query in every panel</h1>
sum(rate(http_requests_total[5m])) by (job, instance, method, endpoint, status)
<h1>‚úÖ Good: Limit time range for high-cardinality metrics</h1>
http_requests_total[1h]
<h1>‚ùå Bad: Querying weeks of high-resolution data</h1>
http_requests_total[30d]</code></pre>
<h3>5. Templating Best Practices</h3>
<pre><code class="language-json">{
  &quot;templating&quot;: {
    &quot;list&quot;: [
      // ‚úÖ Use &quot;All&quot; option for filtering
      {
        &quot;name&quot;: &quot;namespace&quot;,
        &quot;includeAll&quot;: true,
        &quot;allValue&quot;: &quot;.*&quot;
      },
      
      // ‚úÖ Set reasonable refresh intervals
      {
        &quot;name&quot;: &quot;pod&quot;,
        &quot;refresh&quot;: 2,  // On time range change and dashboard load
        &quot;regex&quot;: &quot;/^(prod|staging)-.*/&quot;,  // Filter options
        &quot;sort&quot;: 1  // Alphabetical sort
      }
    ]
  }
}</code></pre>
<p>---</p>
<h2>Advanced Features {#advanced}</h2>
<h3>Annotations</h3>
<p>Display events on graphs.</p>
<pre><code class="language-json">{
  &quot;annotations&quot;: {
    &quot;list&quot;: [
      {
        &quot;name&quot;: &quot;Deployments&quot;,
        &quot;datasource&quot;: &quot;Prometheus&quot;,
        &quot;expr&quot;: &quot;changes(kube_deployment_status_observed_generation[5m]) &gt; 0&quot;,
        &quot;titleFormat&quot;: &quot;Deployment&quot;,
        &quot;textFormat&quot;: &quot;{{deployment}}&quot;,
        &quot;iconColor&quot;: &quot;blue&quot;
      }
    ]
  }
}</code></pre>
<h3>Transformations</h3>
<p>Modify query results before visualization.</p>
<strong>Join by Field:</strong>
<pre><code class="language-json">{
  &quot;transformations&quot;: [
    {
      &quot;id&quot;: &quot;merge&quot;,
      &quot;options&quot;: {}
    },
    {
      &quot;id&quot;: &quot;organize&quot;,
      &quot;options&quot;: {
        &quot;excludeByName&quot;: {&quot;Time&quot;: true},
        &quot;renameByName&quot;: {&quot;Value&quot;: &quot;Requests&quot;}
      }
    }
  ]
}</code></pre>
<strong>Calculate Field:</strong>
<pre><code class="language-json">{
  &quot;transformations&quot;: [
    {
      &quot;id&quot;: &quot;calculateField&quot;,
      &quot;options&quot;: {
        &quot;mode&quot;: &quot;binary&quot;,
        &quot;reduce&quot;: {
          &quot;reducer&quot;: &quot;sum&quot;
        },
        &quot;binary&quot;: {
          &quot;left&quot;: &quot;errors&quot;,
          &quot;operator&quot;: &quot;/&quot;,
          &quot;right&quot;: &quot;total&quot;
        },
        &quot;alias&quot;: &quot;error_rate&quot;
      }
    }
  ]
}</code></pre>
<h3>Plugins</h3>
<strong>Install Panel Plugin:</strong>
<pre><code class="language-bash">grafana-cli plugins install grafana-piechart-panel
docker restart grafana</code></pre>
<strong>Popular Plugins:</strong>
<li><code>grafana-worldmap-panel</code> - Geographic data</li>
<li><code>grafana-piechart-panel</code> - Pie charts</li>
<li><code>grafana-polystat-panel</code> - Hexagon/polygon stats</li>
<li><code>grafana-clock-panel</code> - Clock widget</li>
<p>---</p>
<h2>Interview Questions {#interview-questions}</h2>
<strong>Q1: How do you create dynamic dashboards in Grafana?</strong>
<strong>A:</strong> Use templating variables:
1. Create query variables from label values
2. Reference variables in queries: <code>{instance=~"$instance"}</code>
3. Enable multi-select and "All" options
4. Chain variables (e.g., namespace ‚Üí pod ‚Üí container)
5. Use variables in panel titles and queries
<strong>Q2: What's the difference between Grafana alerts and Prometheus alerts?</strong>
<strong>A:</strong>
<li><strong>Prometheus</strong>: Rule evaluation engine, flexible PromQL, Alertmanager integration</li>
<li><strong>Grafana</strong>: Dashboard-based alerts, multi-datasource support, built-in notification channels</li>
<li><strong>Best Practice</strong>: Use Prometheus for metric-based alerts, Grafana for visualization and dashboard annotations</li>
<strong>Q3: How do you optimize dashboard performance?</strong>
<strong>A:</strong>
1. Use recording rules for expensive queries
2. Limit time ranges (avoid querying months of data)
3. Use variables to filter data dynamically
4. Set appropriate refresh intervals
5. Reduce cardinality in queries
6. Cache datasource queries
7. Use instant queries for current values
<strong>Q4: Explain Grafana's transformation feature.</strong>
<strong>A:</strong> Transformations process query results before visualization:
<li><strong>Merge</strong>: Combine multiple queries</li>
<li><strong>Filter</strong>: Remove rows/columns</li>
<li><strong>Organize</strong>: Rename/reorder fields</li>
<li><strong>Calculate</strong>: Add computed fields</li>
<li><strong>Join by field</strong>: Combine by common column</li>
<p>Example: Merge CPU/Memory metrics, calculate percentage, filter by threshold.</p>
<p>---</p>
<h2>Hands-On Exercise {#exercise}</h2>
<h3>Build a Comprehensive Microservices Dashboard</h3>
<strong>Goal</strong>: Create a production-ready dashboard with multiple panels, variables, and alerts.
<p>#### Requirements</p>
<p>1. <strong>Variables</strong>: namespace, service, instance, interval
2. <strong>Overview Row</strong>: Request rate, error rate, latency, active connections
3. <strong>HTTP Metrics Row</strong>: Requests by method, status code distribution, endpoint breakdown
4. <strong>Infrastructure Row</strong>: CPU, memory, network, disk
5. <strong>Business Metrics Row</strong>: Orders, revenue, cache hit rate
6. <strong>Alerts</strong>: High error rate, slow response time</p>
<p>#### Complete Dashboard JSON</p>
<pre><code class="language-json">{
  &quot;dashboard&quot;: {
    &quot;uid&quot;: &quot;microservices-overview&quot;,
    &quot;title&quot;: &quot;Microservices Monitoring&quot;,
    &quot;tags&quot;: [&quot;microservices&quot;, &quot;api&quot;],
    &quot;timezone&quot;: &quot;browser&quot;,
    &quot;refresh&quot;: &quot;30s&quot;,
    &quot;time&quot;: {
      &quot;from&quot;: &quot;now-1h&quot;,
      &quot;to&quot;: &quot;now&quot;
    },
    &quot;templating&quot;: {
      &quot;list&quot;: [
        {
          &quot;name&quot;: &quot;datasource&quot;,
          &quot;type&quot;: &quot;datasource&quot;,
          &quot;query&quot;: &quot;prometheus&quot;
        },
        {
          &quot;name&quot;: &quot;namespace&quot;,
          &quot;type&quot;: &quot;query&quot;,
          &quot;datasource&quot;: &quot;$datasource&quot;,
          &quot;query&quot;: &quot;label_values(kube_pod_info, namespace)&quot;,
          &quot;refresh&quot;: 1,
          &quot;includeAll&quot;: false
        },
        {
          &quot;name&quot;: &quot;service&quot;,
          &quot;type&quot;: &quot;query&quot;,
          &quot;datasource&quot;: &quot;$datasource&quot;,
          &quot;query&quot;: &quot;label_values(http_requests_total{namespace=\&quot;$namespace\&quot;}, service)&quot;,
          &quot;refresh&quot;: 1,
          &quot;includeAll&quot;: true,
          &quot;multi&quot;: true
        },
        {
          &quot;name&quot;: &quot;interval&quot;,
          &quot;type&quot;: &quot;interval&quot;,
          &quot;query&quot;: &quot;1m,5m,10m,30m,1h&quot;,
          &quot;auto&quot;: true,
          &quot;auto_count&quot;: 30
        }
      ]
    },
    &quot;panels&quot;: [
      {
        &quot;type&quot;: &quot;row&quot;,
        &quot;title&quot;: &quot;Overview&quot;,
        &quot;gridPos&quot;: {&quot;h&quot;: 1, &quot;w&quot;: 24, &quot;x&quot;: 0, &quot;y&quot;: 0}
      },
      {
        &quot;type&quot;: &quot;stat&quot;,
        &quot;title&quot;: &quot;Request Rate&quot;,
        &quot;gridPos&quot;: {&quot;h&quot;: 4, &quot;w&quot;: 6, &quot;x&quot;: 0, &quot;y&quot;: 1},
        &quot;targets&quot;: [
          {
            &quot;expr&quot;: &quot;sum(rate(http_requests_total{namespace=\&quot;$namespace\&quot;, service=~\&quot;$service\&quot;}[$interval]))&quot;
          }
        ],
        &quot;fieldConfig&quot;: {
          &quot;defaults&quot;: {
            &quot;unit&quot;: &quot;reqps&quot;,
            &quot;decimals&quot;: 2,
            &quot;color&quot;: {&quot;mode&quot;: &quot;thresholds&quot;},
            &quot;thresholds&quot;: {
              &quot;steps&quot;: [
                {&quot;value&quot;: 0, &quot;color&quot;: &quot;green&quot;},
                {&quot;value&quot;: 100, &quot;color&quot;: &quot;yellow&quot;},
                {&quot;value&quot;: 500, &quot;color&quot;: &quot;red&quot;}
              ]
            }
          }
        },
        &quot;options&quot;: {
          &quot;graphMode&quot;: &quot;area&quot;,
          &quot;colorMode&quot;: &quot;value&quot;
        }
      },
      {
        &quot;type&quot;: &quot;stat&quot;,
        &quot;title&quot;: &quot;Error Rate %&quot;,
        &quot;gridPos&quot;: {&quot;h&quot;: 4, &quot;w&quot;: 6, &quot;x&quot;: 6, &quot;y&quot;: 1},
        &quot;targets&quot;: [
          {
            &quot;expr&quot;: &quot;(sum(rate(http_requests_total{namespace=\&quot;$namespace\&quot;, service=~\&quot;$service\&quot;, status=~\&quot;5..\&quot;}[$interval])) / sum(rate(http_requests_total{namespace=\&quot;$namespace\&quot;, service=~\&quot;$service\&quot;}[$interval]))) * 100&quot;
          }
        ],
        &quot;fieldConfig&quot;: {
          &quot;defaults&quot;: {
            &quot;unit&quot;: &quot;percent&quot;,
            &quot;decimals&quot;: 2,
            &quot;thresholds&quot;: {
              &quot;steps&quot;: [
                {&quot;value&quot;: 0, &quot;color&quot;: &quot;green&quot;},
                {&quot;value&quot;: 1, &quot;color&quot;: &quot;yellow&quot;},
                {&quot;value&quot;: 5, &quot;color&quot;: &quot;red&quot;}
              ]
            }
          }
        },
        &quot;options&quot;: {
          &quot;graphMode&quot;: &quot;area&quot;,
          &quot;colorMode&quot;: &quot;background&quot;
        }
      },
      {
        &quot;type&quot;: &quot;gauge&quot;,
        &quot;title&quot;: &quot;P95 Latency&quot;,
        &quot;gridPos&quot;: {&quot;h&quot;: 4, &quot;w&quot;: 6, &quot;x&quot;: 12, &quot;y&quot;: 1},
        &quot;targets&quot;: [
          {
            &quot;expr&quot;: &quot;histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace=\&quot;$namespace\&quot;, service=~\&quot;$service\&quot;}[$interval])) by (le))&quot;
          }
        ],
        &quot;fieldConfig&quot;: {
          &quot;defaults&quot;: {
            &quot;unit&quot;: &quot;s&quot;,
            &quot;min&quot;: 0,
            &quot;max&quot;: 2,
            &quot;thresholds&quot;: {
              &quot;steps&quot;: [
                {&quot;value&quot;: 0, &quot;color&quot;: &quot;green&quot;},
                {&quot;value&quot;: 0.5, &quot;color&quot;: &quot;yellow&quot;},
                {&quot;value&quot;: 1, &quot;color&quot;: &quot;red&quot;}
              ]
            }
          }
        }
      },
      {
        &quot;type&quot;: &quot;stat&quot;,
        &quot;title&quot;: &quot;Active Connections&quot;,
        &quot;gridPos&quot;: {&quot;h&quot;: 4, &quot;w&quot;: 6, &quot;x&quot;: 18, &quot;y&quot;: 1},
        &quot;targets&quot;: [
          {
            &quot;expr&quot;: &quot;sum(active_connections{namespace=\&quot;$namespace\&quot;, service=~\&quot;$service\&quot;})&quot;
          }
        ],
        &quot;fieldConfig&quot;: {
          &quot;defaults&quot;: {
            &quot;unit&quot;: &quot;short&quot;,
            &quot;color&quot;: {&quot;mode&quot;: &quot;palette-classic&quot;}
          }
        },
        &quot;options&quot;: {
          &quot;graphMode&quot;: &quot;area&quot;
        }
      },
      {
        &quot;type&quot;: &quot;row&quot;,
        &quot;title&quot;: &quot;HTTP Metrics&quot;,
        &quot;gridPos&quot;: {&quot;h&quot;: 1, &quot;w&quot;: 24, &quot;x&quot;: 0, &quot;y&quot;: 5}
      },
      {
        &quot;type&quot;: &quot;timeseries&quot;,
        &quot;title&quot;: &quot;Requests by Method&quot;,
        &quot;gridPos&quot;: {&quot;h&quot;: 8, &quot;w&quot;: 12, &quot;x&quot;: 0, &quot;y&quot;: 6},
        &quot;targets&quot;: [
          {
            &quot;expr&quot;: &quot;sum(rate(http_requests_total{namespace=\&quot;$namespace\&quot;, service=~\&quot;$service\&quot;}[$interval])) by (method)&quot;,
            &quot;legendFormat&quot;: &quot;{{method}}&quot;
          }
        ],
        &quot;fieldConfig&quot;: {
          &quot;defaults&quot;: {
            &quot;unit&quot;: &quot;reqps&quot;,
            &quot;custom&quot;: {
              &quot;lineInterpolation&quot;: &quot;smooth&quot;,
              &quot;fillOpacity&quot;: 20
            }
          }
        }
      },
      {
        &quot;type&quot;: &quot;piechart&quot;,
        &quot;title&quot;: &quot;Status Code Distribution&quot;,
        &quot;gridPos&quot;: {&quot;h&quot;: 8, &quot;w&quot;: 12, &quot;x&quot;: 12, &quot;y&quot;: 6},
        &quot;targets&quot;: [
          {
            &quot;expr&quot;: &quot;sum(increase(http_requests_total{namespace=\&quot;$namespace\&quot;, service=~\&quot;$service\&quot;}[1h])) by (status)&quot;
          }
        ],
        &quot;options&quot;: {
          &quot;legend&quot;: {
            &quot;displayMode&quot;: &quot;table&quot;,
            &quot;values&quot;: [&quot;value&quot;, &quot;percent&quot;]
          }
        }
      },
      {
        &quot;type&quot;: &quot;row&quot;,
        &quot;title&quot;: &quot;Infrastructure&quot;,
        &quot;gridPos&quot;: {&quot;h&quot;: 1, &quot;w&quot;: 24, &quot;x&quot;: 0, &quot;y&quot;: 14}
      },
      {
        &quot;type&quot;: &quot;timeseries&quot;,
        &quot;title&quot;: &quot;CPU Usage %&quot;,
        &quot;gridPos&quot;: {&quot;h&quot;: 8, &quot;w&quot;: 6, &quot;x&quot;: 0, &quot;y&quot;: 15},
        &quot;targets&quot;: [
          {
            &quot;expr&quot;: &quot;sum(rate(container_cpu_usage_seconds_total{namespace=\&quot;$namespace\&quot;, pod=~\&quot;$service-.*\&quot;}[$interval])) by (pod) * 100&quot;,
            &quot;legendFormat&quot;: &quot;{{pod}}&quot;
          }
        ],
        &quot;fieldConfig&quot;: {
          &quot;defaults&quot;: {
            &quot;unit&quot;: &quot;percent&quot;,
            &quot;max&quot;: 100
          }
        }
      },
      {
        &quot;type&quot;: &quot;timeseries&quot;,
        &quot;title&quot;: &quot;Memory Usage&quot;,
        &quot;gridPos&quot;: {&quot;h&quot;: 8, &quot;w&quot;: 6, &quot;x&quot;: 6, &quot;y&quot;: 15},
        &quot;targets&quot;: [
          {
            &quot;expr&quot;: &quot;sum(container_memory_usage_bytes{namespace=\&quot;$namespace\&quot;, pod=~\&quot;$service-.*\&quot;}) by (pod)&quot;,
            &quot;legendFormat&quot;: &quot;{{pod}}&quot;
          }
        ],
        &quot;fieldConfig&quot;: {
          &quot;defaults&quot;: {
            &quot;unit&quot;: &quot;bytes&quot;
          }
        }
      },
      {
        &quot;type&quot;: &quot;timeseries&quot;,
        &quot;title&quot;: &quot;Network I/O&quot;,
        &quot;gridPos&quot;: {&quot;h&quot;: 8, &quot;w&quot;: 6, &quot;x&quot;: 12, &quot;y&quot;: 15},
        &quot;targets&quot;: [
          {
            &quot;expr&quot;: &quot;sum(rate(container_network_receive_bytes_total{namespace=\&quot;$namespace\&quot;, pod=~\&quot;$service-.*\&quot;}[$interval])) by (pod)&quot;,
            &quot;legendFormat&quot;: &quot;RX {{pod}}&quot;
          },
          {
            &quot;expr&quot;: &quot;sum(rate(container_network_transmit_bytes_total{namespace=\&quot;$namespace\&quot;, pod=~\&quot;$service-.*\&quot;}[$interval])) by (pod)&quot;,
            &quot;legendFormat&quot;: &quot;TX {{pod}}&quot;
          }
        ],
        &quot;fieldConfig&quot;: {
          &quot;defaults&quot;: {
            &quot;unit&quot;: &quot;Bps&quot;
          }
        }
      },
      {
        &quot;type&quot;: &quot;timeseries&quot;,
        &quot;title&quot;: &quot;Disk I/O&quot;,
        &quot;gridPos&quot;: {&quot;h&quot;: 8, &quot;w&quot;: 6, &quot;x&quot;: 18, &quot;y&quot;: 15},
        &quot;targets&quot;: [
          {
            &quot;expr&quot;: &quot;sum(rate(container_fs_reads_bytes_total{namespace=\&quot;$namespace\&quot;, pod=~\&quot;$service-.*\&quot;}[$interval])) by (pod)&quot;,
            &quot;legendFormat&quot;: &quot;Read {{pod}}&quot;
          },
          {
            &quot;expr&quot;: &quot;sum(rate(container_fs_writes_bytes_total{namespace=\&quot;$namespace\&quot;, pod=~\&quot;$service-.*\&quot;}[$interval])) by (pod)&quot;,
            &quot;legendFormat&quot;: &quot;Write {{pod}}&quot;
          }
        ],
        &quot;fieldConfig&quot;: {
          &quot;defaults&quot;: {
            &quot;unit&quot;: &quot;Bps&quot;
          }
        }
      }
    ]
  }
}</code></pre>
<p>#### Import Dashboard</p>
<pre><code class="language-bash"># Save dashboard JSON to file
cat &gt; dashboard.json &lt;&lt; &#039;EOF&#039;
{... dashboard JSON ...}
EOF
<h1>Import via API</h1>
curl -X POST -H &quot;Content-Type: application/json&quot; \
  -d @dashboard.json \
  http://admin:admin@localhost:3000/api/dashboards/db
<h1>Or import via UI: Dashboards ‚Üí Import ‚Üí Upload JSON</code></pre></h1>
<p>#### Test Dashboard</p>
<pre><code class="language-bash"># Generate metrics
for i in {1..1000}; do
  curl http://api:8080/api/products
  curl -X POST http://api:8080/api/orders
  sleep 0.1
done
<h1>Verify variables populate</h1>
<h1>Verify panels show data</h1>
<h1>Test alert conditions by causing errors</code></pre></h1>
<p>---</p>
<h2>Summary</h2>
<p>You've learned:
<li>‚úÖ Grafana installation and data source configuration</li>
<li>‚úÖ Creating dashboards with multiple panel types</li>
<li>‚úÖ Variables and templating for dynamic dashboards</li>
<li>‚úÖ Alerting with notification channels</li>
<li>‚úÖ Best practices for organization and performance</li>
<li>‚úÖ Advanced features: annotations, transformations, plugins</li></ul></p>
<strong>Next Module</strong>: [Module 28: EFK Stack](28_EFK_Stack.md) - Learn centralized logging with Elasticsearch, Fluentd, and Kibana.

    </div>
    

    <div class="module-content" id="module-28">
        <h1>Module 28: EFK Stack - Centralized Logging</h1>
<h2>Table of Contents</h2>
<ul><li>[Introduction to EFK](#introduction)</li>
<li>[Elasticsearch Fundamentals](#elasticsearch)</li>
<li>[Fluentd Log Collection](#fluentd)</li>
<li>[Kibana Visualization](#kibana)</li>
<li>[Kubernetes Integration](#kubernetes)</li>
<li>[Log Parsing and Enrichment](#parsing)</li>
<li>[Search and Analysis](#search)</li>
<li>[Best Practices](#best-practices)</li>
<li>[Interview Questions](#interview-questions)</li>
<li>[Hands-On Exercise](#exercise)</li>
<p>---</p>
<h2>Introduction to EFK {#introduction}</h2>
<p>EFK Stack is a centralized logging solution for aggregating, processing, and visualizing logs.</p>
<h3>Stack Components</h3>
<pre><code class="language-text">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Applications ‚îÇ Generate logs
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Fluentd    ‚îÇ Collect &amp; parse logs
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇElasticsearch ‚îÇ Store &amp; index logs
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ    Kibana    ‚îÇ Visualize &amp; search
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</code></pre>
<strong>Elasticsearch</strong>: Search and analytics engine (storage)
<strong>Fluentd</strong>: Log collector and forwarder (collection)
<strong>Kibana</strong>: Visualization and UI (analysis)
<h3>Why Centralized Logging?</h3>
<p>‚úÖ <strong>Troubleshooting</strong>: Search across all services in one place
‚úÖ <strong>Monitoring</strong>: Track error rates, patterns, anomalies
‚úÖ <strong>Compliance</strong>: Audit trails, security events
‚úÖ <strong>Performance</strong>: Identify slow queries, bottlenecks
‚úÖ <strong>Correlation</strong>: Link logs across microservices</p>
<h3>EFK vs ELK</h3>
<p>| Component | EFK | ELK |
|-----------|-----|-----|
| Collector | Fluentd | Logstash |
| Language | C/Ruby | Java |
| Memory | Lower (~40MB) | Higher (~500MB) |
| Plugins | 500+ | 200+ |
| K8s Native | Yes | No |</p>
<p>---</p>
<h2>Elasticsearch Fundamentals {#elasticsearch}</h2>
<h3>Architecture</h3>
<pre><code class="language-text">Cluster
‚îú‚îÄ‚îÄ Node 1 (Master, Data)
‚îú‚îÄ‚îÄ Node 2 (Data)
‚îî‚îÄ‚îÄ Node 3 (Data)
    ‚îú‚îÄ‚îÄ Index: logs-2024.12.10
    ‚îÇ   ‚îú‚îÄ‚îÄ Shard 0 (Primary)
    ‚îÇ   ‚îú‚îÄ‚îÄ Shard 0 (Replica)
    ‚îÇ   ‚îú‚îÄ‚îÄ Shard 1 (Primary)
    ‚îÇ   ‚îî‚îÄ‚îÄ Shard 1 (Replica)
    ‚îî‚îÄ‚îÄ Index: logs-2024.12.11</code></pre>
<strong>Cluster</strong>: Collection of nodes
<strong>Node</strong>: Single Elasticsearch instance
<strong>Index</strong>: Collection of documents (like database)
<strong>Shard</strong>: Subset of index data
<strong>Replica</strong>: Copy of shard for redundancy
<h3>Installation (Docker)</h3>
<pre><code class="language-yaml"># docker-compose.yml
version: &#039;3&#039;
services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    environment:
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
      - xpack.security.enabled=false
    ports:
      - &quot;9200:9200&quot;
      - &quot;9300:9300&quot;
    volumes:
      - es-data:/usr/share/elasticsearch/data
    networks:
      - efk
<p>kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - &quot;5601:5601&quot;
    depends_on:
      - elasticsearch
    networks:
      - efk</p>
<p>fluentd:
    build: ./fluentd
    ports:
      - &quot;24224:24224&quot;
      - &quot;24224:24224/udp&quot;
    volumes:
      - ./fluentd/conf:/fluentd/etc
    depends_on:
      - elasticsearch
    networks:
      - efk</p>
<p>volumes:
  es-data:</p>
<p>networks:
  efk:</code></pre></p>
<pre><code class="language-bash">docker-compose up -d
<h1>Verify Elasticsearch</h1>
curl http://localhost:9200
<h1>{</h1>
<h1>  &quot;cluster_name&quot; : &quot;docker-cluster&quot;,</h1>
<h1>  &quot;cluster_uuid&quot; : &quot;...&quot;,</h1>
<h1>  &quot;version&quot; : { &quot;number&quot; : &quot;8.11.0&quot; }</h1>
<h1>}</h1>
<h1>Verify Kibana</h1>
open http://localhost:5601</code></pre>
<h3>Index Management</h3>
<pre><code class="language-bash"># Create index
curl -X PUT &quot;localhost:9200/logs-2024.12.10&quot; -H &#039;Content-Type: application/json&#039; -d&#039;
{
  &quot;settings&quot;: {
    &quot;number_of_shards&quot;: 2,
    &quot;number_of_replicas&quot;: 1
  },
  &quot;mappings&quot;: {
    &quot;properties&quot;: {
      &quot;timestamp&quot;: {&quot;type&quot;: &quot;date&quot;},
      &quot;level&quot;: {&quot;type&quot;: &quot;keyword&quot;},
      &quot;service&quot;: {&quot;type&quot;: &quot;keyword&quot;},
      &quot;message&quot;: {&quot;type&quot;: &quot;text&quot;},
      &quot;user_id&quot;: {&quot;type&quot;: &quot;keyword&quot;},
      &quot;request_id&quot;: {&quot;type&quot;: &quot;keyword&quot;},
      &quot;duration_ms&quot;: {&quot;type&quot;: &quot;integer&quot;}
    }
  }
}
&#039;
<h1>List indices</h1>
curl &quot;localhost:9200/_cat/indices?v&quot;
<h1>Delete index</h1>
curl -X DELETE &quot;localhost:9200/logs-2024.12.10&quot;</code></pre>
<h3>Index Templates</h3>
<pre><code class="language-bash"># Create template for daily indices
curl -X PUT &quot;localhost:9200/_index_template/logs-template&quot; -H &#039;Content-Type: application/json&#039; -d&#039;
{
  &quot;index_patterns&quot;: [&quot;logs-*&quot;],
  &quot;template&quot;: {
    &quot;settings&quot;: {
      &quot;number_of_shards&quot;: 2,
      &quot;number_of_replicas&quot;: 1,
      &quot;index.lifecycle.name&quot;: &quot;logs-policy&quot;,
      &quot;index.lifecycle.rollover_alias&quot;: &quot;logs&quot;
    },
    &quot;mappings&quot;: {
      &quot;properties&quot;: {
        &quot;@timestamp&quot;: {&quot;type&quot;: &quot;date&quot;},
        &quot;level&quot;: {&quot;type&quot;: &quot;keyword&quot;},
        &quot;service&quot;: {&quot;type&quot;: &quot;keyword&quot;},
        &quot;namespace&quot;: {&quot;type&quot;: &quot;keyword&quot;},
        &quot;pod&quot;: {&quot;type&quot;: &quot;keyword&quot;},
        &quot;container&quot;: {&quot;type&quot;: &quot;keyword&quot;},
        &quot;message&quot;: {&quot;type&quot;: &quot;text&quot;},
        &quot;stack_trace&quot;: {&quot;type&quot;: &quot;text&quot;}
      }
    }
  }
}
&#039;</code></pre>
<h3>Index Lifecycle Management (ILM)</h3>
<pre><code class="language-bash"># Create lifecycle policy
curl -X PUT &quot;localhost:9200/_ilm/policy/logs-policy&quot; -H &#039;Content-Type: application/json&#039; -d&#039;
{
  &quot;policy&quot;: {
    &quot;phases&quot;: {
      &quot;hot&quot;: {
        &quot;actions&quot;: {
          &quot;rollover&quot;: {
            &quot;max_size&quot;: &quot;50GB&quot;,
            &quot;max_age&quot;: &quot;1d&quot;
          }
        }
      },
      &quot;warm&quot;: {
        &quot;min_age&quot;: &quot;7d&quot;,
        &quot;actions&quot;: {
          &quot;shrink&quot;: {
            &quot;number_of_shards&quot;: 1
          },
          &quot;forcemerge&quot;: {
            &quot;max_num_segments&quot;: 1
          }
        }
      },
      &quot;delete&quot;: {
        &quot;min_age&quot;: &quot;30d&quot;,
        &quot;actions&quot;: {
          &quot;delete&quot;: {}
        }
      }
    }
  }
}
&#039;</code></pre>
<h3>CRUD Operations</h3>
<pre><code class="language-bash"># Index document (create)
curl -X POST &quot;localhost:9200/logs-2024.12.10/_doc&quot; -H &#039;Content-Type: application/json&#039; -d&#039;
{
  &quot;timestamp&quot;: &quot;2024-12-10T10:30:00Z&quot;,
  &quot;level&quot;: &quot;ERROR&quot;,
  &quot;service&quot;: &quot;api-gateway&quot;,
  &quot;message&quot;: &quot;Database connection timeout&quot;,
  &quot;duration_ms&quot;: 5000
}
&#039;
<h1>Get document</h1>
curl &quot;localhost:9200/logs-2024.12.10/_doc/DOCUMENT_ID&quot;
<h1>Update document</h1>
curl -X POST &quot;localhost:9200/logs-2024.12.10/_update/DOCUMENT_ID&quot; -H &#039;Content-Type: application/json&#039; -d&#039;
{
  &quot;doc&quot;: {
    &quot;resolved&quot;: true
  }
}
&#039;
<h1>Delete document</h1>
curl -X DELETE &quot;localhost:9200/logs-2024.12.10/_doc/DOCUMENT_ID&quot;</code></pre>
<h3>Search Queries</h3>
<pre><code class="language-bash"># Match all
curl &quot;localhost:9200/logs-*/_search?pretty&quot; -H &#039;Content-Type: application/json&#039; -d&#039;
{
  &quot;query&quot;: {
    &quot;match_all&quot;: {}
  }
}
&#039;
<h1>Match specific field</h1>
curl &quot;localhost:9200/logs-*/_search?pretty&quot; -H &#039;Content-Type: application/json&#039; -d&#039;
{
  &quot;query&quot;: {
    &quot;match&quot;: {
      &quot;level&quot;: &quot;ERROR&quot;
    }
  }
}
&#039;
<h1>Boolean query (AND, OR, NOT)</h1>
curl &quot;localhost:9200/logs-*/_search?pretty&quot; -H &#039;Content-Type: application/json&#039; -d&#039;
{
  &quot;query&quot;: {
    &quot;bool&quot;: {
      &quot;must&quot;: [
        {&quot;match&quot;: {&quot;level&quot;: &quot;ERROR&quot;}},
        {&quot;range&quot;: {&quot;duration_ms&quot;: {&quot;gte&quot;: 1000}}}
      ],
      &quot;filter&quot;: [
        {&quot;term&quot;: {&quot;service&quot;: &quot;api-gateway&quot;}}
      ]
    }
  }
}
&#039;
<h1>Aggregations</h1>
curl &quot;localhost:9200/logs-*/_search?pretty&quot; -H &#039;Content-Type: application/json&#039; -d&#039;
{
  &quot;size&quot;: 0,
  &quot;aggs&quot;: {
    &quot;errors_by_service&quot;: {
      &quot;terms&quot;: {
        &quot;field&quot;: &quot;service&quot;,
        &quot;size&quot;: 10
      }
    },
    &quot;avg_duration&quot;: {
      &quot;avg&quot;: {
        &quot;field&quot;: &quot;duration_ms&quot;
      }
    }
  }
}
&#039;</code></pre>
<p>---</p>
<h2>Fluentd Log Collection {#fluentd}</h2>
<h3>Fluentd Architecture</h3>
<pre><code class="language-text">Input ‚Üí Parser ‚Üí Filter ‚Üí Output
  ‚Üì        ‚Üì        ‚Üì        ‚Üì
tail    regexp   record   elasticsearch
http    json     add_tag  s3
syslog  multiline geoip   kafka</code></pre>
<h3>Dockerfile for Fluentd</h3>
<pre><code class="language-dockerfile"># fluentd/Dockerfile
FROM fluent/fluentd:v1.16-1
<p>USER root</p>
<h1>Install plugins</h1>
RUN gem install fluent-plugin-elasticsearch \
    &amp;&amp; gem install fluent-plugin-rewrite-tag-filter \
    &amp;&amp; gem install fluent-plugin-parser \
    &amp;&amp; gem install fluent-plugin-concat
<p>USER fluent</code></pre></p>
<h3>Fluentd Configuration</h3>
<pre><code class="language-ruby"># fluentd/conf/fluent.conf
<h1>Input: Collect from Docker containers</h1>
&lt;source&gt;
  @type forward
  port 24224
  bind 0.0.0.0
&lt;/source&gt;
<h1>Input: Tail log files</h1>
&lt;source&gt;
  @type tail
  path /var/log/app/*.log
  pos_file /var/log/td-agent/app.log.pos
  tag app.logs
  &lt;parse&gt;
    @type json
    time_key timestamp
    time_format %Y-%m-%dT%H:%M:%S.%NZ
  &lt;/parse&gt;
&lt;/source&gt;
<h1>Filter: Add hostname</h1>
&lt;filter **&gt;
  @type record_transformer
  &lt;record&gt;
    hostname &quot;#{Socket.gethostname}&quot;
    tag ${tag}
  &lt;/record&gt;
&lt;/filter&gt;
<h1>Filter: Parse JSON logs</h1>
&lt;filter app.**&gt;
  @type parser
  key_name log
  &lt;parse&gt;
    @type json
  &lt;/parse&gt;
&lt;/filter&gt;
<h1>Output: Send to Elasticsearch</h1>
&lt;match **&gt;
  @type elasticsearch
  host elasticsearch
  port 9200
  logstash_format true
  logstash_prefix logs
  logstash_dateformat %Y.%m.%d
  include_tag_key true
  type_name _doc
  tag_key @log_name
  &lt;buffer&gt;
    @type file
    path /var/log/td-agent/buffer/es
    flush_interval 5s
    retry_max_interval 30s
    retry_forever true
  &lt;/buffer&gt;
&lt;/match&gt;</code></pre>
<h3>Go Application Logging (JSON Format)</h3>
<pre><code class="language-go">package main
<p>import (
    &quot;encoding/json&quot;
    &quot;log&quot;
    &quot;os&quot;
    &quot;time&quot;
)</p>
<p>type LogEntry struct {
    Timestamp   string                 <code>json:&quot;@timestamp&quot;</code>
    Level       string                 <code>json:&quot;level&quot;</code>
    Service     string                 <code>json:&quot;service&quot;</code>
    Message     string                 <code>json:&quot;message&quot;</code>
    RequestID   string                 <code>json:&quot;request_id,omitempty&quot;</code>
    UserID      string                 <code>json:&quot;user_id,omitempty&quot;</code>
    DurationMs  int64                  <code>json:&quot;duration_ms,omitempty&quot;</code>
    Error       string                 <code>json:&quot;error,omitempty&quot;</code>
    StackTrace  string                 <code>json:&quot;stack_trace,omitempty&quot;</code>
    Metadata    map[string]interface{} <code>json:&quot;metadata,omitempty&quot;</code>
}</p>
<p>type Logger struct {
    service string
    output  *json.Encoder
}</p>
<p>func NewLogger(service string) *Logger {
    return &amp;Logger{
        service: service,
        output:  json.NewEncoder(os.Stdout),
    }
}</p>
<p>func (l *Logger) log(level, message string, fields map[string]interface{}) {
    entry := LogEntry{
        Timestamp: time.Now().UTC().Format(time.RFC3339Nano),
        Level:     level,
        Service:   l.service,
        Message:   message,
        Metadata:  fields,
    }
    
    if requestID, ok := fields[&quot;request_id&quot;].(string); ok {
        entry.RequestID = requestID
    }
    if userID, ok := fields[&quot;user_id&quot;].(string); ok {
        entry.UserID = userID
    }
    if duration, ok := fields[&quot;duration_ms&quot;].(int64); ok {
        entry.DurationMs = duration
    }
    if err, ok := fields[&quot;error&quot;].(string); ok {
        entry.Error = err
    }
    
    l.output.Encode(entry)
}</p>
<p>func (l *Logger) Info(message string, fields map[string]interface{}) {
    l.log(&quot;INFO&quot;, message, fields)
}</p>
<p>func (l *Logger) Error(message string, fields map[string]interface{}) {
    l.log(&quot;ERROR&quot;, message, fields)
}</p>
<p>func (l *Logger) Warn(message string, fields map[string]interface{}) {
    l.log(&quot;WARN&quot;, message, fields)
}</p>
<p>func (l *Logger) Debug(message string, fields map[string]interface{}) {
    l.log(&quot;DEBUG&quot;, message, fields)
}</p>
<p>// Usage example
func main() {
    logger := NewLogger(&quot;api-gateway&quot;)
    
    logger.Info(&quot;Server started&quot;, map[string]interface{}{
        &quot;port&quot;: 8080,
    })
    
    logger.Error(&quot;Database connection failed&quot;, map[string]interface{}{
        &quot;error&quot;:    &quot;connection timeout&quot;,
        &quot;host&quot;:     &quot;db.example.com&quot;,
        &quot;duration_ms&quot;: 5000,
    })
    
    logger.Warn(&quot;High memory usage&quot;, map[string]interface{}{
        &quot;memory_mb&quot;: 1024,
        &quot;threshold&quot;: 800,
    })
}</code></pre></p>
<h3>Multiline Log Parsing</h3>
<pre><code class="language-ruby"># Parse Java stack traces
&lt;filter app.**&gt;
  @type concat
  key log
  multiline_start_regexp /^[^\s]/
  flush_interval 5s
  timeout_label @NORMAL
&lt;/filter&gt;
<p>&lt;filter app.**&gt;
  @type parser
  key_name log
  &lt;parse&gt;
    @type multiline
    format_firstline /\d{4}-\d{2}-\d{2}/
    format1 /^(?&lt;timestamp&gt;\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}) \[(?&lt;level&gt;\w+)\] (?&lt;message&gt;.*)/
  &lt;/parse&gt;
&lt;/filter&gt;</code></pre></p>
<p>---</p>
<h2>Kibana Visualization {#kibana}</h2>
<h3>Initial Setup</h3>
<p>1. <strong>Access Kibana</strong>: http://localhost:5601
2. <strong>Create Index Pattern</strong>:
   - Management ‚Üí Index Patterns ‚Üí Create
   - Pattern: <code>logs-*</code>
   - Time field: <code>@timestamp</code>
   - Click "Create"</p>
<h3>Discover Tab</h3>
<p>Search and explore logs in real-time.</p>
<pre><code class="language-text"># KQL (Kibana Query Language) examples
<h1>Simple search</h1>
level: ERROR
<h1>AND condition</h1>
level: ERROR AND service: &quot;api-gateway&quot;
<h1>OR condition</h1>
level: ERROR OR level: WARN
<h1>Range query</h1>
duration_ms &gt;= 1000 AND duration_ms &lt; 5000
<h1>Wildcard</h1>
message: *timeout*
<h1>Exists</h1>
_exists_: error
<h1>Not exists</h1>
NOT _exists_: user_id</code></pre>
<h3>Creating Visualizations</h3>
<strong>1. Line Chart - Error Rate Over Time</strong>
<pre><code class="language-json">{
  &quot;type&quot;: &quot;line&quot;,
  &quot;metrics&quot;: [
    {
      &quot;type&quot;: &quot;count&quot;,
      &quot;schema&quot;: &quot;metric&quot;
    }
  ],
  &quot;buckets&quot;: [
    {
      &quot;type&quot;: &quot;date_histogram&quot;,
      &quot;schema&quot;: &quot;segment&quot;,
      &quot;params&quot;: {
        &quot;field&quot;: &quot;@timestamp&quot;,
        &quot;interval&quot;: &quot;1m&quot;
      }
    },
    {
      &quot;type&quot;: &quot;filters&quot;,
      &quot;schema&quot;: &quot;group&quot;,
      &quot;params&quot;: {
        &quot;filters&quot;: [
          {&quot;input&quot;: {&quot;query&quot;: &quot;level: ERROR&quot;}, &quot;label&quot;: &quot;Errors&quot;},
          {&quot;input&quot;: {&quot;query&quot;: &quot;level: WARN&quot;}, &quot;label&quot;: &quot;Warnings&quot;}
        ]
      }
    }
  ]
}</code></pre>
<strong>2. Pie Chart - Logs by Service</strong>
<pre><code class="language-json">{
  &quot;type&quot;: &quot;pie&quot;,
  &quot;metrics&quot;: [
    {&quot;type&quot;: &quot;count&quot;}
  ],
  &quot;buckets&quot;: [
    {
      &quot;type&quot;: &quot;terms&quot;,
      &quot;schema&quot;: &quot;segment&quot;,
      &quot;params&quot;: {
        &quot;field&quot;: &quot;service.keyword&quot;,
        &quot;size&quot;: 10,
        &quot;order&quot;: &quot;desc&quot;,
        &quot;orderBy&quot;: &quot;_count&quot;
      }
    }
  ]
}</code></pre>
<strong>3. Data Table - Top Errors</strong>
<pre><code class="language-json">{
  &quot;type&quot;: &quot;table&quot;,
  &quot;metrics&quot;: [
    {&quot;type&quot;: &quot;count&quot;, &quot;schema&quot;: &quot;metric&quot;}
  ],
  &quot;buckets&quot;: [
    {
      &quot;type&quot;: &quot;terms&quot;,
      &quot;schema&quot;: &quot;bucket&quot;,
      &quot;params&quot;: {
        &quot;field&quot;: &quot;message.keyword&quot;,
        &quot;size&quot;: 20,
        &quot;order&quot;: &quot;desc&quot;,
        &quot;orderBy&quot;: &quot;_count&quot;
      }
    },
    {
      &quot;type&quot;: &quot;terms&quot;,
      &quot;schema&quot;: &quot;bucket&quot;,
      &quot;params&quot;: {
        &quot;field&quot;: &quot;service.keyword&quot;,
        &quot;size&quot;: 5
      }
    }
  ]
}</code></pre>
<strong>4. Heatmap - Response Time Distribution</strong>
<pre><code class="language-json">{
  &quot;type&quot;: &quot;heatmap&quot;,
  &quot;metrics&quot;: [
    {&quot;type&quot;: &quot;avg&quot;, &quot;field&quot;: &quot;duration_ms&quot;}
  ],
  &quot;buckets&quot;: [
    {
      &quot;type&quot;: &quot;date_histogram&quot;,
      &quot;field&quot;: &quot;@timestamp&quot;,
      &quot;interval&quot;: &quot;5m&quot;
    },
    {
      &quot;type&quot;: &quot;histogram&quot;,
      &quot;field&quot;: &quot;duration_ms&quot;,
      &quot;interval&quot;: 100
    }
  ]
}</code></pre>
<h3>Creating Dashboards</h3>
<pre><code class="language-text">Dashboard: Application Monitoring
‚îú‚îÄ‚îÄ Row 1: Overview
‚îÇ   ‚îú‚îÄ‚îÄ Total Logs (Metric)
‚îÇ   ‚îú‚îÄ‚îÄ Error Count (Metric)
‚îÇ   ‚îî‚îÄ‚îÄ Avg Response Time (Metric)
‚îú‚îÄ‚îÄ Row 2: Trends
‚îÇ   ‚îú‚îÄ‚îÄ Log Volume Over Time (Line)
‚îÇ   ‚îî‚îÄ‚îÄ Errors by Service (Bar)
‚îî‚îÄ‚îÄ Row 3: Details
    ‚îú‚îÄ‚îÄ Top Errors (Table)
    ‚îî‚îÄ‚îÄ Slow Requests (Table)</code></pre>
<h3>Saved Searches</h3>
<pre><code class="language-text">Search: Critical Errors
Query: level: ERROR AND duration_ms &gt; 5000
Fields: @timestamp, service, message, duration_ms, request_id
<p>Search: User Login Events
Query: message: &quot;user login&quot; OR message: &quot;authentication&quot;
Fields: @timestamp, user_id, ip_address, status</code></pre></p>
<p>---</p>
<h2>Kubernetes Integration {#kubernetes}</h2>
<h3>Fluentd DaemonSet</h3>
<pre><code class="language-yaml"># fluentd-daemonset.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: fluentd
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: fluentd
rules:
<li>apiGroups:</li>
  - &quot;&quot;
  resources:
  - pods
  - namespaces
  verbs:
  - get
  - list
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: fluentd
roleRef:
  kind: ClusterRole
  name: fluentd
  apiGroup: rbac.authorization.k8s.io
subjects:
<li>kind: ServiceAccount</li>
  name: fluentd
  namespace: kube-system
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluentd
  namespace: kube-system
  labels:
    app: fluentd
spec:
  selector:
    matchLabels:
      app: fluentd
  template:
    metadata:
      labels:
        app: fluentd
    spec:
      serviceAccountName: fluentd
      containers:
      - name: fluentd
        image: fluent/fluentd-kubernetes-daemonset:v1-debian-elasticsearch
        env:
        - name: FLUENT_ELASTICSEARCH_HOST
          value: &quot;elasticsearch.logging.svc.cluster.local&quot;
        - name: FLUENT_ELASTICSEARCH_PORT
          value: &quot;9200&quot;
        - name: FLUENT_ELASTICSEARCH_SCHEME
          value: &quot;http&quot;
        - name: FLUENT_ELASTICSEARCH_LOGSTASH_PREFIX
          value: &quot;k8s-logs&quot;
        - name: FLUENT_ELASTICSEARCH_LOGSTASH_FORMAT
          value: &quot;true&quot;
        resources:
          limits:
            memory: 200Mi
          requests:
            cpu: 100m
            memory: 200Mi
        volumeMounts:
        - name: varlog
          mountPath: /var/log
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
        - name: config
          mountPath: /fluentd/etc/fluent.conf
          subPath: fluent.conf
      volumes:
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
      - name: config
        configMap:
          name: fluentd-config</code></pre>
<h3>Fluentd ConfigMap for Kubernetes</h3>
<pre><code class="language-yaml"># fluentd-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluentd-config
  namespace: kube-system
data:
  fluent.conf: |
    # Input: Kubernetes logs
    &lt;source&gt;
      @type tail
      path /var/log/containers/*.log
      pos_file /var/log/fluentd-containers.log.pos
      tag kubernetes.*
      read_from_head true
      &lt;parse&gt;
        @type json
        time_format %Y-%m-%dT%H:%M:%S.%NZ
      &lt;/parse&gt;
    &lt;/source&gt;
<p># Filter: Kubernetes metadata
    &lt;filter kubernetes.**&gt;
      @type kubernetes_metadata
      @id filter_kube_metadata
      kubernetes_url &quot;#{ENV[&#039;FLUENT_FILTER_KUBERNETES_URL&#039;] || &#039;https://&#039; + ENV.fetch(&#039;KUBERNETES_SERVICE_HOST&#039;) + &#039;:&#039; + ENV.fetch(&#039;KUBERNETES_SERVICE_PORT&#039;) + &#039;/api&#039;}&quot;
      verify_ssl &quot;#{ENV[&#039;KUBERNETES_VERIFY_SSL&#039;] || true}&quot;
      ca_file &quot;#{ENV[&#039;KUBERNETES_CA_FILE&#039;]}&quot;
    &lt;/filter&gt;</p>
<p># Filter: Add custom fields
    &lt;filter kubernetes.**&gt;
      @type record_transformer
      &lt;record&gt;
        cluster_name &quot;#{ENV[&#039;CLUSTER_NAME&#039;] || &#039;production&#039;}&quot;
        environment &quot;#{ENV[&#039;ENVIRONMENT&#039;] || &#039;prod&#039;}&quot;
      &lt;/record&gt;
    &lt;/filter&gt;</p>
<p># Filter: Exclude system namespaces
    &lt;filter kubernetes.**&gt;
      @type grep
      &lt;exclude&gt;
        key $.kubernetes.namespace_name
        pattern ^(kube-system|kube-public|kube-node-lease)$
      &lt;/exclude&gt;
    &lt;/filter&gt;</p>
<p># Output: Elasticsearch
    &lt;match kubernetes.**&gt;
      @type elasticsearch
      @id out_es
      host &quot;#{ENV[&#039;FLUENT_ELASTICSEARCH_HOST&#039;]}&quot;
      port &quot;#{ENV[&#039;FLUENT_ELASTICSEARCH_PORT&#039;]}&quot;
      scheme &quot;#{ENV[&#039;FLUENT_ELASTICSEARCH_SCHEME&#039;] || &#039;http&#039;}&quot;
      logstash_format true
      logstash_prefix &quot;#{ENV[&#039;FLUENT_ELASTICSEARCH_LOGSTASH_PREFIX&#039;] || &#039;k8s-logs&#039;}&quot;
      &lt;buffer&gt;
        @type file
        path /var/log/fluentd-buffers/kubernetes.system.buffer
        flush_mode interval
        retry_type exponential_backoff
        flush_interval 5s
        retry_forever
        retry_max_interval 30
        chunk_limit_size 2M
        queue_limit_length 8
        overflow_action block
      &lt;/buffer&gt;
    &lt;/match&gt;</code></pre></p>
<h3>Deploy EFK Stack on Kubernetes</h3>
<pre><code class="language-bash"># Create namespace
kubectl create namespace logging
<h1>Deploy Elasticsearch</h1>
kubectl apply -f - &lt;&lt;EOF
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: elasticsearch
  namespace: logging
spec:
  serviceName: elasticsearch
  replicas: 1
  selector:
    matchLabels:
      app: elasticsearch
  template:
    metadata:
      labels:
        app: elasticsearch
    spec:
      containers:
      - name: elasticsearch
        image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
        env:
        - name: discovery.type
          value: single-node
        - name: ES_JAVA_OPTS
          value: &quot;-Xms512m -Xmx512m&quot;
        - name: xpack.security.enabled
          value: &quot;false&quot;
        ports:
        - containerPort: 9200
          name: http
        - containerPort: 9300
          name: transport
        volumeMounts:
        - name: data
          mountPath: /usr/share/elasticsearch/data
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: [ &quot;ReadWriteOnce&quot; ]
      resources:
        requests:
          storage: 10Gi
---
apiVersion: v1
kind: Service
metadata:
  name: elasticsearch
  namespace: logging
spec:
  selector:
    app: elasticsearch
  ports:
  - port: 9200
    name: http
  - port: 9300
    name: transport
EOF
<h1>Deploy Kibana</h1>
kubectl apply -f - &lt;&lt;EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kibana
  namespace: logging
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kibana
  template:
    metadata:
      labels:
        app: kibana
    spec:
      containers:
      - name: kibana
        image: docker.elastic.co/kibana/kibana:8.11.0
        env:
        - name: ELASTICSEARCH_HOSTS
          value: &quot;http://elasticsearch:9200&quot;
        ports:
        - containerPort: 5601
---
apiVersion: v1
kind: Service
metadata:
  name: kibana
  namespace: logging
spec:
  type: LoadBalancer
  selector:
    app: kibana
  ports:
  - port: 5601
    targetPort: 5601
EOF
<h1>Deploy Fluentd</h1>
kubectl apply -f fluentd-configmap.yaml
kubectl apply -f fluentd-daemonset.yaml
<h1>Verify</h1>
kubectl get pods -n logging
kubectl get pods -n kube-system -l app=fluentd</code></pre>
<p>---</p>
<h2>Log Parsing and Enrichment {#parsing}</h2>
<h3>Grok Patterns</h3>
<pre><code class="language-ruby"># Parse Apache access logs
&lt;filter apache.**&gt;
  @type parser
  key_name log
  &lt;parse&gt;
    @type grok
    grok_pattern %{COMBINEDAPACHELOG}
  &lt;/parse&gt;
&lt;/filter&gt;
<h1>Parse custom format</h1>
&lt;filter app.**&gt;
  @type parser
  key_name log
  &lt;parse&gt;
    @type grok
    grok_pattern \[%{TIMESTAMP_ISO8601:timestamp}\] %{LOGLEVEL:level} %{GREEDYDATA:message}
  &lt;/parse&gt;
&lt;/filter&gt;</code></pre>
<h3>GeoIP Enrichment</h3>
<pre><code class="language-ruby">&lt;filter web.**&gt;
  @type geoip
  geoip_lookup_keys client_ip
  &lt;record&gt;
    location ${city.names.en[&quot;client_ip&quot;]} ${country.names.en[&quot;client_ip&quot;]}
    latitude ${location.latitude[&quot;client_ip&quot;]}
    longitude ${location.longitude[&quot;client_ip&quot;]}
  &lt;/record&gt;
&lt;/filter&gt;</code></pre>
<h3>Custom Fields</h3>
<pre><code class="language-ruby">&lt;filter **&gt;
  @type record_transformer
  enable_ruby true
  &lt;record&gt;
    environment ${tag_parts[0]}
    timestamp ${time.strftime(&#039;%Y-%m-%dT%H:%M:%S%z&#039;)}
    log_level ${record[&quot;level&quot;] || &quot;INFO&quot;}
    day_of_week ${Time.now.strftime(&#039;%A&#039;)}
  &lt;/record&gt;
&lt;/filter&gt;</code></pre>
<p>---</p>
<h2>Search and Analysis {#search}</h2>
<h3>Lucene Query Syntax</h3>
<pre><code class="language-text"># Exact match
service:&quot;api-gateway&quot;
<h1>Wildcard</h1>
message:*timeout*
message:fail?
<h1>Range</h1>
duration_ms:[100 TO 500]
@timestamp:[now-1h TO now]
<h1>Boolean</h1>
level:ERROR AND service:&quot;api-gateway&quot;
level:ERROR OR level:WARN
level:ERROR NOT service:&quot;payment&quot;
<h1>Grouping</h1>
(level:ERROR OR level:WARN) AND service:&quot;api-gateway&quot;
<h1>Regular expression</h1>
message:/database.*error/</code></pre>
<h3>Aggregations in Kibana</h3>
<strong>Terms Aggregation</strong>:
<pre><code class="language-json">{
  &quot;aggs&quot;: {
    &quot;services&quot;: {
      &quot;terms&quot;: {
        &quot;field&quot;: &quot;service.keyword&quot;,
        &quot;size&quot;: 10
      }
    }
  }
}</code></pre>
<strong>Date Histogram</strong>:
<pre><code class="language-json">{
  &quot;aggs&quot;: {
    &quot;logs_over_time&quot;: {
      &quot;date_histogram&quot;: {
        &quot;field&quot;: &quot;@timestamp&quot;,
        &quot;calendar_interval&quot;: &quot;1h&quot;
      }
    }
  }
}</code></pre>
<strong>Nested Aggregation</strong>:
<pre><code class="language-json">{
  &quot;aggs&quot;: {
    &quot;by_service&quot;: {
      &quot;terms&quot;: {&quot;field&quot;: &quot;service.keyword&quot;},
      &quot;aggs&quot;: {
        &quot;by_level&quot;: {
          &quot;terms&quot;: {&quot;field&quot;: &quot;level.keyword&quot;}
        },
        &quot;avg_duration&quot;: {
          &quot;avg&quot;: {&quot;field&quot;: &quot;duration_ms&quot;}
        }
      }
    }
  }
}</code></pre>
<p>---</p>
<h2>Best Practices {#best-practices}</h2>
<h3>1. Structured Logging</h3>
<pre><code class="language-go">// ‚úÖ Good: Structured JSON
logger.Error(&quot;Payment failed&quot;, map[string]interface{}{
    &quot;user_id&quot;: &quot;12345&quot;,
    &quot;order_id&quot;: &quot;67890&quot;,
    &quot;amount&quot;: 99.99,
    &quot;error&quot;: &quot;insufficient_funds&quot;,
})
<p>// ‚ùå Bad: Unstructured string
log.Println(&quot;Payment failed for user 12345 order 67890 amount 99.99: insufficient funds&quot;)</code></pre></p>
<h3>2. Log Levels</h3>
<pre><code class="language-text">DEBUG: Detailed diagnostic information
INFO: General informational messages
WARN: Warning messages (potential issues)
ERROR: Error events (application can continue)
FATAL: Critical errors (application cannot continue)</code></pre>
<h3>3. Correlation IDs</h3>
<pre><code class="language-go">func loggingMiddleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        requestID := r.Header.Get(&quot;X-Request-ID&quot;)
        if requestID == &quot;&quot; {
            requestID = uuid.New().String()
        }
        
        ctx := context.WithValue(r.Context(), &quot;request_id&quot;, requestID)
        
        logger.Info(&quot;Request started&quot;, map[string]interface{}{
            &quot;request_id&quot;: requestID,
            &quot;method&quot;: r.Method,
            &quot;path&quot;: r.URL.Path,
        })
        
        next.ServeHTTP(w, r.WithContext(ctx))
    })
}</code></pre>
<h3>4. Sampling for High Volume</h3>
<pre><code class="language-ruby"># Sample 10% of INFO logs
&lt;filter app.**&gt;
  @type sampling_filter
  &lt;rule&gt;
    count 10
    sample 1
  &lt;/rule&gt;
  &lt;rule&gt;
    level ERROR
    sample 100  # Keep all errors
  &lt;/rule&gt;
&lt;/filter&gt;</code></pre>
<h3>5. Security</h3>
<pre><code class="language-ruby"># Redact sensitive fields
&lt;filter **&gt;
  @type record_modifier
  &lt;replace&gt;
    key password
    expression /.*/
    replace [REDACTED]
  &lt;/replace&gt;
  &lt;replace&gt;
    key credit_card
    expression /\d{4}-\d{4}-\d{4}-\d{4}/
    replace XXXX-XXXX-XXXX-XXXX
  &lt;/replace&gt;
&lt;/filter&gt;</code></pre>
<p>---</p>
<h2>Interview Questions {#interview-questions}</h2>
<strong>Q1: What is the difference between EFK and ELK stacks?</strong>
<strong>A:</strong> 
<li><strong>EFK</strong>: Elasticsearch, Fluentd, Kibana</li>
<li><strong>ELK</strong>: Elasticsearch, Logstash, Kibana</li>
<li><strong>Key Differences</strong>:</li>
  - Fluentd: Lower memory (~40MB), C/Ruby, K8s-native
  - Logstash: Higher memory (~500MB), Java, more features
  - Fluentd better for containers/K8s, Logstash for complex pipelines
<strong>Q2: How do you handle high log volumes in Elasticsearch?</strong>
<strong>A:</strong>
1. <strong>Index Lifecycle Management</strong>: Roll over indices daily, delete old data
2. <strong>Sharding</strong>: Distribute data across multiple shards
3. <strong>Sampling</strong>: Sample non-critical logs (keep all errors)
4. <strong>Buffer in Fluentd</strong>: Prevent data loss during ES downtime
5. <strong>Hot-Warm-Cold architecture</strong>: Move old data to cheaper storage
6. <strong>Compression</strong>: Enable compression for indices
<strong>Q3: Explain Fluentd buffering.</strong>
<strong>A:</strong>
<li><strong>Memory buffer</strong>: Fast, data loss if crash</li>
<li><strong>File buffer</strong>: Persistent, slower, survives restart</li>
<li><strong>Chunk limit</strong>: Max size per chunk (prevent OOM)</li>
<li><strong>Queue limit</strong>: Max chunks in queue</li>
<li><strong>Retry</strong>: Exponential backoff for failures</li>
<strong>Q4: How do you correlate logs across microservices?</strong>
<strong>A:</strong>
1. <strong>Request ID</strong>: Generate unique ID at API gateway, pass in headers
2. <strong>Trace ID</strong>: Use distributed tracing (Jaeger) alongside logs
3. <strong>User ID</strong>: Include user context in all logs
4. <strong>Session ID</strong>: Track user sessions
5. <strong>Kibana</strong>: Search by request_id to see full request flow
<strong>Q5: What is Index Lifecycle Management in Elasticsearch?</strong>
<strong>A:</strong>
ILM automates index management:
<li><strong>Hot phase</strong>: Active writes, fast storage (SSD)</li>
<li><strong>Warm phase</strong>: Read-only, slower storage (HDD), shrink shards</li>
<li><strong>Cold phase</strong>: Rarely accessed, searchable snapshots</li>
<li><strong>Delete phase</strong>: Remove old data after retention period</li>
<p>Example: Keep hot data for 1 day, warm for 7 days, delete after 30 days.</p>
<p>---</p>
<h2>Hands-On Exercise {#exercise}</h2>
<h3>Build a Production EFK Stack</h3>
<strong>Goal</strong>: Deploy EFK on Kubernetes with structured logging from a Go application.
<p>#### Step 1: Go Application with Structured Logging</p>
<pre><code class="language-go">// main.go
package main
<p>import (
    &quot;context&quot;
    &quot;encoding/json&quot;
    &quot;fmt&quot;
    &quot;math/rand&quot;
    &quot;net/http&quot;
    &quot;os&quot;
    &quot;time&quot;
    
    &quot;github.com/google/uuid&quot;
)</p>
<p>type LogEntry struct {
    Timestamp  string                 <code>json:&quot;@timestamp&quot;</code>
    Level      string                 <code>json:&quot;level&quot;</code>
    Service    string                 <code>json:&quot;service&quot;</code>
    Namespace  string                 <code>json:&quot;namespace&quot;</code>
    Pod        string                 <code>json:&quot;pod&quot;</code>
    Message    string                 <code>json:&quot;message&quot;</code>
    RequestID  string                 <code>json:&quot;request_id,omitempty&quot;</code>
    UserID     string                 <code>json:&quot;user_id,omitempty&quot;</code>
    Method     string                 <code>json:&quot;method,omitempty&quot;</code>
    Path       string                 <code>json:&quot;path,omitempty&quot;</code>
    StatusCode int                    <code>json:&quot;status_code,omitempty&quot;</code>
    DurationMs int64                  <code>json:&quot;duration_ms,omitempty&quot;</code>
    Error      string                 <code>json:&quot;error,omitempty&quot;</code>
}</p>
<p>var (
    service   = getEnv(&quot;SERVICE_NAME&quot;, &quot;shop-api&quot;)
    namespace = getEnv(&quot;NAMESPACE&quot;, &quot;default&quot;)
    pod       = getEnv(&quot;HOSTNAME&quot;, &quot;unknown&quot;)
)</p>
<p>func getEnv(key, fallback string) string {
    if value := os.Getenv(key); value != &quot;&quot; {
        return value
    }
    return fallback
}</p>
<p>func logJSON(entry LogEntry) {
    entry.Timestamp = time.Now().UTC().Format(time.RFC3339Nano)
    entry.Service = service
    entry.Namespace = namespace
    entry.Pod = pod
    json.NewEncoder(os.Stdout).Encode(entry)
}</p>
<p>func loggingMiddleware(next http.HandlerFunc) http.HandlerFunc {
    return func(w http.ResponseWriter, r *http.Request) {
        start := time.Now()
        requestID := r.Header.Get(&quot;X-Request-ID&quot;)
        if requestID == &quot;&quot; {
            requestID = uuid.New().String()
        }
        
        ctx := context.WithValue(r.Context(), &quot;request_id&quot;, requestID)
        rw := &amp;responseWriter{ResponseWriter: w, statusCode: 200}
        
        logJSON(LogEntry{
            Level:     &quot;INFO&quot;,
            Message:   &quot;Request started&quot;,
            RequestID: requestID,
            Method:    r.Method,
            Path:      r.URL.Path,
        })
        
        next(rw, r.WithContext(ctx))
        
        duration := time.Since(start).Milliseconds()
        level := &quot;INFO&quot;
        if rw.statusCode &gt;= 500 {
            level = &quot;ERROR&quot;
        } else if rw.statusCode &gt;= 400 {
            level = &quot;WARN&quot;
        }
        
        logJSON(LogEntry{
            Level:      level,
            Message:    &quot;Request completed&quot;,
            RequestID:  requestID,
            Method:     r.Method,
            Path:       r.URL.Path,
            StatusCode: rw.statusCode,
            DurationMs: duration,
        })
    }
}</p>
<p>type responseWriter struct {
    http.ResponseWriter
    statusCode int
}</p>
<p>func (rw *responseWriter) WriteHeader(code int) {
    rw.statusCode = code
    rw.ResponseWriter.WriteHeader(code)
}</p>
<p>func productsHandler(w http.ResponseWriter, r *http.Request) {
    requestID := r.Context().Value(&quot;request_id&quot;).(string)
    
    // Simulate some processing
    time.Sleep(time.Duration(rand.Intn(100)) * time.Millisecond)
    
    // Randomly generate errors
    if rand.Float32() &lt; 0.1 {
        logJSON(LogEntry{
            Level:     &quot;ERROR&quot;,
            Message:   &quot;Database query failed&quot;,
            RequestID: requestID,
            Error:     &quot;connection timeout&quot;,
        })
        http.Error(w, &quot;Internal Server Error&quot;, http.StatusInternalServerError)
        return
    }
    
    products := []map[string]interface{}{
        {&quot;id&quot;: 1, &quot;name&quot;: &quot;Product 1&quot;, &quot;price&quot;: 29.99},
        {&quot;id&quot;: 2, &quot;name&quot;: &quot;Product 2&quot;, &quot;price&quot;: 49.99},
    }
    
    w.Header().Set(&quot;Content-Type&quot;, &quot;application/json&quot;)
    json.NewEncoder(w).Encode(products)
}</p>
<p>func ordersHandler(w http.ResponseWriter, r *http.Request) {
    if r.Method != http.MethodPost {
        http.Error(w, &quot;Method not allowed&quot;, http.StatusMethodNotAllowed)
        return
    }
    
    requestID := r.Context().Value(&quot;request_id&quot;).(string)
    userID := fmt.Sprintf(&quot;user-%d&quot;, rand.Intn(1000))
    
    time.Sleep(time.Duration(rand.Intn(200)) * time.Millisecond)
    
    logJSON(LogEntry{
        Level:     &quot;INFO&quot;,
        Message:   &quot;Order created&quot;,
        RequestID: requestID,
        UserID:    userID,
    })
    
    response := map[string]interface{}{
        &quot;order_id&quot;: uuid.New().String(),
        &quot;status&quot;:   &quot;created&quot;,
    }
    
    w.Header().Set(&quot;Content-Type&quot;, &quot;application/json&quot;)
    json.NewEncoder(w).Encode(response)
}</p>
<p>func healthHandler(w http.ResponseWriter, r *http.Request) {
    w.Write([]byte(&quot;OK&quot;))
}</p>
<p>func main() {
    http.HandleFunc(&quot;/health&quot;, healthHandler)
    http.HandleFunc(&quot;/api/products&quot;, loggingMiddleware(productsHandler))
    http.HandleFunc(&quot;/api/orders&quot;, loggingMiddleware(ordersHandler))
    
    logJSON(LogEntry{
        Level:   &quot;INFO&quot;,
        Message: &quot;Server starting&quot;,
    })
    
    if err := http.ListenAndServe(&quot;:8080&quot;, nil); err != nil {
        logJSON(LogEntry{
            Level:   &quot;FATAL&quot;,
            Message: &quot;Server failed to start&quot;,
            Error:   err.Error(),
        })
    }
}</code></pre></p>
<p>#### Step 2: Kubernetes Deployment</p>
<pre><code class="language-yaml"># deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: shop-api
  namespace: default
spec:
  replicas: 2
  selector:
    matchLabels:
      app: shop-api
  template:
    metadata:
      labels:
        app: shop-api
    spec:
      containers:
      - name: shop-api
        image: shop-api:latest
        env:
        - name: SERVICE_NAME
          value: &quot;shop-api&quot;
        - name: NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        ports:
        - containerPort: 8080
---
apiVersion: v1
kind: Service
metadata:
  name: shop-api
spec:
  selector:
    app: shop-api
  ports:
  - port: 80
    targetPort: 8080</code></pre>
<p>#### Step 3: Generate Traffic and View Logs</p>
<pre><code class="language-bash"># Generate traffic
while true; do
  curl http://shop-api/api/products
  curl -X POST http://shop-api/api/orders
  sleep 0.5
done
<h1>View logs in Kibana</h1>
<h1>1. Go to Kibana ‚Üí Discover</h1>
<h1>2. Select index pattern: logs-*</h1>
<h1>3. Search queries:</h1>
<h1>   - level: ERROR</h1>
<h1>   - service: &quot;shop-api&quot; AND level: ERROR</h1>
<h1>   - duration_ms &gt; 100</h1>
<h1>   - request_id: &quot;specific-id&quot;</h1>
<h1>Create visualization:</h1>
<h1>- Error rate over time</h1>
<h1>- Average response time by endpoint</h1>
<h1>- Top errors by message</code></pre></h1>
<p>---</p>
<h2>Summary</h2>
<p>You've learned:
<li>‚úÖ EFK stack architecture and components</li>
<li>‚úÖ Elasticsearch indices, queries, and ILM</li>
<li>‚úÖ Fluentd configuration and log parsing</li>
<li>‚úÖ Kibana visualizations and dashboards</li>
<li>‚úÖ Kubernetes integration with DaemonSet</li>
<li>‚úÖ Structured logging in Go applications</li>
<li>‚úÖ Log correlation with request IDs</li>
<li>‚úÖ Best practices for production logging</li></ul></p>
<strong>Next Module</strong>: [Module 29: Distributed Tracing](29_Distributed_Tracing.md) - Learn end-to-end request tracing with Jaeger and OpenTelemetry.

    </div>
    

    <div class="module-content" id="module-29">
        <h1>Module 29: Distributed Tracing</h1>
<h2>Table of Contents</h2>
<ul><li>[Introduction to Distributed Tracing](#introduction)</li>
<li>[Tracing Concepts](#concepts)</li>
<li>[Jaeger Architecture](#jaeger)</li>
<li>[OpenTelemetry](#opentelemetry)</li>
<li>[Go Instrumentation](#go-instrumentation)</li>
<li>[Trace Context Propagation](#propagation)</li>
<li>[Sampling Strategies](#sampling)</li>
<li>[Integration with Logs and Metrics](#integration)</li>
<li>[Best Practices](#best-practices)</li>
<li>[Interview Questions](#interview-questions)</li>
<li>[Hands-On Exercise](#exercise)</li>
<p>---</p>
<h2>Introduction to Distributed Tracing {#introduction}</h2>
<p>Distributed tracing tracks requests as they flow through microservices, providing end-to-end visibility.</p>
<h3>Why Distributed Tracing?</h3>
<pre><code class="language-text">User Request ‚Üí API Gateway ‚Üí Auth Service ‚Üí User Service ‚Üí Database
                     ‚Üì
               Product Service ‚Üí Cache ‚Üí Database</code></pre>
<strong>Problems without tracing:</strong>
<li>Which service is slow?</li>
<li>Where did the request fail?</li>
<li>What's the dependency graph?</li>
<strong>With tracing:</strong>
<li>‚úÖ See complete request path</li>
<li>‚úÖ Identify bottlenecks</li>
<li>‚úÖ Track errors across services</li>
<li>‚úÖ Measure latency contributions</li>
<h3>Tracing vs Logging vs Metrics</h3>
<p>| Aspect | Tracing | Logging | Metrics |
|--------|---------|---------|---------|
| <strong>Purpose</strong> | Request flow | Events | Aggregated data |
| <strong>Granularity</strong> | Per-request | Per-event | Over time |
| <strong>Use Case</strong> | Debug latency | Error investigation | Alerting |
| <strong>Example</strong> | "Request took 500ms in Service A" | "Database error at 10:30" | "P95 latency: 200ms" |</p>
<p>---</p>
<h2>Tracing Concepts {#concepts}</h2>
<h3>Core Terminology</h3>
<strong>Trace</strong>: End-to-end journey of a request
<strong>Span</strong>: Single operation within a trace
<strong>Trace ID</strong>: Unique identifier for entire trace
<strong>Span ID</strong>: Unique identifier for span
<strong>Parent Span ID</strong>: Links child spans to parent
<h3>Trace Structure</h3>
<pre><code class="language-text">Trace ID: abc123 (Total: 850ms)
‚îú‚îÄ‚îÄ Span: API Gateway (200ms)
‚îÇ   ‚îú‚îÄ‚îÄ Span: Auth Service (50ms)
‚îÇ   ‚îî‚îÄ‚îÄ Span: User Service (150ms)
‚îÇ       ‚îú‚îÄ‚îÄ Span: Database Query (100ms)
‚îÇ       ‚îî‚îÄ‚îÄ Span: Cache Lookup (20ms)
‚îî‚îÄ‚îÄ Span: Product Service (450ms)
    ‚îú‚îÄ‚îÄ Span: Inventory Check (200ms)
    ‚îî‚îÄ‚îÄ Span: Price Calculation (250ms)</code></pre>
<h3>Span Attributes</h3>
<pre><code class="language-json">{
  &quot;trace_id&quot;: &quot;abc123def456&quot;,
  &quot;span_id&quot;: &quot;span789&quot;,
  &quot;parent_span_id&quot;: &quot;span456&quot;,
  &quot;operation_name&quot;: &quot;GET /api/users&quot;,
  &quot;start_time&quot;: &quot;2024-12-10T10:30:00Z&quot;,
  &quot;duration_ms&quot;: 150,
  &quot;tags&quot;: {
    &quot;http.method&quot;: &quot;GET&quot;,
    &quot;http.url&quot;: &quot;/api/users&quot;,
    &quot;http.status_code&quot;: 200,
    &quot;service.name&quot;: &quot;user-service&quot;,
    &quot;db.type&quot;: &quot;postgres&quot;,
    &quot;db.statement&quot;: &quot;SELECT * FROM users WHERE id = ?&quot;
  },
  &quot;logs&quot;: [
    {
      &quot;timestamp&quot;: &quot;2024-12-10T10:30:00.050Z&quot;,
      &quot;event&quot;: &quot;cache_miss&quot;,
      &quot;key&quot;: &quot;user:123&quot;
    }
  ]
}</code></pre>
<p>---</p>
<h2>Jaeger Architecture {#jaeger}</h2>
<h3>Components</h3>
<pre><code class="language-text">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Application ‚îÇ Sends spans
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Jaeger Agent ‚îÇ Local daemon (UDP)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇJaeger Collector‚îÇ Receives, processes, validates
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ           ‚îÇ Storage      ‚îÇ Cassandra, Elasticsearch, Kafka
       ‚îÇ           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                   ‚îÇ Jaeger Query ‚îÇ API for retrieving traces
                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
                          ‚ñº
                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                   ‚îÇ Jaeger UI    ‚îÇ Web interface
                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</code></pre>
<h3>Installation (Docker)</h3>
<pre><code class="language-yaml"># docker-compose.yml
version: &#039;3&#039;
services:
  jaeger:
    image: jaegertracing/all-in-one:latest
    environment:
      - COLLECTOR_ZIPKIN_HTTP_PORT=9411
    ports:
      - &quot;5775:5775/udp&quot;  # Agent zipkin.thrift compact
      - &quot;6831:6831/udp&quot;  # Agent jaeger.thrift compact
      - &quot;6832:6832/udp&quot;  # Agent jaeger.thrift binary
      - &quot;5778:5778&quot;      # Agent config
      - &quot;16686:16686&quot;    # UI
      - &quot;14268:14268&quot;    # Collector HTTP
      - &quot;9411:9411&quot;      # Collector Zipkin
    networks:
      - tracing
<p>networks:
  tracing:</code></pre></p>
<pre><code class="language-bash">docker-compose up -d
<h1>Access Jaeger UI</h1>
open http://localhost:16686</code></pre>
<h3>Kubernetes Deployment</h3>
<pre><code class="language-bash"># Using Jaeger Operator
kubectl create namespace observability
kubectl apply -f https://github.com/jaegertracing/jaeger-operator/releases/download/v1.50.0/jaeger-operator.yaml -n observability
<h1>Deploy Jaeger instance</h1>
kubectl apply -f - &lt;&lt;EOF
apiVersion: jaegertracing.io/v1
kind: Jaeger
metadata:
  name: jaeger
  namespace: observability
spec:
  strategy: allInOne
  storage:
    type: memory
    options:
      memory:
        max-traces: 100000
  ingress:
    enabled: true
  ui:
    options:
      dependencies:
        menuEnabled: true
EOF
<h1>Access UI</h1>
kubectl port-forward -n observability svc/jaeger-query 16686:16686</code></pre>
<p>---</p>
<h2>OpenTelemetry {#opentelemetry}</h2>
<p>OpenTelemetry is the industry standard for observability instrumentation.</p>
<h3>Architecture</h3>
<pre><code class="language-text">Application
    ‚îÇ
    ‚îú‚îÄ‚îÄ OpenTelemetry SDK
    ‚îÇ   ‚îú‚îÄ‚îÄ Tracer
    ‚îÇ   ‚îú‚îÄ‚îÄ Meter (metrics)
    ‚îÇ   ‚îî‚îÄ‚îÄ Logger
    ‚îÇ
    ‚îú‚îÄ‚îÄ Exporters
    ‚îÇ   ‚îú‚îÄ‚îÄ Jaeger
    ‚îÇ   ‚îú‚îÄ‚îÄ Zipkin
    ‚îÇ   ‚îú‚îÄ‚îÄ Prometheus
    ‚îÇ   ‚îî‚îÄ‚îÄ OTLP (OpenTelemetry Protocol)
    ‚îÇ
    ‚îî‚îÄ‚îÄ Collectors (optional)
        ‚îî‚îÄ‚îÄ Process, batch, export</code></pre>
<h3>Benefits</h3>
<p>‚úÖ <strong>Vendor-neutral</strong>: Switch backends without code changes
‚úÖ <strong>Auto-instrumentation</strong>: Libraries, frameworks, databases
‚úÖ <strong>Context propagation</strong>: W3C Trace Context standard
‚úÖ <strong>Unified API</strong>: Traces, metrics, logs</p>
<p>---</p>
<h2>Go Instrumentation {#go-instrumentation}</h2>
<h3>Setup OpenTelemetry</h3>
<pre><code class="language-bash">go get go.opentelemetry.io/otel
go get go.opentelemetry.io/otel/trace
go get go.opentelemetry.io/otel/exporters/jaeger
go get go.opentelemetry.io/otel/sdk/trace
go get go.opentelemetry.io/contrib/instrumentation/net/http/otelhttp</code></pre>
<h3>Initialize Tracer</h3>
<pre><code class="language-go">package main
<p>import (
    &quot;context&quot;
    &quot;log&quot;
    
    &quot;go.opentelemetry.io/otel&quot;
    &quot;go.opentelemetry.io/otel/attribute&quot;
    &quot;go.opentelemetry.io/otel/exporters/jaeger&quot;
    &quot;go.opentelemetry.io/otel/sdk/resource&quot;
    sdktrace &quot;go.opentelemetry.io/otel/sdk/trace&quot;
    semconv &quot;go.opentelemetry.io/otel/semconv/v1.17.0&quot;
)</p>
<p>func initTracer(serviceName string) (*sdktrace.TracerProvider, error) {
    // Create Jaeger exporter
    exporter, err := jaeger.New(jaeger.WithCollectorEndpoint(
        jaeger.WithEndpoint(&quot;http://localhost:14268/api/traces&quot;),
    ))
    if err != nil {
        return nil, err
    }
    
    // Create resource
    res, err := resource.New(
        context.Background(),
        resource.WithAttributes(
            semconv.ServiceNameKey.String(serviceName),
            semconv.ServiceVersionKey.String(&quot;1.0.0&quot;),
            attribute.String(&quot;environment&quot;, &quot;production&quot;),
        ),
    )
    if err != nil {
        return nil, err
    }
    
    // Create tracer provider
    tp := sdktrace.NewTracerProvider(
        sdktrace.WithBatcher(exporter),
        sdktrace.WithResource(res),
        sdktrace.WithSampler(sdktrace.AlwaysSample()),
    )
    
    otel.SetTracerProvider(tp)
    return tp, nil
}</p>
<p>func main() {
    tp, err := initTracer(&quot;my-service&quot;)
    if err != nil {
        log.Fatal(err)
    }
    defer func() {
        if err := tp.Shutdown(context.Background()); err != nil {
            log.Printf(&quot;Error shutting down tracer provider: %v&quot;, err)
        }
    }()
    
    // Your application code
}</code></pre></p>
<h3>Manual Spans</h3>
<pre><code class="language-go">package main
<p>import (
    &quot;context&quot;
    &quot;time&quot;
    
    &quot;go.opentelemetry.io/otel&quot;
    &quot;go.opentelemetry.io/otel/attribute&quot;
    &quot;go.opentelemetry.io/otel/codes&quot;
)</p>
<p>func processOrder(ctx context.Context, orderID string) error {
    tracer := otel.Tracer(&quot;order-service&quot;)
    
    // Start span
    ctx, span := tracer.Start(ctx, &quot;processOrder&quot;)
    defer span.End()
    
    // Add attributes
    span.SetAttributes(
        attribute.String(&quot;order.id&quot;, orderID),
        attribute.String(&quot;order.status&quot;, &quot;processing&quot;),
    )
    
    // Validate order
    if err := validateOrder(ctx, orderID); err != nil {
        span.RecordError(err)
        span.SetStatus(codes.Error, &quot;Order validation failed&quot;)
        return err
    }
    
    // Check inventory
    if err := checkInventory(ctx, orderID); err != nil {
        span.RecordError(err)
        span.SetStatus(codes.Error, &quot;Inventory check failed&quot;)
        return err
    }
    
    // Process payment
    if err := processPayment(ctx, orderID); err != nil {
        span.RecordError(err)
        span.SetStatus(codes.Error, &quot;Payment failed&quot;)
        return err
    }
    
    span.SetAttributes(attribute.String(&quot;order.status&quot;, &quot;completed&quot;))
    span.SetStatus(codes.Ok, &quot;Order processed successfully&quot;)
    return nil
}</p>
<p>func validateOrder(ctx context.Context, orderID string) error {
    _, span := otel.Tracer(&quot;order-service&quot;).Start(ctx, &quot;validateOrder&quot;)
    defer span.End()
    
    // Add event
    span.AddEvent(&quot;Validating order fields&quot;)
    
    time.Sleep(50 * time.Millisecond)
    return nil
}</p>
<p>func checkInventory(ctx context.Context, orderID string) error {
    _, span := otel.Tracer(&quot;order-service&quot;).Start(ctx, &quot;checkInventory&quot;)
    defer span.End()
    
    span.SetAttributes(
        attribute.String(&quot;inventory.warehouse&quot;, &quot;warehouse-1&quot;),
        attribute.Int(&quot;inventory.available&quot;, 100),
    )
    
    time.Sleep(100 * time.Millisecond)
    return nil
}</p>
<p>func processPayment(ctx context.Context, orderID string) error {
    _, span := otel.Tracer(&quot;order-service&quot;).Start(ctx, &quot;processPayment&quot;)
    defer span.End()
    
    span.SetAttributes(
        attribute.String(&quot;payment.method&quot;, &quot;credit_card&quot;),
        attribute.Float64(&quot;payment.amount&quot;, 99.99),
    )
    
    time.Sleep(150 * time.Millisecond)
    return nil
}</code></pre></p>
<h3>HTTP Server Instrumentation</h3>
<pre><code class="language-go">package main
<p>import (
    &quot;log&quot;
    &quot;net/http&quot;
    
    &quot;go.opentelemetry.io/contrib/instrumentation/net/http/otelhttp&quot;
)</p>
<p>func main() {
    tp, _ := initTracer(&quot;api-gateway&quot;)
    defer tp.Shutdown(context.Background())
    
    // Wrap handlers with otelhttp
    http.Handle(&quot;/api/users&quot;, otelhttp.NewHandler(
        http.HandlerFunc(usersHandler),
        &quot;GET /api/users&quot;,
    ))
    
    http.Handle(&quot;/api/orders&quot;, otelhttp.NewHandler(
        http.HandlerFunc(ordersHandler),
        &quot;POST /api/orders&quot;,
    ))
    
    log.Println(&quot;Server starting on :8080&quot;)
    log.Fatal(http.ListenAndServe(&quot;:8080&quot;, nil))
}</p>
<p>func usersHandler(w http.ResponseWriter, r *http.Request) {
    ctx := r.Context()
    tracer := otel.Tracer(&quot;api-gateway&quot;)
    
    // Create child span
    ctx, span := tracer.Start(ctx, &quot;fetchUsers&quot;)
    defer span.End()
    
    // Call downstream service
    users, err := fetchUsersFromService(ctx)
    if err != nil {
        span.RecordError(err)
        http.Error(w, err.Error(), http.StatusInternalServerError)
        return
    }
    
    json.NewEncoder(w).Encode(users)
}</code></pre></p>
<h3>HTTP Client Instrumentation</h3>
<pre><code class="language-go">package main
<p>import (
    &quot;context&quot;
    &quot;net/http&quot;
    
    &quot;go.opentelemetry.io/contrib/instrumentation/net/http/otelhttp&quot;
)</p>
<p>func fetchUsersFromService(ctx context.Context) ([]User, error) {
    // Create HTTP client with tracing
    client := http.Client{
        Transport: otelhttp.NewTransport(http.DefaultTransport),
    }
    
    req, _ := http.NewRequestWithContext(ctx, &quot;GET&quot;, &quot;http://user-service/users&quot;, nil)
    
    resp, err := client.Do(req)
    if err != nil {
        return nil, err
    }
    defer resp.Body.Close()
    
    var users []User
    json.NewDecoder(resp.Body).Decode(&amp;users)
    return users, nil
}</code></pre></p>
<h3>Database Tracing</h3>
<pre><code class="language-go">package main
<p>import (
    &quot;context&quot;
    &quot;database/sql&quot;
    
    &quot;go.opentelemetry.io/otel&quot;
    &quot;go.opentelemetry.io/otel/attribute&quot;
    &quot;go.opentelemetry.io/otel/codes&quot;
)</p>
<p>func getUserByID(ctx context.Context, db *sql.DB, userID string) (*User, error) {
    tracer := otel.Tracer(&quot;user-service&quot;)
    ctx, span := tracer.Start(ctx, &quot;getUserByID&quot;)
    defer span.End()
    
    span.SetAttributes(
        attribute.String(&quot;db.system&quot;, &quot;postgresql&quot;),
        attribute.String(&quot;db.operation&quot;, &quot;SELECT&quot;),
        attribute.String(&quot;db.table&quot;, &quot;users&quot;),
    )
    
    query := &quot;SELECT id, name, email FROM users WHERE id = $1&quot;
    span.SetAttributes(attribute.String(&quot;db.statement&quot;, query))
    
    var user User
    err := db.QueryRowContext(ctx, query, userID).Scan(&amp;user.ID, &amp;user.Name, &amp;user.Email)
    if err != nil {
        span.RecordError(err)
        span.SetStatus(codes.Error, &quot;Database query failed&quot;)
        return nil, err
    }
    
    span.SetStatus(codes.Ok, &quot;&quot;)
    return &amp;user, nil
}</code></pre></p>
<p>---</p>
<h2>Trace Context Propagation {#propagation}</h2>
<h3>W3C Trace Context</h3>
<p>Headers automatically propagated:
<pre><code class="language-text">traceparent: 00-abc123def456-span789-01
tracestate: vendor1=value1,vendor2=value2</code></pre></p>
<h3>Manual Propagation</h3>
<pre><code class="language-go">package main
<p>import (
    &quot;context&quot;
    &quot;net/http&quot;
    
    &quot;go.opentelemetry.io/otel&quot;
    &quot;go.opentelemetry.io/otel/propagation&quot;
)</p>
<p>func callDownstreamService(ctx context.Context) error {
    client := &amp;http.Client{}
    req, _ := http.NewRequest(&quot;GET&quot;, &quot;http://downstream-service/api&quot;, nil)
    
    // Inject trace context into headers
    propagator := otel.GetTextMapPropagator()
    propagator.Inject(ctx, propagation.HeaderCarrier(req.Header))
    
    resp, err := client.Do(req)
    if err != nil {
        return err
    }
    defer resp.Body.Close()
    
    return nil
}</p>
<p>func downstreamHandler(w http.ResponseWriter, r *http.Request) {
    // Extract trace context from headers
    propagator := otel.GetTextMapPropagator()
    ctx := propagator.Extract(r.Context(), propagation.HeaderCarrier(r.Header))
    
    // Continue trace
    tracer := otel.Tracer(&quot;downstream-service&quot;)
    ctx, span := tracer.Start(ctx, &quot;handleRequest&quot;)
    defer span.End()
    
    // Process request...
}</code></pre></p>
<p>---</p>
<h2>Sampling Strategies {#sampling}</h2>
<h3>Sampling Types</h3>
<strong>Always Sample</strong> (development):
<pre><code class="language-go">sdktrace.WithSampler(sdktrace.AlwaysSample())</code></pre>
<strong>Never Sample</strong> (testing):
<pre><code class="language-go">sdktrace.WithSampler(sdktrace.NeverSample())</code></pre>
<strong>Probabilistic</strong> (production):
<pre><code class="language-go">// Sample 10% of traces
sdktrace.WithSampler(sdktrace.TraceIDRatioBased(0.1))</code></pre>
<strong>Parent-based</strong> (default):
<pre><code class="language-go">// If parent is sampled, sample child
sdktrace.WithSampler(sdktrace.ParentBased(sdktrace.TraceIDRatioBased(0.1)))</code></pre>
<h3>Custom Sampler</h3>
<pre><code class="language-go">type CustomSampler struct {
    highPrioritySampler sdktrace.Sampler
    defaultSampler      sdktrace.Sampler
}
<p>func (s *CustomSampler) ShouldSample(params sdktrace.SamplingParameters) sdktrace.SamplingResult {
    // Always sample errors
    if params.Attributes != nil {
        for _, attr := range params.Attributes {
            if attr.Key == &quot;error&quot; &amp;&amp; attr.Value.AsBool() {
                return s.highPrioritySampler.ShouldSample(params)
            }
        }
    }
    
    // Sample slow requests
    // (requires custom logic based on span duration)
    
    return s.defaultSampler.ShouldSample(params)
}</p>
<p>func NewCustomSampler() sdktrace.Sampler {
    return &amp;CustomSampler{
        highPrioritySampler: sdktrace.AlwaysSample(),
        defaultSampler:      sdktrace.TraceIDRatioBased(0.01), // 1%
    }
}</code></pre></p>
<p>---</p>
<h2>Integration with Logs and Metrics {#integration}</h2>
<h3>Correlate Traces with Logs</h3>
<pre><code class="language-go">package main
<p>import (
    &quot;context&quot;
    &quot;encoding/json&quot;
    &quot;os&quot;
    
    &quot;go.opentelemetry.io/otel/trace&quot;
)</p>
<p>type LogEntry struct {
    Timestamp string <code>json:&quot;@timestamp&quot;</code>
    Level     string <code>json:&quot;level&quot;</code>
    Message   string <code>json:&quot;message&quot;</code>
    TraceID   string <code>json:&quot;trace_id,omitempty&quot;</code>
    SpanID    string <code>json:&quot;span_id,omitempty&quot;</code>
}</p>
<p>func logWithTrace(ctx context.Context, level, message string) {
    entry := LogEntry{
        Timestamp: time.Now().UTC().Format(time.RFC3339Nano),
        Level:     level,
        Message:   message,
    }
    
    // Extract trace context
    span := trace.SpanFromContext(ctx)
    if span.SpanContext().IsValid() {
        entry.TraceID = span.SpanContext().TraceID().String()
        entry.SpanID = span.SpanContext().SpanID().String()
    }
    
    json.NewEncoder(os.Stdout).Encode(entry)
}</p>
<p>// Usage
func handler(w http.ResponseWriter, r *http.Request) {
    ctx := r.Context()
    
    logWithTrace(ctx, &quot;INFO&quot;, &quot;Processing request&quot;)
    
    // In Kibana, search by trace_id to see all logs for this request
    // In Jaeger, see logs attached to span
}</code></pre></p>
<h3>Add Trace Links to Metrics</h3>
<pre><code class="language-go">package main
<p>import (
    &quot;context&quot;
    
    &quot;github.com/prometheus/client_golang/prometheus&quot;
    &quot;go.opentelemetry.io/otel/trace&quot;
)</p>
<p>var requestDuration = prometheus.NewHistogramVec(
    prometheus.HistogramOpts{
        Name: &quot;http_request_duration_seconds&quot;,
        Help: &quot;HTTP request duration&quot;,
    },
    []string{&quot;method&quot;, &quot;endpoint&quot;, &quot;trace_id&quot;},
)</p>
<p>func recordMetricWithTrace(ctx context.Context, method, endpoint string, duration float64) {
    traceID := &quot;&quot;
    span := trace.SpanFromContext(ctx)
    if span.SpanContext().IsValid() {
        traceID = span.SpanContext().TraceID().String()
    }
    
    requestDuration.WithLabelValues(method, endpoint, traceID).Observe(duration)
}</code></pre></p>
<p>---</p>
<h2>Best Practices {#best-practices}</h2>
<h3>1. Span Naming</h3>
<pre><code class="language-go">// ‚úÖ Good: Clear operation names
&quot;GET /api/users&quot;
&quot;processOrder&quot;
&quot;database.query&quot;
<p>// ‚ùå Bad: Generic names
&quot;handler&quot;
&quot;method1&quot;
&quot;doWork&quot;</code></pre></p>
<h3>2. Attributes</h3>
<pre><code class="language-go">// ‚úÖ Good: Semantic conventions
span.SetAttributes(
    semconv.HTTPMethodKey.String(&quot;GET&quot;),
    semconv.HTTPURLKey.String(&quot;/api/users&quot;),
    semconv.HTTPStatusCodeKey.Int(200),
)
<p>// ‚ùå Bad: Non-standard attributes
span.SetAttributes(
    attribute.String(&quot;method&quot;, &quot;GET&quot;),
    attribute.String(&quot;url&quot;, &quot;/api/users&quot;),
)</code></pre></p>
<h3>3. Error Handling</h3>
<pre><code class="language-go">// ‚úÖ Good: Record errors with context
if err != nil {
    span.RecordError(err)
    span.SetStatus(codes.Error, &quot;Database connection failed&quot;)
    span.SetAttributes(attribute.String(&quot;error.type&quot;, &quot;connection_timeout&quot;))
    return err
}
<p>// ‚ùå Bad: Silent failure
if err != nil {
    return err
}</code></pre></p>
<h3>4. Sampling Strategy</h3>
<pre><code class="language-text">Development: AlwaysSample()
Staging: TraceIDRatioBased(0.5)  // 50%
Production: TraceIDRatioBased(0.01)  // 1%
Critical paths: Always sample errors and slow requests</code></pre>
<h3>5. Span Lifecycle</h3>
<pre><code class="language-go">// ‚úÖ Good: Defer span.End()
ctx, span := tracer.Start(ctx, &quot;operation&quot;)
defer span.End()
<p>// Do work...</p>
<p>// ‚ùå Bad: Manual span.End() (easy to forget)
ctx, span := tracer.Start(ctx, &quot;operation&quot;)
// Do work...
span.End()</code></pre></p>
<p>---</p>
<h2>Interview Questions {#interview-questions}</h2>
<strong>Q1: What is the difference between a trace and a span?</strong>
<strong>A:</strong>
<li><strong>Trace</strong>: Complete journey of a request across all services</li>
<li><strong>Span</strong>: Single operation within a trace (e.g., database query, HTTP call)</li>
<li>Relationship: Trace contains multiple spans organized hierarchically</li>
<strong>Q2: How does distributed tracing work across services?</strong>
<strong>A:</strong>
1. Generate trace ID and span ID at entry point
2. Pass trace context via HTTP headers (W3C Trace Context)
3. Each service extracts context, creates child spans
4. All spans sent to collector with same trace ID
5. Collector stitches spans into complete trace
<strong>Q3: What is sampling and why is it important?</strong>
<strong>A:</strong>
Sampling reduces overhead by collecting subset of traces.
<li><strong>100% sampling</strong>: High overhead, expensive storage</li>
<li><strong>1% sampling</strong>: Low overhead, might miss issues</li>
<li><strong>Strategies</strong>: Probabilistic, always sample errors, tail-based sampling</li>
<strong>Q4: How do you correlate traces with logs?</strong>
<strong>A:</strong>
1. Extract trace ID and span ID from context
2. Include in log structured format
3. Search logs by trace ID in Kibana
4. Link from Jaeger UI to logs
5. See complete picture: trace + logs + metrics
<strong>Q5: What are semantic conventions in OpenTelemetry?</strong>
<strong>A:</strong>
Standard attribute names for common operations:
<li><code>http.method</code>, <code>http.url</code>, <code>http.status_code</code></li>
<li><code>db.system</code>, <code>db.operation</code>, <code>db.statement</code></li>
<li><code>messaging.system</code>, <code>messaging.destination</code></li>
<p>Benefits: Consistency, backend compatibility, automatic visualization</p>
<p>---</p>
<h2>Hands-On Exercise {#exercise}</h2>
<h3>Build a Traced Microservices System</h3>
<strong>Goal</strong>: Implement distributed tracing across 3 services.
<p>#### Architecture</p>
<pre><code class="language-text">API Gateway ‚Üí User Service ‚Üí Database
         ‚Üì
    Product Service ‚Üí Cache</code></pre>
<p>#### Service 1: API Gateway</p>
<pre><code class="language-go">// api-gateway/main.go
package main
<p>import (
    &quot;context&quot;
    &quot;encoding/json&quot;
    &quot;log&quot;
    &quot;net/http&quot;
    
    &quot;go.opentelemetry.io/contrib/instrumentation/net/http/otelhttp&quot;
    &quot;go.opentelemetry.io/otel&quot;
)</p>
<p>func main() {
    tp, _ := initTracer(&quot;api-gateway&quot;)
    defer tp.Shutdown(context.Background())
    
    http.Handle(&quot;/api/dashboard&quot;, otelhttp.NewHandler(
        http.HandlerFunc(dashboardHandler),
        &quot;GET /api/dashboard&quot;,
    ))
    
    log.Fatal(http.ListenAndServe(&quot;:8080&quot;, nil))
}</p>
<p>func dashboardHandler(w http.ResponseWriter, r *http.Request) {
    ctx := r.Context()
    tracer := otel.Tracer(&quot;api-gateway&quot;)
    
    ctx, span := tracer.Start(ctx, &quot;fetchDashboard&quot;)
    defer span.End()
    
    // Parallel calls
    userCh := make(chan *User)
    productsCh := make(chan []Product)
    
    go func() {
        user, _ := fetchUser(ctx)
        userCh &lt;- user
    }()
    
    go func() {
        products, _ := fetchProducts(ctx)
        productsCh &lt;- products
    }()
    
    dashboard := Dashboard{
        User:     &lt;-userCh,
        Products: &lt;-productsCh,
    }
    
    json.NewEncoder(w).Encode(dashboard)
}</p>
<p>func fetchUser(ctx context.Context) (*User, error) {
    client := http.Client{Transport: otelhttp.NewTransport(http.DefaultTransport)}
    req, _ := http.NewRequestWithContext(ctx, &quot;GET&quot;, &quot;http://user-service:8081/user&quot;, nil)
    
    resp, err := client.Do(req)
    if err != nil {
        return nil, err
    }
    defer resp.Body.Close()
    
    var user User
    json.NewDecoder(resp.Body).Decode(&amp;user)
    return &amp;user, nil
}</p>
<p>func fetchProducts(ctx context.Context) ([]Product, error) {
    client := http.Client{Transport: otelhttp.NewTransport(http.DefaultTransport)}
    req, _ := http.NewRequestWithContext(ctx, &quot;GET&quot;, &quot;http://product-service:8082/products&quot;, nil)
    
    resp, err := client.Do(req)
    if err != nil {
        return nil, err
    }
    defer resp.Body.Close()
    
    var products []Product
    json.NewDecoder(resp.Body).Decode(&amp;products)
    return products, nil
}</code></pre></p>
<p>#### Service 2: User Service</p>
<pre><code class="language-go">// user-service/main.go
package main
<p>import (
    &quot;context&quot;
    &quot;database/sql&quot;
    &quot;encoding/json&quot;
    &quot;log&quot;
    &quot;net/http&quot;
    
    &quot;go.opentelemetry.io/contrib/instrumentation/net/http/otelhttp&quot;
    &quot;go.opentelemetry.io/otel&quot;
    &quot;go.opentelemetry.io/otel/attribute&quot;
)</p>
<p>var db *sql.DB</p>
<p>func main() {
    tp, _ := initTracer(&quot;user-service&quot;)
    defer tp.Shutdown(context.Background())
    
    db, _ = sql.Open(&quot;postgres&quot;, &quot;postgres://user:pass@db:5432/mydb&quot;)
    
    http.Handle(&quot;/user&quot;, otelhttp.NewHandler(
        http.HandlerFunc(userHandler),
        &quot;GET /user&quot;,
    ))
    
    log.Fatal(http.ListenAndServe(&quot;:8081&quot;, nil))
}</p>
<p>func userHandler(w http.ResponseWriter, r *http.Request) {
    ctx := r.Context()
    
    user, err := getUserFromDB(ctx, &quot;user123&quot;)
    if err != nil {
        http.Error(w, err.Error(), http.StatusInternalServerError)
        return
    }
    
    json.NewEncoder(w).Encode(user)
}</p>
<p>func getUserFromDB(ctx context.Context, userID string) (*User, error) {
    tracer := otel.Tracer(&quot;user-service&quot;)
    ctx, span := tracer.Start(ctx, &quot;getUserFromDB&quot;)
    defer span.End()
    
    span.SetAttributes(
        attribute.String(&quot;db.system&quot;, &quot;postgresql&quot;),
        attribute.String(&quot;db.operation&quot;, &quot;SELECT&quot;),
    )
    
    var user User
    query := &quot;SELECT id, name, email FROM users WHERE id = $1&quot;
    err := db.QueryRowContext(ctx, query, userID).Scan(&amp;user.ID, &amp;user.Name, &amp;user.Email)
    
    if err != nil {
        span.RecordError(err)
        return nil, err
    }
    
    return &amp;user, nil
}</code></pre></p>
<p>#### Service 3: Product Service</p>
<pre><code class="language-go">// product-service/main.go
package main
<p>import (
    &quot;context&quot;
    &quot;encoding/json&quot;
    &quot;log&quot;
    &quot;net/http&quot;
    &quot;time&quot;
    
    &quot;go.opentelemetry.io/contrib/instrumentation/net/http/otelhttp&quot;
    &quot;go.opentelemetry.io/otel&quot;
    &quot;go.opentelemetry.io/otel/attribute&quot;
)</p>
<p>func main() {
    tp, _ := initTracer(&quot;product-service&quot;)
    defer tp.Shutdown(context.Background())
    
    http.Handle(&quot;/products&quot;, otelhttp.NewHandler(
        http.HandlerFunc(productsHandler),
        &quot;GET /products&quot;,
    ))
    
    log.Fatal(http.ListenAndServe(&quot;:8082&quot;, nil))
}</p>
<p>func productsHandler(w http.ResponseWriter, r *http.Request) {
    ctx := r.Context()
    
    // Check cache
    products, err := getFromCache(ctx)
    if err == nil {
        json.NewEncoder(w).Encode(products)
        return
    }
    
    // Cache miss, fetch from database
    products, _ = getFromDatabase(ctx)
    json.NewEncoder(w).Encode(products)
}</p>
<p>func getFromCache(ctx context.Context) ([]Product, error) {
    tracer := otel.Tracer(&quot;product-service&quot;)
    ctx, span := tracer.Start(ctx, &quot;getFromCache&quot;)
    defer span.End()
    
    span.SetAttributes(attribute.String(&quot;cache.key&quot;, &quot;products:all&quot;))
    
    time.Sleep(10 * time.Millisecond)
    
    // Simulate cache miss
    span.AddEvent(&quot;cache_miss&quot;)
    return nil, errors.New(&quot;cache miss&quot;)
}</p>
<p>func getFromDatabase(ctx context.Context) ([]Product, error) {
    tracer := otel.Tracer(&quot;product-service&quot;)
    ctx, span := tracer.Start(ctx, &quot;getFromDatabase&quot;)
    defer span.End()
    
    time.Sleep(100 * time.Millisecond)
    
    products := []Product{
        {ID: &quot;1&quot;, Name: &quot;Product 1&quot;, Price: 29.99},
        {ID: &quot;2&quot;, Name: &quot;Product 2&quot;, Price: 49.99},
    }
    
    return products, nil
}</code></pre></p>
<p>#### Testing</p>
<pre><code class="language-bash"># Generate traffic
for i in {1..100}; do
  curl http://localhost:8080/api/dashboard
  sleep 0.5
done
<h1>View traces in Jaeger UI</h1>
open http://localhost:16686
<h1>Search for:</h1>
<h1>- Service: api-gateway</h1>
<h1>- Operation: GET /api/dashboard</h1>
<h1>- Click trace to see waterfall</h1>
<h1>- See parallel user/product fetches</h1>
<h1>- Identify slowest operations</code></pre></h1>
<p>---</p>
<h2>Summary</h2>
<p>You've learned:
<li>‚úÖ Distributed tracing concepts (traces, spans, context)</li>
<li>‚úÖ Jaeger architecture and deployment</li>
<li>‚úÖ OpenTelemetry instrumentation in Go</li>
<li>‚úÖ Trace context propagation across services</li>
<li>‚úÖ Sampling strategies for production</li>
<li>‚úÖ Integration with logs and metrics</li>
<li>‚úÖ Best practices for span naming and attributes</li></ul></p>
<strong>Next Module</strong>: [Module 30: Production Best Practices](30_Production_Best_Practices.md) - Learn deployment strategies, security, and disaster recovery.

    </div>
    

    <div class="module-content" id="module-30">
        <h1>Module 30: Production Best Practices</h1>
<h2>Table of Contents</h2>
<ul><li>[Deployment Strategies](#deployment)</li>
<li>[High Availability](#high-availability)</li>
<li>[Security Hardening](#security)</li>
<li>[Disaster Recovery](#disaster-recovery)</li>
<li>[Performance Optimization](#performance)</li>
<li>[Monitoring and Alerting](#monitoring)</li>
<li>[Cost Optimization](#cost)</li>
<li>[Interview Questions](#interview-questions)</li>
<p>---</p>
<h2>Deployment Strategies {#deployment}</h2>
<h3>Blue-Green Deployment</h3>
<p>Switch traffic between two identical environments.</p>
<pre><code class="language-text">Blue (Current: v1.0)  ‚îÄ‚îÄ‚îê
                        ‚îú‚îÄ‚îÄ‚ñ∫ Load Balancer ‚îÄ‚îÄ‚ñ∫ Users
Green (New: v1.1)    ‚îÄ‚îÄ‚îÄ‚îò</code></pre>
<strong>Kubernetes Implementation:</strong>
<pre><code class="language-yaml"># blue-deployment.yaml (v1.0)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-blue
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
      version: blue
  template:
    metadata:
      labels:
        app: myapp
        version: blue
    spec:
      containers:
      - name: myapp
        image: myapp:1.0
---
<h1>green-deployment.yaml (v1.1)</h1>
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-green
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
      version: green
  template:
    metadata:
      labels:
        app: myapp
        version: green
    spec:
      containers:
      - name: myapp
        image: myapp:1.1
---
<h1>service.yaml</h1>
apiVersion: v1
kind: Service
metadata:
  name: myapp
spec:
  selector:
    app: myapp
    version: blue  # Switch to &#039;green&#039; to cut over
  ports:
  - port: 80
    targetPort: 8080</code></pre>
<strong>Deployment Steps:</strong>
<pre><code class="language-bash"># 1. Deploy green
kubectl apply -f green-deployment.yaml
<h1>2. Test green</h1>
kubectl port-forward deployment/myapp-green 8080:8080
curl localhost:8080/health
<h1>3. Switch traffic</h1>
kubectl patch service myapp -p &#039;{&quot;spec&quot;:{&quot;selector&quot;:{&quot;version&quot;:&quot;green&quot;}}}&#039;
<h1>4. Monitor, rollback if needed</h1>
kubectl patch service myapp -p &#039;{&quot;spec&quot;:{&quot;selector&quot;:{&quot;version&quot;:&quot;blue&quot;}}}&#039;
<h1>5. Delete old blue deployment</h1>
kubectl delete deployment myapp-blue</code></pre>
<h3>Canary Deployment</h3>
<p>Gradually shift traffic to new version.</p>
<pre><code class="language-yaml"># Using Istio VirtualService
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: myapp
spec:
  hosts:
  - myapp
  http:
  - match:
    - headers:
        x-canary:
          exact: &quot;true&quot;
    route:
    - destination:
        host: myapp
        subset: v2
  - route:
    - destination:
        host: myapp
        subset: v1
      weight: 90  # 90% to v1
    - destination:
        host: myapp
        subset: v2
      weight: 10  # 10% to v2</code></pre>
<strong>Gradual Rollout:</strong>
<pre><code class="language-bash"># Week 1: 10% canary
<h1>Monitor error rates, latency</h1>
<h1>Week 2: 50% canary</h1>
kubectl edit virtualservice myapp
<h1>Update weights: v1=50, v2=50</h1>
<h1>Week 3: 100% canary</h1>
<h1>Update weights: v1=0, v2=100</code></pre></h1>
<h3>Rolling Update</h3>
<p>Default Kubernetes strategy.</p>
<pre><code class="language-yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
spec:
  replicas: 10
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 2        # Max 2 extra pods during update
      maxUnavailable: 1  # Max 1 pod down at a time
  template:
    spec:
      containers:
      - name: myapp
        image: myapp:1.1
        readinessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 5</code></pre>
<p>---</p>
<h2>High Availability {#high-availability}</h2>
<h3>Multi-AZ Deployment</h3>
<pre><code class="language-yaml"># Spread pods across zones
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
spec:
  replicas: 6
  template:
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - myapp
            topologyKey: topology.kubernetes.io/zone
      topologySpreadConstraints:
      - maxSkew: 1
        topologyKey: topology.kubernetes.io/zone
        whenUnsatisfiable: DoNotSchedule
        labelSelector:
          matchLabels:
            app: myapp</code></pre>
<h3>Pod Disruption Budget</h3>
<pre><code class="language-yaml">apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: myapp-pdb
spec:
  minAvailable: 2  # Or maxUnavailable: 1
  selector:
    matchLabels:
      app: myapp</code></pre>
<h3>Health Checks</h3>
<pre><code class="language-go">// Liveness: Is the app alive?
http.HandleFunc(&quot;/healthz&quot;, func(w http.ResponseWriter, r *http.Request) {
    w.WriteHeader(http.StatusOK)
    w.Write([]byte(&quot;OK&quot;))
})
<p>// Readiness: Is the app ready for traffic?
http.HandleFunc(&quot;/ready&quot;, func(w http.ResponseWriter, r *http.Request) {
    if db.Ping() != nil {
        w.WriteHeader(http.StatusServiceUnavailable)
        return
    }
    w.WriteHeader(http.StatusOK)
})</code></pre></p>
<pre><code class="language-yaml">livenessProbe:
  httpGet:
    path: /healthz
    port: 8080
  initialDelaySeconds: 30
  periodSeconds: 10
  failureThreshold: 3
<p>readinessProbe:
  httpGet:
    path: /ready
    port: 8080
  initialDelaySeconds: 5
  periodSeconds: 5</code></pre></p>
<p>---</p>
<h2>Security Hardening {#security}</h2>
<h3>Secrets Management</h3>
<pre><code class="language-bash"># Sealed Secrets (encrypted in Git)
kubectl create secret generic db-creds \
  --from-literal=username=admin \
  --from-literal=password=secret \
  --dry-run=client -o yaml | \
  kubeseal -o yaml &gt; sealed-secret.yaml
<h1>External Secrets Operator (fetch from Vault/AWS)</h1>
apiVersion: external-secrets.io/v1beta1
kind: ExternalSecret
metadata:
  name: db-creds
spec:
  secretStoreRef:
    name: vault-backend
  target:
    name: db-creds
  data:
  - secretKey: password
    remoteRef:
      key: secret/db
      property: password</code></pre>
<h3>RBAC</h3>
<pre><code class="language-yaml"># ServiceAccount
apiVersion: v1
kind: ServiceAccount
metadata:
  name: myapp-sa
---
<h1>Role</h1>
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: myapp-role
rules:
<li>apiGroups: [&quot;&quot;]</li>
  resources: [&quot;configmaps&quot;]
  verbs: [&quot;get&quot;, &quot;list&quot;]
---
<h1>RoleBinding</h1>
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: myapp-binding
subjects:
<li>kind: ServiceAccount</li>
  name: myapp-sa
roleRef:
  kind: Role
  name: myapp-role
  apiGroup: rbac.authorization.k8s.io</code></pre>
<h3>Network Policies</h3>
<pre><code class="language-yaml"># Deny all by default
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-deny
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress
---
<h1>Allow specific traffic</h1>
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: myapp-policy
spec:
  podSelector:
    matchLabels:
      app: myapp
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: api-gateway
    ports:
    - protocol: TCP
      port: 8080
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: database
    ports:
    - protocol: TCP
      port: 5432</code></pre>
<h3>Pod Security Standards</h3>
<pre><code class="language-yaml">apiVersion: v1
kind: Namespace
metadata:
  name: production
  labels:
    pod-security.kubernetes.io/enforce: restricted
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
spec:
  template:
    spec:
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        fsGroup: 2000
        seccompProfile:
          type: RuntimeDefault
      containers:
      - name: myapp
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true</code></pre>
<p>---</p>
<h2>Disaster Recovery {#disaster-recovery}</h2>
<h3>Backup Strategy</h3>
<strong>Velero Setup:</strong>
<pre><code class="language-bash"># Install Velero
velero install \
  --provider aws \
  --bucket my-backup-bucket \
  --secret-file ./credentials-velero \
  --backup-location-config region=us-east-1
<h1>Backup schedule</h1>
velero schedule create daily-backup \
  --schedule=&quot;0 2 * * *&quot; \
  --include-namespaces production
<h1>Restore</h1>
velero restore create --from-backup daily-backup-20241210</code></pre>
<h3>Database Backups</h3>
<pre><code class="language-yaml"># CronJob for PostgreSQL backup
apiVersion: batch/v1
kind: CronJob
metadata:
  name: postgres-backup
spec:
  schedule: &quot;0 2 * * *&quot;
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: backup
            image: postgres:15
            command:
            - /bin/sh
            - -c
            - |
              pg_dump -h $DB_HOST -U $DB_USER $DB_NAME | \
              gzip &gt; /backup/db-$(date +%Y%m%d).sql.gz
              aws s3 cp /backup/db-$(date +%Y%m%d).sql.gz s3://backups/
            env:
            - name: DB_HOST
              valueFrom:
                secretKeyRef:
                  name: db-creds
                  key: host
          restartPolicy: OnFailure</code></pre>
<h3>RTO/RPO</h3>
<strong>Recovery Time Objective (RTO):</strong> Max downtime
<strong>Recovery Point Objective (RPO):</strong> Max data loss
<pre><code class="language-text">Strategy        RTO        RPO        Cost
------------------------------------------
Hot Standby     Minutes    Seconds    High
Warm Standby    Hours      Minutes    Medium
Cold Backup     Days       Hours      Low</code></pre>
<p>---</p>
<h2>Performance Optimization {#performance}</h2>
<h3>Horizontal Pod Autoscaler</h3>
<pre><code class="language-yaml">apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: myapp-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: myapp
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60</code></pre>
<h3>Resource Limits</h3>
<pre><code class="language-yaml">containers:
<li>name: myapp</li>
  resources:
    requests:
      memory: &quot;256Mi&quot;
      cpu: &quot;250m&quot;
    limits:
      memory: &quot;512Mi&quot;
      cpu: &quot;500m&quot;</code></pre>
<h3>Caching</h3>
<pre><code class="language-go">// Redis caching layer
func GetUser(ctx context.Context, userID string) (*User, error) {
    // Check cache
    cached, err := redisClient.Get(ctx, &quot;user:&quot;+userID).Result()
    if err == nil {
        var user User
        json.Unmarshal([]byte(cached), &amp;user)
        return &amp;user, nil
    }
    
    // Cache miss, query database
    user, err := db.QueryUser(userID)
    if err != nil {
        return nil, err
    }
    
    // Store in cache (TTL: 5 minutes)
    data, _ := json.Marshal(user)
    redisClient.Set(ctx, &quot;user:&quot;+userID, data, 5*time.Minute)
    
    return user, nil
}</code></pre>
<h3>Database Optimization</h3>
<pre><code class="language-sql">-- Add indexes
CREATE INDEX idx_users_email ON users(email);
CREATE INDEX idx_orders_user_id ON orders(user_id);
<p>-- Use connection pooling
db.SetMaxOpenConns(25)
db.SetMaxIdleConns(5)
db.SetConnMaxLifetime(5 * time.Minute)</p>
<p>-- Read replicas for scaling
SELECT * FROM users WHERE id = ? -- Read replica
INSERT INTO users VALUES (...)   -- Primary</code></pre></p>
<p>---</p>
<h2>Monitoring and Alerting {#monitoring}</h2>
<h3>SLIs, SLOs, SLAs</h3>
<strong>SLI (Service Level Indicator):</strong> Metric
<li>Request latency: P95 < 200ms</li>
<li>Error rate: < 0.1%</li>
<li>Availability: 99.9%</li>
<strong>SLO (Service Level Objective):</strong> Target
<li>95% of requests < 200ms</li>
<li>99.9% uptime (43 min downtime/month)</li>
<strong>SLA (Service Level Agreement):</strong> Contract
<li>99.9% uptime or refund</li>
<h3>Error Budget</h3>
<pre><code class="language-text">Monthly error budget = (1 - SLO) √ó Total requests
If SLO = 99.9%, budget = 0.1% = 1000 errors per 1M requests
<p>Current: 500 errors ‚Üí 50% budget consumed
Remaining: 500 errors before breaching SLO</code></pre></p>
<h3>Alerting Rules</h3>
<pre><code class="language-yaml"># Prometheus alerts
groups:
<li>name: production</li>
  rules:
  - alert: HighErrorRate
    expr: |
      (sum(rate(http_requests_total{status=~&quot;5..&quot;}[5m])) / 
       sum(rate(http_requests_total[5m]))) &gt; 0.01
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: &quot;Error rate &gt; 1%&quot;
  
  - alert: HighLatency
    expr: |
      histogram_quantile(0.95,
        rate(http_request_duration_seconds_bucket[5m])
      ) &gt; 0.2
    for: 10m
    labels:
      severity: warning
    annotations:
      summary: &quot;P95 latency &gt; 200ms&quot;</code></pre>
<p>---</p>
<h2>Cost Optimization {#cost}</h2>
<h3>Right-Sizing</h3>
<pre><code class="language-bash"># Analyze resource usage
kubectl top pods -n production
<h1>Identify over-provisioned pods</h1>
requests &gt; 2x actual usage ‚Üí reduce
<h1>Use VPA (Vertical Pod Autoscaler)</h1>
kubectl apply -f vpa.yaml</code></pre>
<h3>Spot Instances</h3>
<pre><code class="language-yaml"># EKS Node Group with Spot
apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig
nodeGroups:
  - name: spot-workers
    instancesDistribution:
      instanceTypes:
      - t3.medium
      - t3a.medium
      onDemandBaseCapacity: 2
      onDemandPercentageAboveBaseCapacity: 0
      spotInstancePools: 2</code></pre>
<h3>Storage Optimization</h3>
<pre><code class="language-bash"># Delete unused PVCs
kubectl delete pvc unused-pvc
<h1>Use storage classes with reclaim policy</h1>
kind: StorageClass
reclaimPolicy: Delete  # Auto-delete when PVC deleted</code></pre>
<p>---</p>
<h2>Interview Questions {#interview-questions}</h2>
<strong>Q1: Explain blue-green vs canary deployment.</strong>
<strong>A:</strong>
<li><strong>Blue-Green</strong>: Two identical environments, instant switch, easy rollback</li>
  - Good for: Major releases, database migrations
  - Downside: 2x infrastructure cost during deployment
  
<li><strong>Canary</strong>: Gradual traffic shift (10% ‚Üí 50% ‚Üí 100%)</li>
  - Good for: Incremental risk, A/B testing
  - Downside: Longer deployment time, complex rollback
<strong>Q2: How do you achieve zero-downtime deployment?</strong>
<strong>A:</strong>
1. Rolling update with <code>maxUnavailable: 0</code>
2. Readiness probes (don't send traffic until ready)
3. Graceful shutdown (handle SIGTERM)
4. PodDisruptionBudget (min available pods)
5. Health checks (liveness + readiness)
<strong>Q3: What is an error budget?</strong>
<strong>A:</strong> Acceptable amount of downtime/errors before breaching SLO.
<li>SLO = 99.9% ‚Üí 0.1% error budget</li>
<li>Consumed by: outages, bugs, deployments</li>
<li>When depleted: freeze releases, focus on reliability</li>
<strong>Q4: How do you secure secrets in Kubernetes?</strong>
<strong>A:</strong>
1. <strong>Never in Git</strong>: Use external secret managers (Vault, AWS Secrets Manager)
2. <strong>Encrypt at rest</strong>: Enable encryption in etcd
3. <strong>RBAC</strong>: Limit access to secrets
4. <strong>Rotation</strong>: Regularly rotate credentials
5. <strong>Tools</strong>: Sealed Secrets, External Secrets Operator
<strong>Q5: What's the difference between horizontal and vertical scaling?</strong>
<strong>A:</strong>
<li><strong>Horizontal</strong>: Add more pods (HPA) - preferred for stateless apps</li>
<li><strong>Vertical</strong>: Increase pod resources (VPA) - for stateful/legacy apps</li>
<li><strong>Cluster</strong>: Add more nodes (Cluster Autoscaler)</li>
<p>---</p>
<h2>Summary</h2>
<p>You've learned:
<li>‚úÖ Deployment strategies: blue-green, canary, rolling</li>
<li>‚úÖ High availability with multi-AZ and PDBs</li>
<li>‚úÖ Security: RBAC, network policies, pod security</li>
<li>‚úÖ Disaster recovery: backups, RTO/RPO</li>
<li>‚úÖ Performance: HPA, caching, database optimization</li>
<li>‚úÖ Monitoring: SLIs/SLOs/SLAs, error budgets</li>
<li>‚úÖ Cost optimization: right-sizing, spot instances</li></ul></p>
<strong>Next Module</strong>: [Module 31: System Design Interview](31_System_Design_Interview.md) - Master system design problems for interviews.

    </div>
    

    <div class="module-content" id="module-31">
        <h1>Module 31: System Design Interview</h1>
<h2>Table of Contents</h2>
<ul><li>[Interview Framework](#framework)</li>
<li>[Design Fundamentals](#fundamentals)</li>
<li>[Case Study: URL Shortener](#url-shortener)</li>
<li>[Case Study: Rate Limiter](#rate-limiter)</li>
<li>[Case Study: Chat System](#chat-system)</li>
<li>[Case Study: News Feed](#news-feed)</li>
<li>[Case Study: Video Streaming](#video-streaming)</li>
<li>[Common Patterns](#patterns)</li>
<li>[Evaluation Criteria](#evaluation)</li>
<p>---</p>
<h2>Interview Framework {#framework}</h2>
<h3>4-Step Process</h3>
<strong>1. Understand Requirements (5-10 min)</strong>
<li>Functional requirements (features)</li>
<li>Non-functional requirements (scale, performance)</li>
<li>Constraints and assumptions</li>
<strong>2. High-Level Design (10-15 min)</strong>
<li>API design</li>
<li>Database schema</li>
<li>System architecture diagram</li>
<strong>3. Deep Dive (15-20 min)</strong>
<li>Bottlenecks and scaling</li>
<li>Data partitioning</li>
<li>Caching strategy</li>
<li>Trade-offs</li>
<strong>4. Wrap-Up (5 min)</strong>
<li>Monitoring and metrics</li>
<li>Next steps and improvements</li>
<h3>Key Questions to Ask</h3>
<pre><code class="language-text">Functional:
<li>What features are critical? (MVP vs nice-to-have)</li>
<li>Who are the users? (internal, external, global)</li>
<li>What&#039;s the user flow?</li>
<p>Scale:
<li>How many users? (DAU, MAU)</li>
<li>Read/write ratio?</li>
<li>Data size and growth rate?</li></p>
<p>Performance:
<li>Latency requirements? (real-time, near-real-time, eventual)</li>
<li>Availability requirements? (99.9%, 99.99%)</li>
<li>Consistency vs availability trade-off?</code></pre></li></p>
<p>---</p>
<h2>Design Fundamentals {#fundamentals}</h2>
<h3>Capacity Estimation</h3>
<pre><code class="language-text">Example: Twitter-like system
------------------------------
Users: 300M MAU (Monthly Active Users)
DAU: 100M (33% of MAU)
Tweets per user per day: 2
Total tweets per day: 200M
<p>Write QPS: 200M / 86400 = 2,300 writes/sec
Read QPS: Assume 10x reads = 23,000 reads/sec</p>
<p>Peak QPS (3x average): 7,000 writes/sec, 70,000 reads/sec</p>
<p>Storage:
<li>Tweet size: 280 chars √ó 2 bytes = 560 bytes</li>
<li>Media: 20% have media, avg 1MB</li>
<li>Daily storage: 200M √ó 560 bytes + 40M √ó 1MB = 40TB/day</li>
<li>Annual: 40TB √ó 365 = 14.6PB/year</code></pre></li></p>
<h3>Database Choices</h3>
<p>| Type | Use Case | Examples |
|------|----------|----------|
| <strong>Relational</strong> | ACID, complex queries | PostgreSQL, MySQL |
| <strong>Document</strong> | Flexible schema, nested data | MongoDB, DynamoDB |
| <strong>Key-Value</strong> | Simple lookups, caching | Redis, Memcached |
| <strong>Column</strong> | Analytics, time-series | Cassandra, HBase |
| <strong>Graph</strong> | Social networks, relationships | Neo4j |
| <strong>Search</strong> | Full-text search | Elasticsearch |</p>
<h3>CAP Theorem</h3>
<pre><code class="language-text">Consistency: All nodes see same data
Availability: Every request gets response
Partition Tolerance: System works despite network failures
<p>Pick 2:
<li>CP: Consistent + Partition-tolerant (MongoDB, HBase)</li>
<li>AP: Available + Partition-tolerant (Cassandra, DynamoDB)</li>
<li>CA: Impossible in distributed systems</code></pre></li></p>
<p>---</p>
<h2>Case Study: URL Shortener {#url-shortener}</h2>
<h3>Requirements</h3>
<strong>Functional:</strong>
<li>Shorten URL: <code>https://example.com/very/long/url</code> ‚Üí <code>https://short.ly/abc123</code></li>
<li>Redirect: GET <code>https://short.ly/abc123</code> ‚Üí redirect to original</li>
<li>Custom aliases (optional)</li>
<li>Expiration (optional)</li>
<strong>Non-Functional:</strong>
<li>100M URLs shortened/month</li>
<li>Read-heavy (100:1 read:write ratio)</li>
<li>Low latency (<50ms)</li>
<li>99.9% availability</li>
<h3>API Design</h3>
<pre><code class="language-text">POST /api/shorten
Request:  {&quot;url&quot;: &quot;https://example.com/long&quot;}
Response: {&quot;short_url&quot;: &quot;https://short.ly/abc123&quot;}
<p>GET /{shortCode}
Response: 302 Redirect to original URL</p>
<p>GET /api/stats/{shortCode}
Response: {&quot;clicks&quot;: 1234, &quot;created&quot;: &quot;2024-12-10&quot;}</code></pre></p>
<h3>Database Schema</h3>
<pre><code class="language-sql">CREATE TABLE urls (
  id BIGSERIAL PRIMARY KEY,
  short_code VARCHAR(10) UNIQUE NOT NULL,
  original_url TEXT NOT NULL,
  user_id BIGINT,
  created_at TIMESTAMP DEFAULT NOW(),
  expires_at TIMESTAMP,
  clicks BIGINT DEFAULT 0
);
<p>CREATE INDEX idx_short_code ON urls(short_code);
CREATE INDEX idx_user_id ON urls(user_id);</code></pre></p>
<h3>URL Encoding</h3>
<pre><code class="language-go">// Base62 encoding (62 chars: a-z, A-Z, 0-9)
const base62 = &quot;abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789&quot;
<p>func encode(num uint64) string {
    if num == 0 {
        return string(base62[0])
    }
    
    var encoded strings.Builder
    for num &gt; 0 {
        encoded.WriteByte(base62[num%62])
        num /= 62
    }
    
    // Reverse string
    runes := []rune(encoded.String())
    for i, j := 0, len(runes)-1; i &lt; j; i, j = i+1, j-1 {
        runes[i], runes[j] = runes[j], runes[i]
    }
    
    return string(runes)
}</p>
<p>// Example: ID 125 ‚Üí &quot;b9&quot; (7 chars = 62^7 = 3.5 trillion URLs)</code></pre></p>
<h3>Architecture</h3>
<pre><code class="language-text">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Client  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ
     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Load Balancer‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ        ‚îÇ App Server‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ Database ‚îÇ
       ‚îÇ        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ (Primary)‚îÇ
       ‚îÇ                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇ  Redis   ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ Database ‚îÇ
                ‚îÇ  Cache   ‚îÇ      ‚îÇ (Replica)‚îÇ
                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</code></pre>
<h3>Scaling</h3>
<strong>Sharding:</strong>
<pre><code class="language-text">Shard by short_code hash:
<li>Shard 0: a-m</li>
<li>Shard 1: n-z</li>
<p>Or range-based:
<li>Shard 0: ID 0-1B</li>
<li>Shard 1: ID 1B-2B</code></pre></li></p>
<strong>Caching:</strong>
<pre><code class="language-text">Cache popular URLs (80/20 rule)
<li>TTL: 24 hours</li>
<li>Eviction: LRU</li>
<li>Cache size: 1M URLs √ó 1KB = 1GB</code></pre></li>
<p>---</p>
<h2>Case Study: Rate Limiter {#rate-limiter}</h2>
<h3>Requirements</h3>
<strong>Functional:</strong>
<li>Limit requests per user/IP</li>
<li>Configurable rules (10 req/sec, 100 req/min)</li>
<li>Return HTTP 429 when exceeded</li>
<strong>Non-Functional:</strong>
<li>Low latency (<1ms)</li>
<li>Distributed (multiple servers)</li>
<li>Accurate (no over-counting)</li>
<h3>Algorithms</h3>
<strong>1. Token Bucket</strong>
<pre><code class="language-go">type TokenBucket struct {
    capacity int
    tokens   int
    refillRate int  // tokens per second
    lastRefill time.Time
}
<p>func (tb *TokenBucket) Allow() bool {
    tb.refill()
    if tb.tokens &gt; 0 {
        tb.tokens--
        return true
    }
    return false
}</p>
<p>func (tb *TokenBucket) refill() {
    now := time.Now()
    elapsed := now.Sub(tb.lastRefill).Seconds()
    tokensToAdd := int(elapsed * float64(tb.refillRate))
    tb.tokens = min(tb.capacity, tb.tokens + tokensToAdd)
    tb.lastRefill = now
}</code></pre></p>
<strong>2. Sliding Window (Redis)</strong>
<pre><code class="language-lua">-- Redis Lua script
local key = KEYS[1]
local limit = tonumber(ARGV[1])
local window = tonumber(ARGV[2])
local now = tonumber(ARGV[3])
<p>redis.call(&#039;ZREMRANGEBYSCORE&#039;, key, 0, now - window)
local count = redis.call(&#039;ZCARD&#039;, key)</p>
<p>if count &lt; limit then
    redis.call(&#039;ZADD&#039;, key, now, now)
    redis.call(&#039;EXPIRE&#039;, key, window)
    return 1
else
    return 0
end</code></pre></p>
<pre><code class="language-go">func isAllowed(userID string) bool {
    script := <code>... (Lua script above)</code>
    result := redisClient.Eval(ctx, script, []string{&quot;ratelimit:&quot; + userID}, 10, 60, time.Now().Unix())
    return result.Val().(int64) == 1
}</code></pre>
<h3>Architecture</h3>
<pre><code class="language-text">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Client ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇAPI Gateway‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ Service ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇRate Limiter ‚îÇ
              ‚îÇ   (Redis)   ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</code></pre>
<p>---</p>
<h2>Case Study: Chat System {#chat-system}</h2>
<h3>Requirements</h3>
<strong>Functional:</strong>
<li>1-on-1 chat</li>
<li>Group chat</li>
<li>Online status</li>
<li>Message history</li>
<li>Read receipts</li>
<strong>Non-Functional:</strong>
<li>50M DAU</li>
<li>Real-time delivery (<100ms)</li>
<li>Message persistence</li>
<h3>Architecture</h3>
<pre><code class="language-text">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  WebSocket  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Client ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ Chat Server ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                      ‚îÇ               ‚îÇ
                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇ  Redis   ‚îÇ   ‚îÇ  Kafka     ‚îÇ
                ‚îÇ (Presence)   ‚îÇ (Messages) ‚îÇ
                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                     ‚îÇ
                              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                              ‚îÇ PostgreSQL ‚îÇ
                              ‚îÇ (History)  ‚îÇ
                              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</code></pre>
<h3>Database Schema</h3>
<pre><code class="language-sql">CREATE TABLE users (
  id BIGSERIAL PRIMARY KEY,
  username VARCHAR(50) UNIQUE,
  created_at TIMESTAMP
);
<p>CREATE TABLE conversations (
  id BIGSERIAL PRIMARY KEY,
  type VARCHAR(10), -- &#039;direct&#039; or &#039;group&#039;
  created_at TIMESTAMP
);</p>
<p>CREATE TABLE participants (
  conversation_id BIGINT REFERENCES conversations(id),
  user_id BIGINT REFERENCES users(id),
  joined_at TIMESTAMP,
  PRIMARY KEY (conversation_id, user_id)
);</p>
<p>CREATE TABLE messages (
  id BIGSERIAL PRIMARY KEY,
  conversation_id BIGINT REFERENCES conversations(id),
  sender_id BIGINT REFERENCES users(id),
  content TEXT,
  created_at TIMESTAMP
);</p>
<p>CREATE INDEX idx_messages_conversation ON messages(conversation_id, created_at DESC);</code></pre></p>
<h3>WebSocket Connection Management</h3>
<pre><code class="language-go">type ChatServer struct {
    clients map[string]*Client  // userID -&gt; Client
    mu      sync.RWMutex
}
<p>func (s *ChatServer) HandleConnection(userID string, conn *websocket.Conn) {
    client := &amp;Client{UserID: userID, Conn: conn}
    
    s.mu.Lock()
    s.clients[userID] = client
    s.mu.Unlock()
    
    // Mark online in Redis
    redisClient.Set(ctx, &quot;online:&quot;+userID, &quot;1&quot;, 5*time.Minute)
    
    // Listen for messages
    for {
        var msg Message
        if err := conn.ReadJSON(&amp;msg); err != nil {
            break
        }
        s.handleMessage(client, msg)
    }
    
    // Cleanup
    s.mu.Lock()
    delete(s.clients, userID)
    s.mu.Unlock()
    redisClient.Del(ctx, &quot;online:&quot;+userID)
}</p>
<p>func (s *ChatServer) sendMessage(recipientID string, msg Message) {
    s.mu.RLock()
    client, online := s.clients[recipientID]
    s.mu.RUnlock()
    
    if online {
        client.Conn.WriteJSON(msg)
    } else {
        // Store for later delivery
        kafka.Produce(&quot;pending_messages&quot;, msg)
    }
}</code></pre></p>
<p>---</p>
<h2>Case Study: News Feed {#news-feed}</h2>
<h3>Requirements</h3>
<strong>Functional:</strong>
<li>User posts (text, images)</li>
<li>Follow users</li>
<li>Home feed (posts from followed users)</li>
<li>Ranking algorithm</li>
<strong>Non-Functional:</strong>
<li>500M users, 100M DAU</li>
<li>Feed load <500ms</li>
<li>Post delivery <5 sec</li>
<h3>Feed Generation Strategies</h3>
<strong>1. Fanout on Write (Push)</strong>
<pre><code class="language-text">User posts ‚Üí Write to all followers&#039; feeds
<p>Pros: Fast read
Cons: Slow write for celebrities (1M followers)</code></pre></p>
<strong>2. Fanout on Read (Pull)</strong>
<pre><code class="language-text">User opens feed ‚Üí Fetch from all followed users
<p>Pros: Fast write
Cons: Slow read (N queries)</code></pre></p>
<strong>3. Hybrid</strong>
<pre><code class="language-text">Normal users: Fanout on write
Celebrities: Fanout on read
Cache recent posts</code></pre>
<h3>Database Schema</h3>
<pre><code class="language-sql">CREATE TABLE users (
  id BIGSERIAL PRIMARY KEY,
  username VARCHAR(50)
);
<p>CREATE TABLE follows (
  follower_id BIGINT REFERENCES users(id),
  followee_id BIGINT REFERENCES users(id),
  created_at TIMESTAMP,
  PRIMARY KEY (follower_id, followee_id)
);</p>
<p>CREATE TABLE posts (
  id BIGSERIAL PRIMARY KEY,
  user_id BIGINT REFERENCES users(id),
  content TEXT,
  created_at TIMESTAMP
);</p>
<p>-- Feed cache (fanout on write)
CREATE TABLE feeds (
  user_id BIGINT,
  post_id BIGINT,
  created_at TIMESTAMP,
  PRIMARY KEY (user_id, post_id)
);</p>
<p>CREATE INDEX idx_feeds_user_time ON feeds(user_id, created_at DESC);</code></pre></p>
<h3>Feed Generation</h3>
<pre><code class="language-go">// Fanout on write
func createPost(userID int64, content string) {
    // Save post
    postID := db.Insert(&quot;posts&quot;, Post{UserID: userID, Content: content})
    
    // Get followers
    followers := db.Query(&quot;SELECT follower_id FROM follows WHERE followee_id = ?&quot;, userID)
    
    // Write to each follower&#039;s feed (async)
    for _, followerID := range followers {
        kafkaProducer.Send(&quot;feed_updates&quot;, FeedUpdate{
            UserID: followerID,
            PostID: postID,
        })
    }
}
<p>// Fanout on read
func getFeed(userID int64) []Post {
    // Get followed users
    followees := db.Query(&quot;SELECT followee_id FROM follows WHERE follower_id = ?&quot;, userID)
    
    // Fetch recent posts
    posts := []Post{}
    for _, followeeID := range followees {
        posts = append(posts, db.Query(&quot;SELECT * FROM posts WHERE user_id = ? ORDER BY created_at DESC LIMIT 10&quot;, followeeID)...)
    }
    
    // Sort by timestamp
    sort.Slice(posts, func(i, j int) bool {
        return posts[i].CreatedAt.After(posts[j].CreatedAt)
    })
    
    return posts[:20]
}</code></pre></p>
<p>---</p>
<h2>Case Study: Video Streaming {#video-streaming}</h2>
<h3>Requirements</h3>
<strong>Functional:</strong>
<li>Upload videos</li>
<li>Transcode to multiple resolutions</li>
<li>Adaptive bitrate streaming</li>
<li>Recommendations</li>
<strong>Non-Functional:</strong>
<li>1B videos</li>
<li>10M concurrent viewers</li>
<li>99.99% availability</li>
<h3>Architecture</h3>
<pre><code class="language-text">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   Upload   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   Store   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Client ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇAPI Server ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  S3  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                      Trigger‚îÇ
                            ‚ñº
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ Transcode  ‚îÇ FFmpeg
                    ‚îÇ   Queue    ‚îÇ (Lambda)
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
                      Store‚îÇ
                           ‚ñº
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ     CDN     ‚îÇ
                    ‚îÇ (CloudFront)‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
                     Stream‚îÇ
                           ‚ñº
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   Client   ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</code></pre>
<h3>Transcoding</h3>
<pre><code class="language-yaml"># Resolutions
<li>4K: 3840x2160, 15 Mbps</li>
<li>1080p: 1920x1080, 5 Mbps</li>
<li>720p: 1280x720, 2.5 Mbps</li>
<li>480p: 854x480, 1 Mbps</li>
<li>360p: 640x360, 0.5 Mbps</li>
<h1>HLS (HTTP Live Streaming)</h1>
video.m3u8 (playlist)
‚îú‚îÄ‚îÄ video_4k.m3u8
‚îú‚îÄ‚îÄ video_1080p.m3u8
‚îú‚îÄ‚îÄ video_720p.m3u8
‚îî‚îÄ‚îÄ video_480p.m3u8</code></pre>
<h3>CDN Caching</h3>
<pre><code class="language-text">Origin (S3) ‚Üí Edge Locations (CloudFront) ‚Üí Users
<p>Cache-Control: max-age=31536000 (1 year for videos)
Cache hit ratio: &gt;90%</code></pre></p>
<p>---</p>
<h2>Common Patterns {#patterns}</h2>
<h3>Caching Strategy</h3>
<pre><code class="language-text">Cache-Aside:
1. Check cache
2. If miss, query DB
3. Write to cache
4. Return data
<p>Write-Through:
1. Write to cache
2. Write to DB
3. Return success</p>
<p>Write-Behind:
1. Write to cache
2. Async write to DB
3. Return success (faster)</code></pre></p>
<h3>Database Sharding</h3>
<pre><code class="language-text">Hash-based: shard = hash(userID) % num_shards
Range-based: shard = userID / 1000000
Geography-based: shard = user.country</code></pre>
<h3>Load Balancing</h3>
<pre><code class="language-text">Round Robin: Distribute evenly
Least Connections: Send to least busy
IP Hash: Consistent routing
Weighted: Based on capacity</code></pre>
<p>---</p>
<h2>Evaluation Criteria {#evaluation}</h2>
<p>Interviewers assess:</p>
<p>‚úÖ <strong>Problem Solving</strong>: Clarify requirements, ask questions
‚úÖ <strong>Communication</strong>: Explain decisions clearly
‚úÖ <strong>System Thinking</strong>: Consider trade-offs
‚úÖ <strong>Scalability</strong>: Handle growth
‚úÖ <strong>Practical Knowledge</strong>: Real-world technologies
‚úÖ <strong>Trade-offs</strong>: No perfect solution, justify choices</p>
<strong>Common Mistakes:</strong>
‚ùå Jump to solution without clarifying
‚ùå Over-engineer for small scale
‚ùå Ignore non-functional requirements
‚ùå Not considering failures
‚ùå Vague hand-waving
<p>---</p>
<h2>Summary</h2>
<p>You've learned:
<li>‚úÖ 4-step interview framework</li>
<li>‚úÖ Capacity estimation and scaling math</li>
<li>‚úÖ 5 detailed case studies with solutions</li>
<li>‚úÖ Common design patterns</li>
<li>‚úÖ Evaluation criteria and mistakes to avoid</li></ul></p>
<strong>Next Module</strong>: [Module 32: Backend Interview Prep](32_Backend_Interview_Prep.md) - Technical coding and conceptual questions.

    </div>
    

    <div class="module-content" id="module-32">
        <h1>Module 32: Backend Interview Preparation</h1>
<h2>Table of Contents</h2>
<ul><li>[Go Programming Questions](#go-questions)</li>
<li>[Databases & SQL](#database-questions)</li>
<li>[System Design Quickfire](#system-design)</li>
<li>[Kubernetes & DevOps](#kubernetes-questions)</li>
<li>[Microservices & Architecture](#architecture-questions)</li>
<li>[Behavioral Questions](#behavioral)</li>
<li>[Coding Challenges](#coding)</li>
<li>[Interview Tips](#tips)</li>
<p>---</p>
<h2>Go Programming Questions {#go-questions}</h2>
<h3>Q1: What is the difference between a goroutine and a thread?</h3>
<strong>A:</strong> 
<li><strong>Goroutines</strong>: Lightweight (2KB stack), managed by Go runtime, multiplexed onto OS threads</li>
<li><strong>Threads</strong>: Heavyweight (1MB+ stack), managed by OS, 1:1 with OS threads</li>
<li><strong>M:N model</strong>: M goroutines run on N OS threads via scheduler</li>
<h3>Q2: Explain channels and when to use buffered vs unbuffered.</h3>
<strong>A:</strong>
<pre><code class="language-go">// Unbuffered: Synchronous, sender blocks until receiver ready
ch := make(chan int)
ch &lt;- 42  // Blocks until someone receives
<p>// Buffered: Asynchronous up to capacity
ch := make(chan int, 3)
ch &lt;- 1  // Doesn&#039;t block
ch &lt;- 2  // Doesn&#039;t block
ch &lt;- 3  // Doesn&#039;t block
ch &lt;- 4  // Blocks (buffer full)</code></pre></p>
<strong>Use unbuffered</strong> for synchronization, <strong>buffered</strong> for throughput.
<h3>Q3: How does defer work?</h3>
<strong>A:</strong>
<pre><code class="language-go">func example() {
    defer fmt.Println(&quot;3&quot;)  // Last in, first out (LIFO)
    defer fmt.Println(&quot;2&quot;)
    fmt.Println(&quot;1&quot;)
}
// Output: 1, 2, 3
<p>// Common use: cleanup
func readFile() error {
    f, err := os.Open(&quot;file.txt&quot;)
    if err != nil {
        return err
    }
    defer f.Close()  // Guaranteed to run
    
    // Use file...
    return nil
}</code></pre></p>
<h3>Q4: What are interfaces and how do they enable polymorphism?</h3>
<strong>A:</strong>
<pre><code class="language-go">type Reader interface {
    Read(p []byte) (n int, err error)
}
<p>// Any type with Read() satisfies Reader (implicit implementation)
type File struct {}
func (f File) Read(p []byte) (int, error) { ... }</p>
<p>type Network struct {}
func (n Network) Read(p []byte) (int, error) { ... }</p>
<p>// Polymorphic function
func processData(r Reader) {
    r.Read(...)  // Works with File, Network, or any Reader
}</code></pre></p>
<h3>Q5: Explain context.Context and its use cases.</h3>
<strong>A:</strong>
<pre><code class="language-go">// Cancellation
ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
defer cancel()
<p>resp, err := http.Get Ctx(ctx, &quot;https://api.example.com&quot;)
// Request canceled after 5 seconds</p>
<p>// Passing request-scoped values
ctx = context.WithValue(ctx, &quot;userID&quot;, &quot;12345&quot;)
userID := ctx.Value(&quot;userID&quot;).(string)</p>
<p>// Propagation across goroutines
go processRequest(ctx)  // Inherits cancellation</code></pre></p>
<strong>Use cases</strong>: Timeouts, cancellation, request-scoped data (trace IDs, auth)
<h3>Q6: What causes goroutine leaks and how to prevent them?</h3>
<strong>A:</strong>
<pre><code class="language-go">// ‚ùå Leak: goroutine blocked forever
func leak() {
    ch := make(chan int)
    go func() {
        val := &lt;-ch  // Blocks forever, no sender
        fmt.Println(val)
    }()
}
<p>// ‚úÖ Fix: Use context for cancellation
func fixed() {
    ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
    defer cancel()
    
    ch := make(chan int)
    go func() {
        select {
        case val := &lt;-ch:
            fmt.Println(val)
        case &lt;-ctx.Done():
            return  // Exit on timeout
        }
    }()
}</code></pre></p>
<p>---</p>
<h2>Databases & SQL {#database-questions}</h2>
<h3>Q7: Explain ACID properties.</h3>
<strong>A:</strong>
<li><strong>Atomicity</strong>: All or nothing (transaction succeeds or rolls back)</li>
<li><strong>Consistency</strong>: Data satisfies constraints (foreign keys, unique)</li>
<li><strong>Isolation</strong>: Transactions don't interfere (serializable levels)</li>
<li><strong>Durability</strong>: Committed data persists (survives crashes)</li>
<h3>Q8: What are isolation levels and their trade-offs?</h3>
<strong>A:</strong>
<pre><code class="language-sql">-- Read Uncommitted: Dirty reads possible
SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;
<p>-- Read Committed: No dirty reads, but non-repeatable reads
SET TRANSACTION ISOLATION LEVEL READ COMMITTED;</p>
<p>-- Repeatable Read: Consistent reads, but phantom reads
SET TRANSACTION ISOLATION LEVEL REPEATABLE READ;</p>
<p>-- Serializable: Full isolation, slowest
SET TRANSACTION ISOLATION LEVEL SERIALIZABLE;</code></pre></p>
<p>| Level | Dirty Read | Non-Repeatable | Phantom | Performance |
|-------|------------|----------------|---------|-------------|
| Read Uncommitted | Yes | Yes | Yes | Fastest |
| Read Committed | No | Yes | Yes | Fast |
| Repeatable Read | No | No | Yes | Slow |
| Serializable | No | No | No | Slowest |</p>
<h3>Q9: How do indexes work and when to use them?</h3>
<strong>A:</strong>
<pre><code class="language-sql">-- B-Tree index (default, most common)
CREATE INDEX idx_users_email ON users(email);
<p>-- Composite index (order matters)
CREATE INDEX idx_orders_user_date ON orders(user_id, created_at);
-- Good for: WHERE user_id = ? AND created_at &gt; ?
-- Bad for: WHERE created_at &gt; ? (doesn&#039;t use index)</p>
<p>-- Partial index
CREATE INDEX idx_active_users ON users(email) WHERE status = &#039;active&#039;;</p>
<p>-- When to use:
-- ‚úÖ Columns in WHERE, JOIN, ORDER BY
-- ‚úÖ Foreign keys
-- ‚ùå Small tables (&lt;1000 rows)
-- ‚ùå Frequently updated columns (index maintenance overhead)</code></pre></p>
<h3>Q10: Explain database normalization.</h3>
<strong>A:</strong>
<pre><code class="language-text">1NF: Atomic values, no repeating groups
2NF: 1NF + no partial dependencies
3NF: 2NF + no transitive dependencies
<p>Example:
‚ùå Denormalized:
orders: id, user_name, user_email, product_name, quantity
(user data repeated for each order)</p>
<p>‚úÖ Normalized:
users: id, name, email
products: id, name
orders: id, user_id, product_id, quantity</code></pre></p>
<strong>Trade-off</strong>: Normalized = less redundancy, slower reads. Denormalized = faster reads, more storage.
<h3>Q11: How do you optimize slow queries?</h3>
<strong>A:</strong>
1. <strong>EXPLAIN ANALYZE</strong>: Identify bottleneck
<pre><code class="language-sql">EXPLAIN ANALYZE
SELECT * FROM orders WHERE user_id = 123;
-- Look for: Seq Scan (bad), Index Scan (good)</code></pre>
<p>2. <strong>Add indexes</strong>: On WHERE/JOIN columns
3. <strong>Avoid SELECT \</strong>*: Fetch only needed columns
4. <strong>Limit results</strong>: Use LIMIT and pagination
5. <strong>Denormalize</strong>: For read-heavy workloads
6. <strong>Use caching</strong>: Redis for frequent queries
7. <strong>Connection pooling</strong>: Reuse connections</p>
<p>---</p>
<h2>System Design Quickfire {#system-design}</h2>
<h3>Q12: How would you design a URL shortener?</h3>
<strong>A:</strong>
<pre><code class="language-text">API: POST /shorten ‚Üí short URL, GET /{code} ‚Üí redirect
Database: short_code (indexed), original_url, created_at
Encoding: Base62 of auto-incrementing ID
Scaling: Read replicas, Redis cache for popular URLs
Sharding: Hash(short_code) % num_shards</code></pre>
<h3>Q13: How do you handle millions of concurrent WebSocket connections?</h3>
<strong>A:</strong>
<pre><code class="language-text">Architecture:
<li>Multiple WebSocket servers (horizontal scaling)</li>
<li>Redis Pub/Sub for cross-server messaging</li>
<li>Consistent hashing for user‚Üíserver routing</li>
<li>Load balancer with sticky sessions</li>
<li>Connection pooling to database</li>
<p>Scaling:
<li>1 server ‚âà 10K connections (1GB RAM)</li>
<li>100 servers = 1M connections</li>
<li>Use C10K problem solutions (epoll, kqueue)</code></pre></li></p>
<h3>Q14: How would you implement rate limiting?</h3>
<strong>A:</strong>
<pre><code class="language-text">Algorithm: Token bucket or sliding window
Storage: Redis (fast, distributed)
Key: user_id or IP address
Lua script for atomic operations
<p>Rate limit headers:
X-RateLimit-Limit: 100
X-RateLimit-Remaining: 45
X-RateLimit-Reset: 1638360000</code></pre></p>
<h3>Q15: How do you ensure idempotency in distributed systems?</h3>
<strong>A:</strong>
<pre><code class="language-go">// Idempotency key in request
type PaymentRequest struct {
    IdempotencyKey string  // UUID
    Amount         float64
}
<p>func processPayment(req PaymentRequest) error {
    // Check if already processed
    if result := redis.Get(&quot;payment:&quot; + req.IdempotencyKey); result != nil {
        return result  // Return cached result
    }
    
    // Process payment
    result := chargeCard(req.Amount)
    
    // Cache result (24 hours)
    redis.Set(&quot;payment:&quot; + req.IdempotencyKey, result, 24*time.Hour)
    
    return result
}</code></pre></p>
<p>---</p>
<h2>Kubernetes & DevOps {#kubernetes-questions}</h2>
<h3>Q16: Explain Kubernetes architecture.</h3>
<strong>A:</strong>
<pre><code class="language-text">Control Plane:
<li>API Server: Entry point for all operations</li>
<li>etcd: Distributed key-value store (cluster state)</li>
<li>Scheduler: Assigns pods to nodes</li>
<li>Controller Manager: Maintains desired state</li>
<p>Node:
<li>Kubelet: Runs containers, reports to API server</li>
<li>Kube-proxy: Network routing, load balancing</li>
<li>Container Runtime: Docker, containerd</code></pre></li></p>
<h3>Q17: What's the difference between Deployment, StatefulSet, and DaemonSet?</h3>
<strong>A:</strong>
<pre><code class="language-text">Deployment: Stateless apps, rolling updates, scaling
<li>Example: Web servers, API services</li>
<p>StatefulSet: Stateful apps, stable network IDs, persistent storage
<li>Example: Databases (Postgres, MongoDB), Kafka</li></p>
<p>DaemonSet: One pod per node
<li>Example: Log collectors (Fluentd), monitoring agents</code></pre></li></p>
<h3>Q18: How do you troubleshoot a crashing pod?</h3>
<strong>A:</strong>
<pre><code class="language-bash"># 1. Check pod status
kubectl get pods
kubectl describe pod myapp-pod
<h1>2. Check logs</h1>
kubectl logs myapp-pod
kubectl logs myapp-pod --previous  # Previous crashed container
<h1>3. Check events</h1>
kubectl get events --sort-by=&#039;.lastTimestamp&#039;
<h1>4. Exec into pod (if running)</h1>
kubectl exec -it myapp-pod -- /bin/sh
<h1>Common issues:</h1>
<h1>- OOMKilled: Increase memory limits</h1>
<h1>- CrashLoopBackOff: Application bug, check logs</h1>
<h1>- ImagePullBackOff: Wrong image name/tag</h1>
<h1>- Pending: Insufficient resources</code></pre></h1>
<p>---</p>
<h2>Microservices & Architecture {#architecture-questions}</h2>
<h3>Q19: What are the trade-offs of microservices vs monolith?</h3>
<strong>A:</strong>
<pre><code class="language-text">Microservices Pros:
‚úÖ Independent deployment
‚úÖ Technology flexibility
‚úÖ Team autonomy
‚úÖ Better fault isolation
<p>Microservices Cons:
‚ùå Complexity (distributed systems)
‚ùå Network latency
‚ùå Data consistency challenges
‚ùå Higher operational overhead</p>
<p>When to use:
<li>Microservices: Large teams, different tech stacks, need scalability</li>
<li>Monolith: Small teams, early stage, simple domain</code></pre></li></p>
<h3>Q20: Explain the Saga pattern for distributed transactions.</h3>
<strong>A:</strong>
<pre><code class="language-text">Problem: No ACID transactions across microservices
<p>Solution: Saga (sequence of local transactions + compensating actions)</p>
<p>Example: Order processing
1. Reserve inventory ‚Üí Success
2. Charge payment ‚Üí Success
3. Create shipment ‚Üí Failure
4. Compensate: Refund payment
5. Compensate: Release inventory</p>
<p>Implementation:
<li>Choreography: Event-driven (OrderCreated ‚Üí InventoryReserved ‚Üí PaymentCharged)</li>
<li>Orchestration: Central coordinator manages steps</code></pre></li></p>
<h3>Q21: How do you handle service discovery?</h3>
<strong>A:</strong>
<pre><code class="language-text">Client-side: Client queries service registry (Consul, etcd)
<li>Pros: No single point of failure</li>
<li>Cons: Logic in client</li>
<p>Server-side: Load balancer queries registry
<li>Pros: Simple clients</li>
<li>Cons: Extra hop</li></p>
<p>Kubernetes: DNS-based (service.namespace.svc.cluster.local)
<li>Automatic service discovery via CoreDNS</code></pre></li></p>
<p>---</p>
<h2>Behavioral Questions {#behavioral}</h2>
<h3>Q22: Tell me about a time you debugged a production issue.</h3>
<strong>Framework: STAR (Situation, Task, Action, Result)</strong>
<strong>Example:</strong>
<pre><code class="language-text">Situation: Production API latency spiked to 5 seconds
<p>Task: Identify root cause and fix within 1 hour (SLA)</p>
<p>Action:
1. Checked monitoring (Grafana): Database query time increased
2. Analyzed slow query logs: Missing index on orders.user_id
3. Created index: CREATE INDEX idx_orders_user ON orders(user_id)
4. Latency dropped to &lt;100ms</p>
<p>Result: 
<li>Resolved in 45 minutes</li>
<li>Added automated query performance tests</li>
<li>Documented indexing strategy for team</code></pre></li></p>
<h3>Q23: Describe a time you improved system performance.</h3>
<strong>Example:</strong>
<pre><code class="language-text">Situation: Dashboard loading 10 seconds with 10K users
<p>Action:
1. Profiled API: 90% time in database queries
2. Added Redis cache (TTL: 5 minutes)
3. Implemented pagination (limit 20)
4. Added database read replicas
5. Used connection pooling</p>
<p>Result:
<li>Load time: 10s ‚Üí 500ms (20x improvement)</li>
<li>Cache hit ratio: 85%</li>
<li>Handled 100K users without degradation</code></pre></li></p>
<p>---</p>
<h2>Coding Challenges {#coding}</h2>
<h3>Q24: Implement LRU Cache</h3>
<pre><code class="language-go">type LRUCache struct {
    capacity int
    cache    map[int]*Node
    head     *Node
    tail     *Node
}
<p>type Node struct {
    key, value int
    prev, next *Node
}</p>
<p>func Constructor(capacity int) LRUCache {
    cache := LRUCache{
        capacity: capacity,
        cache:    make(map[int]*Node),
        head:     &amp;Node{},
        tail:     &amp;Node{},
    }
    cache.head.next = cache.tail
    cache.tail.prev = cache.head
    return cache
}</p>
<p>func (c *LRUCache) Get(key int) int {
    if node, exists := c.cache[key]; exists {
        c.moveToHead(node)
        return node.value
    }
    return -1
}</p>
<p>func (c *LRUCache) Put(key, value int) {
    if node, exists := c.cache[key]; exists {
        node.value = value
        c.moveToHead(node)
    } else {
        node := &amp;Node{key: key, value: value}
        c.cache[key] = node
        c.addToHead(node)
        
        if len(c.cache) &gt; c.capacity {
            removed := c.removeTail()
            delete(c.cache, removed.key)
        }
    }
}</p>
<p>func (c *LRUCache) moveToHead(node *Node) {
    c.removeNode(node)
    c.addToHead(node)
}</p>
<p>func (c *LRUCache) removeNode(node *Node) {
    node.prev.next = node.next
    node.next.prev = node.prev
}</p>
<p>func (c *LRUCache) addToHead(node *Node) {
    node.next = c.head.next
    node.prev = c.head
    c.head.next.prev = node
    c.head.next = node
}</p>
<p>func (c *LRUCache) removeTail() *Node {
    node := c.tail.prev
    c.removeNode(node)
    return node
}</code></pre></p>
<h3>Q25: Implement API Rate Limiter</h3>
<pre><code class="language-go">type RateLimiter struct {
    requests map[string][]time.Time
    mu       sync.Mutex
    limit    int
    window   time.Duration
}
<p>func NewRateLimiter(limit int, window time.Duration) *RateLimiter {
    return &amp;RateLimiter{
        requests: make(map[string][]time.Time),
        limit:    limit,
        window:   window,
    }
}</p>
<p>func (rl *RateLimiter) Allow(userID string) bool {
    rl.mu.Lock()
    defer rl.mu.Unlock()
    
    now := time.Now()
    windowStart := now.Add(-rl.window)
    
    // Get user&#039;s requests
    timestamps := rl.requests[userID]
    
    // Remove old requests outside window
    valid := []time.Time{}
    for _, t := range timestamps {
        if t.After(windowStart) {
            valid = append(valid, t)
        }
    }
    
    // Check limit
    if len(valid) &gt;= rl.limit {
        return false
    }
    
    // Add current request
    valid = append(valid, now)
    rl.requests[userID] = valid
    
    return true
}</p>
<p>// Usage
limiter := NewRateLimiter(10, 1*time.Minute)  // 10 requests/minute
if limiter.Allow(&quot;user123&quot;) {
    // Process request
} else {
    // Return 429 Too Many Requests
}</code></pre></p>
<h3>Q26: Find Top K Frequent Elements</h3>
<pre><code class="language-go">func topKFrequent(nums []int, k int) []int {
    // Count frequencies
    freq := make(map[int]int)
    for _, num := range nums {
        freq[num]++
    }
    
    // Min heap of size k
    h := &amp;MinHeap{}
    heap.Init(h)
    
    for num, count := range freq {
        heap.Push(h, Element{num, count})
        if h.Len() &gt; k {
            heap.Pop(h)
        }
    }
    
    // Extract results
    result := make([]int, k)
    for i := k - 1; i &gt;= 0; i-- {
        result[i] = heap.Pop(h).(Element).value
    }
    
    return result
}
<p>type Element struct {
    value int
    freq  int
}</p>
<p>type MinHeap []Element</p>
<p>func (h MinHeap) Len() int           { return len(h) }
func (h MinHeap) Less(i, j int) bool { return h[i].freq &lt; h[j].freq }
func (h MinHeap) Swap(i, j int)      { h[i], h[j] = h[j], h[i] }
func (h *MinHeap) Push(x interface{}) { *h = append(*h, x.(Element)) }
func (h *MinHeap) Pop() interface{} {
    old := *h
    n := len(old)
    x := old[n-1]
    *h = old[0 : n-1]
    return x
}</code></pre></p>
<p>---</p>
<h2>Interview Tips {#tips}</h2>
<h3>Before the Interview</h3>
<p>‚úÖ <strong>Review fundamentals</strong>: Go, SQL, Kubernetes, system design
‚úÖ <strong>Practice coding</strong>: LeetCode medium problems (20-30)
‚úÖ <strong>Study the company</strong>: Tech stack, products, challenges
‚úÖ <strong>Prepare questions</strong>: Ask about team, projects, culture</p>
<h3>During the Interview</h3>
<p>‚úÖ <strong>Clarify requirements</strong>: Don't assume, ask questions
‚úÖ <strong>Think aloud</strong>: Explain your reasoning
‚úÖ <strong>Start simple</strong>: Basic solution first, then optimize
‚úÖ <strong>Consider edge cases</strong>: Empty input, large scale, failures
‚úÖ <strong>Discuss trade-offs</strong>: No perfect solution, explain choices</p>
<h3>Common Mistakes</h3>
<p>‚ùå <strong>Jumping to code</strong>: Plan first (5 min thinking > 30 min debugging)
‚ùå <strong>Ignoring hints</strong>: Interviewer is helping, listen carefully
‚ùå <strong>Not testing</strong>: Walk through examples, edge cases
‚ùå <strong>Over-engineering</strong>: Start with simple, working solution
‚ùå <strong>Giving up</strong>: Stuck? Ask for hints, think aloud</p>
<h3>Sample Questions to Ask</h3>
<pre><code class="language-text">Technical:
<li>&quot;What&#039;s your tech stack and why did you choose it?&quot;</li>
<li>&quot;How do you handle deployments and rollbacks?&quot;</li>
<li>&quot;What&#039;s your approach to monitoring and incident response?&quot;</li>
<p>Team:
<li>&quot;What does a typical day look like?&quot;</li>
<li>&quot;How is the team structured? (Backend, frontend, full-stack?)&quot;</li>
<li>&quot;How do you handle technical debt?&quot;</li></p>
<p>Growth:
<li>&quot;What opportunities are there for learning and growth?&quot;</li>
<li>&quot;How do you support career development?&quot;</li>
<li>&quot;What are the biggest challenges the team is facing?&quot;</code></pre></li></p>
<p>---</p>
<h2>Summary</h2>
<p>You've completed the comprehensive backend learning path! üéâ</p>
<strong>32 Modules Covered:</strong>
<li>‚úÖ Go Programming (5 modules)</li>
<li>‚úÖ Kubernetes (6 modules)</li>
<li>‚úÖ Infrastructure as Code (5 modules)</li>
<li>‚úÖ Microservices & Integration (4 modules)</li>
<li>‚úÖ AWS & Cloud Services (5 modules)</li>
<li>‚úÖ Observability (3 modules: Prometheus, Grafana, EFK)</li>
<li>‚úÖ Distributed Tracing (1 module)</li>
<li>‚úÖ Production Best Practices (1 module)</li>
<li>‚úÖ Interview Preparation (2 modules)</li>
<strong>Next Steps:</strong>
1. Build projects using learned technologies
2. Contribute to open-source Go/Kubernetes projects
3. Practice system design problems weekly
4. Set up a complete observability stack
5. Apply for backend engineering roles!
<strong>Resources:</strong>
<li>LeetCode: Practice coding challenges</li>
<li>System Design Primer: github.com/donnemartin/system-design-primer</li>
<li>Go by Example: gobyexample.com</li>
<li>Kubernetes Docs: kubernetes.io/docs</li>
<li>AWS Well-Architected: aws.amazon.com/architecture</li></ul>
<p>Good luck with your interviews! üöÄ</p>
    </div>
    
        </main>
    </div>

    <button class="scroll-top" id="scrollTop" onclick="scrollToTop()">‚Üë</button>

    <script>
        // Show first module by default
        document.addEventListener('DOMContentLoaded', () => {
            showModule('module-0');
        });

        function showModule(moduleId) {
            // Hide all modules
            document.querySelectorAll('.module-content').forEach(el => {
                el.classList.remove('active');
            });

            // Show selected module
            const selectedModule = document.getElementById(moduleId);
            if (selectedModule) {
                selectedModule.classList.add('active');
            }

            // Update nav active state
            document.querySelectorAll('.nav-item').forEach(el => {
                el.classList.remove('active');
            });
            
            const activeNav = document.querySelector(`a[href="#${moduleId}"]`);
            if (activeNav) {
                activeNav.classList.add('active');
            }

            // Scroll to top
            window.scrollTo({ top: 0, behavior: 'smooth' });
        }

        // Search functionality
        function searchModules() {
            const searchTerm = document.getElementById('searchInput').value.toLowerCase();
            const navItems = document.querySelectorAll('.nav-item');
            
            navItems.forEach(item => {
                const text = item.textContent.toLowerCase();
                if (text.includes(searchTerm)) {
                    item.style.display = 'block';
                } else {
                    item.style.display = 'none';
                }
            });
        }

        // Progress bar
        window.addEventListener('scroll', () => {
            const winScroll = document.body.scrollTop || document.documentElement.scrollTop;
            const height = document.documentElement.scrollHeight - document.documentElement.clientHeight;
            const scrolled = (winScroll / height) * 100;
            document.getElementById('progressBar').style.transform = `scaleX(${scrolled / 100})`;

            // Show/hide scroll to top button
            const scrollTop = document.getElementById('scrollTop');
            if (winScroll > 300) {
                scrollTop.classList.add('visible');
            } else {
                scrollTop.classList.remove('visible');
            }
        });

        function scrollToTop() {
            window.scrollTo({ top: 0, behavior: 'smooth' });
        }

        // Keyboard navigation
        document.addEventListener('keydown', (e) => {
            const modules = Array.from(document.querySelectorAll('.module-content'));
            const activeModule = document.querySelector('.module-content.active');
            const currentIndex = modules.indexOf(activeModule);

            if (e.key === 'ArrowRight' && currentIndex < modules.length - 1) {
                showModule(`module-${currentIndex + 1}`);
            } else if (e.key === 'ArrowLeft' && currentIndex > 0) {
                showModule(`module-${currentIndex - 1}`);
            }
        });
    </script>
</body>
</html>